<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2024-01-23">
<meta name="description" content="Good Old-Fashioned AI never die. They just fade away.">

<title>Eulogy to Logical AI – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-02dbcd97b8f3f8f7231673c1d5e4b7bf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-64d6e61f7496feb4de6eb78c8a3b8add.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Eulogy to Logical AI – Yuxi on the Wired">
<meta property="og:description" content="Good Old-Fashioned AI never die. They just fade away.">
<meta property="og:image" content="https://yuxi-liu-wired.github.io/essays/posts/logical-ai-eulogy/figure/Vauquois triangle.png">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta property="og:image:height" content="497">
<meta property="og:image:width" content="850">
<meta name="twitter:title" content="Eulogy to Logical AI – Yuxi on the Wired">
<meta name="twitter:description" content="Good Old-Fashioned AI never die. They just fade away.">
<meta name="twitter:image" content="https://yuxi-liu-wired.github.io/essays/posts/logical-ai-eulogy/figure/Vauquois triangle.png">
<meta name="twitter:image-height" content="497">
<meta name="twitter:image-width" content="850">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://bair.berkeley.edu/"> <i class="bi bi-folder-symlink" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi.liu.1995@gmail.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Eulogy to Logical AI</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Good Old-Fashioned AI never die. They just fade away.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">scaling</div>
                <div class="quarto-category">history</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 23, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 23, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#translation" id="toc-translation" class="nav-link active" data-scroll-target="#translation">Translation</a>
  <ul class="collapse">
  <li><a href="#georgetownibm-experiment" id="toc-georgetownibm-experiment" class="nav-link" data-scroll-target="#georgetownibm-experiment">Georgetown–IBM experiment</a></li>
  <li><a href="#natural-language-compiler" id="toc-natural-language-compiler" class="nav-link" data-scroll-target="#natural-language-compiler">Natural language compiler</a></li>
  <li><a href="#winter-comes" id="toc-winter-comes" class="nav-link" data-scroll-target="#winter-comes">Winter comes</a></li>
  <li><a href="#expert-systems" id="toc-expert-systems" class="nav-link" data-scroll-target="#expert-systems">Expert systems</a></li>
  <li><a href="#collapse" id="toc-collapse" class="nav-link" data-scroll-target="#collapse">Collapse</a></li>
  <li><a href="#the-bitter-lesson" id="toc-the-bitter-lesson" class="nav-link" data-scroll-target="#the-bitter-lesson">The Bitter Lesson</a></li>
  </ul></li>
  <li><a href="#vision" id="toc-vision" class="nav-link" data-scroll-target="#vision">Vision</a></li>
  <li><a href="#speech" id="toc-speech" class="nav-link" data-scroll-target="#speech">Speech</a></li>
  <li><a href="#games" id="toc-games" class="nav-link" data-scroll-target="#games">Games</a></li>
  <li><a href="#general" id="toc-general" class="nav-link" data-scroll-target="#general">General</a></li>
  <li><a href="#expert-systems-1" id="toc-expert-systems-1" class="nav-link" data-scroll-target="#expert-systems-1">Expert systems</a></li>
  <li><a href="#language" id="toc-language" class="nav-link" data-scroll-target="#language">Language</a>
  <ul class="collapse">
  <li><a href="#chomsky" id="toc-chomsky" class="nav-link" data-scroll-target="#chomsky">Chomsky</a></li>
  <li><a href="#eliza" id="toc-eliza" class="nav-link" data-scroll-target="#eliza">ELIZA</a></li>
  <li><a href="#shrdlu" id="toc-shrdlu" class="nav-link" data-scroll-target="#shrdlu">SHRDLU</a></li>
  </ul></li>
  <li><a href="#the-fifth-generation" id="toc-the-fifth-generation" class="nav-link" data-scroll-target="#the-fifth-generation">The Fifth Generation</a></li>
  <li><a href="#expert-systems-2" id="toc-expert-systems-2" class="nav-link" data-scroll-target="#expert-systems-2">Expert systems</a>
  <ul class="collapse">
  <li><a href="#origins" id="toc-origins" class="nav-link" data-scroll-target="#origins">Origins</a></li>
  <li><a href="#the-hype" id="toc-the-hype" class="nav-link" data-scroll-target="#the-hype">The hype</a></li>
  <li><a href="#the-fall" id="toc-the-fall" class="nav-link" data-scroll-target="#the-fall">The fall</a></li>
  <li><a href="#cyc" id="toc-cyc" class="nav-link" data-scroll-target="#cyc">Cyc</a></li>
  </ul></li>
  <li><a href="#intelligence-in-the-age-of-war-machines" id="toc-intelligence-in-the-age-of-war-machines" class="nav-link" data-scroll-target="#intelligence-in-the-age-of-war-machines">Intelligence in the age of war machines</a>
  <ul class="collapse">
  <li><a href="#early-war-machines" id="toc-early-war-machines" class="nav-link" data-scroll-target="#early-war-machines">Early war machines</a></li>
  <li><a href="#nuclear-war-machines" id="toc-nuclear-war-machines" class="nav-link" data-scroll-target="#nuclear-war-machines">Nuclear war machines</a></li>
  <li><a href="#intelligence" id="toc-intelligence" class="nav-link" data-scroll-target="#intelligence">Intelligence</a></li>
  <li><a href="#strategic-computing-project" id="toc-strategic-computing-project" class="nav-link" data-scroll-target="#strategic-computing-project">Strategic Computing Project</a></li>
  </ul></li>
  <li><a href="#philosophy" id="toc-philosophy" class="nav-link" data-scroll-target="#philosophy">Philosophy</a>
  <ul class="collapse">
  <li><a href="#the-symbolic-hypothesis" id="toc-the-symbolic-hypothesis" class="nav-link" data-scroll-target="#the-symbolic-hypothesis">The Symbolic Hypothesis</a></li>
  <li><a href="#cognitivism" id="toc-cognitivism" class="nav-link" data-scroll-target="#cognitivism">Cognitivism</a></li>
  <li><a href="#the-sub-symbolic-hypothesis" id="toc-the-sub-symbolic-hypothesis" class="nav-link" data-scroll-target="#the-sub-symbolic-hypothesis">The Sub-symbolic Hypothesis</a></li>
  <li><a href="#connectionism-the-past-tense-debate-and-whatever" id="toc-connectionism-the-past-tense-debate-and-whatever" class="nav-link" data-scroll-target="#connectionism-the-past-tense-debate-and-whatever">Connectionism, the past tense debate, and whatever</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="translation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="translation">Translation</h2>
<blockquote class="blockquote">
<p>One naturally wonders if the problem of translation could conceivably be treated as a problem in cryptography. When I look at an article in Russian, I say: “This is really written in English, but it has been coded in some strange symbols. I will now proceed to decode.”</p>
<p>– Warren Weaver, Letter to Norbert Wiener, 1947-03-04</p>
</blockquote>
<p>During WWII, the science of communication and control took on a life-and-death importance. The mathematically perfect Enigma forced Allied mathematicians to turn their art of code into the science of information, so as to extract every last bit of information leaked out from the unknown enemy who was less than mathematically perfect, who made mistakes, who stuttered with verbal tics like <code>WETTER</code> or <code>KEINE BESONDEREN EREIGNISSE</code>. On two sides of the Atlantic, Alan Turing of computer science, and Claude Shannon of information theory, fought in this information warfare.</p>
<p>Before the war, some feared that the bombers would finally be the ultimate weapon, as a fleet of <a href="https://en.wikipedia.org/wiki/The_bomber_will_always_get_through">them will always get through</a>. Bombing was becoming a cyborg activity. The bombers were flying so high and so fast, the bombardiers needed <a href="https://en.wikipedia.org/wiki/Norden_bombsight">intricate bombsights</a> filled with mechanical calculators, just to calculate the correct time to drop the bombs.</p>
<p>But the bombers would not go through after all, as radar screens and flak cannons raised invisible walls in the sky, and the anti-aircraft fire became another cyborg activity. Norbert Wiener developed his control theory in the context of anti-aircraft fire and radar screening. He thought of both as a form of deadly communication. A radar speaks to the aircraft, “Who and where are you?” Despite itself, the aircraft must answer. The radar’s job is to speak clearly with the right ping and listen carefully with the right filter. In this context, he developed the <a href="https://en.wikipedia.org/wiki/Wiener_filter">Wiener filter</a>.</p>
<p>Anti-aircraft (AA) seems even less like a deadly communication, yet Wiener made it work. To shoot down an aircraft, one must predict where it will be a few seconds into the future, since that is how long bullets take to fly that high. The AA looks to the sky and asks, “Where are you going?”. Despite itself, the aircraft speaks with where it had been in the past few seconds, as if writing a cursive word in the sky. The AA reads and understands this writing, and act accordingly. The past is a code for the future, like the Enigma is a code for the plaintext. <span class="citation" data-cites="yeangFilteringNoiseAntiaircraft2023">(<a href="#ref-yeangFilteringNoiseAntiaircraft2023" role="doc-biblioref">Yeang 2023</a>)</span></p>
<p>If the soldiers are always preparing to fight the previous war, the same seems true for some mathematicians. Wiener and his collaborator, Warren Weaver, decided to tackle the problem of machine translation with the same tools they developed for war. If information theory helps with breaking the Enigma code, would it not also help with breaking the language codes?</p>
<p>The wartime metaphor would become ominously appropriate with the Cold War.</p>
<section id="georgetownibm-experiment" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="georgetownibm-experiment">Georgetown–IBM experiment</h3>
<p>During the 1950s, electronic computers were mainly understood and used as tools for real-valued calculations, such as simulating nuclear explosions, the aerodynamics of ballistic missiles, macroeconomic planning, and other important real-valued functions that are necessary to safeguard freedom. However, there was already early attempts at using computers for symbolic calculations.</p>
<p>In a sense, this was quite old. Whereas Charles Babbage designed his computer as an arithmetic mill to grind out numerical tables, Ada Lovelace speculated that computers can grind out symbolic music too, as long as music and its transformation rules are encoded into integers.</p>
<p>On 1954-01-07, the world’s first non-human translator appeared in the body of an IBM 701. At least, that is what the newspapers made it seam to be.</p>
<p>Back in 1952-06, at a MIT conference on machine translation, Leon Dostert was convinced that instead of arguments about whether MT works <em>in theory</em>, they needed to try it out on an actual problem to see if it would work <em>in practice</em>. This led to the <a href="https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment">Georgetown–IBM experiment</a> 1.5 years later. It was the first public demonstration of machine translation – from Russian to English, and was widely reported with titles like “Electronic brain translates Russian” or “Robot brain translates Russian into King’s English”. The project originated when a conference on machine translation took place at MIT i</p>
<p>The IBM 701 machine operated at <span class="math inline">\(2000 \;\mathrm{FLOP/s}\)</span> with read/write speed <span class="math inline">\(3.6 \;\mathrm{kB/s}\)</span> (in the form of 80-column punched cards).</p>
<p>The program took up <span class="math inline">\(2400 \;\mathrm{instruction} \times 18 \;\mathrm{bit/instruction} = 5.4 \;\mathrm{kB}\)</span>, whereas the dictionary took up <span class="math inline">\(6000 \;\mathrm{word} \times 36 \;\mathrm{bit/word} = 27 \;\mathrm{kB}\)</span>.</p>
<p>The dictionary is a table with 6 columns: Russian, English equivalent I, English equivalent II, Code 1, Code 2, Code 3. As we see, each Russian word has 1 or 2 possible English translations. The three <code>Code</code>s are essentially grammar categories. As an example, the suffix <code>-a</code> is coded as <code>(-a, of, , 131, 222, 25)</code>, while the word stem <code>ugl-</code> is coded as <code>(ugl-, coal, angle, 121, ***, 25)</code>.</p>
<p>The dictionary contains just 250 lexical items (stems and endings). Its grammar has just 6 rules. All input sentences must be made of words that are of form either <code>stem</code> or <code>stem-ending</code>. Some example translations included:</p>
<ul>
<li>Mi pyeryedayem mislyi posryedstvom ryechyi.</li>
<li>We transmit thoughts by means of speech.</li>
</ul>
<p>The algorithm is essentially a word-substitution program, using the 6 rules to disambiguate, and to decide whether to switch a word with a previous word. The word-order switch is necessary since Russian puts prepositions as word suffixes. For example, <code>ugl-a</code> would be word-substituted to <code>angle-by</code>, but must be translated as <code>by angle</code>.</p>
<p>The experiment was a hit, and there were some predictions of imminent breakthrough <span class="citation" data-cites="hutchinsFirstPublicDemonstration2005">(<a href="#ref-hutchinsFirstPublicDemonstration2005" role="doc-biblioref">Hutchins 2005</a>)</span>:</p>
<ul>
<li>Such a device should be ready within three to five years… As soon as cards for Russian are completed, sets will be made for German and French. Then other Slavic, Germanic and Romance languages can be set up at will.</li>
<li>100 rules would be needed to govern 20,000 words for free translation.</li>
</ul>
<p>From our perspective, these seem painfully optimistic. However, it was a common belief that electronic computers, like the IBM 701, were designed for numerical computation, something that is more difficult than natural language processing. As such, a machine translator needed not faster computers, but more data. Yet among the general optimism, there was a disquieting note:</p>
<blockquote class="blockquote">
<p>the formulation of logic required to convert word meanings properly even in a small segment of two languages necessitates two and a half times as many instructions to the computer as are required to simulate the flight of a guided missile.</p>
<p><a href="https://aclanthology.org/www.mt-archive.info/IBM-1954.pdf">“701 Translator”, IBM Press release</a> (1954-01-08)</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled" title="Give me code or give me nothing!">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Give me code or give me nothing!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>One thing I dislike about some technical histories and overviews is that I keep getting a cotton-like, vaporwave feeling in the brain after reading them. It is easy to read an abstract story.</p>
<p>For example, many AI papers by OpenAI after 2020 has become like that. In any case, I looked up the program, which appeared in <span class="citation" data-cites="ornsteinMechanicalTranslationNew1955">(<a href="#ref-ornsteinMechanicalTranslationNew1955" role="doc-biblioref">Ornstein 1955</a>)</span> as a single giant flowchart. I didn’t read the spaghetti code in detail, but it seems to me that it first parses the input sequence into words and sub-words, then it starts from left to right, for each word/sub-word, find the rule that applies to it. Executing the rule would pick an English translation for that word/sub-word, and either switch that fragment of translation with the previous fragment, or not. There are 6 rules, of which I just copy one, since the others look similarly boring:</p>
<blockquote class="blockquote">
<p>Choice-Rearrangement. If first code is <code>131</code>, is third code of preceding complete word or either portion (root or ending) of preceding subdivided word equal to <code>23</code>? If so, adopt English equivalent II of word carrying <code>131</code> and retain order of appearance of words in output; if not, adopt English equivalent I and reverse order of appearance of words in output.</p>
</blockquote>
<p>The following is a rough sketch. It implements just rule 3, and even that is not quite correct, but it gives you an idea of how the program would go. I estimate that it should take about 100 lines to implement a fully correct version.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse(sentence):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> sentence.split(<span class="st">' '</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="op">==</span> stem <span class="op">++</span> prefix <span class="cf">for</span> some stem <span class="kw">in</span> stems <span class="kw">and</span> prefix <span class="kw">in</span> prefixes:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>            replace word <span class="kw">in</span> words by [stem, prefix]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> words</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate(words):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    translation <span class="op">=</span> []</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(words):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        word <span class="op">=</span> words[i]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> dictionary[word][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">131</span>: <span class="co"># rule 3</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dictionary[words[i<span class="op">-</span><span class="dv">1</span>]][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span>:</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                translation.append(dictionary[word][<span class="st">'English equivalent II'</span>])</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                translation.append(dictionary[word][<span class="st">'English equivalent I'</span>])</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                translation[i<span class="op">-</span><span class="dv">2</span>, i<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> [translation[i<span class="op">-</span><span class="dv">1</span>], translation[i<span class="op">-</span><span class="dv">2</span>]]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> dictionary[word][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">141</span>: <span class="co"># rule 4</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> translation.join(<span class="st">' '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>The exact details on how the program was implemented on the IBM was non-trivial, since both the machine and the programming environment around it were designed for numerical computations, not discrete symbolic manipulations. <span class="citation" data-cites="sheridanResearchLanguageTranslation1955">(<a href="#ref-sheridanResearchLanguageTranslation1955" role="doc-biblioref">Sheridan 1955</a>)</span> described the details. The programming language LISP must wait until 1960 to appear. Dedicated to symbolic manipulations. It would dominate most of AI research until the 1980s.</p>
<p>Another interesting fact is the amount of restrictions placed on the demo: 250 words, each word having just 1 or 2 possible translations, and each Russian word is either a full word or a <code>stem-suffix</code>, etc. An even deeper restriction was entirely hidden from view: pronouns. In Russian, pronouns are often dropped when the verb form makes it clear. To avoid this problem, for all demonstrated sentences, the English pronouns occur only in translations of verbs in the third person plural.</p>
<p>The demo worked. The CIA started funding MT research at Georgetown University (eventually up to $1,500,000), and other MT groups sprang up in America, Europe, and the Soviet Union. Subsequent research at Georgetown was based on a multi-level analysis (morphological, syntagmatic, syntax), later formalized as the <a href="https://en.wikipedia.org/wiki/Bernard_Vauquois#Vauquois_triangle">Vanquois triangle</a>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Vauquois triangle.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The Vanquois triangle.</figcaption>
</figure>
</div>
</section>
<section id="natural-language-compiler" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-compiler">Natural language compiler</h3>
</section>
<section id="winter-comes" class="level3">
<h3 class="anchored" data-anchor-id="winter-comes">Winter comes</h3>
<p>In 1964, the US government established ALPAC, a committee of 7 linguists, to review the progress on machine translation. 2 years later, the committee released the ALPAC report.</p>
<p><span class="citation" data-cites="hutchinsALPACFamousReport2003">(<a href="#ref-hutchinsALPACFamousReport2003" role="doc-biblioref">Hutchins 2003</a>)</span></p>
<p>Evaluation by demo is bad, because</p>
<ol type="1">
<li>Demos are cherry-picked, and don’t tell you how the system would work in practice.</li>
<li>Demos encourage an empirical kind of AI, an “artful deception” that is not science.</li>
</ol>
<p>The argument against full machine translation was simple but devastating:</p>
<ol type="1">
<li>Natural language is highly ambiguous.</li>
<li>Disambiguation is not purely syntactical, and requires semantics – world knowledge, or commonsense.</li>
<li>The amount of world knowledge, or commonsense, is extremely large, since after decades of manual entry, the machines still do not seem any closer to having commonsense.</li>
</ol>
<p>There were several solutions:</p>
<ol type="1">
<li>Intelligence amplification: Instead of trying the mirage of fully automatic MT, we should</li>
<li>Brute force logical programming: Scale up commonsense by hiring more linguists to program in increasingly large chunks of the world.</li>
<li>The contrarian: AI is a mirage, and the failures of MT is a symptom of that.</li>
</ol>
<p>From our vantage point, none of the solutions were correct. The actual solution turned out to be:</p>
<ol start="4" type="1">
<li>The bitter lesson: Wait a few decades, then just train a giant neural network on a trillion words from the Internet.</li>
</ol>
<p>There is a common mistake about the bitter lesson, that even Richard Sutton makes. It is not just that the bitter lesson is bitter, but also that it is <em>difficult</em>. People did not believe in it, not because they were afraid of bitterness, but because it was obviously stupid, a kind of straw man’s argument.</p>
<p>Case study in not taking the bitter lesson:</p>
<blockquote class="blockquote">
<p>The case against machine translation as a solution to practical problems is overwhelming and has been made many times. I do not propose to repeat it in any detail here. It will, however, be worth a few words to make a <em>prima facie</em> case for the implausibility of practical machine translation if only so that the contrast with realistic approaches to the problem will be more striking… There is a great deal that computer scientists and linguists could contribute to the practical problem of producing translations, but, in their own interests as well as those of their customers, they should <strong>never</strong> be asked to provide an engineering solution to a problem that they only dimly understand.</p>
<p>I want to advocate a view of the problem in which machines are gradually, almost imperceptibly, allowed to take over certain functions in the overall translation process. First they will take over functions not essentially related to translation. Then, little by little, they will approach translation itself. The keynote will be <em>modesty</em>. At each stage, we will do only what we know we can do reliably.</p>
<p><span class="citation" data-cites="kayProperPlaceMen1997">(<a href="#ref-kayProperPlaceMen1997" role="doc-biblioref">Kay 1997</a>)</span></p>
</blockquote>
</section>
<section id="expert-systems" class="level3">
<h3 class="anchored" data-anchor-id="expert-systems">Expert systems</h3>
</section>
<section id="collapse" class="level3">
<h3 class="anchored" data-anchor-id="collapse">Collapse</h3>
</section>
<section id="the-bitter-lesson" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-bitter-lesson">The Bitter Lesson</h3>
<p>In 2011, Kenneth proposed a 20-year cycle between “Empiricism” (turns out it works) and “Rationalism” (it must work if you think carefully about it), and argued that we were on the brink of a return to Rationalism:</p>
<ul>
<li>1950s: Empiricism (Shannon, Skinner, Firth, Harris)</li>
<li>1970s: Rationalism (Chomsky, Minsky)</li>
<li>1990s: Empiricism (IBM Speech Group, AT&amp;T Bell Labs)</li>
<li>2010s: A Return to Rationalism?</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Kenneth_2011_fig_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The shift from Rationalism to Empiricism, as measured by the proportion of statistical papers submitted to the Association for Computational Linguistics. Based on two independent surveys by Bob Moore and Fred Jelinek.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>When we revived empiricism in the 1990s, we chose to reject the position of our teachers for pragmatic reasons. Data had become available like never before. What could we do with it? We argued that it is better to do something simple than nothing at all. Let’s go pick some low hanging fruit. While trigrams cannot capture everything, they often work better than the alternatives… That argument made a lot of sense in the 1990s, especially given unrealistic expectations that had been raised during the previous [expert systems] boom. But today’s students might be faced with a very different set of challenges in the not-too-distant future. What should they do when most of the low hanging fruit has been pretty much picked over? … we should expect Machine Translation research to make more and more use of richer and richer linguistic representations. So too, there will soon be a day when stress will become important for speech recognition.</p>
<p><span class="citation" data-cites="churchPendulumSwungToo2011">(<a href="#ref-churchPendulumSwungToo2011" role="doc-biblioref">Church 2011</a>)</span></p>
</blockquote>
<p>As of 2025, the pendulum has swung even deeper into Empiricism.</p>
</section>
</section>
<section id="vision" class="level2">
<h2 class="anchored" data-anchor-id="vision">Vision</h2>
</section>
<section id="speech" class="level2">
<h2 class="anchored" data-anchor-id="speech">Speech</h2>
<p>DARPA and the Speech Understanding Research program at Carnegie Mellon University</p>
<p>Whither Speech Recognition? (1971)</p>
<p>Whither speech recognition: The next 25 years (1993)</p>
</section>
<section id="games" class="level2">
<h2 class="anchored" data-anchor-id="games">Games</h2>
<p>This chapter would be short since logical AI in games is well-known.</p>
<p>Artificial intelligence has abandoned the quest for certainty and truth. The new patchwork rationalism is built upon mounds of <em>micro-truths</em> gleaned through common sense introspection, ad hoc programming and so-called <em>knowledge acquisition</em> techniques for interviewing experts. The grounding on this shifting sand is pragmatic in the crude sense__If it seems to be working, it_s right.</p>
<p>Samuel Checkers, DeepBlue.</p>
</section>
<section id="general" class="level2">
<h2 class="anchored" data-anchor-id="general">General</h2>
<p>General Problem Solver, Symbolic hypothesis, McCarthy, Minsky</p>
</section>
<section id="expert-systems-1" class="level2">
<h2 class="anchored" data-anchor-id="expert-systems-1">Expert systems</h2>
<blockquote class="blockquote">
<p>The miracle product is knowledge, and the Japanese are planning to package and sell it the way other nations package and sell energy, food, or manufactured goods… The essence of the computer revolution is that the burden of producing the future knowledge of the world will be transferred from human heads to machine artifacts.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">Feigenbaum and McCorduck 1984, chap. 4</a>)</span></p>
</blockquote>
</section>
<section id="language" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="language">Language</h2>
<section id="chomsky" class="level3">
<h3 class="anchored" data-anchor-id="chomsky">Chomsky</h3>
<p>HMM models, and indeed, <em>all</em> probabilistic models of English, must fail, because English has central embedding.</p>
</section>
<section id="eliza" class="level3">
<h3 class="anchored" data-anchor-id="eliza">ELIZA</h3>
<p>Weizenbaum became a fully human-centric critique of AI, culminating with <em>Computer Power and Human Reason: From Judgment to Calculation</em> (1976). In brief, the book had theese theses:</p>
<ol type="1">
<li>Computers might be intelligent, but they will never be wise (or to feel emotions, to love, etc). To “calculate” requires just intelligence, but to “judge” requires wisdom.</li>
<li>The development of AI threatens to replace judgment with calculation, which will destroy human dignity. This replacement of judgment with calculation is an absurd political ideology, and must be resisted politically.</li>
<li>If, however, we do not resist, but keep following this political ideology, we would end up with the obviously absurd conclusion that “the brain is merely a meat machine”. <em>Reductio ad absurdum</em>.</li>
<li>This dangerous development of AI did not come from a wise scientific project of understanding how human intelligence works, but from a megalomaniac, obsessive-compulsive desire to make machine parodies of human behavior. The method of AI development was heuristic, empirical, a kind of “I wonder what the machine would do if I write this program…”, without a scientific theory.</li>
</ol>
<p>When the book came out, it received many reviews, and Weizenbaum wrote replies to these reviews. I found this one the funniest:</p>
<blockquote class="blockquote">
<p>I have in mind also the teaching urged on us by some leaders of the AI community that there is nothing unique about the human species, that in fact, the embrace of the illusion of human uniqueness amounts to a kind of species prejudice and is unworthy of enlightened intellectuals. If we find nothing abhorrent in the use of artificially sustained, disembodied animal brains as computer components, and if there is nothing that uniquely distinguishes the human species from animal species, then – need I spell out where that idea leads?</p>
<p><span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 370</a>)</span></p>
</blockquote>
<p>Apparently Weizenbaum, in his human-centered wisdom, rejected Darwinism as well. In any case, he stopped doing AI research since 1970, so it is quite useless to talk more about him.</p>
</section>
<section id="shrdlu" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="shrdlu">SHRDLU</h3>
<p>For his PhD in mathematics, Terry Winograd programmed the SHRDLU during the years 1968–1970. In the program, the user carries on a conversation with the computer, moving objects, naming collections and querying the state of a simplified “blocks world”, essentially a virtual box filled with different blocks. It was in around 500 KB of LISP code.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/SHRDLU.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The result of typing “Will you please stack up both of the red blocks and either a green cube or a pyramid?” <span class="citation" data-cites="winogradUnderstandingNaturalLanguage1972">(<a href="#ref-winogradUnderstandingNaturalLanguage1972" role="doc-biblioref">Winograd 1972, fig. 5</a>)</span></figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>it occupies around 200k of core (caution: indiscriminately running a job that big in the middle of the day is a good way to make enemies!!!!! Alway check the level of system usage before loading…)</p>
<p>– <code>mannew</code> from <a href="code/SHRDLU.zip">the SHRDLU archive</a>.</p>
</blockquote>
<blockquote class="blockquote">
<p>The system answers questions, executes commands, and accepts information in normal English dialog. It uses semantic information and context to understand discourse and to disambiguate sentences. It combines a complete syntactic analysis of each sentence with a “heuristic understander” which uses different kinds of information about a sentence, other parts of the discourse, and general information about the world in deciding what the sentence means. It is based on the belief that a computer cannot deal reasonably with language unless it can “understand” the subject it is discussing. The program is given a detailed model of the knowledge needed by a simple robot having only a hand and an eye. We can give it instructions to manipulate toy objects, interrogate it about the scene, and give it information it will use in deduction. In addition to knowing the properties of toy objects, the program has a simple model of its own mentality. It can remember and discuss its plans and actions as well as carry them out. It enters into a dialog with a person, responding to English sentences with actions and English replies, and asking for clarification when its heuristic programs cannot understand a sentence through use of context and physical knowledge.</p>
<p>Procedures as a Representation for Data in a Computer Program for Understanding Natural Language</p>
</blockquote>
<p>As a fun side-note. The original SHRDLU had some manual fixes in the compiled assembly code (!). Terry Winograd’s first research student rewrote much of SHRDLU so that it is portable. Some people sent letters (physical letters!) to request the code, and they would duly mail it out (by magnetic tape?). As one can imagine, only a few dozen source codes were mailed out.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://web.archive.org/web/20171117063022/http://www.semaphorecorp.com/misc/shrdlu.html">SHRDLU resurrection</a>. Created in 2002, and last updated on 2013-08-22.</p></div></div><p>It is pretty amusing now that</p>
</section>
</section>
<section id="the-fifth-generation" class="level2">
<h2 class="anchored" data-anchor-id="the-fifth-generation">The Fifth Generation</h2>
<p>In 1982, the Japanese was ready to take on the world.</p>
<p>With some irony, the Japanese might look back and call them the Gosei [五世].</p>
</section>
<section id="expert-systems-2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="expert-systems-2">Expert systems</h2>
<section id="origins" class="level3">
<h3 class="anchored" data-anchor-id="origins">Origins</h3>
<p>Beginning in 1965, Edward Feigenbaum and Joshua Lederberg developed DENDRAL, first as a model to understand how organic chemists do their daily work: Given a molecule with this kind of mass spectra, this melting point, or other experimental data, what might be its chemical formula and molecular structure?</p>
</section>
<section id="the-hype" class="level3">
<h3 class="anchored" data-anchor-id="the-hype">The hype</h3>
</section>
<section id="the-fall" class="level3">
<h3 class="anchored" data-anchor-id="the-fall">The fall</h3>
<blockquote class="blockquote">
<p>One system for medical diagnosis, called <a href="https://en.wikipedia.org/wiki/CADUCEUS_(expert_system)">CADUCEUS</a> (originally INTERNIST), has 500 disease profiles, 350 disease variations, several thousand symptoms, and 6,500 rules describing relations among symptoms. After fifteen years of development, the system is still not on the market. According to one report, it gave a correct diagnosis in only 75 percent of its carefully selected test cases. Nevertheless, Myers, the medical expert who developed it, “believes that the addition of another 50 [diseases] will make the system workable and, more importantly, practical.”</p>
<p><span class="citation" data-cites="winograd10ThinkingMachines1991">(<a href="#ref-winograd10ThinkingMachines1991" role="doc-biblioref">Winograd 1991</a>)</span></p>
</blockquote>
<p><span class="citation" data-cites="wolframAppraisalINTERNISTI1995">(<a href="#ref-wolframAppraisalINTERNISTI1995" role="doc-biblioref">Wolfram 1995</a>)</span></p>
<p>Winograd argued that expert systems are structured like human bureaucracies, with formalized explicit rules, and so they have same strengths and weaknesses. This explains why they work only in stable and precise technical areas, where exceptions are not the rule. <span class="citation" data-cites="winograd10ThinkingMachines1991">(<a href="#ref-winograd10ThinkingMachines1991" role="doc-biblioref">Winograd 1991</a>)</span></p>
</section>
<section id="cyc" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cyc">Cyc</h3>
<blockquote class="blockquote">
<p>AI has for many years understood enough about representation and inference to tackle this project, but no one has sat down and done it… only by pulling together the latest human interface tools, Lisp machines, ideas of enforced semantics, and funding for a decade-long effort could we attempt a project of this scale. <span class="citation" data-cites="lenatCycUsingCommon1985">(<a href="#ref-lenatCycUsingCommon1985" role="doc-biblioref">D. B. Lenat, Prakash, and Shepherd 1985</a>)</span></p>
</blockquote>
<p>In 1984, <a href="https://en.wikipedia.org/wiki/Douglas_Lenat">Douglas Lenat</a> began the Cyc project, an ambitious attempt to scale symbolic AI up to the real world. Like most expert systems, the Cyc project consists of a giant knowledge base encoded in a LISP-like symbolic logic language, upon which inference engines can be run to produce logical reasoning. Unlike most expert systems, the ambition of Cyc was universal: Its knowledge base would not be restricted to expert knowledge in a particular domain, but <em>all</em> commonsense knowledge in <em>all</em> domains that humans have commonsense about.</p>
<p>Even from the vantage point of 1985, it was clear to all that there was a lot of commonsense to code in, although few could have predicted that Lenat would persevere at it for over 30 years.</p>
<p>They themselves underestimated the difficulty. In 1990, they confidently titled a paper “Cyc: A midterm report” <span class="citation" data-cites="lenatCycMidtermReport1990">(<a href="#ref-lenatCycMidtermReport1990" role="doc-biblioref">D. Lenat and Guha 1990</a>)</span>, suggesting that they expected to be done around 1995.</p>
<p>The progress report in 1995 stated that, while the system is far from done, they have at least manually entered <span class="math inline">\(10^5\)</span> “general concepts” and <span class="math inline">\(10^6\)</span> “commonsense axioms” into Cyc, at the price of 100 person-years. <span class="citation" data-cites="lenatCycLargescaleInvestment1995">(<a href="#ref-lenatCycLargescaleInvestment1995" role="doc-biblioref">D. B. Lenat 1995</a>)</span></p>
<blockquote class="blockquote">
<p>Moreover, statistics, colocation, and frequency do not resolve such questions. But the task goes from impossible to trivial if one already knows a few things about boxes and pens, police and demonstrators, and water and teakettles. The same sort of chicken-and-egg relationship characterizes CYC and ML because learning occurs at the fringe of what one already knows. Therefore, in the early 1980s, when the rest of the world was so enthusiastic about Natural Language Understanding, Machine Learning, and AI in general, we were pessimistic. We concluded the only way out of this codependency would be to prime the pump by manually crafting a million axioms covering an appreciable fraction of the required knowledge. That knowledge would serve as a critical mass, enabling further knowledge collection through NLU and ML, beginning in the mid-1990s. Mary Shepherd and I embarked on that task in 1984, knowing we had little chance of success, but seeing no alternative but to try… we are now moving toward the transition point where NLU and ML are supported. The rest of the world is disillusioned and pessimistic about symbolic AI, but ironically, as CYC reaches closure, our hopes for NLU and ML in the next 10 years are very high.</p>
<p><span class="citation" data-cites="lenatCycLargescaleInvestment1995">(<a href="#ref-lenatCycLargescaleInvestment1995" role="doc-biblioref">D. B. Lenat 1995</a>)</span></p>
</blockquote>
<p>In 2016, Lenat finally declared the Cyc project “done” and set about commercializing it.</p>
<blockquote class="blockquote">
<p>Having spent the past 31 years memorizing an astonishing collection of general knowledge, the artificial-intelligence engine created by Doug Lenat is finally ready to go to work… most of what is left to be added is relevant to a specific area of expertise, such as finance or oncology.</p>
<p>Among other projects, the company is developing a personal assistant equipped with Cyc’s general knowledge. This could perhaps lead to something similar to Siri… the CEO of Lucid says the new company is in talks with various others interested in using the Cyc knowledge base. Lucid has been working with the Cleveland Clinic, for example, to help automate the process of finding patients for clinical studies.</p>
<p><span class="citation" data-cites="knightAI30Years2016">(<a href="#ref-knightAI30Years2016" role="doc-biblioref">Knight 2016</a>)</span></p>
</blockquote>
<p>That was essentially the last we heard from Cyc.</p>
<p>When looking at this figure from 1985, one is simultaneously filled with respect and sadness, for they were facing impossible odds, and yet they charged right into it.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/cyc_project_ontology.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="lenatCycUsingCommon1985">(<a href="#ref-lenatCycUsingCommon1985" role="doc-biblioref">D. B. Lenat, Prakash, and Shepherd 1985, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>Their “midterm report” only accentuates this sense of tragedy, of seeing them fighting impossible odds, and losing. They saw with clarity that there is no shortcut to intelligence, no “Maxwell’s equations of thought”.</p>
<blockquote class="blockquote">
<p>The majority of work in knowledge representation has dealt with the technicalities of relating predicate calculus to other formalisms and with the details of various schemes for default reasoning. There has almost been an aversion to addressing the problems that arise in actually representing large bodies of knowledge with content. However, deep, important issues must be addressed if we are to ever have a large intelligent knowledge-based program: What ontological categories would make up an adequate set for carving up the universe? How are they related? What are the important facts and heuristics most humans today know about solid objects? And so on. In short, we must bite the bullet.</p>
<p>We don’t believe there is any shortcut to being intelligent, any yet-to-be-discovered Maxwell’s equations of thought, any AI Risc architecture that will yield vast amounts of problem-solving power. Although issues such as architecture are important, no powerful formalism can obviate the need for a lot of knowledge.</p>
<p>By knowledge, we don’t just mean dry, almanac-like or highly domain-specific facts. Rather, most of what we need to know to get by in the real world is prescientific (knowledge that is too commonsensical to be included in reference books; for example, animals live for a single solid interval of time, nothing can be in two places at once, animals don’t like pain), dynamic (scripts and rules of thumb for solving problems) and metaknowledge (how to fill in gaps in the knowledge base, how to keep it organized, how to monitor and switch among problem-solving methods, and so on). Perhaps the hardest truth to face, one that AI has been trying to wriggle out of for 34 years, is that there is probably no elegant, effortless way to obtain this immense knowledge base. Rather, the bulk of the effort must (at least initially) be manual entry of assertion after assertion. <span class="citation" data-cites="lenatCycMidtermReport1990">(<a href="#ref-lenatCycMidtermReport1990" role="doc-biblioref">D. Lenat and Guha 1990</a>)</span></p>
</blockquote>
</section>
</section>
<section id="intelligence-in-the-age-of-war-machines" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="intelligence-in-the-age-of-war-machines">Intelligence in the age of war machines</h2>
<section id="early-war-machines" class="level3">
<h3 class="anchored" data-anchor-id="early-war-machines">Early war machines</h3>
<p>The dream of peace produces war machines. Ancient Athenians dreamed of <a href="https://en.wikipedia.org/wiki/Talos">Talos</a>, a bronze giant who defended Crete, while the Jews of Prague dreamed of <a href="https://en.wikipedia.org/wiki/Golem#Etymology">Golem</a>. The ages has been too kind to Zhuge Liang, and his wheelbarrow, invented for carrying war supplies, became the legend of <a href="https://en.wikipedia.org/wiki/Wooden_ox">wooden robot oxen</a>.</p>
<p>The industrial revolution produced early ideas of feedback mechanism, such as the <a href="https://en.wikipedia.org/wiki/Centrifugal_governor">centrifugal governor</a> and the <a href="https://en.wikipedia.org/wiki/Gyroscopic_autopilot">gyro autopilot</a>. It took until WWII for someone to put together high explosives, slow burning fuel, and the feedback mechanism, to create the cruise missile. The first of its kind was the V-1 rocket, which already incorporates the basic features of all cruise missiles.</p>
<p>The V-1 looks like a small unmanned jet airplane. It has the following senses: roll (gyro), pitch (gyro), yaw (magnetic compass), altitude (barometer), distance traveled (vane anemometer). The roll, pitch, yaw, and altitude are maintained by negative feedback. So for example, if the missile is heading east to the set-point of yaw, a valve would open, and compressed gas would force the rudder to turn, which yaws the missile west. As soon as the vane anemometer has turned a designated number, the missile considers itself to have reached the target. It turns off the engine and sharply dives to the ground, and explodes upon impact.</p>
<p>Other than V-1 and V-2, there were no autonomous war machines during WWII, though there were several radio-controlled weapons such as <a href="https://en.wikipedia.org/wiki/Goliath_tracked_mine">explosive little tanks</a> and <a href="https://en.wikipedia.org/wiki/Radioplane_OQ-2">little planes for target practice</a>. Skinner, thinking outside (inside?) the box, worked on <a href="https://en.wikipedia.org/wiki/Project_Pigeon">Project Pigeon</a>. He trained pigeons in skinner boxes to peck at the ship appearing on a screen. If the pigeon is pecking on the top-left, then the missile would turn to the bottom-right. In effect, the pigeon becomes the negative feedback controller. Though it was cancelled, it would have been considerably cheaper than <a href="https://en.wikipedia.org/wiki/Kamikaze">the Japanese version</a> should it have ever reached production.</p>
<video controls="" width="100%">
<source src="figure/Project Pigeon.webm" type="video/webm">
</video>
<p>After WWII, some autonomous defense systems were developed and deployed, such as <a href="https://en.wikipedia.org/wiki/Close-in_weapon_system">close-in weapon systems</a> on ships. These detect incoming incoming missiles and enemy aircraft by radar, computes their trajectories, and shoots them down. Since they must operate on the time-scale of seconds, they are fully automatic with no human in the loop. Despite this, these are quite uncontroversial and do not typically earn the title of “killer robots”, presumably because compared to autonomous <em>offense</em>, defense is inherently more controllable and predictable in effect.</p>
</section>
<section id="nuclear-war-machines" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="nuclear-war-machines">Nuclear war machines</h3>
<blockquote class="blockquote">
<p>Deterrence is the art of producing in the mind of the enemy the fear to attack. And so, because of the automated and irrevocable decision making process which rules out human meddling, the doomsday machine is terrifying. It’s simple to understand. And completely credible, and convincing… When you merely wish to bury bombs, there is no limit to the size. After that they are connected to a gigantic complex of computers. Now then, a specific and clearly defined set of circumstances, under which the bombs are to be exploded, is programmed into a tape memory bank.</p>
<p>— <a href="https://en.wikipedia.org/wiki/Dr._Strangelove">Dr.&nbsp;Strangelove</a> (1964)</p>
</blockquote>
<p>During the Cold War, the following technological factors of nuclear weapons determined the grand nuclear strategy.</p>
<ol type="1">
<li>First-strike nuclear offense is impossible to defend against. Some bombs will get through all defense.</li>
<li>Nuclear weapon is so much more powerful than non-nuclear weapons, that the only proportionate deterrence to a nuclear attack is another nuclear attack.</li>
<li>First-strike capability is indistinguishable from second-strike capability.</li>
</ol>
<p>Because of (1) and (2), the only way to deter a nuclear first-strike was to threaten a nuclear second-strike. This is the <a href="https://en.wikipedia.org/wiki/Mutual_assured_destruction">MAD</a> nuclear deterrence doctrine. Because deterrence requires enough bombs to survive a first-strike, both sides would rather build up more second-strike bombs than the other side’s first-strike bombs. Because of (3), there aren’t “second-strike bombs” vs “first-strike bombs”, only bombs. Therefore, we have a positive feedback loop where both sides aim to have more bombs than the other – the <a href="https://en.wikipedia.org/wiki/Nuclear_arms_race">nuclear arms race</a>. Because having too many bombs increases the chance of accidents, both sides are motivated to slow down the race. Thus the <a href="https://en.wikipedia.org/wiki/Anti-Ballistic_Missile_Treaty">ABM Treaty</a>, where both sides agree to <em>not</em> build many missile defense systems! This paradoxical treaty was designed to make both sides <em>more</em> vulnerable to second-strike, meaning that less bombs are needed to ensure second-strike capability.</p>
<p>Both sides’ nuclear technology went through several iterations, with increasing second-strike capability, and ended up with the “nuclear triad” of bombers that stay in the air 24/7, submarines hidden under the sea, and ICBMs hardened inside silos. Each of the three has different tradeoffs, necessitating all three to be maintained.</p>
<p>Of course, even if the triad survives the first-strike, it is no good if they won’t activate. The command center might be destroyed. The communication lines might be cut. The soldiers might refuse to launch based on their own conscience. All these dangers lead to the pressure to automate second-strike. The pinnacle of this logic was the <a href="https://en.wikipedia.org/wiki/Supersonic_Low_Altitude_Missile">Supersonic Low Altitude Missile (SLAM)</a>, a cruise missile powered by a nuclear engine. The nuclear engine is like a fission nuclear reactor in nuclear power plants, except that the fission power does not boil water, but heat up air, which expands and shoots out from the tail of the missile, allowing it to fly at Mach 3.</p>
<p>Despite having no GPS (it was the 1960s!), because the SLAM would fly <span class="math inline">\(\sim 200 \;\mathrm{m}\)</span> above ground, it could navigate itself by <a href="https://en.wikipedia.org/wiki/TERCOM">terrain contour matching</a>: It compares a height-scan of the local terrain against a stored copy of the terrain. Even after dropping all its nuclear warheads, it can remain airborne for weeks, destroying the ground with sonic booms as overkill. The project was shelved in 1964, apparently considered too destabilizing, and they settled for just drilling the nuclear launch routines into the missileers until they work like robots that would not hesitate to execute the launch command.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/TERCOM.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The terrain contour matching algorithm. By a curious coincidence, the algorithm typically attempts to find a line segment within the stored terrain map that minimizes the <a href="https://en.wikipedia.org/wiki/Average_absolute_deviation">Mean Absolute Deviation</a> with the local terrain of the missile… also with the “MAD” acronym. <span class="citation" data-cites="goldenTerrainContourMatching1980">(<a href="#ref-goldenTerrainContourMatching1980" role="doc-biblioref">Golden 1980, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>In the movie <em>Dr.&nbsp;Strangelove</em> (1964), nuclear deterrence was taken to its logical end point. In the movie, the Soviet Union built a “doomsday machine”, which is a Cobalt bomb that when exploded, makes enough fallout to render the entire earth uninhabitable for a century. This was then connected to sensors around the Soviet Union, so that any nuclear attack automatically triggers it. Finally, the machine triggers if it detects attempts to un-trigger it, thus closing the logic loop and making it a fully automatic deterrence machine.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;I was going to write something about the <a href="https://en.wikipedia.org/wiki/Dead_Hand">Dead Hand</a> system, but after a brief search, the available information looks too much like conspiracy theory and rumors, so I will not.</p></div></div></section>
<section id="intelligence" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="intelligence">Intelligence</h3>
<p>During the Cold War, intelligence, in the sense of intelligence-gathering and reconnaissance was a vital area of artificial intelligence.</p>
<p>Some of the early neural networks, such as MINOS II, was explicitly built with an objective of scanning aerial photographs for interesting military targets like tanks. <span class="citation" data-cites="nilssonQuestArtificialIntelligence2009">(<a href="#ref-nilssonQuestArtificialIntelligence2009" role="doc-biblioref">Nilsson 2009, 98–109</a>)</span> The CIA even experimented with Rosenblatt’s Mark I Perceptron machine for the same purpose <span class="citation" data-cites="irwinArtificialWorldsPerceptronic2024">(<a href="#ref-irwinArtificialWorldsPerceptronic2024" role="doc-biblioref">Irwin 2024</a>)</span>. As an example, <span class="citation" data-cites="kanalRecognitionSystemDesign1964">(<a href="#ref-kanalRecognitionSystemDesign1964" role="doc-biblioref">Kanal and Randall 1964</a>)</span> describes a two-layered perceptron network, of type <span class="math inline">\(\mathbb{R}^{N \times N} \to \{0, 1\}^{32\times 32} \to \{0, 1\}^{24} \to \{0, 1\}\)</span>. It works as follows:</p>
<ul>
<li>The grayscale photo is down-scaled and binarized by convolution with a <a href="https://en.wikipedia.org/wiki/Discrete_Laplace_operator">discrete Laplace filter</a>: <span class="math inline">\(\mathbb{R}^{N \times N} \to \{0, 1\}^{32\times 32}\)</span>.</li>
<li>The weights for the 24 hidden perceptrons are constructed by <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">linear discriminant analysis</a>: <span class="math inline">\(\{0, 1\}^{32\times 32} \to \{0, 1\}^{24}\)</span></li>
<li>The output perceptron is learned by the <a href="https://en.wikipedia.org/wiki/Perceptron#Learning_algorithm_for_a_single-layer_perceptron">perceptron learning rule</a>: <span class="math inline">\(\{0, 1\}^{24} \to \{0, 1\}\)</span>.</li>
</ul>
<div id="fig-kanal-1964-neural-tanks" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kanal-1964-neural-tanks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-tank-nontank-mosaic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-tank-nontank-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_tank_nontank_mosaic.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-tank-nontank-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Grayscale photos, some containing tanks, and some not.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-binary-image-tank" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-binary-image-tank-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_binary_image_tank.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-binary-image-tank-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) A picture of a tank after convolution with a discrete Laplace filter.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-architecture" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-architecture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_architecture.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-architecture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) The architecture of the network.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kanal-1964-neural-tanks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Images from <span class="citation" data-cites="kanalRecognitionSystemDesign1964">(<a href="#ref-kanalRecognitionSystemDesign1964" role="doc-biblioref">Kanal and Randall 1964</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="strategic-computing-project" class="level3">
<h3 class="anchored" data-anchor-id="strategic-computing-project">Strategic Computing Project</h3>
<p>The Strategic Computing Project (SCI) was named to resemble the <a href="https://en.wikipedia.org/wiki/Strategic_Defense_Initiative">Strategic Defense Initiative</a>, better known as “Star Wars”. The SDI was a project to</p>
</section>
</section>
<section id="philosophy" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="philosophy">Philosophy</h2>
<p>Astrophysicists, measuring the motion of galaxies, notice that the stars are rotating too fast. There is not enough matter to tether them, and they ought to fly out into the intergalactic emptiness. To solve this problem, they proposed “dark matter”, unknown matter that provides the missing gravitational force, and physicists ever since had been searching them.</p>
<p>Similarly, sometimes when you read through a field of study, you notice that the arguments seem to rotate around some kind of unspoken assumption that you might see if you just take all the books and throw them to the ground, so that they are all opened at random places. Then you turn your head and squint at the words refracted through the eyelids, the pupils, and the cornea, which you have repurposed as a primitive kind of optical computer. And you see the dark matter, the intellectual centers of gravity.</p>
<blockquote class="blockquote">
<p>Under an invisible spell, they will each start out anew, only to end up revolving in the same orbit once again… their thinking is not nearly as much a discovery as it is a recognition, remembrance, a returning and homecoming into a distant, primordial, total economy of the soul, from which each concept once grew: – to this extent, philosophizing is a type of atavism of the highest order.</p>
<p><span class="citation" data-cites="nietzscheGoodEvilPrelude2002">(<a href="#ref-nietzscheGoodEvilPrelude2002" role="doc-biblioref">Nietzsche, Horstmann, and Norman 2002, sec. 1.20</a>)</span></p>
</blockquote>
<section id="the-symbolic-hypothesis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-symbolic-hypothesis">The Symbolic Hypothesis</h3>
<p>General Problem Solver</p>
<p><em>Human Problem Solving</em></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/human_problem_solving_behavior_graph.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Newell and Simon 1972, 533</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/human_problem_solving_transcript.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Newell and Simon 1972, 534</a>)</span></figcaption>
</figure>
</div>
<p>In <a href="https://yuxi-liu-wired.github.io/docs/posts/1975-herbert-simon-allen-newell/">their Turing award lecture of 1975</a>, Allen Newell and Herbert Simon gave a definitive statement of the Physical Symbol System Hypothesis for AI, which they had labored under, first unconsciously but then consciously, since the early 1950s.</p>
<p>They began by some examples of “qualitative structure” in science, which do not deal with numbers, but with symbols. For example, a basic statement of cell theory – “organisms are made of little cells that are mostly alike” – doesn’t contain a single number, yet it has great significance. Such non-numerical discrete statements are made of “symbols”, and they stated their <strong>Physical Symbol System Hypothesis</strong> (PSSH):</p>
<blockquote class="blockquote">
<p>A physical symbol system has the necessary and sufficient means for general intelligent action.</p>
</blockquote>
<p>where a physical symbol system is essentially a machine that can be built in our physical world, and that manipulates with symbols. As an example, a digital computer running a LISP interpreter is a physical symbol system. We can attach cameras and wheels to the computer, so that the camera sends into the interpreter a symbolic representation of what it sees, and the wheels receives symbolic commands for motion. This is basically a robot according to the PSSH.</p>
<p>They also gave a <strong>Heuristic Search Hypothesis</strong>:</p>
<blockquote class="blockquote">
<p>A physical symbol system exercises its intelligence in problem solving by search-that is, by generating and progressively modifying symbol structures until it produces a solution structure.</p>
</blockquote>
<p>What is not said is equally revealing. In the lecture, there were over 100 mentions of the word “search”, but the only statement about learning is… a mention of Plato’s theory of <a href="https://en.wikipedia.org/wiki/Anamnesis_(philosophy)">anamnesis</a>! For them, a symbolic system starts out already with a solution generator and a solution tester, and problem-solving is nothing but heuristically searching over the generated solutions until one passes the tester. Indeed, in their telling, AI research is just search, not learning.</p>
<blockquote class="blockquote">
<p>… During the first decade or so of artificial intelligence research, the study of problem solving was almost synonymous with the study of search processes. From our characterization of problems and problem solving, it is easy to see why this was so. In fact, it might be asked whether it could be otherwise. … There is no mystery where the information that guided the search came from. We need not follow Plato in endowing the symbol system with a previous existence in which it already knew the solution. A moderately sophisticated generator-test system did the trick without invoking reincarnation.</p>
</blockquote>
</section>
<section id="cognitivism" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cognitivism">Cognitivism</h3>
<p>There was a persistent legend about a certain psychologist, that he educated his own children with <a href="https://en.wikipedia.org/wiki/Operant_conditioning_chamber">skinner boxes</a>. While just a legend, the real B. F. Skinner did have a philosophy as radical as the legend suggests.</p>
<p>In the 1950s, Skinner dominated behaviorism, which dominated American psychology. In short, behaviorism models animal behavior as stimulus-response reflexes, which can be understood as parameterized functions <span class="math inline">\(a_\theta(o)\)</span>, where <span class="math inline">\(o\)</span> stands for the observational stimulus, <span class="math inline">\(\theta\)</span> the internal parameters of the animal, and <span class="math inline">\(a_\theta(o)\)</span> the response action. The parameters <span class="math inline">\(\theta\)</span> is a function of the previous history of stimuli and reward/punishments: <span class="math inline">\((o_0, a_0, r_0, o_1, a_1, r_1, \dots)\)</span>. The set up is the same as modern reinforcement learning (RL).</p>
<p>The great thing about skinner boxes is that they are standardized to be lightproof, soundproof, and whatever-proof, thus controlling for all confounding variables. Before skinner boxes, mouse experiments were full of confounding variables, and had a kind of replication crisis in the 1930s. With the skinner box, the degrees of rat freedom are minimized, turning rats into standardized systems. This finally allowed measurable progress, allowing the breakout success of behaviorism in the 1950s.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://gwern.net/maze">Feynman told of the following maze-running rat legend</a>:</p>
<blockquote class="blockquote">
<p>He had a long corridor with doors all along one side where the rats came in, and doors along the other side where the food was. He wanted to see if he could train the rats to go in at the third door down from wherever he started them off. No.&nbsp;The rats went immediately to the door where the food had been the time before. The question was, how did the rats know, because the corridor was so beautifully built and so uniform, that this was the same door as before? Obviously there was something about the door that was different from the other doors. So he painted the doors very carefully, arranging the textures on the faces of the doors exactly the same. Still the rats could tell. Then he thought maybe the rats were smelling the food, so he used chemicals to change the smell after each run. Still the rats could tell. Then he realized the rats might be able to tell by seeing the lights and the arrangement in the laboratory like any commonsense person. So he covered the corridor, and, still the rats could tell. He finally found that they could tell by the way the floor sounded when they ran over it. And he could only fix that by putting his corridor in sand. So he covered one after another of all possible clues and finally was able to fool the rats so that they had to learn to go in the third door. If he relaxed any of his conditions, the rats could tell.</p>
</blockquote>
</div></div><p>Skinner’s ambitions went far beyond rats. In 1957, he published <a href="https://en.wikipedia.org/wiki/Verbal_Behavior"><em>Verbal Behavior</em></a>, in which he explained human language as stimulus-response networks, built up piece by piece during child development. To give an example, when one searches for a book with a title “Verbal Behavior”, one would say “Verbal Behavior, Verbal Behavior, Verbal Behavior…” (a “self-echoic”) while the eye scans the shelf. When the visual stimulus matches the verbal stimulus, the “grab book” action is triggered (a “tact”). The touch of the hand with the book then stops self-echoic behavior. In Skinner’s terms, this verbal behavior is a “<a href="https://en.wikipedia.org/wiki/Autoclitic">descriptive autoclitic</a>”.</p>
<p>He was at his most radical in <a href="https://en.wikipedia.org/wiki/Beyond_Freedom_and_Dignity"><em>Beyond Freedom and Dignity</em> (1971)</a>, which essentially argued that human society will be reorganized according to behaviorist principles. Instead of the indirect and unreliable behavior control using verbal moral judgment, a society would use more direct operant conditioning methods that are experimentally proven by behaviorist psychologists.</p>
<p>Though behaviorism has remained alive and well to this day, linguistics took a sudden turn around 1960 thanks to Noam Chomsky. According to legend, Chomsky wrote a review of <em>Verbal Behavior</em> in 1959, in which he soundly routed behaviorist linguistics <span class="citation" data-cites="chomskyReviewSkinnersVerbal1959">(<a href="#ref-chomskyReviewSkinnersVerbal1959" role="doc-biblioref">Chomsky 1959</a>)</span>. The truth is more complicated, since Chomsky also wrote several other famous works like <a href="https://en.wikipedia.org/wiki/Syntactic_Structures"><em>Syntactic Structures</em> (1957)</a>, <a href="https://en.wikipedia.org/wiki/Aspects_of_the_Theory_of_Syntax"><em>Aspects of the Theory of Syntax</em> (1967)</a>, and the foundational papers on formal grammar like the <a href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">Chomsky hierarchy</a>.</p>
<p>Chomsky argued that there are two ways of doing research in psychology and linguistics: “empiricism” and “rationalism”. Skinner’s book was the best example of empiricism, and since Skinner’s book is wrong, the book becomes a <em>reductio ad absurdum</em> of empiricism. Instead, one must turn back to rationalist psychology and linguistics.</p>
<blockquote class="blockquote">
<p>I had intended this review not specifically as a criticism of Skinner’s speculations regarding language, but rather as a more general critique of behaviorist (I would now prefer to say “empiricist”) speculation as to the nature of higher mental processes… I do not, in other words, see any way in which his proposals can be substantially improved within the general framework of behaviorist or neobehaviorist, or, more generally, empiricist ideas that has dominated much of modern linguistics, psychology, and philosophy. The conclusion that I hoped to establish in the review, by discussing these speculations in their most explicit and detailed form, was that the general point of view was largely mythology, and that its widespread acceptance is not the result of empirical support, persuasive reasoning, or the absence of a plausible alternative.</p>
<p>– Preface to the 1967 reprint. <span class="citation" data-cites="chomskyReviewBFSkinners1967">(<a href="#ref-chomskyReviewBFSkinners1967" role="doc-biblioref">Chomsky 1967</a>)</span></p>
</blockquote>
</section>
<section id="the-sub-symbolic-hypothesis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-sub-symbolic-hypothesis">The Sub-symbolic Hypothesis</h3>
<p>The dominance of the Symbolic Hypothesis was never complete. There were often objections to it.</p>
<p>In 1972, Hubert Dreyfus raised a fuss with a book <em>What Computers Can’t Do: The Limits of Artificial Intelligence</em>. Unfortunately, his work was based on the phenomenology of Merleau-Ponty and Heidegger, who wrote like <em>real and genuine</em> philosophers,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> so I just resorted to checking <a href="https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence">his Wikipedia article</a>. From what I gathered, his argument was that the Symbolic Hypothesis is flawed in the sense that it is too “closed”.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Edward Feigenbaum’s reaction is representative of most AI scientists:</p>
<blockquote class="blockquote">
<p>What artificial intelligence needs is a good Dreyfus. The conceptual problems in AI are really rough, and a guy like that could be an enormous help… But Dreyfus bludgeons us over the head with stuff he’s misunderstood and is obsolete anyway – and every time you confront him with one more intelligent program, he says, “I never said a computer couldn’t do that.” And what does he offer us instead? Phenomenology! That ball of fluff! That cotton candy! <span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 229–30</a>)</span></p>
</blockquote>
</div><div id="fn5"><p><sup>5</sup>&nbsp;This example was given by Anatol Holt at ARPA Principal Investigators’ Conference in 1974, and quoted in <span class="citation" data-cites="winograd10ThinkingMachines1991">(<a href="#ref-winograd10ThinkingMachines1991" role="doc-biblioref">Winograd 1991</a>)</span>:</p>
<blockquote class="blockquote">
<p>A brilliant chess move while the room is filling with smoke because the house is burning down does not show intelligence. If the capacity for brilliant chess moves without regard to life circumstances deserves a name, I would naturally call it “artificial intelligence.”</p>
</blockquote>
</div></div><p><a href="https://en.wikipedia.org/wiki/Douglas_Hofstadter">Douglas Hofstadter</a> raised a similar objection, but from within the logical AI tradition. His essential point was that logical AI, as conceived by Simon and Newell, is a closed system. For example, a chess computer might play a perfect chess even when the room is on fire. The concept of fire, or indeed anything that is beyond the mathematical strucure of chess, does not feature in the computer’s symbolic universe, and so it does not exist for the computer.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Whereas Dreyfus argued that intelligence is open by the “cotton candy” of phenomenology, sieging the head from the outside in, Hofstadter used the Gödel incompleteness theorems to break the head open, from the inside out.</p>
<p>The rough idea is that any symbolic system that is powerful enough would be incomplete, and furthermore, would “reflect” its own incompleteness. The incompleteness theorems state that in any sufficiently powerful formal system, there are statements that are true about the system that cannot be proven within the system. For example, let <span class="math inline">\(\Sigma\)</span> be the logical system of Peano arithmetics, then by the incompleteness theorems, there are sentences like <a href="https://en.wikipedia.org/wiki/Rosser%27s_trick">Rosser’s sentence</a>, or “PA is consistent”, which are <em>provably unprovable</em> assuming PA is consistent.</p>
<p>Stated in another way, arithmetical truth cannot be defined in arithmetic – <a href="https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem">Tarski’s undefinability</a>.</p>
<blockquote class="blockquote">
<p>O God, I could be bounded in a nut shell and count myself a king of infinite space, were it not that I have bad dreams.</p>
<p>— Hamlet, Act 2, Scene 2</p>
</blockquote>
<p>In the context of AI, this means that a symbolic system, no matter how complex, will always have limitations in representing and reasoning about the world, even if the world is but itself. We need not assume there is an “outside”. The symbolic system, even when floating in a mathematical vacuum, creates its own outside.</p>
<p>His solution was to add in some “strange loops”, which would both create general intelligence and create consciousness in one fell swoop. These strange loops are hierarchical structures where crossing levels leads back to the starting point. In the context of AI, Hofstadter proposed that implementing strange loops within a symbolic system would allow the system to refer to itself and its own structure, potentially leading to self-awareness and general intelligence. This self-referential capability would enable the system to overcome the limitations imposed by the incompleteness theorems and exhibit more flexible and human-like intelligence.</p>
<p>Hofstadter was a far better writer than Dreyfus, and his 1979 book <em>Gödel, Escher, Bach</em> was a popular hit among both the common people and the computer scientists. Despite this, the trajectory of AI did not go as he expected.</p>
<blockquote class="blockquote">
<p>There may be programs which can beat anyone at chess, but they will not be exclusively chess players. They will be programs of general intelligence, and they will be just as temperamental as people. “Do you want to play chess?” “No, I’m bored with chess. Let’s talk about poetry.” <span class="citation" data-cites="hofstadterGodelEscherBach1999">(<a href="#ref-hofstadterGodelEscherBach1999" role="doc-biblioref">Hofstadter 1999, 678</a>)</span></p>
</blockquote>
<p>In the preface to the second edition (1999), Hofstadter admitted that this prediction went way off, but still committed to the philosophical belief behind these. Unfortunately, the disappointments did not stop coming. In</p>
<p>With the rise of Transformer-based language models, . He expressed his confusion and traumatic response in a 2023 interview:</p>
<blockquote class="blockquote">
<p>[In 1960,] I knew how computers worked, and I knew how extraordinarily rigid they were. You made the slightest typing error and it completely ruined your program… It felt as if artificial intelligence was the art of trying to make very rigid systems behave as if they were fluid… I felt it would be hundreds of years before anything even remotely like a human mind would be asymptotically approaching the level of the human mind, but from beneath… But when certain systems started appearing maybe 20 years ago, they gave me pause. And then this started happening at an accelerating pace where unreachable goals and things that computers shouldn’t be able to do started toppling. The defeat of Gary Kasparov by Deep Blue, and then going on to Go systems, systems that could defeat some of the best Go players in the world. And then systems got better and better at translation between languages and then at producing intelligible responses to difficult questions in natural language, and even writing poetry.</p>
<p>My whole intellectual edifice, my system of beliefs–it’s a very traumatic experience when some of your most core beliefs about the world start collapsing… I think about it practically all the time, every single day… and it overwhelms me and depresses me in a way that I haven’t been depressed for a very long time.</p>
<p><a href="https://www.buzzsprout.com/222312/episodes/13125914">Reflections on AI</a>, interview with Douglas Hofstadter by Amy Jo Kim (2023-06-29)</p>
</blockquote>
</section>
<section id="connectionism-the-past-tense-debate-and-whatever" class="level3">
<h3 class="anchored" data-anchor-id="connectionism-the-past-tense-debate-and-whatever">Connectionism, the past tense debate, and whatever</h3>
<p>“Connectionism” is a word you don’t see much nowadays, but it was a big word back in the 1980s. It is hard to pin down, but if I summarize it, it is the result of philosophers in the 1980s noticing how researchers were trying neural networks on problems that had defied logical AI approaches, and somehow achieved state of the art, way past expectations. They say, “Weird! How is it possible for neural networks, written by people not having a deep knowledge of the problem domain, using such simplistic features, to work better than the best logical AI? I must philosophize this at once!”</p>
<p>Two clear camps immediately formed. On one side were the connectionists with <a href="https://en.wikipedia.org/wiki/Paul_Churchland">Paul Churchland</a>, <a href="https://en.wikipedia.org/wiki/Patricia_Churchland">Patricia Churchland</a>, <a href="https://en.wikipedia.org/wiki/Paul_Smolensky">Paul Smolensky</a>, <a href="https://en.wikipedia.org/wiki/Jeffrey_Elman">Jeffrey Elman</a>. On the other side were the cognitivists (or perhaps the rationalists) <a href="https://en.wikipedia.org/wiki/Jerry_Fodor">Jerry Fodor</a>, <a href="https://en.wikipedia.org/wiki/Zenon_Pylyshyn">Zenon Pylyshyn</a>, with the spirit of Noam Chomsky always present in the background.</p>
<p>Chapter 18 of <em>Parallel Distributed Processing</em> vol.&nbsp;2 bore the unassuming title “On learning the past tenses of verbs in English” <span class="citation" data-cites="rumelhartLearningTensesEnglish1986">(<a href="#ref-rumelhartLearningTensesEnglish1986" role="doc-biblioref">Rumelhart and McClelland 1986</a>)</span>. Nobody would have predicted that it ignited a long and bitter dispute “the past tense debate”.</p>
<p><span class="citation" data-cites="seidenbergQuasiregularityItsDiscontents2014">(<a href="#ref-seidenbergQuasiregularityItsDiscontents2014" role="doc-biblioref">Seidenberg and Plaut 2014</a>)</span></p>


<!-- -->


</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-chomskyReviewSkinnersVerbal1959" class="csl-entry" role="listitem">
Chomsky, Noam. 1959. <span>“A <span>Review</span> of <span>B</span>. <span>F</span>. <span>Skinner</span>’s <span>Verbal Behavior</span>.”</span> <em>Language</em> 35 (1): 26–58. <a href="https://doi.org/10.2307/411334">https://doi.org/10.2307/411334</a>.
</div>
<div id="ref-chomskyReviewBFSkinners1967" class="csl-entry" role="listitem">
———. 1967. <span>“A <span>Review</span> of <span>BF Skinner</span>’s <span>Verbal Behavior</span>.”</span> In <em>Readings in the <span>Psychology</span> of <span>Language</span></em>, edited by Murray S. Miron and Leon A. Jakobovits.
</div>
<div id="ref-churchPendulumSwungToo2011" class="csl-entry" role="listitem">
Church, Kenneth. 2011. <span>“A Pendulum Swung Too Far.”</span> <em>Linguistic Issues in Language Technology</em> 6.
</div>
<div id="ref-feigenbaumFifthGenerationArtificial1984" class="csl-entry" role="listitem">
Feigenbaum, Edward A., and Pamela McCorduck. 1984. <em>The <span>Fifth Generation</span>: <span>Artificial Intelligence</span> and <span>Japan</span>’s <span>Computer Challenge</span> to the <span>World</span></em>. Revised. New American Library.
</div>
<div id="ref-goldenTerrainContourMatching1980" class="csl-entry" role="listitem">
Golden, Joe P. 1980. <span>“Terrain Contour Matching (<span>TERCOM</span>): A Cruise Missile Guidance Aid.”</span> In <em>Image Processing for Missile Guidance</em>, 238:10–18. SPIE.
</div>
<div id="ref-hofstadterGodelEscherBach1999" class="csl-entry" role="listitem">
Hofstadter, Douglas R. 1999. <em>G<span>ö</span>del, <span>Escher</span>, <span>Bach</span>: An Eternal Golden Braid</em>. 20th-anniversary ed., [Repr.]. New York: Basic Books.
</div>
<div id="ref-hutchinsALPACFamousReport2003" class="csl-entry" role="listitem">
Hutchins, John. 2003. <span>“<span>ALPAC</span>: The (in) Famous Report.”</span> <em>Readings in Machine Translation</em> 14: 131–35.
</div>
<div id="ref-hutchinsFirstPublicDemonstration2005" class="csl-entry" role="listitem">
———. 2005. <span>“The First Public Demonstration of Machine Translation: The <span>Georgetown-IBM</span> System, 7th <span>January</span> 1954.”</span>
</div>
<div id="ref-irwinArtificialWorldsPerceptronic2024" class="csl-entry" role="listitem">
Irwin, Julia A. 2024. <span>“Artificial <span>Worlds</span> and <span>Perceptronic Objects</span>: <span>The CIA</span>’s <span class="nocase">Mid-century Automatic Target Recognition</span>.”</span> <em>Grey Room</em>, no. 97 (September): 6–35. <a href="https://doi.org/10.1162/grey_a_00415">https://doi.org/10.1162/grey_a_00415</a>.
</div>
<div id="ref-kanalRecognitionSystemDesign1964" class="csl-entry" role="listitem">
Kanal, Laveen N., and Neil C. Randall. 1964. <span>“Recognition System Design by Statistical Analysis.”</span> In <em>Proceedings of the 1964 19th <span>ACM</span> National Conference</em>, 42–501.
</div>
<div id="ref-kayProperPlaceMen1997" class="csl-entry" role="listitem">
Kay, Martin. 1997. <span>“The <span>Proper Place</span> of <span>Men</span> and <span>Machines</span> in <span>Language Translation</span>.”</span> <em>Machine Translation</em> 12 (1/2): 3–23. <a href="https://doi.org/10.1023/A:1007911416676">https://doi.org/10.1023/A:1007911416676</a>.
</div>
<div id="ref-knightAI30Years2016" class="csl-entry" role="listitem">
Knight, Will. 2016. <span>“An <span>AI</span> with 30 <span>Years</span>’ <span>Worth</span> of <span>Knowledge Finally Goes</span> to <span>Work</span>.”</span> <em>MIT Technology Review</em>, March.
</div>
<div id="ref-lenatCycLargescaleInvestment1995" class="csl-entry" role="listitem">
Lenat, Douglas B. 1995. <span>“Cyc: A Large-Scale Investment in Knowledge Infrastructure.”</span> <em>Communications of the ACM</em> 38 (11): 33–38. <a href="https://doi.org/10.1145/219717.219745">https://doi.org/10.1145/219717.219745</a>.
</div>
<div id="ref-lenatCycUsingCommon1985" class="csl-entry" role="listitem">
Lenat, Douglas B., Mayank Prakash, and Mary Shepherd. 1985. <span>“Cyc: <span>Using</span> Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks.”</span> <em>AI Magazine</em> 6 (4): 65–65.
</div>
<div id="ref-lenatCycMidtermReport1990" class="csl-entry" role="listitem">
Lenat, Douglas, and Ramanathan V. Guha. 1990. <span>“Cyc: <span>A</span> Midterm Report.”</span> <em>AI Magazine</em> 11 (3): 32–32.
</div>
<div id="ref-mccorduckMachinesWhoThink2004" class="csl-entry" role="listitem">
McCorduck, Pamela. 2004. <em>Machines Who Think: A Personal Inquiry into the History and Prospects of Artificial Intelligence</em>. 25th anniversary update. Natick, Mass: A.K. Peters.
</div>
<div id="ref-newellHumanProblemSolving1972" class="csl-entry" role="listitem">
Newell, Allen, and Herbert Alexander Simon. 1972. <em>Human Problem Solving</em>.
</div>
<div id="ref-nietzscheGoodEvilPrelude2002" class="csl-entry" role="listitem">
Nietzsche, Friedrich Wilhelm, Rolf-Peter Horstmann, and Judith Norman. 2002. <em>Beyond Good and Evil: Prelude to a Philosophy of the Future</em>. Cambridge Texts in the History of Philosophy. Cambridge ; New York: Cambridge University Press.
</div>
<div id="ref-nilssonQuestArtificialIntelligence2009" class="csl-entry" role="listitem">
Nilsson, Nils J. 2009. <em>The <span>Quest</span> for <span>Artificial Intelligence</span></em>. 1st edition. Cambridge ; New York: Cambridge University Press.
</div>
<div id="ref-ornsteinMechanicalTranslationNew1955" class="csl-entry" role="listitem">
Ornstein, Jacob. 1955. <span>“Mechanical <span>Translation</span>: <span>New Challenge</span> to <span>Communication</span>.”</span> <em>Science</em> 122 (3173): 745–48. <a href="https://doi.org/10.1126/science.122.3173.745">https://doi.org/10.1126/science.122.3173.745</a>.
</div>
<div id="ref-rumelhartLearningTensesEnglish1986" class="csl-entry" role="listitem">
Rumelhart, D. E., and J. L. McClelland. 1986. <span>“On Learning the Past Tenses of <span>English</span> Verbs.”</span> In <em>Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 2: Psychological and Biological Models</em>, 216–71. Cambridge, MA, USA: MIT Press.
</div>
<div id="ref-seidenbergQuasiregularityItsDiscontents2014" class="csl-entry" role="listitem">
Seidenberg, Mark S., and David C. Plaut. 2014. <span>“Quasiregularity and <span>Its Discontents</span>: <span>The Legacy</span> of the <span>Past Tense Debate</span>.”</span> <em>Cognitive Science</em> 38 (6): 1190–1228. <a href="https://doi.org/10.1111/cogs.12147">https://doi.org/10.1111/cogs.12147</a>.
</div>
<div id="ref-sheridanResearchLanguageTranslation1955" class="csl-entry" role="listitem">
Sheridan, Peter. 1955. <span>“Research in Language Translation on the <span>IBM</span> Type 701.”</span> <em>IBM Technical Newsletter</em> 9: 5–24.
</div>
<div id="ref-winogradUnderstandingNaturalLanguage1972" class="csl-entry" role="listitem">
Winograd, Terry. 1972. <span>“Understanding Natural Language.”</span> <em>Cognitive Psychology</em> 3 (1): 1–191. <a href="https://doi.org/10.1016/0010-0285(72)90002-3">https://doi.org/10.1016/0010-0285(72)90002-3</a>.
</div>
<div id="ref-winograd10ThinkingMachines1991" class="csl-entry" role="listitem">
———. 1991. <span>“10. <span>Thinking Machines</span>: <span>Can There Be</span>? <span>Are We</span>?”</span> In <em>The <span>Boundaries</span> of <span>Humanity</span></em>, edited by James J. Sheehan and Morton Sosna, 198–223. University of California Press. <a href="https://doi.org/10.1525/9780520313118-013">https://doi.org/10.1525/9780520313118-013</a>.
</div>
<div id="ref-wolframAppraisalINTERNISTI1995" class="csl-entry" role="listitem">
Wolfram, D. A. 1995. <span>“An Appraisal of <span>INTERNIST-I</span>.”</span> <em>Artificial Intelligence in Medicine</em> 7 (2): 93–116. <a href="https://doi.org/10.1016/0933-3657(94)00028-Q">https://doi.org/10.1016/0933-3657(94)00028-Q</a>.
</div>
<div id="ref-yeangFilteringNoiseAntiaircraft2023" class="csl-entry" role="listitem">
Yeang, Chen-Pang. 2023. <span>“Filtering <span>Noise</span> for <span>Antiaircraft Gunfire Control</span>.”</span> In <em>Transforming <span>Noise</span>: <span>A History</span> of <span>Its Science</span> and <span>Technology</span> from <span>Disturbing Sounds</span> to <span>Informational Errors</span>, 1900-1955</em>, edited by Chen-Pang Yeang, 0. Oxford University Press. <a href="https://doi.org/10.1093/oso/9780198887768.003.0011">https://doi.org/10.1093/oso/9780198887768.003.0011</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/yuxi-liu-wired\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb2" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Eulogy to Logical AI"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yuxi Liu"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-01-23"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2024-01-23"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [AI, scaling, history]</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Good Old-Fashioned AI never die. They just fade away."</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># image: "figure/banner.png"</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "finished"</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "likely"</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 3</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../utils/blog_utils/_macros.tex &gt;}}</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Translation</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One naturally wonders if the problem of translation could conceivably be treated as a problem in cryptography. When I look at an article in Russian, I say: "This is really written in English, but it has been coded in some strange symbols. I will now proceed to decode."</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- Warren Weaver, Letter to Norbert Wiener, 1947-03-04</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>During WWII, the science of communication and control took on a life-and-death importance. The mathematically perfect Enigma forced Allied mathematicians to turn their art of code into the science of information, so as to extract every last bit of information leaked out from the unknown enemy who was less than mathematically perfect, who made mistakes, who stuttered with verbal tics like <span class="in">`WETTER`</span> or <span class="in">`KEINE BESONDEREN EREIGNISSE`</span>. On two sides of the Atlantic, Alan Turing of computer science, and Claude Shannon of information theory, fought in this information warfare.</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>Before the war, some feared that the bombers would finally be the ultimate weapon, as a fleet of <span class="co">[</span><span class="ot">them will always get through</span><span class="co">](https://en.wikipedia.org/wiki/The_bomber_will_always_get_through)</span>. Bombing was becoming a cyborg activity. The bombers were flying so high and so fast, the bombardiers needed <span class="co">[</span><span class="ot">intricate bombsights</span><span class="co">](https://en.wikipedia.org/wiki/Norden_bombsight)</span> filled with mechanical calculators, just to calculate the correct time to drop the bombs.</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>But the bombers would not go through after all, as radar screens and flak cannons raised invisible walls in the sky, and the anti-aircraft fire became another cyborg activity. Norbert Wiener developed his control theory in the context of anti-aircraft fire and radar screening. He thought of both as a form of deadly communication. A radar speaks to the aircraft, "Who and where are you?" Despite itself, the aircraft must answer. The radar's job is to speak clearly with the right ping and listen carefully with the right filter. In this context, he developed the <span class="co">[</span><span class="ot">Wiener filter</span><span class="co">](https://en.wikipedia.org/wiki/Wiener_filter)</span>.</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>Anti-aircraft (AA) seems even less like a deadly communication, yet Wiener made it work. To shoot down an aircraft, one must predict where it will be a few seconds into the future, since that is how long bullets take to fly that high. The AA looks to the sky and asks, "Where are you going?". Despite itself, the aircraft speaks with where it had been in the past few seconds, as if writing a cursive word in the sky. The AA reads and understands this writing, and act accordingly. The past is a code for the future, like the Enigma is a code for the plaintext. <span class="co">[</span><span class="ot">@yeangFilteringNoiseAntiaircraft2023</span><span class="co">]</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>If the soldiers are always preparing to fight the previous war, the same seems true for some mathematicians. Wiener and his collaborator, Warren Weaver, decided to tackle the problem of machine translation with the same tools they developed for war. If information theory helps with breaking the Enigma code, would it not also help with breaking the language codes?</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>The wartime metaphor would become ominously appropriate with the Cold War.</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="fu">### Georgetown--IBM experiment</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>During the 1950s, electronic computers were mainly understood and used as tools for real-valued calculations, such as simulating nuclear explosions, the aerodynamics of ballistic missiles, macroeconomic planning, and other important real-valued functions that are necessary to safeguard freedom. However, there was already early attempts at using computers for symbolic calculations.</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>In a sense, this was quite old. Whereas Charles Babbage designed his computer as an arithmetic mill to grind out numerical tables, Ada Lovelace speculated that computers can grind out symbolic music too, as long as music and its transformation rules are encoded into integers.</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>On 1954-01-07, the world's first non-human translator appeared in the body of an IBM 701. At least, that is what the newspapers made it seam to be.</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>Back in 1952-06, at a MIT conference on machine translation, Leon Dostert was convinced that instead of arguments about whether MT works *in theory*, they needed to try it out on an actual problem to see if it would work *in practice*. This led to the <span class="co">[</span><span class="ot">Georgetown--IBM experiment</span><span class="co">](https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment)</span> 1.5 years later. It was the first public demonstration of machine translation -- from Russian to English, and was widely reported with titles like "Electronic brain translates Russian" or "Robot brain translates Russian into King's English". The project originated when a conference on machine translation took place at MIT i</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>The IBM 701 machine operated at $2000 \;\mathrm{FLOP/s}$ with read/write speed $3.6 \;\mathrm{kB/s}$ (in the form of 80-column punched cards). </span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>The program took up $2400 \;\mathrm{instruction} \times 18 \;\mathrm{bit/instruction} = 5.4 \;\mathrm{kB}$, whereas the dictionary took up $6000 \;\mathrm{word} \times 36 \;\mathrm{bit/word} = 27 \;\mathrm{kB}$. </span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>The dictionary is a table with 6 columns: Russian, English equivalent I, English equivalent II, Code 1, Code 2, Code 3. As we see, each Russian word has 1 or 2 possible English translations. The three <span class="in">`Code`</span>s are essentially grammar categories. As an example, the suffix <span class="in">`-a`</span> is coded as <span class="in">`(-a, of, , 131, 222, 25)`</span>, while the word stem <span class="in">`ugl-`</span> is coded as <span class="in">`(ugl-, coal, angle, 121, ***, 25)`</span>.</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>The dictionary contains just 250 lexical items (stems and endings). Its grammar has just 6 rules. All input sentences must be made of words that are of form either <span class="in">`stem`</span> or <span class="in">`stem-ending`</span>. Some example translations included:</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Mi pyeryedayem mislyi posryedstvom ryechyi.</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We transmit thoughts by means of speech.</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>The algorithm is essentially a word-substitution program, using the 6 rules to disambiguate, and to decide whether to switch a word with a previous word. The word-order switch is necessary since Russian puts prepositions as word suffixes. For example, <span class="in">`ugl-a`</span> would be word-substituted to <span class="in">`angle-by`</span>, but must be translated as <span class="in">`by angle`</span>.</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>The experiment was a hit, and there were some predictions of imminent breakthrough <span class="co">[</span><span class="ot">@hutchinsFirstPublicDemonstration2005</span><span class="co">]</span>:</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Such a device should be ready within three to five years... As soon as cards for Russian are completed, sets will be made for German and French. Then other Slavic, Germanic and Romance languages can be set up at will.</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>100 rules would be needed to govern 20,000 words for free translation.</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>From our perspective, these seem painfully optimistic. However, it was a common belief that electronic computers, like the IBM 701, were designed for numerical computation, something that is more difficult than natural language processing. As such, a machine translator needed not faster computers, but more data. Yet among the general optimism, there was a disquieting note:</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; the formulation of logic required to convert word meanings properly even in a small segment of two languages necessitates two and a half times as many instructions to the computer as are required to simulate the flight of a guided missile.</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">"701 Translator", IBM Press release</span><span class="co">](https://aclanthology.org/www.mt-archive.info/IBM-1954.pdf)</span><span class="at"> (1954-01-08)</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Give me code or give me nothing!" collapse="true" }</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>One thing I dislike about some technical histories and overviews is that I keep getting a cotton-like, vaporwave feeling in the brain after reading them. It is easy to read an abstract story. </span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>For example, many AI papers by OpenAI after 2020 has become like that. In any case, I looked up the program, which appeared in <span class="co">[</span><span class="ot">@ornsteinMechanicalTranslationNew1955</span><span class="co">]</span> as a single giant flowchart. I didn't read the spaghetti code in detail, but it seems to me that it first parses the input sequence into words and sub-words, then it starts from left to right, for each word/sub-word, find the rule that applies to it. Executing the rule would pick an English translation for that word/sub-word, and either switch that fragment of translation with the previous fragment, or not. There are 6 rules, of which I just copy one, since the others look similarly boring:</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Choice-Rearrangement. If first code is </span><span class="in">`131`</span><span class="at">, is third code of preceding complete word or either portion (root or ending) of preceding subdivided word equal to </span><span class="in">`23`</span><span class="at">? If so, adopt English equivalent II of word carrying </span><span class="in">`131`</span><span class="at"> and retain order of appearance of words in output; if not, adopt English equivalent I and reverse order of appearance of words in output.</span></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>The following is a rough sketch. It implements just rule 3, and even that is not quite correct, but it gives you an idea of how the program would go. I estimate that it should take about 100 lines to implement a fully correct version.</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse(sentence):</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> sentence.split(<span class="st">' '</span>)</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="op">==</span> stem <span class="op">++</span> prefix <span class="cf">for</span> some stem <span class="kw">in</span> stems <span class="kw">and</span> prefix <span class="kw">in</span> prefixes:</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>            replace word <span class="kw">in</span> words by [stem, prefix]</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> words</span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate(words):</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>    translation <span class="op">=</span> []</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(words):</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>        word <span class="op">=</span> words[i]</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> dictionary[word][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">131</span>: <span class="co"># rule 3</span></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dictionary[words[i<span class="op">-</span><span class="dv">1</span>]][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span>:</span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>                translation.append(dictionary[word][<span class="st">'English equivalent II'</span>])</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>                translation.append(dictionary[word][<span class="st">'English equivalent I'</span>])</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>                translation[i<span class="op">-</span><span class="dv">2</span>, i<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> [translation[i<span class="op">-</span><span class="dv">1</span>], translation[i<span class="op">-</span><span class="dv">2</span>]]</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> dictionary[word][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">141</span>: <span class="co"># rule 4</span></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> translation.join(<span class="st">' '</span>)</span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>The exact details on how the program was implemented on the IBM was non-trivial, since both the machine and the programming environment around it were designed for numerical computations, not discrete symbolic manipulations. <span class="co">[</span><span class="ot">@sheridanResearchLanguageTranslation1955</span><span class="co">]</span> described the details. The programming language LISP must wait until 1960 to appear. Dedicated to symbolic manipulations. It would dominate most of AI research until the 1980s.</span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>Another interesting fact is the amount of restrictions placed on the demo: 250 words, each word having just 1 or 2 possible translations, and each Russian word is either a full word or a <span class="in">`stem-suffix`</span>, etc. An even deeper restriction was entirely hidden from view: pronouns. In Russian, pronouns are often dropped when the verb form makes it clear. To avoid this problem, for all demonstrated sentences, the English pronouns occur only in translations of verbs in the third person plural.</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>The demo worked. The CIA started funding MT research at Georgetown University (eventually up to \$1,500,000), and other MT groups sprang up in America, Europe, and the Soviet Union. Subsequent research at Georgetown was based on a multi-level analysis (morphological, syntagmatic, syntax), later formalized as the <span class="co">[</span><span class="ot">Vanquois triangle</span><span class="co">](https://en.wikipedia.org/wiki/Bernard_Vauquois#Vauquois_triangle)</span>.</span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a><span class="al">![The Vanquois triangle.](figure/Vauquois%20triangle.png)</span></span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a><span class="fu">### Natural language compiler</span></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a><span class="fu">### Winter comes</span></span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a>In 1964, the US government established ALPAC, a committee of 7 linguists, to review the progress on machine translation. 2 years later, the committee released the ALPAC report.</span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@hutchinsALPACFamousReport2003</span><span class="co">]</span></span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>Evaluation by demo is bad, because </span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Demos are cherry-picked, and don't tell you how the system would work in practice.</span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Demos encourage an empirical kind of AI, an "artful deception" that is not science.</span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>The argument against full machine translation was simple but devastating:</span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Natural language is highly ambiguous.</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Disambiguation is not purely syntactical, and requires semantics -- world knowledge, or commonsense.</span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The amount of world knowledge, or commonsense, is extremely large, since after decades of manual entry, the machines still do not seem any closer to having commonsense.</span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a>There were several solutions:</span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Intelligence amplification: Instead of trying the mirage of fully automatic MT, we should </span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Brute force logical programming: Scale up commonsense by hiring more linguists to program in increasingly large chunks of the world.</span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The contrarian: AI is a mirage, and the failures of MT is a symptom of that.</span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a>From our vantage point, none of the solutions were correct. The actual solution turned out to be:</span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>The bitter lesson: Wait a few decades, then just train a giant neural network on a trillion words from the Internet.</span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a>There is a common mistake about the bitter lesson, that even Richard Sutton makes. It is not just that the bitter lesson is bitter, but also that it is *difficult*. People did not believe in it, not because they were afraid of bitterness, but because it was obviously stupid, a kind of straw man's argument.</span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>Case study in not taking the bitter lesson:</span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The case against machine translation as a solution to practical problems is overwhelming and has been made many times. I do not propose to repeat it in any detail here. It will, however, be worth a few words to make a *prima facie* case for the implausibility of practical machine translation if only so that the contrast with realistic approaches to the problem will be more striking... There is a great deal that computer scientists and linguists could contribute to the practical problem of producing translations, but, in their own interests as well as those of their customers, they should **never** be asked to provide an engineering solution to a problem that they only dimly understand.</span></span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I want to advocate a view of the problem in which machines are gradually, almost imperceptibly, allowed to take over certain functions in the overall translation process. First they will take over functions not essentially related to translation. Then, little by little, they will approach translation itself. The keynote will be *modesty*. At each stage, we will do only what we know we can do reliably.</span></span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@kayProperPlaceMen1997</span><span class="co">]</span></span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### Expert systems</span></span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Collapse</span></span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Bitter Lesson</span></span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-162"><a href="#cb2-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-163"><a href="#cb2-163" aria-hidden="true" tabindex="-1"></a>In 2011, Kenneth proposed a 20-year cycle between "Empiricism" (turns out it works) and "Rationalism" (it must work if you think carefully about it), and argued that we were on the brink of a return to Rationalism:</span>
<span id="cb2-164"><a href="#cb2-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-165"><a href="#cb2-165" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1950s: Empiricism (Shannon, Skinner, Firth, Harris)</span>
<span id="cb2-166"><a href="#cb2-166" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1970s: Rationalism (Chomsky, Minsky)</span>
<span id="cb2-167"><a href="#cb2-167" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1990s: Empiricism (IBM Speech Group, AT&amp;T Bell Labs)</span>
<span id="cb2-168"><a href="#cb2-168" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>2010s: A Return to Rationalism?</span>
<span id="cb2-169"><a href="#cb2-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-170"><a href="#cb2-170" aria-hidden="true" tabindex="-1"></a><span class="al">![The shift from Rationalism to Empiricism, as measured by the proportion of statistical papers submitted to the Association for Computational Linguistics. Based on two independent surveys by Bob Moore and Fred Jelinek.](figure/Kenneth_2011_fig_1.png)</span></span>
<span id="cb2-171"><a href="#cb2-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-172"><a href="#cb2-172" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; When we revived empiricism in the 1990s, we chose to reject the position of our teachers for pragmatic reasons. Data had become available like never before. What could we do with it? We argued that it is better to do something simple than nothing at all. Let's go pick some low hanging fruit. While trigrams cannot capture everything, they often work better than the alternatives... That argument made a lot of sense in the 1990s, especially given unrealistic expectations that had been raised during the previous </span><span class="sc">\[</span><span class="at">expert systems</span><span class="sc">\]</span><span class="at"> boom. But today's students might be faced with a very different set of challenges in the not-too-distant future. What should they do when most of the low hanging fruit has been pretty much picked over? ... we should expect Machine Translation research to make more and more use of richer and richer linguistic representations. So too, there will soon be a day when stress will become important for speech recognition.</span></span>
<span id="cb2-173"><a href="#cb2-173" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-174"><a href="#cb2-174" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@churchPendulumSwungToo2011</span><span class="co">]</span></span>
<span id="cb2-175"><a href="#cb2-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-176"><a href="#cb2-176" aria-hidden="true" tabindex="-1"></a>As of 2025, the pendulum has swung even deeper into Empiricism.</span>
<span id="cb2-177"><a href="#cb2-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-178"><a href="#cb2-178" aria-hidden="true" tabindex="-1"></a><span class="fu">## Vision</span></span>
<span id="cb2-179"><a href="#cb2-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-180"><a href="#cb2-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-181"><a href="#cb2-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-182"><a href="#cb2-182" aria-hidden="true" tabindex="-1"></a><span class="fu">## Speech</span></span>
<span id="cb2-183"><a href="#cb2-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-184"><a href="#cb2-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-185"><a href="#cb2-185" aria-hidden="true" tabindex="-1"></a>DARPA and the Speech Understanding Research program at Carnegie Mellon University</span>
<span id="cb2-186"><a href="#cb2-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-187"><a href="#cb2-187" aria-hidden="true" tabindex="-1"></a>Whither Speech Recognition? (1971)</span>
<span id="cb2-188"><a href="#cb2-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-189"><a href="#cb2-189" aria-hidden="true" tabindex="-1"></a>Whither speech recognition: The next 25 years (1993)</span>
<span id="cb2-190"><a href="#cb2-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-191"><a href="#cb2-191" aria-hidden="true" tabindex="-1"></a><span class="fu">## Games</span></span>
<span id="cb2-192"><a href="#cb2-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-193"><a href="#cb2-193" aria-hidden="true" tabindex="-1"></a>This chapter would be short since logical AI in games is well-known.</span>
<span id="cb2-194"><a href="#cb2-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-195"><a href="#cb2-195" aria-hidden="true" tabindex="-1"></a>Artificial intelligence has abandoned the quest</span>
<span id="cb2-196"><a href="#cb2-196" aria-hidden="true" tabindex="-1"></a>for certainty and truth. The new patchwork rationalism is built upon</span>
<span id="cb2-197"><a href="#cb2-197" aria-hidden="true" tabindex="-1"></a>mounds of _micro-truths_ gleaned through common sense introspection, ad</span>
<span id="cb2-198"><a href="#cb2-198" aria-hidden="true" tabindex="-1"></a>hoc programming and so-called _knowledge acquisition_ techniques for</span>
<span id="cb2-199"><a href="#cb2-199" aria-hidden="true" tabindex="-1"></a>interviewing experts. The grounding on this shifting sand is pragmatic</span>
<span id="cb2-200"><a href="#cb2-200" aria-hidden="true" tabindex="-1"></a>in the crude sense__If it seems to be working, it_s right.</span>
<span id="cb2-201"><a href="#cb2-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-202"><a href="#cb2-202" aria-hidden="true" tabindex="-1"></a>Samuel Checkers, DeepBlue.</span>
<span id="cb2-203"><a href="#cb2-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-204"><a href="#cb2-204" aria-hidden="true" tabindex="-1"></a><span class="fu">## General</span></span>
<span id="cb2-205"><a href="#cb2-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-206"><a href="#cb2-206" aria-hidden="true" tabindex="-1"></a>General Problem Solver, Symbolic hypothesis, McCarthy, Minsky</span>
<span id="cb2-207"><a href="#cb2-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-208"><a href="#cb2-208" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expert systems</span></span>
<span id="cb2-209"><a href="#cb2-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-210"><a href="#cb2-210" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The miracle product is knowledge, and the Japanese are planning to package and sell it the way other nations package and sell energy, food, or manufactured goods... The essence of the computer revolution is that the burden of producing the future knowledge of the world will be transferred from human heads to machine artifacts.</span>  </span>
<span id="cb2-211"><a href="#cb2-211" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-212"><a href="#cb2-212" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, Chapter 4</span><span class="co">]</span></span>
<span id="cb2-213"><a href="#cb2-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-214"><a href="#cb2-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-215"><a href="#cb2-215" aria-hidden="true" tabindex="-1"></a><span class="fu">## Language</span></span>
<span id="cb2-216"><a href="#cb2-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-217"><a href="#cb2-217" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chomsky</span></span>
<span id="cb2-218"><a href="#cb2-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-219"><a href="#cb2-219" aria-hidden="true" tabindex="-1"></a>HMM models, and indeed, *all* probabilistic models of English, must fail, because English has central embedding.</span>
<span id="cb2-220"><a href="#cb2-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-221"><a href="#cb2-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-222"><a href="#cb2-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-223"><a href="#cb2-223" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELIZA</span></span>
<span id="cb2-224"><a href="#cb2-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-225"><a href="#cb2-225" aria-hidden="true" tabindex="-1"></a>Weizenbaum became a fully human-centric critique of AI, culminating with *Computer Power and Human Reason: From Judgment to Calculation* (1976). In brief, the book had theese theses:</span>
<span id="cb2-226"><a href="#cb2-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-227"><a href="#cb2-227" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Computers might be intelligent, but they will never be wise (or to feel emotions, to love, etc). To "calculate" requires just intelligence, but to "judge" requires wisdom.</span>
<span id="cb2-228"><a href="#cb2-228" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The development of AI threatens to replace judgment with calculation, which will destroy human dignity. This replacement of judgment with calculation is an absurd political ideology, and must be resisted politically.</span>
<span id="cb2-229"><a href="#cb2-229" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>If, however, we do not resist, but keep following this political ideology, we would end up with the obviously absurd conclusion that "the brain is merely a meat machine". *Reductio ad absurdum*.</span>
<span id="cb2-230"><a href="#cb2-230" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>This dangerous development of AI did not come from a wise scientific project of understanding how human intelligence works, but from a megalomaniac, obsessive-compulsive desire to make machine parodies of human behavior. The method of AI development was heuristic, empirical, a kind of "I wonder what the machine would do if I write this program...", without a scientific theory.</span>
<span id="cb2-231"><a href="#cb2-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-232"><a href="#cb2-232" aria-hidden="true" tabindex="-1"></a>When the book came out, it received many reviews, and Weizenbaum wrote replies to these reviews. I found this one the funniest:</span>
<span id="cb2-233"><a href="#cb2-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-234"><a href="#cb2-234" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I have in mind also the teaching urged on us by some leaders of the AI community that there is nothing unique about the human species, that in fact, the embrace of the illusion of human uniqueness amounts to a kind of species prejudice and is unworthy of enlightened intellectuals. If we find nothing abhorrent in the use of artificially sustained, disembodied animal brains as computer components, and if there is nothing that uniquely distinguishes the human species from animal species, then -- need I spell out where that idea leads?</span></span>
<span id="cb2-235"><a href="#cb2-235" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-236"><a href="#cb2-236" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mccorduckMachinesWhoThink2004, page 370</span><span class="co">]</span></span>
<span id="cb2-237"><a href="#cb2-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-238"><a href="#cb2-238" aria-hidden="true" tabindex="-1"></a>Apparently Weizenbaum, in his human-centered wisdom, rejected Darwinism as well. In any case, he stopped doing AI research since 1970, so it is quite useless to talk more about him.</span>
<span id="cb2-239"><a href="#cb2-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-240"><a href="#cb2-240" aria-hidden="true" tabindex="-1"></a><span class="fu">### SHRDLU</span></span>
<span id="cb2-241"><a href="#cb2-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-242"><a href="#cb2-242" aria-hidden="true" tabindex="-1"></a>For his PhD in mathematics, Terry Winograd programmed the SHRDLU during the years 1968--1970. In the program, the user carries on a conversation with the computer, moving objects, naming collections and querying the state of a simplified "blocks world", essentially a virtual box filled with different blocks. It was in around 500 KB of LISP code.</span>
<span id="cb2-243"><a href="#cb2-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-244"><a href="#cb2-244" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The result of typing "Will you please stack up both of the red blocks and either a green cube or a pyramid?" [@winogradUnderstandingNaturalLanguage1972, figure 5]</span><span class="co">](figure/SHRDLU.png)</span></span>
<span id="cb2-245"><a href="#cb2-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-246"><a href="#cb2-246" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; it occupies around 200k of core (caution: indiscriminately running a job that big in the middle of the day is a good way to make enemies!!!!! Alway check the level of system usage before loading...)</span></span>
<span id="cb2-247"><a href="#cb2-247" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-248"><a href="#cb2-248" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- </span><span class="in">`mannew`</span><span class="at"> from </span><span class="co">[</span><span class="ot">the SHRDLU archive</span><span class="co">](code/SHRDLU.zip)</span><span class="at">.</span></span>
<span id="cb2-249"><a href="#cb2-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-250"><a href="#cb2-250" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The system answers questions, executes commands, and accepts information in normal English dialog. It uses semantic information and context to understand discourse and to disambiguate sentences. It combines a complete syntactic analysis of each sentence with a "heuristic understander" which uses different kinds of information about a sentence, other parts of the discourse, and general information about the world in deciding what the sentence means. It is based on the belief that a computer cannot deal reasonably with language unless it can "understand" the subject it is discussing. The program is given a detailed model of the knowledge needed by a simple robot having only a hand and an eye. We can give it instructions to manipulate toy objects, interrogate it about the scene, and give it information it will use in deduction. In addition to knowing the properties of toy objects, the program has a simple model of its own mentality. It can remember and discuss its plans and actions as well as carry them out. It enters into a dialog with a person, responding to English sentences with actions and English replies, and asking for clarification when its heuristic programs cannot understand a sentence through use of context and physical knowledge.</span></span>
<span id="cb2-251"><a href="#cb2-251" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-252"><a href="#cb2-252" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Procedures as a Representation for Data in a Computer Program for Understanding Natural Language</span></span>
<span id="cb2-253"><a href="#cb2-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-254"><a href="#cb2-254" aria-hidden="true" tabindex="-1"></a>As a fun side-note. The original SHRDLU had some manual fixes in the compiled assembly code (!). Terry Winograd's first research student rewrote much of SHRDLU so that it is portable. Some people sent letters (physical letters!) to request the code, and they would duly mail it out (by magnetic tape?). As one can imagine, only a few dozen source codes were mailed out.<span class="ot">[^shrdlu-resurrection]</span></span>
<span id="cb2-255"><a href="#cb2-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-256"><a href="#cb2-256" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shrdlu-resurrection]: </span><span class="co">[</span><span class="ot">SHRDLU resurrection</span><span class="co">](https://web.archive.org/web/20171117063022/http://www.semaphorecorp.com/misc/shrdlu.html)</span>. Created in 2002, and last updated on 2013-08-22.</span>
<span id="cb2-257"><a href="#cb2-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-258"><a href="#cb2-258" aria-hidden="true" tabindex="-1"></a>It is pretty amusing now that </span>
<span id="cb2-259"><a href="#cb2-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-260"><a href="#cb2-260" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Fifth Generation</span></span>
<span id="cb2-261"><a href="#cb2-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-262"><a href="#cb2-262" aria-hidden="true" tabindex="-1"></a>In 1982, the Japanese was ready to take on the world.</span>
<span id="cb2-263"><a href="#cb2-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-264"><a href="#cb2-264" aria-hidden="true" tabindex="-1"></a>With some irony, the Japanese might look back and call them the Gosei <span class="sc">\[</span>五世<span class="sc">\]</span>.</span>
<span id="cb2-265"><a href="#cb2-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-266"><a href="#cb2-266" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expert systems</span></span>
<span id="cb2-267"><a href="#cb2-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-268"><a href="#cb2-268" aria-hidden="true" tabindex="-1"></a><span class="fu">### Origins</span></span>
<span id="cb2-269"><a href="#cb2-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-270"><a href="#cb2-270" aria-hidden="true" tabindex="-1"></a>Beginning in 1965, Edward Feigenbaum and Joshua Lederberg developed DENDRAL, first as a model to understand how organic chemists do their daily work: Given a molecule with this kind of mass spectra, this melting point, or other experimental data, what might be its chemical formula and molecular structure?</span>
<span id="cb2-271"><a href="#cb2-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-272"><a href="#cb2-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-273"><a href="#cb2-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-274"><a href="#cb2-274" aria-hidden="true" tabindex="-1"></a><span class="fu">### The hype</span></span>
<span id="cb2-275"><a href="#cb2-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-276"><a href="#cb2-276" aria-hidden="true" tabindex="-1"></a><span class="fu">### The fall</span></span>
<span id="cb2-277"><a href="#cb2-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-278"><a href="#cb2-278" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One system for medical diagnosis, called </span><span class="co">[</span><span class="ot">CADUCEUS</span><span class="co">]</span><span class="at">(https://en.wikipedia.org/wiki/CADUCEUS_(expert_system)) (originally INTERNIST), has 500 disease profiles, 350 disease variations, several thousand symptoms, and 6,500 rules describing relations among symptoms. After fifteen years of development, the system is still not on the market. According to one report, it gave a correct diagnosis in only 75 percent of its carefully selected test cases. Nevertheless, Myers, the medical expert who developed it, "believes that the addition of another 50 </span><span class="co">[</span><span class="ot">diseases</span><span class="co">]</span><span class="at"> will make the system workable and, more importantly, practical."</span></span>
<span id="cb2-279"><a href="#cb2-279" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-280"><a href="#cb2-280" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@winograd10ThinkingMachines1991</span><span class="co">]</span></span>
<span id="cb2-281"><a href="#cb2-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-282"><a href="#cb2-282" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@wolframAppraisalINTERNISTI1995</span><span class="co">]</span></span>
<span id="cb2-283"><a href="#cb2-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-284"><a href="#cb2-284" aria-hidden="true" tabindex="-1"></a>Winograd argued that expert systems are structured like human bureaucracies, with formalized explicit rules, and so they have same strengths and weaknesses. This explains why they work only in stable and precise technical areas, where exceptions are not the rule. <span class="co">[</span><span class="ot">@winograd10ThinkingMachines1991</span><span class="co">]</span></span>
<span id="cb2-285"><a href="#cb2-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-286"><a href="#cb2-286" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cyc</span></span>
<span id="cb2-287"><a href="#cb2-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-288"><a href="#cb2-288" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; AI has for many years understood enough about representation and inference to tackle this project, but no one has sat down and done it... only by pulling together the latest human interface tools, Lisp machines, ideas of enforced semantics, and funding for a decade-long effort could we attempt a project of this scale. </span><span class="co">[</span><span class="ot">@lenatCycUsingCommon1985</span><span class="co">]</span></span>
<span id="cb2-289"><a href="#cb2-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-290"><a href="#cb2-290" aria-hidden="true" tabindex="-1"></a>In 1984, <span class="co">[</span><span class="ot">Douglas Lenat</span><span class="co">](https://en.wikipedia.org/wiki/Douglas_Lenat)</span> began the Cyc project, an ambitious attempt to scale symbolic AI up to the real world. Like most expert systems, the Cyc project consists of a giant knowledge base encoded in a LISP-like symbolic logic language, upon which inference engines can be run to produce logical reasoning. Unlike most expert systems, the ambition of Cyc was universal: Its knowledge base would not be restricted to expert knowledge in a particular domain, but *all* commonsense knowledge in *all* domains that humans have commonsense about.</span>
<span id="cb2-291"><a href="#cb2-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-292"><a href="#cb2-292" aria-hidden="true" tabindex="-1"></a>Even from the vantage point of 1985, it was clear to all that there was a lot of commonsense to code in, although few could have predicted that Lenat would persevere at it for over 30 years.</span>
<span id="cb2-293"><a href="#cb2-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-294"><a href="#cb2-294" aria-hidden="true" tabindex="-1"></a>They themselves underestimated the difficulty. In 1990, they confidently titled a paper "Cyc: A midterm report" <span class="co">[</span><span class="ot">@lenatCycMidtermReport1990</span><span class="co">]</span>, suggesting that they expected to be done around 1995.</span>
<span id="cb2-295"><a href="#cb2-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-296"><a href="#cb2-296" aria-hidden="true" tabindex="-1"></a>The progress report in 1995 stated that, while the system is far from done, they have at least manually entered $10^5$ "general concepts" and $10^6$ "commonsense axioms" into Cyc, at the price of 100 person-years. <span class="co">[</span><span class="ot">@lenatCycLargescaleInvestment1995</span><span class="co">]</span></span>
<span id="cb2-297"><a href="#cb2-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-298"><a href="#cb2-298" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Moreover, statistics, colocation, and frequency do not resolve such questions. But the task goes from impossible to trivial if one already knows a few things about boxes and pens, police and demonstrators, and water and teakettles. The same sort of chicken-and-egg relationship characterizes CYC and ML because learning occurs at the fringe of what one already knows. Therefore, in the early 1980s, when the rest of the world was so enthusiastic about Natural Language Understanding, Machine Learning, and AI in general, we were pessimistic. We concluded the only way out of this codependency would be to prime the pump by manually crafting a million axioms covering an appreciable fraction of the required knowledge. That knowledge would serve as a critical mass, enabling further knowledge collection through NLU and ML, beginning in the mid-1990s. Mary Shepherd and I embarked on that task in 1984, knowing we had little chance of success, but seeing no alternative but to try... we are now moving toward the transition point where NLU and ML are supported. The rest of the world is disillusioned and pessimistic about symbolic AI, but ironically, as CYC reaches closure, our hopes for NLU and ML in the next 10 years are very high.</span></span>
<span id="cb2-299"><a href="#cb2-299" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-300"><a href="#cb2-300" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@lenatCycLargescaleInvestment1995</span><span class="co">]</span></span>
<span id="cb2-301"><a href="#cb2-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-302"><a href="#cb2-302" aria-hidden="true" tabindex="-1"></a>In 2016, Lenat finally declared the Cyc project "done" and set about commercializing it.</span>
<span id="cb2-303"><a href="#cb2-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-304"><a href="#cb2-304" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Having spent the past 31 years memorizing an astonishing collection of general knowledge, the artificial-intelligence engine created by Doug Lenat is finally ready to go to work... most of what is left to be added is relevant to a specific area of expertise, such as finance or oncology.</span></span>
<span id="cb2-305"><a href="#cb2-305" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-306"><a href="#cb2-306" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Among other projects, the company is developing a personal assistant equipped with Cyc's general knowledge. This could perhaps lead to something similar to Siri... the CEO of Lucid says the new company is in talks with various others interested in using the Cyc knowledge base. Lucid has been working with the Cleveland Clinic, for example, to help automate the process of finding patients for clinical studies.</span></span>
<span id="cb2-307"><a href="#cb2-307" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-308"><a href="#cb2-308" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@knightAI30Years2016</span><span class="co">]</span></span>
<span id="cb2-309"><a href="#cb2-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-310"><a href="#cb2-310" aria-hidden="true" tabindex="-1"></a>That was essentially the last we heard from Cyc.</span>
<span id="cb2-311"><a href="#cb2-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-312"><a href="#cb2-312" aria-hidden="true" tabindex="-1"></a>When looking at this figure from 1985, one is simultaneously filled with respect and sadness, for they were facing impossible odds, and yet they charged right into it.</span>
<span id="cb2-313"><a href="#cb2-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-314"><a href="#cb2-314" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@lenatCycUsingCommon1985, Figure 1</span><span class="co">]</span>](figure/cyc_project_ontology.png)</span>
<span id="cb2-315"><a href="#cb2-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-316"><a href="#cb2-316" aria-hidden="true" tabindex="-1"></a>Their "midterm report" only accentuates this sense of tragedy, of seeing them fighting impossible odds, and losing. They saw with clarity that there is no shortcut to intelligence, no "Maxwell's equations of thought".</span>
<span id="cb2-317"><a href="#cb2-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-318"><a href="#cb2-318" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The majority of work in knowledge representation has dealt with the technicalities of relating predicate calculus to other formalisms and with the details of various schemes for default reasoning. There has almost been an aversion to addressing the problems that arise in actually representing large bodies of knowledge with content. However, deep, important issues must be addressed if we are to ever have a large intelligent knowledge-based program: What ontological categories would make up an adequate set for carving up the universe? How are they related? What are the important facts and heuristics most humans today know about solid objects? And so on. In short, we must bite the bullet.</span></span>
<span id="cb2-319"><a href="#cb2-319" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-320"><a href="#cb2-320" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We don't believe there is any shortcut to being intelligent, any yet-to-be-discovered Maxwell's equations of thought, any AI Risc architecture that will yield vast amounts of problem-solving power. Although issues such as architecture are important, no powerful formalism can obviate the need for a lot of knowledge.</span></span>
<span id="cb2-321"><a href="#cb2-321" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-322"><a href="#cb2-322" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By knowledge, we don't just mean dry, almanac-like or highly domain-specific facts. Rather, most of what we need to know to get by in the real world is prescientific (knowledge that is too commonsensical to be included in reference books; for example, animals live for a single solid interval of time, nothing can be in two places at once, animals don't like pain), dynamic (scripts and rules of thumb for solving problems) and metaknowledge (how to fill in gaps in the knowledge base, how to keep it organized, how to monitor and switch among problem-solving methods, and so on). Perhaps the hardest truth to face, one that AI has been trying to wriggle out of for 34 years, is that there is probably no elegant, effortless way to obtain this immense knowledge base. Rather, the bulk of the effort must (at least initially) be manual entry of assertion after assertion. </span><span class="co">[</span><span class="ot">@lenatCycMidtermReport1990</span><span class="co">]</span></span>
<span id="cb2-323"><a href="#cb2-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-324"><a href="#cb2-324" aria-hidden="true" tabindex="-1"></a><span class="fu">## Intelligence in the age of war machines</span></span>
<span id="cb2-325"><a href="#cb2-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-326"><a href="#cb2-326" aria-hidden="true" tabindex="-1"></a><span class="fu">### Early war machines</span></span>
<span id="cb2-327"><a href="#cb2-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-328"><a href="#cb2-328" aria-hidden="true" tabindex="-1"></a>The dream of peace produces war machines. Ancient Athenians dreamed of <span class="co">[</span><span class="ot">Talos</span><span class="co">](https://en.wikipedia.org/wiki/Talos)</span>, a bronze giant who defended Crete, while the Jews of Prague dreamed of <span class="co">[</span><span class="ot">Golem</span><span class="co">](https://en.wikipedia.org/wiki/Golem#Etymology)</span>. The ages has been too kind to Zhuge Liang, and his wheelbarrow, invented for carrying war supplies, became the legend of <span class="co">[</span><span class="ot">wooden robot oxen</span><span class="co">](https://en.wikipedia.org/wiki/Wooden_ox)</span>.</span>
<span id="cb2-329"><a href="#cb2-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-330"><a href="#cb2-330" aria-hidden="true" tabindex="-1"></a>The industrial revolution produced early ideas of feedback mechanism, such as the <span class="co">[</span><span class="ot">centrifugal governor</span><span class="co">](https://en.wikipedia.org/wiki/Centrifugal_governor)</span> and the <span class="co">[</span><span class="ot">gyro autopilot</span><span class="co">](https://en.wikipedia.org/wiki/Gyroscopic_autopilot)</span>. It took until WWII for someone to put together high explosives, slow burning fuel, and the feedback mechanism, to create the cruise missile. The first of its kind was the V-1 rocket, which already incorporates the basic features of all cruise missiles.</span>
<span id="cb2-331"><a href="#cb2-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-332"><a href="#cb2-332" aria-hidden="true" tabindex="-1"></a>The V-1 looks like a small unmanned jet airplane. It has the following senses: roll (gyro), pitch (gyro), yaw (magnetic compass), altitude (barometer), distance traveled (vane anemometer). The roll, pitch, yaw, and altitude are maintained by negative feedback. So for example, if the missile is heading east to the set-point of yaw, a valve would open, and compressed gas would force the rudder to turn, which yaws the missile west. As soon as the vane anemometer has turned a designated number, the missile considers itself to have reached the target. It turns off the engine and sharply dives to the ground, and explodes upon impact.</span>
<span id="cb2-333"><a href="#cb2-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-334"><a href="#cb2-334" aria-hidden="true" tabindex="-1"></a>Other than V-1 and V-2, there were no autonomous war machines during WWII, though there were several radio-controlled weapons such as <span class="co">[</span><span class="ot">explosive little tanks</span><span class="co">](https://en.wikipedia.org/wiki/Goliath_tracked_mine)</span> and <span class="co">[</span><span class="ot">little planes for target practice</span><span class="co">](https://en.wikipedia.org/wiki/Radioplane_OQ-2)</span>. Skinner, thinking outside (inside?) the box, worked on <span class="co">[</span><span class="ot">Project Pigeon</span><span class="co">](https://en.wikipedia.org/wiki/Project_Pigeon)</span>. He trained pigeons in skinner boxes to peck at the ship appearing on a screen. If the pigeon is pecking on the top-left, then the missile would turn to the bottom-right. In effect, the pigeon becomes the negative feedback controller. Though it was cancelled, it would have been considerably cheaper than <span class="co">[</span><span class="ot">the Japanese version</span><span class="co">](https://en.wikipedia.org/wiki/Kamikaze)</span> should it have ever reached production.</span>
<span id="cb2-335"><a href="#cb2-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-336"><a href="#cb2-336" aria-hidden="true" tabindex="-1"></a>&lt;video controls width=100%&gt;</span>
<span id="cb2-337"><a href="#cb2-337" aria-hidden="true" tabindex="-1"></a>  &lt;source src="figure/Project%20Pigeon.webm" type="video/webm" /&gt;</span>
<span id="cb2-338"><a href="#cb2-338" aria-hidden="true" tabindex="-1"></a>&lt;/video&gt;</span>
<span id="cb2-339"><a href="#cb2-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-340"><a href="#cb2-340" aria-hidden="true" tabindex="-1"></a>After WWII, some autonomous defense systems were developed and deployed, such as <span class="co">[</span><span class="ot">close-in weapon systems</span><span class="co">](https://en.wikipedia.org/wiki/Close-in_weapon_system)</span> on ships. These detect incoming incoming missiles and enemy aircraft by radar, computes their trajectories, and shoots them down. Since they must operate on the time-scale of seconds, they are fully automatic with no human in the loop. Despite this, these are quite uncontroversial and do not typically earn the title of "killer robots", presumably because compared to autonomous *offense*, defense is inherently more controllable and predictable in effect.</span>
<span id="cb2-341"><a href="#cb2-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-342"><a href="#cb2-342" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nuclear war machines</span></span>
<span id="cb2-343"><a href="#cb2-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-344"><a href="#cb2-344" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Deterrence is the art of producing in the mind of the enemy the fear to attack. And so, because of the automated and irrevocable decision making process which rules out human meddling, the doomsday machine is terrifying. It's simple to understand. And completely credible, and convincing... When you merely wish to bury bombs, there is no limit to the size. After that they are connected to a gigantic complex of computers. Now then, a specific and clearly defined set of circumstances, under which the bombs are to be exploded, is programmed into a tape memory bank.</span></span>
<span id="cb2-345"><a href="#cb2-345" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-346"><a href="#cb2-346" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- </span><span class="co">[</span><span class="ot">Dr. Strangelove</span><span class="co">](https://en.wikipedia.org/wiki/Dr._Strangelove)</span><span class="at"> (1964)</span></span>
<span id="cb2-347"><a href="#cb2-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-348"><a href="#cb2-348" aria-hidden="true" tabindex="-1"></a>During the Cold War, the following technological factors of nuclear weapons determined the grand nuclear strategy.</span>
<span id="cb2-349"><a href="#cb2-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-350"><a href="#cb2-350" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>First-strike nuclear offense is impossible to defend against. Some bombs will get through all defense.</span>
<span id="cb2-351"><a href="#cb2-351" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Nuclear weapon is so much more powerful than non-nuclear weapons, that the only proportionate deterrence to a nuclear attack is another nuclear attack.</span>
<span id="cb2-352"><a href="#cb2-352" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>First-strike capability is indistinguishable from second-strike capability.</span>
<span id="cb2-353"><a href="#cb2-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-354"><a href="#cb2-354" aria-hidden="true" tabindex="-1"></a>Because of (1) and (2), the only way to deter a nuclear first-strike was to threaten a nuclear second-strike. This is the <span class="co">[</span><span class="ot">MAD</span><span class="co">](https://en.wikipedia.org/wiki/Mutual_assured_destruction)</span> nuclear deterrence doctrine. Because deterrence requires enough bombs to survive a first-strike, both sides would rather build up more second-strike bombs than the other side's first-strike bombs. Because of (3), there aren't "second-strike bombs" vs "first-strike bombs", only bombs. Therefore, we have a positive feedback loop where both sides aim to have more bombs than the other -- the <span class="co">[</span><span class="ot">nuclear arms race</span><span class="co">](https://en.wikipedia.org/wiki/Nuclear_arms_race)</span>. Because having too many bombs increases the chance of accidents, both sides are motivated to slow down the race. Thus the <span class="co">[</span><span class="ot">ABM Treaty</span><span class="co">](https://en.wikipedia.org/wiki/Anti-Ballistic_Missile_Treaty)</span>, where both sides agree to *not* build many missile defense systems! This paradoxical treaty was designed to make both sides *more* vulnerable to second-strike, meaning that less bombs are needed to ensure second-strike capability.</span>
<span id="cb2-355"><a href="#cb2-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-356"><a href="#cb2-356" aria-hidden="true" tabindex="-1"></a>Both sides' nuclear technology went through several iterations, with increasing second-strike capability, and ended up with the "nuclear triad" of bombers that stay in the air 24/7, submarines hidden under the sea, and ICBMs hardened inside silos. Each of the three has different tradeoffs, necessitating all three to be maintained.</span>
<span id="cb2-357"><a href="#cb2-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-358"><a href="#cb2-358" aria-hidden="true" tabindex="-1"></a>Of course, even if the triad survives the first-strike, it is no good if they won't activate. The command center might be destroyed. The communication lines might be cut. The soldiers might refuse to launch based on their own conscience. All these dangers lead to the pressure to automate second-strike. The pinnacle of this logic was the <span class="co">[</span><span class="ot">Supersonic Low Altitude Missile (SLAM)</span><span class="co">](https://en.wikipedia.org/wiki/Supersonic_Low_Altitude_Missile)</span>, a cruise missile powered by a nuclear engine. The nuclear engine is like a fission nuclear reactor in nuclear power plants, except that the fission power does not boil water, but heat up air, which expands and shoots out from the tail of the missile, allowing it to fly at Mach 3.</span>
<span id="cb2-359"><a href="#cb2-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-360"><a href="#cb2-360" aria-hidden="true" tabindex="-1"></a>Despite having no GPS (it was the 1960s!), because the SLAM would fly $\sim 200 \;\mathrm{m}$ above ground, it could navigate itself by <span class="co">[</span><span class="ot">terrain contour matching</span><span class="co">](https://en.wikipedia.org/wiki/TERCOM)</span>: It compares a height-scan of the local terrain against a stored copy of the terrain. Even after dropping all its nuclear warheads, it can remain airborne for weeks, destroying the ground with sonic booms as overkill. The project was shelved in 1964, apparently considered too destabilizing, and they settled for just drilling the nuclear launch routines into the missileers until they work like robots that would not hesitate to execute the launch command.</span>
<span id="cb2-361"><a href="#cb2-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-362"><a href="#cb2-362" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The terrain contour matching algorithm. By a curious coincidence, the algorithm typically attempts to find a line segment within the stored terrain map that minimizes the [Mean Absolute Deviation](https://en.wikipedia.org/wiki/Average_absolute_deviation) with the local terrain of the missile... also with the "MAD" acronym. [@goldenTerrainContourMatching1980, figure 2]</span><span class="co">](figure/TERCOM.png)</span></span>
<span id="cb2-363"><a href="#cb2-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-364"><a href="#cb2-364" aria-hidden="true" tabindex="-1"></a>In the movie *Dr. Strangelove* (1964), nuclear deterrence was taken to its logical end point. In the movie, the Soviet Union built a "doomsday machine", which is a Cobalt bomb that when exploded, makes enough fallout to render the entire earth uninhabitable for a century. This was then connected to sensors around the Soviet Union, so that any nuclear attack automatically triggers it. Finally, the machine triggers if it detects attempts to un-trigger it, thus closing the logic loop and making it a fully automatic deterrence machine.<span class="ot">[^dead-hand]</span></span>
<span id="cb2-365"><a href="#cb2-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-366"><a href="#cb2-366" aria-hidden="true" tabindex="-1"></a><span class="ot">[^dead-hand]: </span>I was going to write something about the <span class="co">[</span><span class="ot">Dead Hand</span><span class="co">](https://en.wikipedia.org/wiki/Dead_Hand)</span> system, but after a brief search, the available information looks too much like conspiracy theory and rumors, so I will not.</span>
<span id="cb2-367"><a href="#cb2-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-368"><a href="#cb2-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### Intelligence</span></span>
<span id="cb2-369"><a href="#cb2-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-370"><a href="#cb2-370" aria-hidden="true" tabindex="-1"></a>During the Cold War, intelligence, in the sense of intelligence-gathering and reconnaissance was a vital area of artificial intelligence. </span>
<span id="cb2-371"><a href="#cb2-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-372"><a href="#cb2-372" aria-hidden="true" tabindex="-1"></a>Some of the early neural networks, such as MINOS II, was explicitly built with an objective of scanning aerial photographs for interesting military targets like tanks. <span class="co">[</span><span class="ot">@nilssonQuestArtificialIntelligence2009, pages 98--109</span><span class="co">]</span> The CIA even experimented with Rosenblatt's Mark I Perceptron machine for the same purpose <span class="co">[</span><span class="ot">@irwinArtificialWorldsPerceptronic2024</span><span class="co">]</span>. As an example, <span class="co">[</span><span class="ot">@kanalRecognitionSystemDesign1964</span><span class="co">]</span> describes a two-layered perceptron network, of type $\R^{N \times N} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>$. It works as follows:</span>
<span id="cb2-373"><a href="#cb2-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-374"><a href="#cb2-374" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The grayscale photo is down-scaled and binarized by convolution with a <span class="co">[</span><span class="ot">discrete Laplace filter</span><span class="co">](https://en.wikipedia.org/wiki/Discrete_Laplace_operator)</span>: $\R^{N \times N} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32}$.</span>
<span id="cb2-375"><a href="#cb2-375" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The weights for the 24 hidden perceptrons are constructed by <span class="co">[</span><span class="ot">linear discriminant analysis</span><span class="co">](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)</span>: $<span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24}$</span>
<span id="cb2-376"><a href="#cb2-376" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The output perceptron is learned by the <span class="co">[</span><span class="ot">perceptron learning rule</span><span class="co">](https://en.wikipedia.org/wiki/Perceptron#Learning_algorithm_for_a_single-layer_perceptron)</span>: $<span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>$.</span>
<span id="cb2-377"><a href="#cb2-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-378"><a href="#cb2-378" aria-hidden="true" tabindex="-1"></a>::: {#fig-kanal-1964-neural-tanks layout-ncol=2}</span>
<span id="cb2-379"><a href="#cb2-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-380"><a href="#cb2-380" aria-hidden="true" tabindex="-1"></a><span class="al">![Grayscale photos, some containing tanks, and some not.](figure/kanal_1964_fig_tank_nontank_mosaic.png)</span>{#fig-kanal-1964-neural-tanks-tank-nontank-mosaic}</span>
<span id="cb2-381"><a href="#cb2-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-382"><a href="#cb2-382" aria-hidden="true" tabindex="-1"></a><span class="al">![A picture of a tank after convolution with a discrete Laplace filter.](figure/kanal_1964_fig_binary_image_tank.png)</span>{#fig-kanal-1964-neural-tanks-binary-image-tank}</span>
<span id="cb2-383"><a href="#cb2-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-384"><a href="#cb2-384" aria-hidden="true" tabindex="-1"></a><span class="al">![The architecture of the network.](figure/kanal_1964_fig_architecture.png)</span>{#fig-kanal-1964-neural-tanks-architecture}</span>
<span id="cb2-385"><a href="#cb2-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-386"><a href="#cb2-386" aria-hidden="true" tabindex="-1"></a>Images from <span class="co">[</span><span class="ot">@kanalRecognitionSystemDesign1964</span><span class="co">]</span>.</span>
<span id="cb2-387"><a href="#cb2-387" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb2-388"><a href="#cb2-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-389"><a href="#cb2-389" aria-hidden="true" tabindex="-1"></a><span class="fu">### Strategic Computing Project</span></span>
<span id="cb2-390"><a href="#cb2-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-391"><a href="#cb2-391" aria-hidden="true" tabindex="-1"></a>The Strategic Computing Project (SCI) was named to resemble the <span class="co">[</span><span class="ot">Strategic Defense Initiative</span><span class="co">](https://en.wikipedia.org/wiki/Strategic_Defense_Initiative)</span>, better known as "Star Wars". The SDI was a project to </span>
<span id="cb2-392"><a href="#cb2-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-393"><a href="#cb2-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-394"><a href="#cb2-394" aria-hidden="true" tabindex="-1"></a><span class="fu">## Philosophy</span></span>
<span id="cb2-395"><a href="#cb2-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-396"><a href="#cb2-396" aria-hidden="true" tabindex="-1"></a>Astrophysicists, measuring the motion of galaxies, notice that the stars are rotating too fast. There is not enough matter to tether them, and they ought to fly out into the intergalactic emptiness. To solve this problem, they proposed "dark matter", unknown matter that provides the missing gravitational force, and physicists ever since had been searching them.</span>
<span id="cb2-397"><a href="#cb2-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-398"><a href="#cb2-398" aria-hidden="true" tabindex="-1"></a>Similarly, sometimes when you read through a field of study, you notice that the arguments seem to rotate around some kind of unspoken assumption that you might see if you just take all the books and throw them to the ground, so that they are all opened at random places. Then you turn your head and squint at the words refracted through the eyelids, the pupils, and the cornea, which you have repurposed as a primitive kind of optical computer. And you see the dark matter, the intellectual centers of gravity.</span>
<span id="cb2-399"><a href="#cb2-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-400"><a href="#cb2-400" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Under an invisible spell, they will each start out anew, only to end up revolving in the same orbit once again... their thinking is not nearly as much a discovery as it is a recognition, remembrance, a returning and homecoming into a distant, primordial, total economy of the soul, from which each concept once grew: -- to this extent, philosophizing is a type of atavism of the highest order.</span></span>
<span id="cb2-401"><a href="#cb2-401" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-402"><a href="#cb2-402" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@nietzscheGoodEvilPrelude2002, Section 1.20</span><span class="co">]</span></span>
<span id="cb2-403"><a href="#cb2-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-404"><a href="#cb2-404" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Symbolic Hypothesis</span></span>
<span id="cb2-405"><a href="#cb2-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-406"><a href="#cb2-406" aria-hidden="true" tabindex="-1"></a>General Problem Solver</span>
<span id="cb2-407"><a href="#cb2-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-408"><a href="#cb2-408" aria-hidden="true" tabindex="-1"></a>*Human Problem Solving*</span>
<span id="cb2-409"><a href="#cb2-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-410"><a href="#cb2-410" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@newellHumanProblemSolving1972, page 533</span><span class="co">]</span>](figure/human_problem_solving_behavior_graph.png)</span>
<span id="cb2-411"><a href="#cb2-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-412"><a href="#cb2-412" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@newellHumanProblemSolving1972, page 534</span><span class="co">]</span>](figure/human_problem_solving_transcript.png)</span>
<span id="cb2-413"><a href="#cb2-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-414"><a href="#cb2-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-415"><a href="#cb2-415" aria-hidden="true" tabindex="-1"></a>In <span class="co">[</span><span class="ot">their Turing award lecture of 1975</span><span class="co">](https://yuxi-liu-wired.github.io/docs/posts/1975-herbert-simon-allen-newell/)</span>, Allen Newell and Herbert Simon gave a definitive statement of the Physical Symbol System Hypothesis for AI, which they had labored under, first unconsciously but then consciously, since the early 1950s.</span>
<span id="cb2-416"><a href="#cb2-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-417"><a href="#cb2-417" aria-hidden="true" tabindex="-1"></a>They began by some examples of "qualitative structure" in science, which do not deal with numbers, but with symbols. For example, a basic statement of cell theory -- "organisms are made of little cells that are mostly alike" -- doesn't contain a single number, yet it has great significance. Such non-numerical discrete statements are made of "symbols", and they stated their **Physical Symbol System Hypothesis** (PSSH):</span>
<span id="cb2-418"><a href="#cb2-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-419"><a href="#cb2-419" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A physical symbol system has the necessary and sufficient means for general intelligent action.</span></span>
<span id="cb2-420"><a href="#cb2-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-421"><a href="#cb2-421" aria-hidden="true" tabindex="-1"></a>where a physical symbol system is essentially a machine that can be built in our physical world, and that manipulates with symbols. As an example, a digital computer running a LISP interpreter is a physical symbol system. We can attach cameras and wheels to the computer, so that the camera sends into the interpreter a symbolic representation of what it sees, and the wheels receives symbolic commands for motion. This is basically a robot according to the PSSH.</span>
<span id="cb2-422"><a href="#cb2-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-423"><a href="#cb2-423" aria-hidden="true" tabindex="-1"></a>They also gave a **Heuristic Search Hypothesis**:</span>
<span id="cb2-424"><a href="#cb2-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-425"><a href="#cb2-425" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A physical symbol system exercises its intelligence in problem solving by search-that is, by generating and progressively modifying symbol structures until it produces a solution structure.</span></span>
<span id="cb2-426"><a href="#cb2-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-427"><a href="#cb2-427" aria-hidden="true" tabindex="-1"></a>What is not said is equally revealing. In the lecture, there were over 100 mentions of the word "search", but the only statement about learning is... a mention of Plato's theory of <span class="co">[</span><span class="ot">anamnesis</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Anamnesis_(philosophy))! For them, a symbolic system starts out already with a solution generator and a solution tester, and problem-solving is nothing but heuristically searching over the generated solutions until one passes the tester. Indeed, in their telling, AI research is just search, not learning.</span>
<span id="cb2-428"><a href="#cb2-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-429"><a href="#cb2-429" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... During the first decade or so of artificial intelligence research, the study of problem solving was almost synonymous with the study of search processes. From our characterization of problems and problem solving, it is easy to see why this was so. In fact, it might be asked whether it could be otherwise. ...  There is no mystery where the information that guided the search came from. We need not follow Plato in endowing the symbol system with a previous existence in which it already knew the solution. A moderately sophisticated generator-test system did the trick without invoking reincarnation.</span></span>
<span id="cb2-430"><a href="#cb2-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-431"><a href="#cb2-431" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cognitivism</span></span>
<span id="cb2-432"><a href="#cb2-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-433"><a href="#cb2-433" aria-hidden="true" tabindex="-1"></a>There was a persistent legend about a certain psychologist, that he educated his own children with <span class="co">[</span><span class="ot">skinner boxes</span><span class="co">](https://en.wikipedia.org/wiki/Operant_conditioning_chamber)</span>. While just a legend, the real B. F. Skinner did have a philosophy as radical as the legend suggests.</span>
<span id="cb2-434"><a href="#cb2-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-435"><a href="#cb2-435" aria-hidden="true" tabindex="-1"></a>In the 1950s, Skinner dominated behaviorism, which dominated American psychology. In short, behaviorism models animal behavior as stimulus-response reflexes, which can be understood as parameterized functions $a_\theta(o)$, where $o$ stands for the observational stimulus, $\theta$ the internal parameters of the animal, and $a_\theta(o)$ the response action. The parameters $\theta$ is a function of the previous history of stimuli and reward/punishments: $(o_0, a_0, r_0, o_1, a_1, r_1, \dots)$. The set up is the same as modern reinforcement learning (RL).</span>
<span id="cb2-436"><a href="#cb2-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-437"><a href="#cb2-437" aria-hidden="true" tabindex="-1"></a><span class="ot">[^skinner-box]</span>:</span>
<span id="cb2-438"><a href="#cb2-438" aria-hidden="true" tabindex="-1"></a>    <span class="co">[</span><span class="ot">Feynman told of the following maze-running rat legend</span><span class="co">](https://gwern.net/maze)</span>:</span>
<span id="cb2-439"><a href="#cb2-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-440"><a href="#cb2-440" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; He had a long corridor with doors all along one side where the rats came in, and doors along the other side where the food was. He wanted to see if he could train the rats to go in at the third door down from wherever he started them off. No. The rats went immediately to the door where the food had been the time before. The question was, how did the rats know, because the corridor was so beautifully built and so uniform, that this was the same door as before? Obviously there was something about the door that was different from the other doors. So he painted the doors very carefully, arranging the textures on the faces of the doors exactly the same. Still the rats could tell. Then he thought maybe the rats were smelling the food, so he used chemicals to change the smell after each run. Still the rats could tell. Then he realized the rats might be able to tell by seeing the lights and the arrangement in the laboratory like any commonsense person. So he covered the corridor, and, still the rats could tell. He finally found that they could tell by the way the floor sounded when they ran over it. And he could only fix that by putting his corridor in sand. So he covered one after another of all possible clues and finally was able to fool the rats so that they had to learn to go in the third door. If he relaxed any of his conditions, the rats could tell.</span></span>
<span id="cb2-441"><a href="#cb2-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-442"><a href="#cb2-442" aria-hidden="true" tabindex="-1"></a>The great thing about skinner boxes is that they are standardized to be lightproof, soundproof, and whatever-proof, thus controlling for all confounding variables. Before skinner boxes, mouse experiments were full of confounding variables, and had a kind of replication crisis in the 1930s. With the skinner box, the degrees of rat freedom are minimized, turning rats into standardized systems. This finally allowed measurable progress, allowing the breakout success of behaviorism in the 1950s.<span class="ot">[^skinner-box]</span></span>
<span id="cb2-443"><a href="#cb2-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-444"><a href="#cb2-444" aria-hidden="true" tabindex="-1"></a>Skinner's ambitions went far beyond rats. In 1957, he published <span class="co">[</span><span class="ot">*Verbal Behavior*</span><span class="co">](https://en.wikipedia.org/wiki/Verbal_Behavior)</span>, in which he explained human language as stimulus-response networks, built up piece by piece during child development. To give an example, when one searches for a book with a title "Verbal Behavior", one would say "Verbal Behavior, Verbal Behavior, Verbal Behavior..." (a "self-echoic") while the eye scans the shelf. When the visual stimulus matches the verbal stimulus, the "grab book" action is triggered (a "tact"). The touch of the hand with the book then stops self-echoic behavior. In Skinner's terms, this verbal behavior is a "<span class="co">[</span><span class="ot">descriptive autoclitic</span><span class="co">](https://en.wikipedia.org/wiki/Autoclitic)</span>".</span>
<span id="cb2-445"><a href="#cb2-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-446"><a href="#cb2-446" aria-hidden="true" tabindex="-1"></a>He was at his most radical in <span class="co">[</span><span class="ot">*Beyond Freedom and Dignity* (1971)</span><span class="co">](https://en.wikipedia.org/wiki/Beyond_Freedom_and_Dignity)</span>, which essentially argued that human society will be reorganized according to behaviorist principles. Instead of the indirect and unreliable behavior control using verbal moral judgment, a society would use more direct operant conditioning methods that are experimentally proven by behaviorist psychologists.</span>
<span id="cb2-447"><a href="#cb2-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-448"><a href="#cb2-448" aria-hidden="true" tabindex="-1"></a>Though behaviorism has remained alive and well to this day, linguistics took a sudden turn around 1960 thanks to Noam Chomsky. According to legend, Chomsky wrote a review of *Verbal Behavior* in 1959, in which he soundly routed behaviorist linguistics [@chomskyReviewSkinnersVerbal1959]. The truth is more complicated, since Chomsky also wrote several other famous works like [*Syntactic Structures* (1957)](https://en.wikipedia.org/wiki/Syntactic_Structures), [*Aspects of the Theory of Syntax* (1967)](https://en.wikipedia.org/wiki/Aspects_of_the_Theory_of_Syntax), and the foundational papers on formal grammar like the <span class="co">[</span><span class="ot">Chomsky hierarchy</span><span class="co">](https://en.wikipedia.org/wiki/Chomsky_hierarchy)</span>.</span>
<span id="cb2-449"><a href="#cb2-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-450"><a href="#cb2-450" aria-hidden="true" tabindex="-1"></a>Chomsky argued that there are two ways of doing research in psychology and linguistics: "empiricism" and "rationalism". Skinner's book was the best example of empiricism, and since Skinner's book is wrong, the book becomes a *reductio ad absurdum* of empiricism. Instead, one must turn back to rationalist psychology and linguistics.</span>
<span id="cb2-451"><a href="#cb2-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-452"><a href="#cb2-452" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I had intended this review not specifically as a criticism of Skinner's speculations regarding language, but rather as a more general critique of behaviorist (I would now prefer to say "empiricist") speculation as to the nature of higher mental processes... I do not, in other words, see any way in which his proposals can be substantially improved within the general framework of behaviorist or neobehaviorist, or, more generally, empiricist ideas that has dominated much of modern linguistics, psychology, and philosophy. The conclusion that I hoped to establish in the review, by discussing these speculations in their most explicit and detailed form, was that the general point of view was largely mythology, and that its widespread acceptance is not the result of empirical support, persuasive reasoning, or the absence of a plausible alternative.</span></span>
<span id="cb2-453"><a href="#cb2-453" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-454"><a href="#cb2-454" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- Preface to the 1967 reprint. </span><span class="co">[</span><span class="ot">@chomskyReviewBFSkinners1967</span><span class="co">]</span></span>
<span id="cb2-455"><a href="#cb2-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-456"><a href="#cb2-456" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Sub-symbolic Hypothesis</span></span>
<span id="cb2-457"><a href="#cb2-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-458"><a href="#cb2-458" aria-hidden="true" tabindex="-1"></a>The dominance of the Symbolic Hypothesis was never complete. There were often objections to it.</span>
<span id="cb2-459"><a href="#cb2-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-460"><a href="#cb2-460" aria-hidden="true" tabindex="-1"></a>In 1972, Hubert Dreyfus raised a fuss with a book *What Computers Can't Do: The Limits of Artificial Intelligence*. Unfortunately, his work was based on the phenomenology of Merleau-Ponty and Heidegger, who wrote like *real and genuine* philosophers,<span class="ot">[^feigenbaum-cotton-candy]</span> so I just resorted to checking <span class="co">[</span><span class="ot">his Wikipedia article</span><span class="co">](https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence)</span>. From what I gathered, his argument was that the Symbolic Hypothesis is flawed in the sense that it is too "closed".</span>
<span id="cb2-461"><a href="#cb2-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-462"><a href="#cb2-462" aria-hidden="true" tabindex="-1"></a><span class="ot">[^feigenbaum-cotton-candy]</span>: </span>
<span id="cb2-463"><a href="#cb2-463" aria-hidden="true" tabindex="-1"></a>    Edward Feigenbaum's reaction is representative of most AI scientists:</span>
<span id="cb2-464"><a href="#cb2-464" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-465"><a href="#cb2-465" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; What artificial intelligence needs is a good Dreyfus. The conceptual problems in AI are really rough, and a guy like that could be an enormous help... But Dreyfus bludgeons us over the head with stuff he's misunderstood and is obsolete anyway -- and every time you confront him with one more intelligent program, he says, "I never said a computer couldn't do that." And what does he offer us instead? Phenomenology! That ball of fluff! That cotton candy! [@mccorduckMachinesWhoThink2004, pages 229--230]</span></span>
<span id="cb2-466"><a href="#cb2-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-467"><a href="#cb2-467" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Douglas Hofstadter</span><span class="co">](https://en.wikipedia.org/wiki/Douglas_Hofstadter)</span> raised a similar objection, but from within the logical AI tradition. His essential point was that logical AI, as conceived by Simon and Newell, is a closed system. For example, a chess computer might play a perfect chess even when the room is on fire. The concept of fire, or indeed anything that is beyond the mathematical strucure of chess, does not feature in the computer's symbolic universe, and so it does not exist for the computer.<span class="ot">[^holt-chess-fire]</span> Whereas Dreyfus argued that intelligence is open by the "cotton candy" of phenomenology, sieging the head from the outside in, Hofstadter used the Gödel incompleteness theorems to break the head open, from the inside out.</span>
<span id="cb2-468"><a href="#cb2-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-469"><a href="#cb2-469" aria-hidden="true" tabindex="-1"></a><span class="ot">[^holt-chess-fire]</span>:</span>
<span id="cb2-470"><a href="#cb2-470" aria-hidden="true" tabindex="-1"></a>    This example was given by Anatol Holt at ARPA Principal Investigators' Conference in 1974, and quoted in <span class="co">[</span><span class="ot">@winograd10ThinkingMachines1991</span><span class="co">]</span>:</span>
<span id="cb2-471"><a href="#cb2-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-472"><a href="#cb2-472" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; A brilliant chess move while the room is filling with smoke because the house is burning down does not show intelligence. If the capacity for brilliant chess moves without regard to life circumstances deserves a name, I would naturally call it "artificial intelligence."</span></span>
<span id="cb2-473"><a href="#cb2-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-474"><a href="#cb2-474" aria-hidden="true" tabindex="-1"></a>The rough idea is that any symbolic system that is powerful enough would be incomplete, and furthermore, would "reflect" its own incompleteness. The incompleteness theorems state that in any sufficiently powerful formal system, there are statements that are true about the system that cannot be proven within the system. For example, let $\Sigma$ be the logical system of Peano arithmetics, then by the incompleteness theorems, there are sentences like <span class="co">[</span><span class="ot">Rosser's sentence</span><span class="co">](https://en.wikipedia.org/wiki/Rosser%27s_trick)</span>, or "PA is consistent", which are *provably unprovable* assuming PA is consistent.</span>
<span id="cb2-475"><a href="#cb2-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-476"><a href="#cb2-476" aria-hidden="true" tabindex="-1"></a>Stated in another way, arithmetical truth cannot be defined in arithmetic -- <span class="co">[</span><span class="ot">Tarski's undefinability</span><span class="co">](https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem)</span>.</span>
<span id="cb2-477"><a href="#cb2-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-478"><a href="#cb2-478" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; O God, I could be bounded in a nut shell and count</span></span>
<span id="cb2-479"><a href="#cb2-479" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; myself a king of infinite space, were it not that I</span></span>
<span id="cb2-480"><a href="#cb2-480" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; have bad dreams.</span></span>
<span id="cb2-481"><a href="#cb2-481" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-482"><a href="#cb2-482" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Hamlet, Act 2, Scene 2</span></span>
<span id="cb2-483"><a href="#cb2-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-484"><a href="#cb2-484" aria-hidden="true" tabindex="-1"></a>In the context of AI, this means that a symbolic system, no matter how complex, will always have limitations in representing and reasoning about the world, even if the world is but itself. We need not assume there is an "outside". The symbolic system, even when floating in a mathematical vacuum, creates its own outside.</span>
<span id="cb2-485"><a href="#cb2-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-486"><a href="#cb2-486" aria-hidden="true" tabindex="-1"></a>His solution was to add in some "strange loops", which would both create general intelligence and create consciousness in one fell swoop. These strange loops are hierarchical structures where crossing levels leads back to the starting point. In the context of AI, Hofstadter proposed that implementing strange loops within a symbolic system would allow the system to refer to itself and its own structure, potentially leading to self-awareness and general intelligence. This self-referential capability would enable the system to overcome the limitations imposed by the incompleteness theorems and exhibit more flexible and human-like intelligence.</span>
<span id="cb2-487"><a href="#cb2-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-488"><a href="#cb2-488" aria-hidden="true" tabindex="-1"></a>Hofstadter was a far better writer than Dreyfus, and his 1979 book *Gödel, Escher, Bach* was a popular hit among both the common people and the computer scientists. Despite this, the trajectory of AI did not go as he expected.</span>
<span id="cb2-489"><a href="#cb2-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-490"><a href="#cb2-490" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There may be programs which can beat anyone at chess, but they will not be exclusively chess players. They will be programs of general intelligence, and they will be just as temperamental as people. "Do you want to play chess?" "No, I'm bored with chess. Let's talk about poetry." </span><span class="co">[</span><span class="ot">@hofstadterGodelEscherBach1999, page 678</span><span class="co">]</span></span>
<span id="cb2-491"><a href="#cb2-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-492"><a href="#cb2-492" aria-hidden="true" tabindex="-1"></a>In the preface to the second edition (1999), Hofstadter admitted that this prediction went way off, but still committed to the philosophical belief behind these. Unfortunately, the disappointments did not stop coming. In </span>
<span id="cb2-493"><a href="#cb2-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-494"><a href="#cb2-494" aria-hidden="true" tabindex="-1"></a>With the rise of Transformer-based language models, . He expressed his confusion and traumatic response in a 2023 interview:</span>
<span id="cb2-495"><a href="#cb2-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-496"><a href="#cb2-496" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">In 1960,</span><span class="sc">\]</span><span class="at"> I knew how computers worked, and I knew how extraordinarily rigid they were. You made the slightest typing error and it completely ruined your program... It felt as if artificial intelligence was the art of trying to make very rigid systems behave as if they were fluid... I felt it would be hundreds of years before anything even remotely like a human mind would be asymptotically approaching the level of the human mind, but from beneath... But when certain systems started appearing maybe 20 years ago, they gave me pause. And then this started happening at an accelerating pace where unreachable goals and things that computers shouldn't be able to do started toppling. The defeat of Gary Kasparov by Deep Blue, and then going on to Go systems, systems that could defeat some of the best Go players in the world. And then systems got better and better at translation between languages and then at producing intelligible responses to difficult questions in natural language, and even writing poetry.</span></span>
<span id="cb2-497"><a href="#cb2-497" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb2-498"><a href="#cb2-498" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; My whole intellectual edifice, my system of beliefs--it's a very traumatic experience when some of your most core beliefs about the world start collapsing... I think about it practically all the time, every single day... and it overwhelms me and depresses me in a way that I haven't been depressed for a very long time.</span></span>
<span id="cb2-499"><a href="#cb2-499" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb2-500"><a href="#cb2-500" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Reflections on AI</span><span class="co">](https://www.buzzsprout.com/222312/episodes/13125914)</span><span class="at">, interview with Douglas Hofstadter by Amy Jo Kim (2023-06-29)</span></span>
<span id="cb2-501"><a href="#cb2-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-502"><a href="#cb2-502" aria-hidden="true" tabindex="-1"></a><span class="fu">### Connectionism, the past tense debate, and whatever</span></span>
<span id="cb2-503"><a href="#cb2-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-504"><a href="#cb2-504" aria-hidden="true" tabindex="-1"></a>"Connectionism" is a word you don't see much nowadays, but it was a big word back in the 1980s. It is hard to pin down, but if I summarize it, it is the result of philosophers in the 1980s noticing how researchers were trying neural networks on problems that had defied logical AI approaches, and somehow achieved state of the art, way past expectations. They say, "Weird! How is it possible for neural networks, written by people not having a deep knowledge of the problem domain, using such simplistic features, to work better than the best logical AI? I must philosophize this at once!"</span>
<span id="cb2-505"><a href="#cb2-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-506"><a href="#cb2-506" aria-hidden="true" tabindex="-1"></a>Two clear camps immediately formed. On one side were the connectionists with <span class="co">[</span><span class="ot">Paul Churchland</span><span class="co">](https://en.wikipedia.org/wiki/Paul_Churchland)</span>, <span class="co">[</span><span class="ot">Patricia Churchland</span><span class="co">](https://en.wikipedia.org/wiki/Patricia_Churchland)</span>, <span class="co">[</span><span class="ot">Paul Smolensky</span><span class="co">](https://en.wikipedia.org/wiki/Paul_Smolensky)</span>, <span class="co">[</span><span class="ot">Jeffrey Elman</span><span class="co">](https://en.wikipedia.org/wiki/Jeffrey_Elman)</span>. On the other side were the cognitivists (or perhaps the rationalists) <span class="co">[</span><span class="ot">Jerry Fodor</span><span class="co">](https://en.wikipedia.org/wiki/Jerry_Fodor)</span>, <span class="co">[</span><span class="ot">Zenon Pylyshyn</span><span class="co">](https://en.wikipedia.org/wiki/Zenon_Pylyshyn)</span>, with the spirit of Noam Chomsky always present in the background.</span>
<span id="cb2-507"><a href="#cb2-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-508"><a href="#cb2-508" aria-hidden="true" tabindex="-1"></a>Chapter 18 of *Parallel Distributed Processing* vol. 2 bore the unassuming title "On learning the past tenses of verbs in English" <span class="co">[</span><span class="ot">@rumelhartLearningTensesEnglish1986</span><span class="co">]</span>. Nobody would have predicted that it ignited a long and bitter dispute "the past tense debate". </span>
<span id="cb2-509"><a href="#cb2-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-510"><a href="#cb2-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-511"><a href="#cb2-511" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@seidenbergQuasiregularityItsDiscontents2014</span><span class="co">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="faux-block"><a href="https://forms.gle/LBFx3sUqrD9LLLHb7/">Give anonymous feedback</a></span></p>
</div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>
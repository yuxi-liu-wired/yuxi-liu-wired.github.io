<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2024-01-23">
<meta name="description" content="Good Old-Fashioned AI never die. They just fade away.">

<title>Eulogy to Logical AI – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-02dbcd97b8f3f8f7231673c1d5e4b7bf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-64d6e61f7496feb4de6eb78c8a3b8add.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Eulogy to Logical AI – Yuxi on the Wired">
<meta property="og:description" content="Good Old-Fashioned AI never die. They just fade away.">
<meta property="og:image" content="https://yuxi-liu-wired.github.io/essays/posts/logical-ai-eulogy/figure/Georgetown-IBM_punched_card.png">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta property="og:image:height" content="491">
<meta property="og:image:width" content="919">
<meta name="twitter:title" content="Eulogy to Logical AI – Yuxi on the Wired">
<meta name="twitter:description" content="Good Old-Fashioned AI never die. They just fade away.">
<meta name="twitter:image" content="https://yuxi-liu-wired.github.io/essays/posts/logical-ai-eulogy/figure/Georgetown-IBM_punched_card.png">
<meta name="twitter:image-height" content="491">
<meta name="twitter:image-width" content="919">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://bair.berkeley.edu/"> <i class="bi bi-folder-symlink" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi.liu.1995@gmail.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Eulogy to Logical AI</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Good Old-Fashioned AI never die. They just fade away.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">scaling</div>
                <div class="quarto-category">history</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 23, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 23, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#translation" id="toc-translation" class="nav-link active" data-scroll-target="#translation">Translation</a>
  <ul class="collapse">
  <li><a href="#georgetownibm-experiment" id="toc-georgetownibm-experiment" class="nav-link" data-scroll-target="#georgetownibm-experiment">Georgetown–IBM experiment</a></li>
  <li><a href="#subsequent-work" id="toc-subsequent-work" class="nav-link" data-scroll-target="#subsequent-work">Subsequent work</a></li>
  <li><a href="#winter-comes" id="toc-winter-comes" class="nav-link" data-scroll-target="#winter-comes">Winter comes</a></li>
  <li><a href="#the-alignment-problem" id="toc-the-alignment-problem" class="nav-link" data-scroll-target="#the-alignment-problem">The alignment problem</a></li>
  <li><a href="#abbyys-last-stand" id="toc-abbyys-last-stand" class="nav-link" data-scroll-target="#abbyys-last-stand">ABBYY’s last stand</a></li>
  </ul></li>
  <li><a href="#sec-speech" id="toc-sec-speech" class="nav-link" data-scroll-target="#sec-speech">Speech</a>
  <ul class="collapse">
  <li><a href="#early-days" id="toc-early-days" class="nav-link" data-scroll-target="#early-days">Early days</a></li>
  <li><a href="#logical-asr" id="toc-logical-asr" class="nav-link" data-scroll-target="#logical-asr">Logical ASR</a></li>
  <li><a href="#arpa-speech-understanding-project" id="toc-arpa-speech-understanding-project" class="nav-link" data-scroll-target="#arpa-speech-understanding-project">ARPA Speech Understanding Project</a></li>
  <li><a href="#linguists-fired" id="toc-linguists-fired" class="nav-link" data-scroll-target="#linguists-fired">Linguists fired</a></li>
  <li><a href="#a-farewell-to-linguists" id="toc-a-farewell-to-linguists" class="nav-link" data-scroll-target="#a-farewell-to-linguists">A farewell to linguists</a></li>
  <li><a href="#text-to-speech" id="toc-text-to-speech" class="nav-link" data-scroll-target="#text-to-speech">Text to speech</a></li>
  </ul></li>
  <li><a href="#vision" id="toc-vision" class="nav-link" data-scroll-target="#vision">Vision</a></li>
  <li><a href="#logic-and-logistics" id="toc-logic-and-logistics" class="nav-link" data-scroll-target="#logic-and-logistics">Logic and logistics</a>
  <ul class="collapse">
  <li><a href="#planning" id="toc-planning" class="nav-link" data-scroll-target="#planning">Planning</a></li>
  <li><a href="#mechanizing-mathematics" id="toc-mechanizing-mathematics" class="nav-link" data-scroll-target="#mechanizing-mathematics">Mechanizing Mathematics</a></li>
  <li><a href="#information-processing-system" id="toc-information-processing-system" class="nav-link" data-scroll-target="#information-processing-system">Information Processing System</a></li>
  <li><a href="#the-drosophila-of-ai" id="toc-the-drosophila-of-ai" class="nav-link" data-scroll-target="#the-drosophila-of-ai">The drosophila of AI</a></li>
  </ul></li>
  <li><a href="#expert-systems" id="toc-expert-systems" class="nav-link" data-scroll-target="#expert-systems">Expert systems</a>
  <ul class="collapse">
  <li><a href="#dendral" id="toc-dendral" class="nav-link" data-scroll-target="#dendral">DENDRAL</a></li>
  <li><a href="#meta-dendral" id="toc-meta-dendral" class="nav-link" data-scroll-target="#meta-dendral">Meta-DENDRAL</a></li>
  <li><a href="#mycin" id="toc-mycin" class="nav-link" data-scroll-target="#mycin">MYCIN</a></li>
  <li><a href="#what-is-knowledge" id="toc-what-is-knowledge" class="nav-link" data-scroll-target="#what-is-knowledge">What is knowledge?</a></li>
  <li><a href="#knowledge-principle" id="toc-knowledge-principle" class="nav-link" data-scroll-target="#knowledge-principle">Knowledge Principle</a></li>
  <li><a href="#ai-boom" id="toc-ai-boom" class="nav-link" data-scroll-target="#ai-boom">AI boom</a></li>
  <li><a href="#the-knowledge-bottleneck" id="toc-the-knowledge-bottleneck" class="nav-link" data-scroll-target="#the-knowledge-bottleneck">The knowledge bottleneck</a></li>
  <li><a href="#where-did-it-go" id="toc-where-did-it-go" class="nav-link" data-scroll-target="#where-did-it-go">Where did it go?</a></li>
  <li><a href="#did-it-succeed-after-all" id="toc-did-it-succeed-after-all" class="nav-link" data-scroll-target="#did-it-succeed-after-all">Did it succeed after all?</a></li>
  <li><a href="#but-why-the-hype" id="toc-but-why-the-hype" class="nav-link" data-scroll-target="#but-why-the-hype">But why the hype?</a></li>
  </ul></li>
  <li><a href="#sec-cyc" id="toc-sec-cyc" class="nav-link" data-scroll-target="#sec-cyc">Cyc</a>
  <ul class="collapse">
  <li><a href="#am" id="toc-am" class="nav-link" data-scroll-target="#am">AM</a></li>
  <li><a href="#eurisko" id="toc-eurisko" class="nav-link" data-scroll-target="#eurisko">EURISKO</a></li>
  <li><a href="#cyc" id="toc-cyc" class="nav-link" data-scroll-target="#cyc">Cyc</a></li>
  </ul></li>
  <li><a href="#robots" id="toc-robots" class="nav-link" data-scroll-target="#robots">Robots</a>
  <ul class="collapse">
  <li><a href="#eliza" id="toc-eliza" class="nav-link" data-scroll-target="#eliza">ELIZA</a></li>
  <li><a href="#sec-shrdlu" id="toc-sec-shrdlu" class="nav-link" data-scroll-target="#sec-shrdlu">SHRDLU</a></li>
  <li><a href="#sec-shakey" id="toc-sec-shakey" class="nav-link" data-scroll-target="#sec-shakey">Shakey</a></li>
  </ul></li>
  <li><a href="#the-fifth-generation" id="toc-the-fifth-generation" class="nav-link" data-scroll-target="#the-fifth-generation">The Fifth Generation</a>
  <ul class="collapse">
  <li><a href="#japan-was-number-one" id="toc-japan-was-number-one" class="nav-link" data-scroll-target="#japan-was-number-one">Japan Was Number One</a></li>
  <li><a href="#autopsy" id="toc-autopsy" class="nav-link" data-scroll-target="#autopsy">Autopsy</a></li>
  </ul></li>
  <li><a href="#intelligence-in-the-age-of-war-machines" id="toc-intelligence-in-the-age-of-war-machines" class="nav-link" data-scroll-target="#intelligence-in-the-age-of-war-machines">Intelligence in the age of war machines</a>
  <ul class="collapse">
  <li><a href="#early-war-machines" id="toc-early-war-machines" class="nav-link" data-scroll-target="#early-war-machines">Early war machines</a></li>
  <li><a href="#nuclear-war-machines" id="toc-nuclear-war-machines" class="nav-link" data-scroll-target="#nuclear-war-machines">Nuclear war machines</a></li>
  <li><a href="#intelligence" id="toc-intelligence" class="nav-link" data-scroll-target="#intelligence">Intelligence</a></li>
  <li><a href="#sec-sci" id="toc-sec-sci" class="nav-link" data-scroll-target="#sec-sci">Strategic Computing Project</a></li>
  <li><a href="#computing" id="toc-computing" class="nav-link" data-scroll-target="#computing">Computing</a></li>
  <li><a href="#pilots-associate" id="toc-pilots-associate" class="nav-link" data-scroll-target="#pilots-associate">Pilot’s associate</a></li>
  <li><a href="#battle-management" id="toc-battle-management" class="nav-link" data-scroll-target="#battle-management">Battle management</a></li>
  <li><a href="#autonomous-land-vehicle" id="toc-autonomous-land-vehicle" class="nav-link" data-scroll-target="#autonomous-land-vehicle">Autonomous Land Vehicle</a></li>
  <li><a href="#demo-or-die" id="toc-demo-or-die" class="nav-link" data-scroll-target="#demo-or-die">Demo or die</a></li>
  <li><a href="#general-ai-technologies" id="toc-general-ai-technologies" class="nav-link" data-scroll-target="#general-ai-technologies">General AI technologies</a></li>
  </ul></li>
  <li><a href="#philosophy" id="toc-philosophy" class="nav-link" data-scroll-target="#philosophy">Philosophy</a>
  <ul class="collapse">
  <li><a href="#the-symbolic-hypothesis" id="toc-the-symbolic-hypothesis" class="nav-link" data-scroll-target="#the-symbolic-hypothesis">The Symbolic Hypothesis</a></li>
  <li><a href="#cognitivism" id="toc-cognitivism" class="nav-link" data-scroll-target="#cognitivism">Cognitivism</a></li>
  <li><a href="#the-sub-symbolic-hypothesis" id="toc-the-sub-symbolic-hypothesis" class="nav-link" data-scroll-target="#the-sub-symbolic-hypothesis">The Sub-symbolic Hypothesis</a></li>
  <li><a href="#statistical-learning-theory" id="toc-statistical-learning-theory" class="nav-link" data-scroll-target="#statistical-learning-theory">Statistical learning theory</a></li>
  <li><a href="#connectionism-the-past-tense-debate-and-whatever" id="toc-connectionism-the-past-tense-debate-and-whatever" class="nav-link" data-scroll-target="#connectionism-the-past-tense-debate-and-whatever">Connectionism, the past tense debate, and whatever</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="translation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="translation">Translation</h2>
<blockquote class="blockquote">
<p>One naturally wonders if the problem of translation could conceivably be treated as a problem in cryptography. When I look at an article in Russian, I say: “This is really written in English, but it has been coded in some strange symbols. I will now proceed to decode.”</p>
<p>– Warren Weaver, Letter to Norbert Wiener, 1947-03-04</p>
</blockquote>
<p>During WWII, the science of communication and control took on a life-and-death importance. The mathematically perfect Enigma forced Allied mathematicians to turn their art of code into the science of information, so as to extract every last bit of information leaked out from the unknown enemy who was less than mathematically perfect, who made mistakes, who stuttered with verbal tics like <code>WETTER</code> or <code>KEINE BESONDEREN EREIGNISSE</code>. On two sides of the Atlantic, Alan Turing of computer science, and Claude Shannon of information theory, fought in this information warfare.</p>
<p>Before the war, some feared that the bombers would finally be the ultimate weapon, as a fleet of <a href="https://en.wikipedia.org/wiki/The_bomber_will_always_get_through">them will always get through</a>. Bombing was becoming a cyborg activity. The bombers were flying so high and so fast, the bombardiers needed <a href="https://en.wikipedia.org/wiki/Norden_bombsight">intricate bombsights</a> filled with mechanical calculators, just to calculate the correct time to drop the bombs.</p>
<p>But the bombers would not go through after all, as radar screens and flak cannons raised invisible walls in the sky, and the anti-aircraft fire became another cyborg activity. Norbert Wiener developed his control theory in the context of anti-aircraft fire and radar screening. He thought of both as a form of deadly communication. A radar speaks to the aircraft, “Who and where are you?” Despite itself, the aircraft must answer. The radar’s job is to speak clearly with the right ping and listen carefully with the right filter. In this context, he developed the <a href="https://en.wikipedia.org/wiki/Wiener_filter">Wiener filter</a>.</p>
<p>Anti-aircraft (AA) seems even less like a deadly communication, yet Wiener made it work. To shoot down an aircraft, one must predict where it will be a few seconds into the future, since that is how long bullets take to fly that high. The AA looks to the sky and asks, “Where are you going?”. Despite itself, the aircraft speaks with where it had been in the past few seconds, as if writing a cursive word in the sky. The AA reads and understands this writing, and act accordingly. The past is a code for the future, like the Enigma is a code for the plaintext. <span class="citation" data-cites="yeangFilteringNoiseAntiaircraft2023">(<a href="#ref-yeangFilteringNoiseAntiaircraft2023" role="doc-biblioref">Yeang 2023</a>)</span></p>
<p>If the soldiers are always preparing to fight the previous war, the same seems true for some mathematicians. Wiener and his collaborator, Warren Weaver, decided to tackle the problem of machine translation with the same tools they developed for war. If information theory helps with breaking the Enigma code, would it not also help with breaking the language codes?</p>
<p>The wartime metaphor would become ominously appropriate with the Cold War.</p>
<section id="georgetownibm-experiment" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="georgetownibm-experiment">Georgetown–IBM experiment</h3>
<p>During the 1950s, electronic computers were mainly understood and used as tools for real-valued calculations, such as simulating nuclear explosions, the aerodynamics of ballistic missiles, macroeconomic planning, and other important real-valued functions that are necessary to safeguard freedom. However, there was already early attempts at using computers for symbolic calculations.</p>
<p>In a sense, this was quite old. Whereas Charles Babbage designed his computer as an arithmetic mill to grind out numerical tables, Ada Lovelace speculated that computers can grind out symbolic music too, as long as music and its transformation rules are encoded into integers.</p>
<p>On 1954-01-07, the world’s first non-human translator appeared in the body of an IBM 701. At least, that is what the newspapers made it seam to be.</p>
<p>Back in 1952-06, at a MIT conference on machine translation (MT),<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Leon Dostert was convinced that instead of arguments about whether MT works <em>in theory</em>, they needed to try it out on an actual problem to see if it would work <em>in practice</em>. This led to the <a href="https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment">Georgetown–IBM experiment</a> 1.5 years later. It was the first public demonstration of machine translation – from Russian to English, and was widely reported with titles like “Electronic brain translates Russian” or “Robot brain translates Russian into King’s English”.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The acronym “MT” now stands for “machine translation”, but in the early days, it stood for “mechanical translation”.</p></div></div><p>To put some meat to the bones, consider the following hardware specs for the IBM 701 and the demo:</p>
<ul>
<li>The IBM 701 machine operated at <span class="math inline">\(2000 \;\mathrm{FLOP/s}\)</span></li>
<li>It performed read/write speed <span class="math inline">\(3.6 \;\mathrm{kB/s}\)</span> (in the form of 80-column punched cards).</li>
<li>The program took up <span class="math inline">\(2400 \;\mathrm{instruction} \times 18 \;\mathrm{bit/instruction} = 5.4 \;\mathrm{kB}\)</span></li>
<li>The dictionary took up <span class="math inline">\(6000 \;\mathrm{word} \times 36 \;\mathrm{bit/word} = 27 \;\mathrm{kB}\)</span>.</li>
</ul>
<p>The dictionary is a table with 6 columns: Russian, English equivalent I, English equivalent II, Code 1, Code 2, Code 3. As we see, each Russian word has 1 or 2 possible English translations. The three <code>Code</code>s are essentially grammar categories. As an example, the suffix <code>-a</code> is coded as <code>(-a, of, , 131, 222, 25)</code>, while the word stem <code>ugl-</code> is coded as <code>(ugl-, coal, angle, 121, ***, 25)</code>.</p>
<p>The dictionary contains just 250 lexical items (stems and endings). Its grammar has just 6 rules. All input sentences must be made of words that are of form either <code>stem</code> or <code>stem-ending</code>. Some example translations included:</p>
<blockquote class="blockquote">
<p>Mi pyeryedayem mislyi posryedstvom ryechyi.</p>
<p>We transmit thoughts by means of speech.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Georgetown-IBM_punched_card.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A punched card from the demo. The Russian sentence is encoded with the hole patterns and then read by the IBM 701. The output was not by punched cards, but by a printer.</figcaption>
</figure>
</div>
<p>The algorithm is essentially a word-substitution program, using the 6 rules to disambiguate, and to decide whether to switch a word with a previous word. The word-order switch is necessary since Russian puts prepositions as word suffixes. For example, <code>ugl-a</code> would be word-substituted to <code>angle-by</code>, but must be translated as <code>by angle</code>.</p>
<p>The experiment was a hit, and there were some predictions of imminent breakthrough <span class="citation" data-cites="hutchinsFirstPublicDemonstration2005">(<a href="#ref-hutchinsFirstPublicDemonstration2005" role="doc-biblioref">Hutchins 2005</a>)</span>:</p>
<ul>
<li>Such a device should be ready within three to five years… As soon as cards for Russian are completed, sets will be made for German and French. Then other Slavic, Germanic and Romance languages can be set up at will.</li>
<li>100 rules would be needed to govern 20,000 words for free translation.</li>
</ul>
<p>From our perspective, these seem painfully optimistic. However, it was a common belief that electronic computers, like the IBM 701, were designed for numerical computation, something that is more difficult than natural language processing. As such, a machine translator needed not faster computers, but more data. Yet among the general optimism, there was a disquieting note:</p>
<blockquote class="blockquote">
<p>the formulation of logic required to convert word meanings properly even in a small segment of two languages necessitates two and a half times as many instructions to the computer as are required to simulate the flight of a guided missile.</p>
<p><a href="https://aclanthology.org/www.mt-archive.info/IBM-1954.pdf">“701 Translator”, IBM Press release</a> (1954-01-08)</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled" title="Give me code or give me nothing!">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Give me code or give me nothing!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>One thing I dislike about some technical histories and overviews is that I keep getting a cotton-like, vaporwave feeling in the brain after reading them. It is easy to read an abstract story.</p>
<p>For example, many AI papers by OpenAI after 2020 has become like that. In any case, I looked up the program, which appeared in <span class="citation" data-cites="ornsteinMechanicalTranslationNew1955">(<a href="#ref-ornsteinMechanicalTranslationNew1955" role="doc-biblioref">Ornstein 1955</a>)</span> as a single giant flowchart. I didn’t read the spaghetti code in detail, but it seems to me that it first parses the input sequence into words and sub-words, then it starts from left to right, for each word/sub-word, find the rule that applies to it. Executing the rule would pick an English translation for that word/sub-word, and either switch that fragment of translation with the previous fragment, or not. There are 6 rules, of which I just copy one, since the others look similarly boring:</p>
<blockquote class="blockquote">
<p>Choice-Rearrangement. If first code is <code>131</code>, is third code of preceding complete word or either portion (root or ending) of preceding subdivided word equal to <code>23</code>? If so, adopt English equivalent II of word carrying <code>131</code> and retain order of appearance of words in output; if not, adopt English equivalent I and reverse order of appearance of words in output.</p>
</blockquote>
<p>The following is a rough Python sketch. It just implements half of rule 3, but gives you an idea of how the program would go. I estimate that it should take about 100 lines to implement a fully correct version. Even this rough sketch tells you that it is a very 1950s kind of program, with imperatives and if-then statements everywhere, combined with table lookups.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> {</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ugl-"</span>: (<span class="st">"coal"</span>, <span class="st">"angle"</span>, <span class="dv">121</span>, <span class="dv">0</span>, <span class="dv">25</span>),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-a"</span>: (<span class="st">"of"</span>, <span class="st">""</span>, <span class="dv">131</span>, <span class="dv">222</span>, <span class="dv">25</span>), </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>stems <span class="op">=</span> [word[:<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> word <span class="kw">in</span> dictionary.keys() <span class="cf">if</span> word[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="st">'-'</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>suffixes <span class="op">=</span> [word[<span class="dv">0</span>:] <span class="cf">for</span> word <span class="kw">in</span> dictionary.keys() <span class="cf">if</span> word[<span class="dv">0</span>] <span class="op">=</span> <span class="st">'-'</span>]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="kw">class</span> Word:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, word, stems, suffixes):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.stem <span class="op">=</span> word</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.suffix <span class="op">=</span> <span class="st">''</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> stem <span class="kw">in</span> stems:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> suffix <span class="kw">in</span> suffixes:</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> word <span class="op">=</span> stem <span class="op">++</span> suffix:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.stem <span class="op">=</span> stem</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.suffix <span class="op">=</span> suffix</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse(sentence, stems, suffixes):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> sentence.split(<span class="st">' '</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [Word(word, stems, suffixes) <span class="cf">for</span> word <span class="kw">in</span> words]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate(words, dictionary):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    translation <span class="op">=</span> []</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(words):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        word <span class="op">=</span> words[i]</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word.suffix <span class="op">=</span> <span class="st">''</span>:</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dictionary[word.stem][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">131</span>:</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>                    previous_word <span class="op">=</span> words[i<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> dictionary[previous_word.stem][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span> <span class="kw">or</span> (previous_word.suffix <span class="op">!=</span> <span class="st">''</span> <span class="kw">and</span> dictionary[previous_word.suffix][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span>):</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>                        flag <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>                        flag <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>                    flag <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> flag <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>                    translation.append(dictionary[word.stem][<span class="st">'code 1'</span>])</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>                    translation[<span class="op">-</span><span class="dv">2</span>:<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> [translation[<span class="op">-</span><span class="dv">1</span>], translation[<span class="op">-</span><span class="dv">2</span>]]</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>                    translation.append(dictionary[word.stem][<span class="st">'code 2'</span>])</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Translate stem, then suffix. It's a bit tedious.</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> translation.join(<span class="st">' '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>The exact details on how the program was implemented on the IBM was non-trivial, since both the machine and the programming environment around it were designed for numerical computations, not discrete symbolic manipulations. <span class="citation" data-cites="sheridanResearchLanguageTranslation1955">(<a href="#ref-sheridanResearchLanguageTranslation1955" role="doc-biblioref">Sheridan 1955</a>)</span> described the details. The programming language LISP must wait until 1960 to appear. Dedicated to symbolic manipulations. It would dominate most of AI research until the 1980s.</p>
<p>Another interesting fact is the amount of restrictions placed on the demo: 250 words, each word having just 1 or 2 possible translations, and each Russian word is either a full word or a <code>stem-suffix</code>, etc. An even deeper restriction was entirely hidden from view: pronouns. In Russian, pronouns are often dropped when the verb form makes it clear. To avoid this problem, for all demonstrated sentences, the English pronouns occur only in translations of verbs in the third person plural.</p>
</section>
<section id="subsequent-work" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="subsequent-work">Subsequent work</h3>
<p>The Georgetown–IBM demo worked. The CIA started funding MT research at Georgetown University (eventually up to $1,500,000), and other MT groups sprang up in America, Europe, and the Soviet Union. In general, their approaches could be divided into three parts: word-for-word, syntax, and eclectic.</p>
<p>The idea of word-for-word translation is essentially a direct scale-up of the Georgetown–IBM demo, just with a much bigger dictionary and a few more local word-reordering rules. True, there are some ambiguities like “The vodka was good, but the meat was rotten.”, but we can just pick the most likely translation, or translate a multi-word Russian phrase directly to a multi-word English phrase, etc. Erwin Reifler exemplified the “solved by lexicography” approach:</p>
<blockquote class="blockquote">
<p>Papers on MT are nowadays heavily weighted on the side of the development of structural linguistic procedures for the solution of MT problems, and very rightly so. But many of these problems can be solved by lexicography… in certain types of cases of higher frequency it is possible to solve grammatical and non-grammatical problems by lexicography and lexicographical procedures alone–that is, without the necessity of logical procedures and logical machine operations. Since our sponsors had asked us to concentrate, at least during the initial phases of our project, on the elaboration of a bilingual lexicon, we decided to try to achieve an optimum of lexicography which would solve as many of our bilingual problems as possible. The results of this lexicographical work were… almost 170,000 MT-operational Russian-English entries.</p>
<p><span class="citation" data-cites="reiflerSolutionMTLinguistic1960">(<a href="#ref-reiflerSolutionMTLinguistic1960" role="doc-biblioref">Reifler 1960</a>)</span></p>
</blockquote>
<p>This was the <a href="https://en.wikipedia.org/wiki/AN/GSQ-16_Automatic_Language_Translator">AN/GSQ-16 translator</a>, which would eventually be subsumed by SYSTRAN.</p>
<p>Similarly, at RAND corporation, they performed large-scale statistical analysis of corpus, used the analysis to write some Russian-English dictionary and reordering rules. Ran the program, checked the output, rewrote the dictionary and rules, etc. It was kind of a RAND-om gradient descent.</p>
<p>At MIT under Victor Yngve, the research agenda was fully based on syntax. A sentence in the source language is parsed into a syntax tree, then the syntax tree is transformed by some rotation, grafting, cutting, and pasting, and finally the leaf-words are substituted into the target language. To see an example use of this, consider the German sentence »Hans kommt heute abend an.«, which translates to “Hans arrives this evening”.. Here, “arrives” corresponds to »kommt … an«, and the distance between the two pieces of the verb can be arbitrarily long, thus no local transformation rule would work. However, though this is similar in spirit to Chomskyan linguistics, Chomsky was only briefly in the group, and his generative grammar was not used.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Yngve_1960_fig_31.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Some example syntax trees according to Yngve. They show “discontinuous constituents”, much like the German example of »Hans kommt heute abend an.«. <span class="citation" data-cites="yngveModelHypothesisLanguage1960">(<a href="#ref-yngveModelHypothesisLanguage1960" role="doc-biblioref">Yngve 1960, fig. 31</a>)</span></figcaption>
</figure>
</div>
<p>At Georgetown, the approach was more eclectic, with some syntax parsing and some statistical analysis with dictionary. Like most eclectic systems, it defies summary.</p>
<p>Meanwhile in the Soviet Union, MT research was based on a deep analysis of language at multiple levels (phonetic, phonemic, morphemic, surface syntactic, deep syntactic, semantic), similar to the <a href="https://en.wikipedia.org/wiki/Bernard_Vauquois#Vauquois_triangle">Vauquois triangle</a>, though they called it “<a href="https://en.wikipedia.org/wiki/Meaning%E2%80%93text_theory">Meaning–Text Theory</a>”.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Vauquois triangle.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The Vauquois triangle.</figcaption>
</figure>
</div>
<p>For details on this period, I refer to <span class="citation" data-cites="hutchinsMachineTranslationConcise2007">(<a href="#ref-hutchinsMachineTranslationConcise2007" role="doc-biblioref">Hutchins 2007</a>)</span>.</p>
</section>
<section id="winter-comes" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="winter-comes">Winter comes</h3>
<p>Around 1964, there was an uneasy feeling around AI. The post-war flood of governmental funds was slowing as the optimistic “Science, the Endless Frontier” lost its shine. There were much bigger projects to do, like sending 2 men to the moon or 3 million to Vietnam. The general atmosphere was subdued. Eventually funding would be cut even more with the Mansfield Amendments of 1973, which limited ARPA to only funding projects directly relevant to military applications.</p>
<blockquote class="blockquote">
<p>By 1966, it was estimated that roughly 20 million dollars (in contemporary dollars) had been spent on MT in the US, with Georgetown, at 1,317,239 dollars (93.5 percent from the CIA, 6.5 percent from the NSF) being the largest.. “In comparison, let us notice that in June 1952, when the First conference on Machine Translation convened at MIT, there was probably one person in the world engaged more than half-time in work on MT, namely myself [Bar-Hillel]”. The budget had been roughly ten thousand dollars.</p>
<p><span class="citation" data-cites="gordinForgettingRediscoverySoviet2020">(<a href="#ref-gordinForgettingRediscoverySoviet2020" role="doc-biblioref">Gordin 2020</a>)</span></p>
</blockquote>
<p>In 1964, the US government created the ALPAC committee of 7 linguists “to advise the Department of Defense, the Central Intelligence Agency, and the National Science Foundation on research and development in the general field of mechanical translation of foreign languages”. The roster of names makes it clear that MT was a matter of state security. It was all well and good if MT could eventually reach human level performance in a few centuries, or if MT research could <em>right now</em> inform the science of linguistics and assist the universe’s ceaseless striving to rationally know itself, but let us never confuse the universal with the here and now.</p>
<blockquote class="blockquote">
<p>“Are you looking for the Secret Name, Scharlach?” … in his voice Lönnrot detected a fatigued triumph, a hatred the size of the universe, a sadness no smaller than that hatred. “No.&nbsp;I am looking for something more ephemeral and slippery, I am looking for Erik Lönnrot…”</p>
<p>— Borges, <em>Death and the Compass</em> (1942)</p>
</blockquote>
<p>The Georgetown–IBM experiment proved to be <em>too</em> good of a demo. The sentences were picked to present it in the best light, and the rules were written so that the machine would translate the sentences correctly. Subsequent MT research could not match the demo, and skeptics appeared.</p>
<blockquote class="blockquote">
<p>Dorset is “a great conversationalist … but as a researcher I was unsure about him, whether he was just a figurehead or whether he was a bit of a fraud – the Georgetown MT demonstrations seemed always to be contrived; they made impressive publicity for the sponsors, but they soured the atmosphere by raising expectations that nobody could possibly fulfill.” … MT colleague Winifred Lehmann was overheard describing him as “a wart on the field of linguistics”.</p>
<p>— Old gossips quoted in <span class="citation" data-cites="gordinDostoevskyMachineGeorgetown2016">(<a href="#ref-gordinDostoevskyMachineGeorgetown2016" role="doc-biblioref">Gordin 2016</a>)</span></p>
</blockquote>
<p>The ALPAC committee worked for 2 more years before presenting the final report in 1966 <span class="citation" data-cites="automaticlanguageprocessingadvisorycommitteeLanguageMachinesComputers1966">(<a href="#ref-automaticlanguageprocessingadvisorycommitteeLanguageMachinesComputers1966" role="doc-biblioref">Committee et al. 1966</a>)</span>. Most of the report is not on whether MT is possible, but on the economics of translating technical documents from Russian to English, and whether MT would be economically good enough for this within the next few years. For example, it calculated that since a machine-translated document takes longer to read, if a document were to be read by more than 20 people, human translation is more economical. What the report says about MT itself is fairly brief:</p>
<blockquote class="blockquote">
<p>“Machine Translation” presumably means going by algorithm from machine-readable source text to useful target text, without recourse to human translation or editing. In this context, there has been no machine translation of general scientific text, and none is in immediate prospect. The contention that there has been no machine translation of general scientific text is supported by the fact that when, after 8 years of work, the Georgetown University MT project tried to produce useful output in 1962, they had to resort to post-editing. The post-edited translation took slightly longer to do and was more expensive than conventional human translation.</p>
<p>… Early machine translations of simple or selected text, such as those given above, were as deceptively encouraging as “machine translations” of general scientific text have been uniformly discouraging. However, work toward machine translation has produced much valuable linguistic knowledge and insight that we would not otherwise have attained.</p>
<p>… it is wise to press forward undaunted, in the name of science, but that the motive for doing so cannot sensibly be any foreseeable improvement in practical translation. Perhaps our attitude might be different if there were some pressing need for machine translation, but we find none.</p>
</blockquote>
<p>Despite this, it resulted in a swift deep cut in governmental funding for MT research, not just in America, but also in the Soviet Union. Quite understandable. However, like the concurrent loss of funding for neural network research, it resulted in an AI winter for MT, and a general impression that MT had been debunked.</p>
<blockquote class="blockquote">
<p>Its effect was to bring to an end the substantial funding of MT research in the United States for some twenty years. More significantly, perhaps, was the clear message to the general public and the rest of the scientific community that MT was hopeless. For years afterwards, an interest in MT was something to keep quiet about; it was almost shameful. To this day, the ‘failure’ of MT is still repeated by many as an indisputable fact… from time to time in the next decades researchers would discuss among themselves whether “another ALPAC” might not be inflicted upon MT.</p>
<p><span class="citation" data-cites="hutchinsALPACFamousReport2003">(<a href="#ref-hutchinsALPACFamousReport2003" role="doc-biblioref">Hutchins 2003</a>)</span></p>
</blockquote>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>The effect of the ALPAC report in 1966 was as great in the Soviet Union as in the United States. Many projects were not funded any more; machine translation went into decline. The authorities had seen the ALPAC documents and concluded that if the Americans did not think it worthwhile to support MT, if they did not think there was any hope of MT, then nor should we… [But] we had never pretended that we were doing actual machine translation, we were doing formal linguistics.</p>
<p><a href="https://en.wikipedia.org/wiki/Igor_Mel'%C4%8Duk">Igor A. Mel’čuk</a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> (2000), quoted in <span class="citation" data-cites="gordinForgettingRediscoverySoviet2020">(<a href="#ref-gordinForgettingRediscoverySoviet2020" role="doc-biblioref">Gordin 2020</a>)</span></p>
</blockquote><div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Melchuk was one of the founders of Meaning–Text Theory, which as you might imagine, believed in deep theoretical understanding, not in programs that seemed to work in practice. In a 2024 interview:</p>
<blockquote class="blockquote">
<p>60 years later, this problem has been solved in a completely different way… Today’s machine translation using artificial intelligence is admirable, but it has nothing to do with the science of language. The machine translates brilliantly, but we learn nothing new about linguistics from it… In general, I am a typical armchair scientist. I am interested in knowing, not in being able to do something practical.</p>
<p><a href="https://sysblok.ru/interviews/menja-interesuet-znat-a-ne-prosto-umet-igor-melchuk-o-netradicionnoj-lingvistike-mashinnom-perevode-i-zhizni-v-kanade/">Igor Melchuk on non-traditional linguistics and machine translation — “System Block”</a></p>
</blockquote>
<p>Such attitude will appear again and again among the “Chomskyans” or “Rationalists”, as we will see throughout this essay, is the common trend underlying logical AI research.</p></div></div></div>
<p><a href="https://en.wikipedia.org/wiki/Yehoshua_Bar-Hillel">Yehoshua Bar-Hillel</a> against machine translation – what he called FAHQT (Fully Automatic High-Quality Translation, or as I imagine him saying it, “Machine translation? Ah, FAHQT.”). The argument goes like:</p>
<ol type="1">
<li>FAHQT requires general world understanding, because natural language is full of ambiguities that require general world understanding.</li>
<li>General world understanding is “utterly chimerical and hardly deserves any further discussion’.</li>
</ol>
<p>The standard example he gave was “The box is in the pen.”, where the issue is how to disambiguate the word “pen”. Does it mean the writing instrument, or an enclosure? For a machine to pick the right meaning, it must know that a pen cannot contain a box, while an enclosure can. This cannot be done by merely looking up every word in a dictionary, or drawing up its the syntax tree. It must have general world understanding, or common sense.</p>
<blockquote class="blockquote">
<p>Assume, for simplicity’s sake, that <em>pen</em> in English has only the following two meanings: (1) a certain writing utensil, (2) an enclosure where small children can play. I now claim that no existing or imaginable program will enable an electronic computer to determine that the word <em>pen</em> in the given sentence within the given context has the second of the above meanings, whereas every reader with a sufficient knowledge of English will do this “automatically”.</p>
<p>Whenever I offered [the challenge] to one of my colleagues working on MT, their first reaction was: “But why not envisage a system which will put this knowledge at the disposal of the translation machine?” … What such a suggestion amounts to, if taken seriously, is the requirement that a translation machine should not only be supplied with a dictionary but also with a universal encyclopedia. This is surely utterly chimerical and hardly deserves any further discussion… Reasonable goals are then either fully automatic, low quality translation or partly automatic, high quality translation. Both are theoretically feasible and, for certain language pairs, attainable today though not yet on a commercial scale.</p>
<p><span class="citation" data-cites="bar-hillelPresentStatusAutomatic1960">(<a href="#ref-bar-hillelPresentStatusAutomatic1960" role="doc-biblioref">Bar-Hillel 1960</a>)</span></p>
</blockquote>
<p>If FAQHT is impossible for all “existing or imaginable” programs, there can exist only two proper kinds of machine translation. One was automatic low-quality translation, and another was explicitly designed as a help, not a replacement, to human translators. The first kind was all there was, and Bar-Hillel called for researchers to work on the second kind.</p>
<p>Interestingly, it has mentioned “learning machines” only to not discuss it further, even though machine learning would turn out to be the key to general world understanding. This dismissal of machine learning would continue for quite some more years.</p>
<p>He presented his opinion more forcefully 4 years later in an editorial:</p>
<blockquote class="blockquote">
<p>It seems now quite certain to some of us, a small but apparently growing minority, that with all the progress made in hardware (i.e., apparatus), programming techniques and linguistic insight, the quality of fully autonomous mechanical translation, even when restricted to scientific or technological material, will never approach that of qualified human translators and that therefore Machine Translation will only under very exceptional circumstances be able to compete with human translation.</p>
<p>… there is no prospect whatsoever that the employment of electronic digital computers in the field of translation will lead to any revolutionary changes. A complete automation of the activity is wholly utopian, since the fact that books and papers are usually written for readers with a certain background knowledge and an ability for logical deduction and plausible reasoning cannot be over-ridden by even the cleverest utilization of all formal features of a discourse. The hopes to the contrary which many of us had a decade ago just turned out to be by and large unrealizable. The quicker this is understood, the better are the chances that more attention will be paid to finding efficient ways of improving the status of scientific and technological translation–I am not qualified to discuss literary translation–including a judicious and modest use of <em>mechanical aids</em>.</p>
<p><span class="citation" data-cites="bar-hillelFutureMachineTranslation1964">(<a href="#ref-bar-hillelFutureMachineTranslation1964" role="doc-biblioref">Bar-Hillel 1964</a>)</span></p>
</blockquote>
<p>Bar-Hillel’s objection is reminiscent of the <a href="https://en.wikipedia.org/wiki/Winograd_schema_challenge">Winograd schema challenge</a>, which also tests for general world understanding. Indeed, even Terry Winograd had a tentative guess that the Winograd challenge is too challenging, though it is clearly just a weak guess, not a firm prediction like the previous quotes.</p>
<blockquote class="blockquote">
<p>The limitations on the formalization of contextual meaning make it impossible at present – and conceivably forever – to design computer programs that come close to full mimicry of human language understanding.</p>
<p><span class="citation" data-cites="winogradComputerSoftwareWorking1984">(<a href="#ref-winogradComputerSoftwareWorking1984" role="doc-biblioref">Winograd 1984</a>)</span></p>
</blockquote>
<p>What do we make of such criticism? At that point in time, there were three possible replies:</p>
<ol type="1">
<li>Intelligence amplification: Instead of the mirage of replacing human translators, try to build little programs that augment human translators.</li>
<li>Brute force logical programming: Scale up commonsense by hiring more linguists to program in increasingly large chunks of the world.</li>
<li>AI is a mirage, and the failures of MT is a symptom of that.</li>
</ol>
<p>From our vantage point, the actual solution turned out to be:</p>
<ol type="1">
<li>The bitter lesson: Wait a few decades, then train a giant neural network on a trillion words from the Internet to give it general world knowledge.</li>
</ol>
<p>There is a common mistake about the bitter lesson, that even Richard Sutton makes. It is not just that the bitter lesson is bitter, but also that it is <em>difficult</em>. People did not believe in it, not because they were afraid of bitterness, but because it was obviously stupid, a kind of straw man’s argument.</p>
<p>Consider the arguments of a latter-day Bar-Hillel:</p>
<blockquote class="blockquote">
<p>The case against machine translation as a solution to practical problems is overwhelming and has been made many times. I do not propose to repeat it in any detail here. It will, however, be worth a few words to make a <em>prima facie</em> case for the implausibility of practical machine translation if only so that the contrast with realistic approaches to the problem will be more striking… There is a great deal that computer scientists and linguists could contribute to the practical problem of producing translations, but, in their own interests as well as those of their customers, they should <strong>never</strong> be asked to provide an engineering solution to a problem that they only dimly understand.</p>
<p>I want to advocate a view of the problem in which machines are gradually, almost imperceptibly, allowed to take over certain functions in the overall translation process. First they will take over functions not essentially related to translation. Then, little by little, they will approach translation itself. The keynote will be <em>modesty</em>. At each stage, we will do only what we know we can do reliably.</p>
<p><span class="citation" data-cites="kayProperPlaceMen1997">(<a href="#ref-kayProperPlaceMen1997" role="doc-biblioref">Kay 1997</a>)</span></p>
</blockquote>
<p>Now we know that “engineering solutions to a problem they only dimly understand” was precisely the breakthrough in multiple fields. In this essay we would this appearing in <a href="#sec-speech">speech recognition</a>, TODO, TODO, and TODO. It also happened with AlphaGo, made by a team who only had Go amateurs, or diffusion artists made by engineers with minimal understanding of art. However, just try saying out loud, “I’ll solve translation just by training a sequence to sequence neural network, on a few million pairs of English-German sentence pairs. It won’t have a probabilistic interpretation, or a syntax tree, or morphological constraints. In fact I haven’t even taken a course in intermediate linguistics. But I have trained many neural networks. Surely if I can get the loss low enough, it will work.” The reasonable reply would be, “What hubris, to tackle a problem that has stumped decades of linguistic science with the brute reason of engineering! What Goodhart law, to expect minimizing loss will lead to the thing you actually want, which is translation? What alchemy, to expect to put in nothing but data and compute, and somehow create understanding in a machine, an understanding that you don’t have yourself?”.[^feynman-kac]</p>
<p>[^feynman-kac] Perhaps the <a href="https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula">Feynman–Kac</a> anecdote illustrates this better.</p>
<pre><code>&gt; Kac went to Pasadena to lecture at the California Institute of Technology. Richard Feynman was in the audience. After the lecture, Feynman got up and announced: "If all mathematics disappeared, it would set physics back precisely one week." Without a pause, Kac responded: "Precisely the week in which God created the world."
&gt;
&gt; [@cohenLifeImmeasurableMind1986]

So perhaps...

&gt; "If we fired all the linguists, it would set machine translation back precisely one week."
&gt; 
&gt; "Precisely the week in which God struck down the Tower of Babel."</code></pre>
<p>To end this section, I quote from one of the authors of the ALPAC report an amusing anecdote about Yngve, which was an omen of the ultimate fate of logical MT:</p>
<blockquote class="blockquote">
<p>There’s sometimes a strong scholastic emphasis, or current, which causes some psychologists to produce very closely reasoned ideas that aren’t checked at every point with experiment. Some of the theoretical linguists are like that. They are extremely plausible. But I know a fellow, <a href="https://en.wikipedia.org/wiki/Victor_Yngve">Victor Yngve</a>, who tried to write a transformational grammar of the English language, a reasonably complete one. It took him years and years and he never got it written. He kept finding difficulties that don’t appear when you have a few nice examples of what a transformation of grammar is supposed to be all about.</p>
<p>John Pierce, quoted in <span class="citation" data-cites="lyleInterviewJohnRobinson1979">(<a href="#ref-lyleInterviewJohnRobinson1979" role="doc-biblioref">Lyle 1979</a>)</span></p>
</blockquote>
</section>
<section id="the-alignment-problem" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-alignment-problem">The alignment problem</h3>
<p>The decade after ALPAC was more subdued. MT research continued, but with minimal government funding, and it often continued as a kind of computational study in service of basic research in linguistics. They typically followed the approach of Vauquois, that is, to take a sentence from one language, and parse it into higher and higher levels of abstraction, reaching an “interlingua” stage that is fully language-independent, then move back down again until one lands safely in the other language. It reminds me of taking an airplane across an ocean.</p>
<p>But MT was about to take a sudden turn away from theory.</p>
<p>In 1986, speech recognition was solved. Well, not exactly, but during the period of 1976–1986, a group of researchers in IBM managed to produce speech recognition systems better than ever before, by “firing the linguists”, and returning to the information-theoretic approach that Shannon and Weaver had back in the 1950s. Armed with compute, data, and a disregard for linguistic science, they got it to work, and in 1986, they decided to try the same trick, but this time with MT.</p>
<p>In our language, the idea was encoder-decoder translation, using Bayesian probability. Suppose we want to translate a sentence in foreign language <span class="math inline">\(f\)</span> to an English sentence <span class="math inline">\(e\)</span>. We imagine that the foreign speaker was really trying to speak English, but somehow, words came out <em>encoded</em> as a foreign language, and our goal is to <em>decode</em> from it. This gives us 3 components:</p>
<ol type="1">
<li>English language model: <span class="math inline">\(Pr(e)\)</span>, the prior probability of the speaker wanting to say <span class="math inline">\(e\)</span>.</li>
<li>Encoder model: <span class="math inline">\(Pr(f | e)\)</span>, the conditional probability that the speaker would end up saying <span class="math inline">\(f\)</span>, if they wanted to say <span class="math inline">\(e\)</span>.</li>
<li>Decoder: <span class="math inline">\(f \mapsto e\)</span>, the translator we want to construct.</li>
</ol>
<p>The decoder is the maximum a posteriori solution:</p>
<p><span class="math display">\[
e^*(f) := \mathop{\mathrm{argmax}}_e Pr(f|e) Pr(e)
\]</span></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/source-channel_model_MT.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The encoder-decoder translation architecture. <span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005, fig. 3</a>)</span></figcaption>
</figure>
</div>
<p>Once we have both <span class="math inline">\(Pr(f|e)\)</span> and <span class="math inline">\(Pr(e)\)</span>, we have a machine translator. To obtain <span class="math inline">\(Pr(f|e)\)</span> and <span class="math inline">\(Pr(e)\)</span>, the team used simple statistical models, not much more complex than n-gram models, with parameters estimated by <a href="https://en.wikipedia.org/wiki/Expectation-maximization_algorithm">expectation-maximization algorithm</a>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;We are skipping over the word-alignment part of the IBM models, which tells you which words in <span class="math inline">\(f\)</span> corresponds to which words in <span class="math inline">\(e\)</span>. We still have an encoder-decoder architecture, but it’s more complicated.</p></div></div><p>The IBM team worked on this from 1986 to the early 1990s, and their state of the art performance led to a statistical revolution in MT. Compared to the theoretically principled MT of the past, the IBM language model was obviously wrong: languages are obviously impossible to be correctly modelled by an n-gram model, or the slightly more complex upgraded models they used. Where are the syntax trees, the constituencies, etc? Yet it did work, and it took over practical MT research.</p>
<p>Their primary dataset was the Canadian <a href="https://en.wikipedia.org/wiki/Hansard">Hansard</a> corpus – transcripts of proceedings from the Canadian parliament which were available in both English and French due to Canada’s bilingual policy. The Hansard parallel corpus contained around 3 million sentence pairs at the time. While substantial, it pales in comparison to monolingual English corpora to train <span class="math inline">\(Pr(e)\)</span>. English text was abundant from government documents, news archives, books, etc. In short, the encoder-decoder structure was adapted for the data regime of abundant monolingual (used to train <span class="math inline">\(Pr(e)\)</span>) but limited parallel text (used to train <span class="math inline">\(Pr(f|e)\)</span>).</p>
<p>In the introduction to a “Special Issue on Computational Linguistics Using Large Corpora”, <span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>)</span> argued that “Rationalism”, having been reigning since 1970s, was facing legitimate challenge by “Empiricism” again, for three reasons: more compute, more data, and a culture centered on evaluation.</p>
<blockquote class="blockquote">
<p>The emphasis today on empirical methods in the speech recognition community is a reaction to the failure of knowledge-based approaches of the 1970s. It has become popular once again to focus on high-level natural language constraints in order to reduce the search space. But this time, n-gram methods have become the methods of choice because they seem to work better than the alternatives, at least when the search space is measured in terms of entropy. Ideally, we might hope that someday parsers might reduce entropy beyond that of n-grams, but right now, parsers seem to be more useful for other tasks such as understanding who did what to whom, and less useful for predicting what the speaker is likely to say.</p>
<p>Someday parsers might help squeeze out some of this remaining half bit between the trigram model and Shannon’s bound, but thus far, parsing has had little impact… The issue remains as controversial as ever, as evidenced by the lively debate on rationalism versus empiricism at TMI-92, a recent conference on MT… The information theoretic approach to MT may fail for reasons advanced by Chomsky and others in the 1950s. But regardless of its ultimate success or failure, there is a growing community of researchers in corpus-based linguistics who believe that it will produce a number of lexical resources that may be of great value.</p>
<p><span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>)</span></p>
</blockquote>
<p>That was 1993. And the Internet was coming, and it kept coming, and it is still coming, and it just won’t stop coming.</p>
<p>When a user makes a search request like “IBM”, Google’s servers must retrieve not only website urls like <code>www.ibm.com</code>, but also a snippet view like “…<strong>IBM</strong> has been a global technology innovator…”. Therefore, Google had been crawling the Internet and storing a plain-text copy of the Internet regularly, with a size on the order of 100 TB as of 2003. <span class="citation" data-cites="barrosoWebSearchPlanet2003">(<a href="#ref-barrosoWebSearchPlanet2003" role="doc-biblioref">Barroso, Dean, and Holzle 2003</a>)</span> Once with such a large dataset, what could be done with it?</p>
<p>In 2006, Google Translate was launched. Early reactions were a mixture of fascination and sarcasm, leading to memes of hilarious Google translations that has survived to this day, even though the improvements has made it very difficult to do nowadays. Despite this, it was agreed that Google had achieved state of the art in statistical machine translation. How did it do it? By brutally scaling up.</p>
<p>In <span class="citation" data-cites="brantsLargeLanguageModels2007">(<a href="#ref-brantsLargeLanguageModels2007" role="doc-biblioref">Brants et al. 2007</a>)</span>, the authors described how Google achieved such a feat. Despite possibly lower quality than a more sophisticated algorithm, the “stupid backoff” allowed them to train on 60× more data and run 10000× faster during inference. The largest model was trained on a dump of the Internet (January 2006) with 2 trillion tokens, 300M 5-grams, 16M vocab, 1.8 TB language model, took 1 day to train on 1500 machines. They noted that the more data they used, the higher the BLEU score got, and simply drew a straight line, expecting the model to keep improving if they did it on even more data.</p>
<p>The title was “Large Language Models in Machine Translation”. 10 years later, Large Language Models would be reborn in the guise of the Transformer, again out of research efforts to improve Google Translate.</p>
</section>
<section id="abbyys-last-stand" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="abbyys-last-stand">ABBYY’s last stand</h3>
<p>18 years after his introduction <span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>)</span>, Kenneth Church proposed in 2011 a 20-year cycle between Empiricism and Rationalism, and argued that we were on the brink of a return to Rationalism:</p>
<ul>
<li>1950s: Empiricism (Shannon, Skinner, Firth, Harris)</li>
<li>1970s: Rationalism (Chomsky, Minsky)</li>
<li>1990s: Empiricism (IBM Speech Group, AT&amp;T Bell Labs)</li>
<li>2010s: A Return to Rationalism?</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Kenneth_2011_fig_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The shift from Rationalism to Empiricism, as measured by the proportion of statistical papers submitted to the Association for Computational Linguistics. Based on two independent surveys by Bob Moore and Fred Jelinek. <span class="citation" data-cites="churchPendulumSwungToo2011">(<a href="#ref-churchPendulumSwungToo2011" role="doc-biblioref">K. Church 2011, fig. 1</a>)</span></figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>When we revived empiricism in the 1990s, we chose to reject the position of our teachers for pragmatic reasons. Data had become available like never before. What could we do with it? We argued that it is better to do something simple than nothing at all. Let’s go pick some low hanging fruit. While trigrams cannot capture everything, they often work better than the alternatives… That argument made a lot of sense in the 1990s, especially given unrealistic expectations that had been raised during the previous [expert systems] boom. But today’s students might be faced with a very different set of challenges in the not-too-distant future. What should they do when most of the low hanging fruit has been pretty much picked over? … we should expect Machine Translation research to make more and more use of richer and richer linguistic representations. So too, there will soon be a day when stress will become important for speech recognition.</p>
<p><span class="citation" data-cites="churchPendulumSwungToo2011">(<a href="#ref-churchPendulumSwungToo2011" role="doc-biblioref">K. Church 2011</a>)</span></p>
</blockquote>
<p>It has been 15 years. The pendulum is still probing the unknown depths of Empiricism.</p>
<p>In 1989, ABBYY was founded in Moscow. Its first product was an electronic dictionary, followed by an <a href="https://en.wikipedia.org/wiki/ABBYY_FineReader">ABBYY FineReader optical character recognition (OCR)</a>, which became an international hit. With such a stable cash flow, ABBYY aimed higher: It would develop Compreno, a “Natural Language <a href="https://en.wikipedia.org/wiki/Compiler">Compiler</a>” (NLC) based on linguistic theory. Compreno would take the lowest level of Vauquois triangle (actual language) to the highest level (language-independent meaning, interlingua), which can then be decompiled to another language. It was Meaning–Text Theory in action.</p>
<p>The founders of ABBYY were students of <a href="https://en.wikipedia.org/wiki/Moscow_Institute_of_Physics_and_Technology">Moscow PhysTech</a>, and ABBYY already had hired linguists to work on its dictionaries and OCR, so it seemed only natural to implement the natural language compiler based on the science of linguistics.</p>
<blockquote class="blockquote">
<p>Along with the programmers and machine learning specialists who held profitable products like FineReader and FlexiCapture (a smart, customizable payment recognition system for banks) on their shoulders, this cozy office houses dozens, and at its peak, hundreds of linguists. All of them are engaged in the formal description of the language within the semantic hierarchy of ABBYY NLC / Compreno.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/ABBYY_Compreno_sentence_analysis.jpg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Formal analysis of an English sentence in the ABBYY NLC / Compreno model.</figcaption>
</figure>
</div>
<p>In the early 2010s, the cost of Compreno had reached $80 million, yet the finished Compreno translator was as distant as ever. Previews of the translator impressed journalists with cherry-picked examples, but they knew they could not compete with Google Translate. Still, too many had sunk their loving labor into Compreno to abandon it, so ABBYY pivoted it to what looks like <a href="#sec-cyc">CYC</a>, something that boasts homonym resolution, filling in the blanks, information retrieval (in corporate archives) and extracting information from text.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/ABBYY_Compreno_semantic_graph.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A graph display of semantic information extracted by ABBYY Compreno.</figcaption>
</figure>
</div>
<p>It proved brittle like all logical AI systems do:</p>
<blockquote class="blockquote">
<p>We had customers who needed, for example, to extract data on transaction participants from document scans in which the text was written in a kind of “legal dialect” of American English. When this text (with recognition errors, extra dots due to breadcrumbs on the scan and other artifacts) flew into the sophisticated NLC / Compreno analyzer, the output was most often an absolutely unpredictable mess with a bunch of messages about parsing errors… The variety of syntactic-semantic structures was almost greater than the (comparatively more predictable) variety of simple word chains of the source text. At some point, I realized that most of the time I was engaged in a war with Compreno output using regular expressions and other crutches, and I thought that I needed to leave ABBYY.</p>
<p>After leaving the company, I once took HSE computer linguistics students on a tour of ABBYY… One of the students, Pasha, joked that ABBYY employees climb up there during a thunderstorm and shout “I’m making a correct parser in 2018,” after which lightning strikes them. It was a cruel joke, but it hit the mark.</p>
<p>[Despite the success of Transformers,] ABBYY continued to cling to this “suitcase without a handle”, trying to combine the handwritten language model of Compreno and neural network approaches. And they probably would have continued further, if not for 2022.</p>
</blockquote>
<p>After Russia invaded Ukraine in 2022, to avoid Western sanctions, ABBYY quickly distanced itself from its Russian origins, claiming to be a fully American company. To make good on this claim, it finally fired all its Russian employees and became a fully American company in 2024-10. Thus ended Compreno, 20 years and $80 million later, <a href="https://sysblok.ru/blog/gorkij-urok-abbyy-kak-lingvisty-proigrali-poslednjuju-bitvu-za-nlp/">ABBYY’s bitter lesson</a> <span class="citation" data-cites="skorinkinABBYYsBitterLesson2024">(<a href="#ref-skorinkinABBYYsBitterLesson2024" role="doc-biblioref">Skorinkin 2024</a>)</span></p>
<p>The essay was in Russian, and I read it by pure Google Translate. It worked perfectly.</p>
</section>
</section>
<section id="sec-speech" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-speech">Speech</h2>
<section id="early-days" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="early-days">Early days</h3>
<p>Automatic speech recognition (ASR) is the conversion of speech audio to text. Its history resembles the history of MT.</p>
<p>It is hard to know what is closest at hand. Speaking is so natural that it takes effort to even notice that there is structure within the smallest sound, and it required the invention of the phonograph to notice the fine details of even a single vowel. In the early 20th century, as AT&amp;T connected all of America with telephone lines, it funded research into efficient coding of speech, with the hopeful goal of saving on bandwidth. The rough idea is similar to the idea of mp3: If the engineers knew what mattered and what didn’t matter in human speech recognition, then they could squeeze more telephone calls within the same line.</p>
<p>Concretely, one could imagine a device on a telephone that converts all the richness of a speech-stream into just 20 bit-streams, then braid those 20 bit-streams into a narrow frequency band, send it all the way across America, whereupon it gets decompressed back to the speech-stream, impoverished but still perfectly recognizable.</p>
<p>It began with recognition of individual spoken words, which was possible by featurizing the sound, then match that sequence of feature vectors against the template feature vectors.</p>
<p>An illustrative example of this early period of ASR was reported in <span class="citation" data-cites="denesDesignOperationMechanical1959">(<a href="#ref-denesDesignOperationMechanical1959" role="doc-biblioref">Denes 1959</a>)</span>. It could spell individual word phonetically (i.e.&nbsp;“cartoon” spelled as “katun”) – if the word is made out of only 4 vowels and 9 consonants, in an alternating fashion (i.e.&nbsp;no two vowels together, or two consonants together).</p>
<p>The machine first uses a filter bank to featurize the input sound. Pairs of outputs from the filter bank are then multiplied to measure how likely the sound is a phoneme. For example, the outputs from 200 Hz and 320 Hz are multiplied together, and that measures how likely the sound is “m”, because the two principal frequencies of “m” are close to 200 Hz and 320 Hz. Finally, a computer selects the most likely phoneme, based on the multiplied results and a simple statistical model of how likely a phoneme is to follow the previous phoneme.</p>
<p>The following pseudocode describes how the system works:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> featurize(audio_segment):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    filter_bank_features <span class="op">=</span> filter_bank(audio_segment)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"m"</span>: filter_bank_features[<span class="st">"200 Hz"</span>] <span class="op">*</span> filter_bank_features[<span class="st">"320 Hz"</span>],</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"i"</span>: filter_bank_features[<span class="st">"250 Hz"</span>] <span class="op">*</span> filter_bank_features[<span class="st">"3200 Hz"</span>],</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_phoneme(audio_segment, previous_phoneme, phoneme_probability_model):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> featurize(audio_segment)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    phoneme_probabilities <span class="op">=</span> phoneme_probability_model(previous_phoneme)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    best_score <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    best_phoneme <span class="op">=</span> <span class="st">''</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> phoneme <span class="kw">in</span> features.keys():</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> features[phoneme] <span class="op">*</span> phoneme_probabilities[phoneme]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> score <span class="op">&gt;</span> best_score:</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            best_phoneme <span class="op">=</span> phoneme</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            best_score <span class="op">=</span> score</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_phoneme</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Denes_1959_fig_8.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="denesDesignOperationMechanical1959">(<a href="#ref-denesDesignOperationMechanical1959" role="doc-biblioref">Denes 1959, fig. 8</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="logical-asr" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="logical-asr">Logical ASR</h3>
<p>In typical generative grammar of language, you start with a <code>SENTENCE</code>, and repeatedly rewrite it until you end up with a sentence like <code>Did you hit Tom?</code></p>
<p>Here, we push this one level deeper. After a sentence is generated, you substitute each word with its standard pronunciation, resulting in a sequence like <code>dɪd/juː/hɪt/tɒm</code>. Next, apply more rewriting rules to account for the fact that we don’t pronounce a whole sentence like individual words, but always “glide two words together”. For example, <code>did you</code> would actually be pronounced like <code>dija</code>, so we account for this with a rewriting rule <code>d/juː -&gt; jə</code>. Similarly, the double <code>t</code> in <code>hit Tom</code> would be merged to a single <code>t</code>, so we add a rewriting rule <code>t/t -&gt; t</code>. And there is no gliding at <code>ə/h</code>, so we add <code>əh -&gt; əh</code>.</p>
<p>After this transformation, we obtain <code>dɪjəhɪtɒm</code></p>
<p>This is the basic idea of text-to-speech via generative grammar. For speech-to-text, one would first convert the speech audio into a sequence of phonemes,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> then reverse the generative grammar in the same way as one uses generative grammar to parse the syntax tree of a sentence.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Sometimes you see people distinguish “phone” from “phoneme”. In those cases, they make a finer distinction between what the speaker <em>intends to say</em> vs what actually comes out of their mouth. In this example, the phoneme would be <code>...</code> while the phone would be <code>...</code>. This precision is too annoying to me, so instead I will just say that the “phone” is just another “phoneme”, and the speaker intends to say the phoneme sequence <code>...</code>, which the speaking cortex in the brain encodes into the phoneme sequence <code>...</code> to save work for the throat muscles.</p></div></div><p>Unlike other aspects of natural language processing, speech-to-text had never abandoned statistics. Even the most ardent logical AI researcher admit that speech is filled with dirty random noise, and so must be processed by statistical filtering before it is clean enough to run symbolic programs over.</p>
<p>There were many logical ASR systems tried, but most of them consisted of 3 layers:</p>
<ol type="1">
<li>Filter and segment speech into phone-like units, usually in steps of 10 milliseconds (because vowel <a href="https://en.wikipedia.org/wiki/Formant">formants</a> are on the order of 100 Hz).</li>
<li>Use pattern recognition to identify the segments</li>
<li>Find the utterance that best fits the identified segment string.</li>
</ol>
<p>Roughly speaking, “the fit” is usually measured by how many rules are broken, with the rules written by expert linguists. Some examples would make the structure clear.</p>
</section>
<section id="arpa-speech-understanding-project" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="arpa-speech-understanding-project">ARPA Speech Understanding Project</h3>
<p>Like MT, there was also plenty of funding for ASR from the government. And we have not seen the last of John Pierce! 5 years after the ALPAC report debunked MT, he took aim at ASR with mostly the same arguments, but with even sharper language.</p>
<blockquote class="blockquote">
<p>speech recognition is attractive to money. The attraction is perhaps similar to the attraction of schemes for turning water into gasoline, extracting gold from the sea, curing cancer, or going to the moon… It is clear that glamor and any deceit in the field of speech recognition blind the takers of funds as much as they blind the givers of funds. Thus, we may pity workers whom we cannot respect. People who work in the field are full of innocent (in their own view) enthusiasm. What particular considerations have led to this enthusiasm?</p>
<p>… Most recognizers behave, not like scientists, but like mad inventors or untrustworthy engineers. The typical recognizer gets it into his head that he can solve “the problem.” The basis for this is either individual inspiration (the “mad inventor” source of knowledge) or acceptance of untested rules, schemes, or information (the untrustworthy engineer approach).</p>
<p><span class="citation" data-cites="pierceWhitherSpeechRecognition1969">(<a href="#ref-pierceWhitherSpeechRecognition1969" role="doc-biblioref">Pierce 1969</a>)</span></p>
</blockquote>
<p>Pierce gave the same answer as he gave in the ALPAC report. True ASR is impossible until a machine has a general understanding of language, which was very far away. What <em>appears</em> to be ASR is actually “artful deceit” made by mere engineering, not science. A true science of ASR is possible, by having a good scientific theory, then testing it, perhaps by building a device according to the theory, and see if it works as predicted.</p>
<blockquote class="blockquote">
<p>The typical recognizer will have none of this. He builds or programs an elaborate system that either does very little or flops in an obscure way. A lot of money and time are spent. No simple, clear, sure knowledge is gained. The work has been an experience, not an experiment.</p>
<p><span class="citation" data-cites="pierceWhitherSpeechRecognition1969">(<a href="#ref-pierceWhitherSpeechRecognition1969" role="doc-biblioref">Pierce 1969</a>)</span></p>
</blockquote>
<p>I don’t know what caused Pierce to fire off this fiery missive 3 years after the ALPAC report, but it did cause funding to decrease. <span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span> Partly in reaction to this, ARPA started the Speech Understanding Project, a $15 million project to produce ASR, from 1971 to 1976. It funded 4 teams in 4 organizations, with the following goal: Demo a system that can do ASR on a fragment of English limited to 1000 words of vocabulary, and a single tiny domain. Accept new speakers after finetuning. At &lt;10% semantic error, at 100 MIPSS (100 million instructions per second of speech).<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;The full specification is</p>
<blockquote class="blockquote">
<p>Accept continuous speech from many cooperative speakers of the general American dialect, in a quiet room over a good quality microphone, allowing slight tuning of the system per speaker, but requiring only natural adaptation by the user, permitting a slightly selected vocabulary of 1,000 words, with a highly artificial syntax, and a task like the data management or computer status tasks (but not the computer consultant task), with a simple psychological model of the user, providing graceful interaction, tolerating less than 10% semantic error, in a few times real time, and be demonstrable in 1976 with a moderate chance of success.</p>
<p><span class="citation" data-cites="newellSpeechUnderstandingSystems1973">(<a href="#ref-newellSpeechUnderstandingSystems1973" role="doc-biblioref">Allen Newell et al. 1973, fig. 1.1</a>)</span></p>
</blockquote>
<p>but as noted in <span class="citation" data-cites="medressSpeechUnderstandingSystems1977">(<a href="#ref-medressSpeechUnderstandingSystems1977" role="doc-biblioref">Medress et al. 1977</a>, footnote 8)</span>, the report forgot to add in “100 MIPSS”.</p></div></div><p>By the end of 1976, the results were out:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/DARPA_SUR_final_results.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="ermanHearsayIISpeechUnderstandingSystem1980">(<a href="#ref-ermanHearsayIISpeechUnderstandingSystem1980" role="doc-biblioref">Erman et al. 1980, fig. 13</a>)</span></figcaption>
</figure>
</div>
<p>Out of the 4 teams, only Harpy achieved the target – barely. It could recognize 1011 words, at 5% semantic error. It has size 1.2 MB. It costs 30 MIP to process one second of speech, and since it ran on a 0.4 MIPS PDP-KAI0, it takes about 5 minutes to process a single 4-second sentence, costing about $5 to process one sentence. Fine-tuning for a single speaker takes about 30 minutes, or $30.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;According to <a href="https://www.jcmit.net/cpu-performance.htm">Cost of CPU Performance Through Time 1944-2003</a>, it cost $500,000 to rent a PDP-KAI0 for 1 year, or about $1 per minute.</p>
<p>As of 2024, the SOTA ASR model is OpenAI Whisper, which OpenAI offers at a price of <span class="math inline">\(\$10^{-4}\)</span> per second. Since $1 can buy you 1 hour of AI00 at <span class="math inline">\(10^{20} \;\mathrm{FLOP/hour}\)</span>, and assuming hardware utilization 10%, we have about <span class="math inline">\(10^{15} \;\mathrm{FLOP}\)</span> to process 1 second of speech.</p>
<p>I took a double take on this. Are we really throwing 1 million times more compute on ASR compared to Harpy? But the numbers are numbers, and it does seem to checkout: OpenAI Whisper large has <span class="math inline">\(1.55\times 10^9\)</span> parameters, and it featurizes 1 second of speech into <span class="math inline">\(100\)</span> tokens of <span class="math inline">\(80\)</span> dimensions each. So even if we ignore the quadratic scaling of attention, we would take <span class="math inline">\(10^{13} \;\mathrm{FLOP}\)</span> to process 1 second of speech.</p>
<p>And <span class="math inline">\(10^{15}\)</span> is also the number of synapses in the brain. The numbers all seem to come together <em>too</em> well. Sound-bite for thought…</p></div></div><p>Who would be willing to pay $5 to transcribe one sentence? Still, since the target was so ambitious, the project was still considered a great success:</p>
<blockquote class="blockquote">
<p>In 1971, when the program started, perhaps the majority of informed technical opinion put general speech recognition by computers as not possible in the foreseeable future and perhaps not possible at all… Informed technical opinion can now be that general cost-effective speech input to computers is an attainable goal. That is now our opinion.</p>
<p><span class="citation" data-cites="medressSpeechUnderstandingSystems1977">(<a href="#ref-medressSpeechUnderstandingSystems1977" role="doc-biblioref">Medress et al. 1977</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>“How hard is the sentence understanding problem in the limited contexts investigated during the ARPA project?” In 1970, when compared with isolated word recognition, the problems seemed immense. After the limited success of Harpy, one becomes more optimistic about the abilities of future systems.</p>
<p><span class="citation" data-cites="klattReviewARPASpeech1977">(<a href="#ref-klattReviewARPASpeech1977" role="doc-biblioref">Klatt 1977</a>)</span></p>
</blockquote>
<p>Harpy had the simplest architecture, with just two parts.</p>
<ul>
<li>The lower divides the input audio into 10 ms segments. Each segment is featurized to a single <span class="math inline">\(\mathbb{R}^{14}\)</span> vector by <a href="https://en.wikipedia.org/wiki/Linear_predictive_coding">Linear Predictive Coding</a>. If two segments have similar features, they are merged.</li>
<li>The upper part is a 15000-state transition graph. Each graph node is an annotated sound symbol. There are 98 sound symbols like <code>G BURST 1</code> or <code>IY</code>. The annotations allow the system to convert any path through the graph into a text sentence, like “Give me a textbook by Gauss.”.</li>
</ul>
<p>They first designed a complete context-free grammar that incorporates phonetics, syntax, and semantics for making document retrieval requests in a highly simplified and stilted syntax. The 98 sound symbols were constructed by “careful analysis of 747 sentences”. After the design was complete, the grammar was automatically compiled into the 15000-state transition graph.</p>
<p>To perform speech recognition, the lower part gives the upper part the featurized sequence of the audio <span class="math inline">\(v_1, v_2, \dots, v_n\)</span>, and the upper part beam-searches for a path <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> that approximately minimizes <span class="math inline">\(\sum_i \| v_i - v(x_n)\|\)</span>, where <span class="math inline">\(v(x_i)\)</span> is the template feature vector for the sound <span class="math inline">\(x_i\)</span>.</p>
<p>To finetune the system for a new speaker, the new speaker simply speaks 20 sentences designed for finetuning, and the system would recalculate the 98 template feature vectors.</p>
<div id="fig-harpy" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-harpy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Reddy_1980_fig_9_4.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Overall design of Harpy. Note how semantic, syntactic, lexical, and word juncture rules are all compiled into a single network. <span class="citation" data-cites="reddyMachineModelsSpeech1980">(<a href="#ref-reddyMachineModelsSpeech1980" role="doc-biblioref">R. Reddy 1980, fig. 9.4</a>)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Reddy_1980_fig_9_5.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A small fragment of Harpy’s network. <span class="citation" data-cites="reddyMachineModelsSpeech1980">(<a href="#ref-reddyMachineModelsSpeech1980" role="doc-biblioref">R. Reddy 1980, fig. 9.5</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Reddy_1980_fig_9_8.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Example of beam search used in Harpy. <span class="citation" data-cites="reddyMachineModelsSpeech1980">(<a href="#ref-reddyMachineModelsSpeech1980" role="doc-biblioref">R. Reddy 1980, fig. 9.8</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-harpy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1
</figcaption>
</figure>
</div>
<p>Significantly, despite using a beam search, Harpy did <em>not</em> use a probabilistic model of language. It essentially treats language as Chomsky-nonrandom, and all the randomness comes from imperfect matching between the real feature vectors and the template feature vectors. Despite this, it out-performed other systems that did. It seems that the problem was that there was insufficient data to estimate the probabilities in a probabilistic language model.</p>
<blockquote class="blockquote">
<p>Several of the speech understanding systems used estimates of the probability of a phonetic or lexical decision given the acoustic data in scoring the goodness of a theory, and each seems to have gotten into trouble by so doing. The problem is to analyze enough data to be sure of the probability of infrequent confusions. This is nearly impossible if one wants to take into consideration factors such as phonetic environment.</p>
<p><span class="citation" data-cites="klattReviewARPASpeech1977">(<a href="#ref-klattReviewARPASpeech1977" role="doc-biblioref">Klatt 1977</a>)</span></p>
</blockquote>
<p>Just as significant, there was a lot of artificial intelligence, but very little machine learning. All the formal grammars were hand-written. It is revealing that in a comprehensive review of ASR <span class="citation" data-cites="reddySpeechRecognitionMachine1976">(<a href="#ref-reddySpeechRecognitionMachine1976" role="doc-biblioref">D. R. Reddy 1976</a>)</span>, “knowledge acquisition” took up less than 2% of the whole paper. And what little it said comes down to that learning-based methods require a large dataset of carefully and densely annotated audio, which was expensive and did not exist.</p>
<p>The last great attempt at logical ASR was the Hearsay-II, a further development from Hearsay, an unsuccessful entrant to the ARPA Speech Understanding Project. It was a towering giant with 7 levels, from “data base interface” and “phrase” all the way down to the “segment” and “parameter” and 15 knowledge sources (collection of rules) for going up and down the levels of abstraction. To handle this pandemonium of knowledge sources, it uses a “shared blackboard” architecture, so that each source can chime in about whatever is currently being interpreted. This allowed it to still work even if some sources are removed, and to improve whenever any source gets added or upgraded.</p>
<p>On one hand, it is great for interpretability, as one can trace through the entire structure and see exactly how any spoken sentence is parsed into a textual sentence. On the other hand, the interpretation took 39 steps and looks like:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Step 23. KS: PREDICT &amp; VERIFY*.</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Stimulus: BY+FEIGENBAUM+AND+FELDMAN+]* (phrase).</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Action: Predict ten preceding words. Reject five: ABSTRACTS, ARE, BOOKS, PAPERS, REFERENCED. Find two already on the blackboard: </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    ANY* (65,24: 49),</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    THESE (25, 28:49).</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>Verify three more:</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    ARTICLE (25, 9:52),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    WRITTEN (25, 24:52),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    ARTICLES (10, 9:52).</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Hearsay-II_levels.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The levels and knowledge sources of Hearsay-II as of 1976-09. Knowledge sources are indicated by vertical arcs with the circled ends indicating the input level and the pointed ends indicating output level. <span class="citation" data-cites="ermanHearsayIISpeechUnderstandingSystem1980">(<a href="#ref-ermanHearsayIISpeechUnderstandingSystem1980" role="doc-biblioref">Erman et al. 1980, fig. 2</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Hearsay-II_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Overall architecture of Hearsay-II. <span class="citation" data-cites="ermanHearsayIISpeechUnderstandingSystem1980">(<a href="#ref-ermanHearsayIISpeechUnderstandingSystem1980" role="doc-biblioref">Erman et al. 1980, fig. 4</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Hearsay-II_example_sentence.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The example utterance. (a) the waveform of “Are any by Feigenbaum and Feldman?”; (b) the correct words (for reference), (c) segments; (d) syllable classes; (e) words (created by MOW), (f) words (created by VERIFY), (g) word sequences, (h) phrases. <span class="citation" data-cites="ermanHearsayIISpeechUnderstandingSystem1980">(<a href="#ref-ermanHearsayIISpeechUnderstandingSystem1980" role="doc-biblioref">Erman et al. 1980, fig. 5</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="linguists-fired" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="linguists-fired">Linguists fired</h3>
<blockquote class="blockquote">
<p>Every time I fire a linguist, the performance of our speech recognition system goes up.</p>
<p>— Frederick Jelinek (1988) (not apocryphal!)</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Frederick_Jelinek">Frederick Jelinek</a> would go down in history as the one who fired linguists, but he did not start his life this way. In 1961, he sat in Chomsky’s lectures, and “got the crazy notion that I should switch from Information Theory to Linguistics”. His PhD advisor forbade him, so he remained in information theory. After graduation, he tried collaborating with the eminent linguist <a href="https://en.wikipedia.org/wiki/Charles_F._Hockett">Charles Hockett</a>, bu Hockett then turned to composing operas. “Discouraged a second time, I devoted the next 10 years to Information Theory.” <span class="citation" data-cites="jelinekDawnStatisticalASR2009">(<a href="#ref-jelinekDawnStatisticalASR2009" role="doc-biblioref">Jelinek 2009</a>)</span></p>
<p>In 1972, he left academia and joined IBM, where he worked on ASR. The project started with two linguists, but they got frustrated and left of their own accord, leaving behind engineers and physicists with little understanding of linguistics.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;More details about this funny episode:</p>
<blockquote class="blockquote">
<p>When handling natural speech, the main question was how to estimate the language model <span class="math inline">\(Pr(W)\)</span>. There was no simple way of achieving this. We thought that the right approach ought to be somehow related to English grammar. The linguist Stan Petrick, while he still was with us, said “Don’t worry, I will just make a little grammar.” Of course he never did, and the phrase acquired a mythical status in the manner of “famous last words.”</p>
<p><span class="citation" data-cites="jelinekDawnStatisticalASR2009">(<a href="#ref-jelinekDawnStatisticalASR2009" role="doc-biblioref">Jelinek 2009</a>)</span></p>
</blockquote>
</div></div><blockquote class="blockquote">
<p>When our Continuous Speech Recognition group started its work at IBM Research, the management wanted to make sure that our endeavors were guided by strict scientific principle. They therefore placed into the group two linguists who were going to guide our progress. Both linguists were quite self-confident, sure that fast progress will be possible. For instance, when we (trained as engineers or physicists) were at a loss how to construct a language model, one of the linguists declared “I’ll just write a little grammar.”… After about a year of frustration the linguists left our group, returned to their basic research, and we were free to pursue our self-organized, data driven, statistical dream… mostly of engineers and physicists. Only 3 or 4 people out of 10 had any previous experience with speech. None had graduate training in that field. But several of us had a background in Information Theory and that influenced our thinking.</p>
<p><span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span></p>
</blockquote>
<p>It was unclear what exactly frustrated the linguists, but probably it was because they did not want, or did not have, the stamina to produce generative grammar for non-toy English:</p>
<blockquote class="blockquote">
<p>In the 1970s NLP and ASR research was dominated by an artificial intelligence approach. Programs were rule-based, expert systems were beginning to take over… The purest linguists based their work on self-constructed examples, not on the prevalence of phenomena in observed data. As already mentioned, strict distinction between training and test was frequently ignored. Grammars were being written that applied to less than dozen verbs.</p>
<p><span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span></p>
</blockquote>
<p>This dedication to toys and “microworlds” rather than would appear again later in the saga of <a href="#sec-shrdlu">SHRDLU</a>.</p>
<p>The group naturally reproduced the information-theoretic framework for MT proposed by Shannon and Weaver, and adapted it directly to ASR.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> In the framework, there are 4 components:</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;Apparently the idea was obvious as soon as you think about ASR in the mindset of information theory.</p>
<blockquote class="blockquote">
<p>As to our problem formulation, we were later somewhat surprised when it was revealed to be almost common sense. In fact, it was probably Bob Mercer who found the following quotations in an article by Weaver (1995):</p>
<blockquote class="blockquote">
<p>When I look at an article in Russian I say: This is really written in English but it has been coded in some strange symbols. I will now proceed to decode it… the matter is probably absolutely basic – namely the statistical character of the problem.</p>
</blockquote>
<p><span class="citation" data-cites="jelinekDawnStatisticalASR2009">(<a href="#ref-jelinekDawnStatisticalASR2009" role="doc-biblioref">Jelinek 2009</a>)</span></p>
</blockquote>
</div></div><ol type="1">
<li>A language model: <span class="math inline">\(Pr(\text{text})\)</span>. This models how a human thinks up what to say in its head.</li>
<li>A model of the speaker: <span class="math inline">\(Pr(\text{sound}|\text{text})\)</span>. This models how the text to be spoken gets converted into actual sound out of its mouth.</li>
<li>Audio preprocessor: <span class="math inline">\(\text{sound} \mapsto \text{features}\)</span></li>
<li>Decoder: <span class="math inline">\(\text{features} \mapsto \text{text}\)</span></li>
</ol>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/source-channel_model_ASR.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>Step 3 is “feature engineering”, and it has been fairly static in speech processing: apply some high-pass filter, compute the spectrogram, do some more filtering, etc. Step 4 is maximum a posteriori estimation, exactly the same as in the IBM alignment model:<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;Not a coincidence. The IBM team did ASR first, and once that succeeded, proceeded to trying the same trick with MT in 1986.</p>
<blockquote class="blockquote">
<p>we embarked on MT in 1986 when we sought a new area to which to apply our statistical, self organized techniques. Besides, we had 15 years of ASR work behind us and those who switched were also attracted by the change as well as the possibility of picking some “low hanging fruit”. We had two ideas: to use the noisy channel paradigm to formulate the problem (see Figure 3), and to base our learning on parallel texts. <span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span></p>
</blockquote>
</div></div><p><span class="math display">\[
\text{text} = \mathop{\mathrm{argmax}}_{\text{text}} Pr(\text{text}) Pr(\text{sound}|\text{text})
\]</span></p>
<p>Step 1 of this framework turned out to be the critical idea. In the pure Chomskyan viewpoint, step 1 is illegitimate. In the information-theoretic viewpoint, step 1 is essential.</p>
<p>TODO Write about how this forced them to think about a different way to measure success. If they gave up the idea of either-or, then how does one tell if the program was improving? Inspired by Harpy, they decided to measure the branching factor … then perplexity.</p>
<p>It was of course possible, and even obvious, that one can combine the best of both worlds, to combine both linguistic insights and statistical methods, such as a probabilistic CFG. However, they simply trained a dumb trigram language model on a large corpus. From what Jelinek said later,<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> my guess is that they did try such “best of both worlds” approach, but the dumb trigram model just worked better.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><blockquote class="blockquote"><sup>10</sup>&nbsp;
<p>We were never reluctant to include linguistic knowledge or intuition into our systems: if we didn’t succeed, it was because we didn’t find an efficient way to do include it.</p>
<p><span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span></p>
</blockquote>
</div><div id="fn11"><p><sup>11</sup>&nbsp;It was called such because the team took over a previous logical ASR system called “Rayleigh”. Its design was typical Chomskyan:</p>
<blockquote class="blockquote">
<p>The front end of the Raleigh system converted the speech signal… into a sequence of phoneme-like labels (100 labels per second), using an elaborate set of hand-tuned rules that would soon be replaced with an automatically trained procedure. The back end converted these labels into a sequence of words using an artificial finite-state grammar that was so small that the finite-state machine could be written down on a single piece of paper… very often phones were simply mislabeled. The back end was designed to overcome these problems by navigating through the finite-state network, applying a complicated set of hand-tuned penalties and bonuses to the various paths in order to favor those paths where the low-level acoustics matched the high-level grammatical constraints.</p>
<p><span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>)</span></p>
</blockquote>
</div></div><p>The IBM project, compared to the others, was definitely big-data. This served them well for statistical ASR, and would soon serve them well again for statistical MT. They started with a toy model of language called “New Rayleigh”, which is essentially a Markov chain model that generates sentences up to 8 words long, from a vocabulary of 250 words.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/New_Rayleigh_toy_language.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The New Rayleigh toy language. <span class="citation" data-cites="jelinekDawnStatisticalASR2009">(<a href="#ref-jelinekDawnStatisticalASR2009" role="doc-biblioref">Jelinek 2009, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>They soon produced an ASR model that achieved perfect accuracy on this, so they had to go bigger. The next dataset they obtained was the “laser patent corpus”, consisting of 2 million words of patent applications in laser technology, with a vocabulary size of 10,000, twice as large as the <a href="https://en.wikipedia.org/wiki/Brown_Corpus">Brown Corpus (1961)</a>. They used this to train a 3-gram language model. The road to this dataset was quite circuitous, which anyone who has tried making a non-toy dataset can relate:</p>
<blockquote class="blockquote">
<p>The struggle to compile a suitable training corpus featured throughout the CSR [Continuous Speech Recognition] group’s first decade. The researchers first considered using a collection of digitized IBM manuals, but found the vocabulary to be too extensive as well as so technical that it proved “difficult to pass … off as English.” They attempted to produce their own corpus, enlisting the wife of a lab staff member to type approximately a million words of text from children’s novels, but there, too, the vocabulary proved too large for their purposes. Next, the group acquired a collection of laser patent text from the US Patent Office, which was both sufficiently extensive in size and sufficiently narrow in vocabulary that they were finally able to extract a million words of running text confined to a thousand-word vocabulary. Though the laser patent corpus was considered “naturally occurring,” it was in fact meticulously constructed, even before researchers discarded all sentences containing vocabulary outside of the thousand most frequently occurring words. The complete patent text had to be first “subjected to intensive hand and computerized editing”: eliminating duplicates, merging spelling variations, and substituting scientific symbols and formulas. The claims sections of the patents proved especially problematic due to “highly stylized” legal language, and were ultimately excised entirely.</p>
<p>By the 1980s hardware improvements allowed the IBM researchers to expand their recognition vocabulary to five thousand words. They also compiled over 100 million words of data from a variety of sources, including public domain books and magazines from the American Printing House for the Blind, the records of the Amoco oil corporation, and 2.5 million words of office correspondence supplied by physicist Richard Garwin, who, with the aid of four secretaries, maintained computer-formatted duplicates of all of his correspondence. The most substantial collection in this period, however, came as a direct result of IBM’s unique industry dominance: the landmark federal antitrust lawsuit filed against the company in 1969. The case, which spanned thirteen years before it was finally dismissed in 1982, included testimony from 974 witnesses with resulting transcripts that totaled over one hundred thousand pages. The operation to digitize the deposition transcripts during the trial was so prodigious that it required a staff of dedicated keypunch operators large enough to fill a facility the size of a football field in White Plains, New York, where IBM’s Data Processing Division was headquartered. While the suit itself proved extremely costly for IBM, its transcript digitization efforts provided the CSR group with their largest and most robust text collection, resulting in a corpus of one hundred million words. Finally, the CSR group discovered the Hansard corpus, a collection of digitized transcripts of the Canadian Parliament official proceedings in both English and French, in the mid-1980s and incorporated an additional hundred million words from its English text into their language model.</p>
<p><span class="citation" data-cites="liTheresNoData2023">(<a href="#ref-liTheresNoData2023" role="doc-biblioref">Li 2023</a>)</span></p>
</blockquote>
<p>In 1976, their ASR system had already reached state of the art performance. On the same task as the ARPA project, it reached higher accuracy, and only took 30 MIP to process 1 second of speech. <span class="citation" data-cites="reddySpeechRecognitionMachine1976">(<a href="#ref-reddySpeechRecognitionMachine1976" role="doc-biblioref">D. R. Reddy 1976</a>)</span> Though logical ASR continued with systems like Hearsay-II (1980), as the 1980s went on, none could deny the practical success of statistical ASR anymore, even if, compared to logical ASR, statistical ASR was far from linguistic theories of human speech recognition.</p>
<p>In the 1990s, all state of the art ASR were statistical, usually HMM-based. Such a model has multiple levels.</p>
<p>At the top level, there is a Markov chain that serves as a language model, which emits individual words. This is usually an n-gram model, where <span class="math inline">\(n\)</span> is usually 3. In such a model, each node is a 3-gram. For example, the model can have state transitions like “- - what” → “- what is” → “what is the” → “is the last” → …, and it would emit “what”, “is”, “the”, “last”, …</p>
<p>This sequence of words is then converted to a sequence of phonemes, like “wɒtɪzðəlɑːst”. Each phoneme, like “ɪ”, corresponds to a trained Markov chain. That is, we have a Markov chain with around 3 to 5 states that emits feature vectors corresponding to a possible pronunciation of “ɪ”.</p>
<p>We can even hand-write such a Markov chain, as an example. We would start by collecting many recordings of “ɪ”, then cut these into three parts: the start, the middle, and the end. We convert each part into a feature vector: <span class="math inline">\(v_0, v_1, v_2\)</span>. We give each feature vector a state in the Markov chain. A trajectory through the Markov chain would start at <span class="math inline">\(v_0\)</span>, stay there for a short while, then randomly jump to <span class="math inline">\(v_1\)</span>, stay there for a long while, and then randomly jump to <span class="math inline">\(v_2\)</span>, stay there for a short while, and finally jump to the “END” state. We would assign the transition probability <span class="math inline">\(Pr(v_2 | v_2)\)</span> to be roughly <span class="math inline">\(1-1/N\)</span>, where <span class="math inline">\(N\)</span> is the average number of 10-ms segments that it takes to pronounce the middle of “ɪ”.</p>
<p>The above system is the basic idea. It does not handle the effect of gliding between phonemes, like how “did you” would be pronounced as “dija”. The standard way to handle this was the triphone model. The triphone model accounts for how a phoneme is changed by its two neighbors. For example, in the previous example, the “ɪ” should really be pronounced in the context of “tɪz”. So, we would have a Markov chain just for “tɪz”, which would generate a sequence of feature vectors that corresponds to how “ɪ” would be pronounced if it appears in the context of “tɪz”. Since English has about 50 phonemes, a triphone model need ~2500 Markov chains, which explains why quad-phone models, or more, had not been popular. Even if one had the appetite for it, there was not enough data to train them.</p>
<p>By late 1990s, the ASR technology stabilized around the gaussian mixture HMM <span class="citation" data-cites="huangHistoricalPerspectiveSpeech2014">(<a href="#ref-huangHistoricalPerspectiveSpeech2014" role="doc-biblioref">Huang, Baker, and Reddy 2014</a>)</span>, where the lowest level of HMM does not emit a feature vector <span class="math inline">\(v\)</span>, but a <a href="https://en.wikipedia.org/wiki/Mixture_model">gaussian mixture distribution</a> <span class="math inline">\(\sum_i p_i \mathcal N(\mu_i, \Sigma_i)\)</span> of feature vectors. You can add even more epicycles upon epicycles to account for more complex features like omitting phonemes, phonotactic constraints, prosody, etc.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/HMM_ASR.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Rough sketch of HMM ASR. <a href="https://www.cs.cmu.edu/~roni/10601-slides/hmm-for-asr-whw.pdf">Source</a></figcaption>
</figure>
</div>
<p>Unlike in the case of MT, the collapse of logical AI in ASR was decisive. Statistical ASR completely replaced logical ASR in the 1990s, after which logical ASR was never revived. There were two reasons for this. One is the familiar scaling story of data and compute:</p>
<blockquote class="blockquote">
<p>As computers increased in power, ever greater tracts of the heuristic wasteland opened up for colonization by probabilistic models. As greater quantities of recorded data became available, these areas were tamed by automatic training techniques. Today… almost every aspect of most speech recognition systems is dominated by probabilistic models with parameters determined from data.</p>
<p><span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>)</span></p>
</blockquote>
<p>Another is the public benchmark culture. The ARPA SUR project not only demonstrated that ASR was possible, but also gave rise to the benchmark-focused culture of ASR, which allowed the best methods to rapidly spread through the community:</p>
<blockquote class="blockquote">
<p>ARPA (and then DARPA) funded a number of new speech research programs, beginning with 1000-word speaker-independent read-speech tasks like “Resource Management” (Price et al., 1988), recognition of sentences read from the Wall Street Journal (WSJ), Broadcast News domain (LDC 1998, Graff 1997) (transcription of actual news broadcasts, including quite difficult passages such as on-the-street interviews) and the Switchboard, CallHome, CallFriend, and Fisher domains (Godfrey et al.&nbsp;1992, Cieri et al.&nbsp;2004) (natural telephone conversations between friends or strangers). The ARPA competitions resulted in wide-scale borrowing of techniques among labs since it was easy to see which ideas reduced errors the previous year, and the competitions were probably an important factor in the eventual spread of the HMM paradigm.</p>
<p><span class="citation" data-cites="jurafskySpeechLanguageProcessing2023">(<a href="#ref-jurafskySpeechLanguageProcessing2023" role="doc-biblioref">Jurafsky and Martin 2023, 352–53</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/ASR_benchmark_progress_1988--2012.jpg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Progress of ASR benchmarks during 1988–2012. Each time one benchmark was saturated, it was replaced by a harder one. The green dot was the 2012 SOTA for the Switchboard task. <span class="citation" data-cites="huangHistoricalPerspectiveSpeech2014">(<a href="#ref-huangHistoricalPerspectiveSpeech2014" role="doc-biblioref">Huang, Baker, and Reddy 2014, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>This was not the end of the history, however. Once ASR became a statistical problem, one immediately has the problem of feature engineering. Here, the history is similar to that of vision. One begins by imitating the human phoneticians with a nearest-neighbor matching to phonemes, and proceeds to handcrafted features computed over the audio spectrogram, to NN features learned over transforms of the spectrogram, and finally to NN features learned directly over the spectrogram. <span class="citation" data-cites="huangHistoricalPerspectiveSpeech2014">(<a href="#ref-huangHistoricalPerspectiveSpeech2014" role="doc-biblioref">Huang, Baker, and Reddy 2014</a>)</span> However, the story must be left for a future essay.</p>
</section>
<section id="a-farewell-to-linguists" class="level3">
<h3 class="anchored" data-anchor-id="a-farewell-to-linguists">A farewell to linguists</h3>
<p>What was so radical about Jelinek’s approach?</p>
<p>One, to believe in the probabilistic system at all was a breakthrough during the Chomskyan period. As Liberman recounts in an anecdote in the 1970s:</p>
<blockquote class="blockquote">
<p>[Kenneth Church was] applying context-free parsing to phonotactic speech recognition, assuming a non-stochastic grammar. I suggested that Ken should find or create a collection of phonetic transcriptions, and use it to associate probabilities with his rewrite rules. Ken’s response was to quote Richard Nixon’s remark about Daniel Ellsberg: “We could kill him–but that would be wrong.” Further discussion elicited a quote from one of his AI lab professors: “If you need to count higher than one, you’ve made a mistake.”</p>
<p><span class="citation" data-cites="libermanObituaryFredJelinek2010">(<a href="#ref-libermanObituaryFredJelinek2010" role="doc-biblioref">Liberman 2010</a>)</span></p>
</blockquote>
<p>Two, to throw away preconceptions of what the language model could be, and let results speak. He proceeded directly to using a 3-gram not because it resembles anything like how people really produce language, but because it works.</p>
<blockquote class="blockquote">
<p>In the future the design of a LM for a naturally generated text will probably involve considerations of syntax. semantics. and discourse pragmatics. So far no one has accomplished this.</p>
<p><span class="citation" data-cites="jelinekSelfOrganizedContinuousSpeech1982">(<a href="#ref-jelinekSelfOrganizedContinuousSpeech1982" role="doc-biblioref">Jelinek 1982</a>)</span></p>
</blockquote>
<p>Three, to believe in the power of big data and big compute.</p>
<blockquote class="blockquote">
<p>Our models are derived from as much actual speech data as we can obtain and handle computationally. We have devised methods of automatic model computation, thus minimizing or completely eliminating human intervention. Our strategies are not based on rules developed from trying to intuit how people recognize sentences (as is prevalent elsewhere), although the basic structure of our models is, of course, man-made. This approach is both more accurate and more flexible; as the speaker or the components of the system change, our self-organizing programs remain valid, and computer time is all that is required to adjust to a new configuration.</p>
<p><span class="citation" data-cites="jelinekSelfOrganizedContinuousSpeech1982">(<a href="#ref-jelinekSelfOrganizedContinuousSpeech1982" role="doc-biblioref">Jelinek 1982</a>)</span></p>
</blockquote>
<p>More presciently, he was even considering the possibility of throwing away the preconceptions of what the features could be, and let data speak:</p>
<blockquote class="blockquote">
<p>Because we have found it more fruitful to view the acoustic processor as a data compressor than as an artificial phonetician, we do not attempt to identify phonetic segments in the continuous speech.</p>
<p><span class="citation" data-cites="jelinekSelfOrganizedContinuousSpeech1982">(<a href="#ref-jelinekSelfOrganizedContinuousSpeech1982" role="doc-biblioref">Jelinek 1982</a>)</span></p>
</blockquote>
<p>Previous MT systems typically performs multi-step processing on a raw audio signal, and somewhere in the middle, the audio signal would be transformed into a phonetic transcription. Jelinek, instead of following tradition and featurize audio into a list of phonemes (“an artificial phonetician”), just proposed to featurize audio in whatever way that seemed to work better for the system. As far as I see, this was not used in HMM ASR during the 1990s, but we know that automatic feature learning would finally be vindicated by neural networks around 2010 as the encoder-decoder architectures trained fully end-to-end <span class="citation" data-cites="gravesConnectionistTemporalClassification2006 chorowskiEndtoendContinuousSpeech2014">(<a href="#ref-gravesConnectionistTemporalClassification2006" role="doc-biblioref">Graves et al. 2006</a>; <a href="#ref-chorowskiEndtoendContinuousSpeech2014" role="doc-biblioref">Chorowski et al. 2014</a>)</span></p>
<p>In 2005, near the end of his life, Jelinek admitted that his quote was, despite his best hopes, genuine.</p>
<blockquote class="blockquote">
<p><em>Whenever I fire a linguist our system performance improves.</em> I have hoped for many years that this quote was only apocryphal, but at least two reliable witnesses have recently convinced me that I really stated this publicly in a conference talk (Jelinek, 1998). Accepting then that I really said it, I must first of all affirm that I never fired anyone, and a linguist least of all. So my motivation is defensive: to show that neither I nor my colleagues at IBM ever had any hostility to linguists or linguistics. In fact, we all hoped that linguists would provide us with needed help. We were never reluctant to include linguistic knowledge or intuition into our systems: if we didn’t succeed, it was because we didn’t find an efficient way to do include it.</p>
<p><span class="citation" data-cites="jelinekMyBestFriends2005">(<a href="#ref-jelinekMyBestFriends2005" role="doc-biblioref">Jelinek 2005</a>)</span></p>
</blockquote>
<p>Reflecting on a lifetime of multiple near-linguistic experiences, Jelinek seemed regretful. It is not that he wanted to fire linguists, it was simply that, somehow, attempting to incorporate linguistic expertise hurt performance. He died in 2010, just in time to miss the deep learning revolution that fired the last linguists.</p>
<blockquote class="blockquote">
<p>the statistical model of language with which he had so successfully replaced linguistic rules was a simple word trigram – i.e.&nbsp;a very crude model of three word sequences. Whilst it was obvious to everyone that this model was hopelessly impoverished, in practice it had proved almost impossible to improve on. However, in the year 2000, Fred published a paper with one of his students called “Structured language modeling for speech recognition”. It sets out a principled way to incorporate linguistics into a statistical framework and as well as representing a significant step forward in language modeling, it has helped bridge the gap between speech engineers and the hitherto diverging computational linguistics community. In 2002, it received a “Best Paper” award and the citation read “for work leading to significant advances in the representation and automatic learning of syntactic structure in statistical language models”. It seemed somehow fitting that 25 years after starting the movement towards statistical approaches, Fred sought to re-engage with aspects of more traditional linguistics. I hope Chomsky read the paper and enjoyed it as much as we speech technologists did.</p>
<p><span class="citation" data-cites="youngFrederickJelinek193220102010">(<a href="#ref-youngFrederickJelinek193220102010" role="doc-biblioref">Young 2010</a>)</span></p>
</blockquote>
</section>
<section id="text-to-speech" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="text-to-speech">Text to speech</h3>
<p>While this section is titled “Speech”, we have only discussed speech-to-text. Naturally, there is also the direction of text-to-speech (TTS). Here the history is more compressed, if for the simple reason that humans are <em>really good</em> at understanding speech. Even the most primitive kinds of text-to-speech was usable, and it was merely a matter of making it cheaper and less robotic-sounding. Indeed, a very early TTS synthesized speech by gluing together magnetic tape recordings and playing the whole thing at once. <span class="citation" data-cites="harrisStudyBuildingBlocks1953">(<a href="#ref-harrisStudyBuildingBlocks1953" role="doc-biblioref">Harris 1953</a>)</span></p>
<p>At the forefront of speech synthesis research was Bell Labs, which was trying to compress and decompress speech to fit more telephone calls into telephone cables. In 1961 at Bell Labs, an IBM 7094 sang “Daisy Bell”. Arthur Clarke, while visiting his friend John Pierce (this is the last time we’ll see him), saw a demo of this, and he was so impressed that he put this scene into <em>2001: A Space Odyssey</em> (1968). <span class="citation" data-cites="woodRecollectionsJohnRobinson1991">(<a href="#ref-woodRecollectionsJohnRobinson1991" role="doc-biblioref">Wood and Pierce 1991</a>)</span></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/TTS_family_tree.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The family tree of TTS systems up to 1987. <span class="citation" data-cites="klattReviewTexttospeechConversion1987">(<a href="#ref-klattReviewTexttospeechConversion1987" role="doc-biblioref">Klatt 1987, fig. 4</a>)</span></figcaption>
</figure>
</div>
<p>In 1983, Digital Equipment Corporation started selling one of the first commercially successful TTS system, the <a href="https://en.wikipedia.org/wiki/DECtalk">DECTalk</a>, at the low price of $4000. It was based on the Klattalk formant synthesizer of Dennis Klatt, who had dedicated his life to research on speech, and had the best TTS system available at the time. In a 1987 review of TTS <span class="citation" data-cites="klattReviewTexttospeechConversion1987">(<a href="#ref-klattReviewTexttospeechConversion1987" role="doc-biblioref">Klatt 1987</a>)</span>, Klatt stayed close to the Chomskyan orthodoxy and described TTS as a problem of writing the generative grammar deeper down, from text all the way to the spectrogram of the physical sound.</p>
<div id="fig-klatt-1987" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-klatt-1987-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-klatt-1987" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-todo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-todo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/Klatt_1987_fig_2.png" class="img-fluid figure-img" data-ref-parent="fig-klatt-1987">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-todo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) General architecture of a TTS system according to the Chomskyan orthodoxy. <span class="citation" data-cites="klattReviewTexttospeechConversion1987">(<a href="#ref-klattReviewTexttospeechConversion1987" role="doc-biblioref">Klatt 1987, fig. 2</a>)</span>
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-klatt-1987" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-todo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-todo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/Klatt_1987_fig_3.png" class="img-fluid figure-img" data-ref-parent="fig-klatt-1987">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-todo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Architecture of Klattalk. <span class="citation" data-cites="klattReviewTexttospeechConversion1987">(<a href="#ref-klattReviewTexttospeechConversion1987" role="doc-biblioref">Klatt 1987, fig. 3</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-klatt-1987-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: TODO
</figcaption>
</figure>
</div>
<p>In his literature review, Klatt did take notice of two upstart systems from the statistical side, one being <a href="https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/index.html#terence-sejnowski">NETtalk of Sejnowski</a>, a neural network model, and another being a statistical TTS system very similar to the IBM alignment model, by the same IBM team. He brushed both off as being inferior to a logical TTS system:</p>
<blockquote class="blockquote">
<p>When evaluated on the words of this training set, [NETtalk] was correct for about 90% of the phonemes and stress patterns. In some sense, this is a surprisingly good result in that so much knowledge could be embedded in a moderate number of about 25000 weights, but the performance is not nearly as accurate as that of a good set of letter-to-sound rules (performing without use of an exceptions dictionary, but with rules for recognizing common affixes)… [The IBM alignment] approach still results in an inferior words-correct error rate compared with traditional rule systems. Even a very powerful statistical package cannot yet discover much of the underlying structure in a process as complex as natural language… given the attention that NETtalk and other neuron-like devices have received recently, it is disturbing that NETtalk does not learn training set data perfectly, appears to make generalizations suboptimally, and has an overall performance that is not acceptable for a practical system. Furthermore, it is unlikely that larger training lexicons would converge to a more acceptable performance.</p>
</blockquote>
<p>Indeed, though the word “rules” appears over 200 times in the review, the above dismissal was the only thing he had to say about learning-based methods. Hostility towards machine learning is a recurring feature among the Chomskyans. However, unlike the Chomskyans, Klatt was not going to be satisfied with writing toy respected the extreme complexity of a proper system of rules. And try he did:</p>
<blockquote class="blockquote">
<p>The hard part of text-to-speech synthesis is to calculate a string of LPC data, or formant-synthesis parameters, not from recorded speech, but from the letters and symbols of typed text… It’s possible to write a simple program for this task, which produces robotlike speech-hard to understand and unpleasant to listen to. The alternative, which only Dennis Klatt and a few others have pursued, is to invest years of effort in devising an increasingly lengthy and subtle set of rules to eliminate the robotic accent.</p>
<p>He turns to a table with two volumes about the size of large world atlases, each stuffed with speech spectrograms… Spectrograms usually feature subtle and easily changing patterns. Klatt’s task has been to reduce these subtleties to rules so that a computer can routinely translate ordinary text into appropriate spectrograms. “I’ve drawn a lot of lines on these spectrograms, made measurements by ruler, tabulated the results, typed in numbers, and done computer analyses,” says Klatt.</p>
<p>As Klatt puts it, “Why doesn’t DECtalk sound more like my original voice, after years of my trying to make it do so? According to the spectral comparisons, I’m getting pretty close. But there’s something left that’s elusive, that I haven’t been able to capture. It has been possible to introduce these details and to resynthesize a very good quality of voice. But to say, ‘here are the rules, now I can do it for any sentence’ – that’s the step that’s failed miserably every time.”</p>
<p>But he has hope: “It’s simply a question of finding the right model.”</p>
<p><span class="citation" data-cites="heppenheimerComputerTalkAmazing1984">(<a href="#ref-heppenheimerComputerTalkAmazing1984" role="doc-biblioref">Heppenheimer 1984</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Klatt_1987_fig_29.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Formant transitions for <code>[g]</code> as a function of preceding and following vowels. <span class="citation" data-cites="klattReviewTexttospeechConversion1987">(<a href="#ref-klattReviewTexttospeechConversion1987" role="doc-biblioref">Klatt 1987, fig. 29</a>)</span></figcaption>
</figure>
</div>
<p>Klatt had been progressively losing his voice from thyroid cancer, and died in 1988. His voice was the template for “Perfect Paul” in DECTalk, which was the voice of Stephen Hawking, which he kept using even after better TTS systems were available. <span class="citation" data-cites="medeirosHowIntelGave2015">(<a href="#ref-medeirosHowIntelGave2015" role="doc-biblioref">Medeiros 2015</a>)</span></p>
</section>
</section>
<section id="vision" class="level2">
<h2 class="anchored" data-anchor-id="vision">Vision</h2>
</section>
<section id="logic-and-logistics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="logic-and-logistics">Logic and logistics</h2>
<section id="planning" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="planning">Planning</h3>
<p>WWII was said to be a war of the physicists, or the code-breakers. It could equally said to be a war of the economists. The side that could sustain a higher industrial output slowly but surely ground down the other side, as strategic bombing destroyed industrial production.</p>
<p>It is either a myth or an obvious point that the soviet union had a bad economic system. In either case, there were two Soviet Nobel laureates in economics. The first was Wassily Leontief, who saw economics not as a simple feedforward network of wheat-to-bread-to-stomach, but as a feedback network of hundreds of industries making commodities for and taking commodities from each other, as made clear in his PhD thesis <em>The Economy as Circular Flow</em> (1928).</p>
<p>Leaving the Soviet Union as a dissident in 1925, he settled in America and performed his input-output analysis of the American economy. Let us divide the economy into <span class="math inline">\(N\)</span> sectors, from “agriculture” to “electricity” to “rubber”. For simplicity, suppose each sector <span class="math inline">\(i\)</span> only makes one kind of commodity <span class="math inline">\(x_i\)</span> – “agriculture” only outputs a generic kind of “food”, etc. Each sector <span class="math inline">\(i\)</span>, in order to create one unit of commodity <span class="math inline">\(x_i\)</span>, requires some commodities <span class="math inline">\(A_{1i}, A_{2i}, \dots, A_{Ni}\)</span> as inputs. Then, if the entire economy produces <span class="math inline">\(x_1, x_2, \dots, x_N\)</span>, then it requires total input <span class="math inline">\(Ax\)</span>, where <span class="math inline">\(A\)</span> is the demand matrix. With this we have the fundamental equation:</p>
<p><span class="math display">\[
x = Ax + y
\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the surplus that comes out of the economy, which Leontieff calls “demand”, since that is what is demanded by consumers outside of the economic production. It seems simplistic – just a linear equation? Yet this was the origin of linear programming.</p>
<p>In 1949, Leontief used an early computer at Harvard and data from the U.S. Bureau of Labor Statistics to divide the U.S. economy into 500 sectors, and balanced the linear equation on the grand scale.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Leontieff_matrix.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Part of an input-output matrix drawn by Leontief. <span class="citation" data-cites="leontiefStructureDevelopment1963">(<a href="#ref-leontiefStructureDevelopment1963" role="doc-biblioref">Leontief 1963, 150</a>)</span></figcaption>
</figure>
</div>
<p>Near the end of the war, Stigler wrote a paper calculating what is the cheapest possible nutritionally complete diet. He concluded that at 1939 prices, a minimal viable diet cost $40 per year for an adult American man, which was 1/3 the price of previous results. He concluded that the previous dieticians were not ruthless enough, and confused biological needs with cultural needs:</p>
<blockquote class="blockquote">
<p>The dieticians take account of the palatability of foods, variety of diet, prestige of various foods, and other cultural facets of consumption. Primarily on such grounds can one explain their emphasis on meats and the inclusion of sugar… If the dieticians persist in presenting minimum diets, they should at least report separately the physical and cultural components of these diets.</p>
<p><span class="citation" data-cites="stiglerCostSubsistence1945">(<a href="#ref-stiglerCostSubsistence1945" role="doc-biblioref">Stigler 1945</a>)</span></p>
</blockquote>
<p>In 1947, George Dantzig was tasked with the US Air Force to mechanize its planning. Inspired by the paper as well as Leontief’s input-output analysis, he thought that constraint-optimization with linear algebra was just the tool to use. As a start, he attacked the same problem of diet, and from there, he developed the <a href="https://en.wikipedia.org/wiki/Simplex_algorithm">simplex method</a>. <span class="citation" data-cites="dantzigDietProblem1990">(<a href="#ref-dantzigDietProblem1990" role="doc-biblioref">Dantzig 1990</a>)</span></p>
<blockquote class="blockquote">
<p>In the fall of 1947 … undertook as a test of the newly proposed simplex method the determination of a least cost adequate diet based on Stigler’s data. It was the first “large scale” computation in the field. The system consisted of 9 equations in 77 unknowns. Jack parcelled out a different 8 or 9 columns (of the 77 columns) to each of the 9 clerks who were assigned to process them. Using hand-operated desk calculators… the 9 clerks took approximately 120 man-days to obtain an optimal solution of $39.69. Stigler’s heuristic solution was only off from the true annual optimal cost by 24 cents: not bad!</p>
<p><span class="citation" data-cites="dantzigDietProblem1990">(<a href="#ref-dantzigDietProblem1990" role="doc-biblioref">Dantzig 1990</a>)</span></p>
</blockquote>
<p>While linear programming became the great success story of early AI – when it was still considered as the “mechanization of thought process”, and often subsumed under operations research – and was quickly taken up by military logisticians and business managers, its original application in diet planning was less successful. Dantzig recounts how he unsuccessfully tried to go on a diet by running a 500-ingredient linear programming problem on an IBM 701. Hilarity ensues.</p>
<blockquote class="blockquote">
<p>One day I said to Anne, my wife, “Today is Der Tag, whatever the 701 says that’s what I want you to feed me each day starting with supper tonight.” … I then read off the amounts of foods in the optimal diet. Her reaction: “The diet is a bit weird but conceivable. Is that it?” “Not exactly,” I replied, “AND 500 gallons of vinegar.” … It turned out that our data source listed vinegar as a very weak acid with water content = zero. Therefore, according to the way the model was formulated the more vinegar you drank the greater would be your feeling of feeling full. I decided that vinegar wasn’t a food.</p>
<p>The next day the above scene was repeated except this time … calling for the consumption of 200 bouillon cubes per day… I called my doctor and asked him how come the nutritional requirements didn’t show a limit on the amount of salt? “Isn’t too much salt dangerous?” He replied that it wasn’t necessary; most people had enough sense not to consume too much. I placed an upper bound of three on the number of bouillon cubes consumed per day. That was how upper bounds on variables in linear programming first began.</p>
<p>The next day the above scene was repeated, except this time the diet called, among other things, for two pounds of bran per day… The model was revised with an upper bound put on the amount of bran. The next day the proposed menu was almost exactly the same except this time it was two pounds of blackstrap molasses which substituted for the bran… she said, “I have been studying the various menus the computer has been generating. There are some good ideas there that I can use. I’ll put you on MY diet. She did and I lost 22 pounds.</p>
<p><span class="citation" data-cites="dantzigDietProblem1990">(<a href="#ref-dantzigDietProblem1990" role="doc-biblioref">Dantzig 1990</a>)</span></p>
</blockquote>
<p>In our hindsight, we say that the AI performed an adversarial attack on the input data and the reward model misspecification, something that gaming and planning AI are wont to do.</p>
<p>The second Soviet Nobel laureate, Leonid Kantorovich, managed to win it while remaining <em>within</em> the USSR. This was no small feat, for in the USSR, the academic study of economics meant only <em>political</em> economy, and mathematical economics was merely a minor branch of political economy, with mathematical economists having to frame their research as a “critique of bourgeois economic thought”. <span class="citation" data-cites="boldyrevCulturesMathematicalEconomics2017">(<a href="#ref-boldyrevCulturesMathematicalEconomics2017" role="doc-biblioref">Boldyrev and Kirtchik 2017</a>)</span></p>
<p>Like Dantzig, Kantorovich discovered linear programming in the context of a practical problem. Feeling burnt out by too much pure math, he decided to do something practical for a change of scenery, and to do something about the imminent threat of Nazi Germany. So he went to a plywoord factory in 1937, and worked on how to cut plywood sheets in such a way as to meet a specified assortment of pieces with minimum waste. And just like Dantzig, he reduced the problem to a maximization problem with linear objective and linear inequality constraints.</p>
<p>Dizzy with success, he tried the same trick again and again, and accidentally improved efficiency so much that he almost ended up in jail.</p>
<blockquote class="blockquote">
<p>… one of the major materials handling operations at the Leningrad E. I. Egorov Railroad Car Building Plant was the cutting of sheet metal for railroad cars. Ordinarily, this cutting produced tremendous quantities of scrap. After introducing Kantorovich’s solution technique to the problem of minimizing waste, officials were able to reduce the amount of scrap by 50%. This had the unfortunate side effect of greatly reducing the amount of scrap metal available to steel plants in the region, and Kantorovich was ordered to appear at Leningrad party headquarters for allegedly sabotaging the economy. In this instance, he was rescued by the military, which needed him for its atomic program.</p>
<p>According to Stalin, the planned economy of the USSR was already “<a href="https://ru.wikipedia.org/wiki/Головокружение_от_успехов">dizzy with success</a>”; hence any criticism of it was anti-Soviet propaganda, a serious crime. In particular, anyone openly suggesting that waste could be cut substantially was at great personal risk. Nevertheless, Kantorovich … wrote a letter to Gosplan suggesting a reform of the price system used in planning.</p>
<p><span class="citation" data-cites="gardnerLVKantorovichPrice1990">(<a href="#ref-gardnerLVKantorovichPrice1990" role="doc-biblioref">Gardner 1990</a>)</span></p>
</blockquote>
<p>Being a socially clueless nerd was not the stuff of romantic comedy in Soviet Russia, but gallows comedy. Fortunately for mathematical economics, his luck held:</p>
<blockquote class="blockquote">
<p>Gosplan wrote back saying that no such reform was necessary. This outcome was rather fortunate for its author, as similar letters critical of the authorities – for example, one by Solzhenitsin – landed their authors promptly in jail.</p>
<p><span class="citation" data-cites="gardnerLVKantorovichPrice1990">(<a href="#ref-gardnerLVKantorovichPrice1990" role="doc-biblioref">Gardner 1990</a>)</span></p>
</blockquote>
<p>Reading Kantorovich’s repeated attempts to reform Soviet economy, I imagined those old silent movies where a protagonist stumbles around, blindfolded, crossing a highway where the cars always <em>just missed</em>. Accidental economic sabotage was not the end of his misadventures, however. His luck was really tested when it came to the “shadow price” affair.</p>
<p>Consider the problem of managing a factory. It has some input constraints (fuel, woods, etc), and the objective of maximizing the total utility of output goods. This is simply solved by the Lagrangian multiplier method, and it turns out that the Lagrangian multipliers themselves have a natural interpretation: the multiplier <span class="math inline">\(\lambda_i\)</span> is the amount of extra utility that the factory can achieve, if the factory were to obtain one more unit of constraint <span class="math inline">\(i\)</span>.</p>
<p>So Kantorovich had the great idea of calling it the “shadow price”,<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> and considered it a way to find the proper price of something, better than the free market mechanism. The free market mechanism leads to maximizing some kind of utility function, but that utility function is not designed by anyone. In contrast, the shadow price naturally falls out of attempts to maximize a social utility function designed by the <a href="https://en.wikipedia.org/wiki/Gosplan">Gosplan (State Planning Committee)</a>. It is a utility designed by humans, for humans, not a utility function emergent from capitalism, for capitalism.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;In his original terms, “objectively determined valuation” [объективно обусловленные оценки], where the “objectively” means “according to an objective function (the social utility function)”.</p></div></div><p>This is, in short, how market socialism should work, according to Kantorovich:</p>
<ol type="1">
<li>Design a social utility function (the “social” part of “socialism”).</li>
<li>Collect data on how the factories <em>should ideally</em> work (big data).</li>
<li>Compute the shadow prices by linear programming (big compute).</li>
<li>Set the prices on every commodity.</li>
<li>Let the factories compete on this market for goods and money, secure in the knowledge that this socialist market would maximize a properly designed social utility, and the market mechanism would allow only the factories that achieve the highest efficiency: The slackers are competed out, and only those who can perform as efficiently as the “ideal factories” (see step 2) can make a profit and thus survive.</li>
</ol>
<p>The whole thing is not hard to prove in a simple model of economy, where all factories are linear functions, and the social utility function is also a linear function. Then the proof is just writing down the “<a href="https://en.wikipedia.org/wiki/Dual_linear_program">linear duality theorem</a>”, and interpreting it as economics.</p>
<blockquote class="blockquote">
<p>[Boyarskii:] You write, “any increase in the requirements of some article entails a corresponding increase in costs and consequently in its o.d. valuation. A decrease in requirements entails a reduction in its o.d. valuation.” What is this, what can this possibly be, but a suggestion that value is determined by supply and demand? Supply and demand, for heaven’s sake: bourgeois ideology’s most transparent disguise for exploitation!</p>
<p>…</p>
<p>[Kantorovich:] It’s true that there is a formal resemblance, but they have a completely different origin, and therefore a completely different meaning. Whereas market prices are formed spontaneously, objective valuations – shadow prices – must be computed on the basis of an optimal plan. As the plan targets change, the valuations change. They are subordinate to the very different production relationships of a socialist society. Yet, yet, the scope for their use is actually bigger under socialism. The capitalists actually agree with you, Dr Boyarskii, that the mathematical methods we’re talking about should only be applied on the small scale, on the level of the individual firm. They have no choice: there is no larger structure, in the economy of West Germany or the United States, in which they can be set to work. They have had some success, I believe. I’m sorry to say that, since George Danzig and Tjalling Koopmans made their discoveries of “linear programming” in America during the war, the techniques have been adopted there far more eagerly, far more quickly, than in the Soviet Union. Linear programmers in the USA calculate routes for airlines, and devise the investment policies of Wall Street corporations. But we still have an opportunity before us which is closed to the capitalists. Capitalism cannot calculate an optimum for a whole economy at once. We can. There is a fundamental harmony between optimal planning and the nature of socialist society.</p>
<p><span class="citation" data-cites="spuffordRedPlenty2010">(<a href="#ref-spuffordRedPlenty2010" role="doc-biblioref">Spufford 2010, chap. 5</a>)</span></p>
</blockquote>
<p>Though he kept trying to propose his idea of socialist optimal planning, and kept sending letters to leaders from Stalin to Andropov, his idea remained a linear programmer’s fanatsy.</p>
</section>
<section id="mechanizing-mathematics" class="level3">
<h3 class="anchored" data-anchor-id="mechanizing-mathematics">Mechanizing Mathematics</h3>
<p>Circa 1900, as mathematicians learned to manufacture paradoxes, mathematics modernized, upgraded paranoia, and tried to get a grip. The angel of topology and the devil of abstract algebra fought for the soul of each individual mathematical domain in this “Foundational Crisis”. With palpable disdain, Poincaré deplored the Hilbert school of formal logic that threatened to bleed even geometry of meaning:</p>
<blockquote class="blockquote">
<p>“Imagine,” says Hilbert,” three kinds of things, which we will call points, straight lines, and planes; let us agree that a straight line shall be determined by two points, and that, instead of saying that this straight line is determined by these two points, we may say that it passes through these two points, or that these two points are situated on the straight line.” What these things are, not only do we not know, but we must not seek to know… We might replace geometry by the reasoning piano imagined by Stanley Jevons; or, if we prefer, we might imagine a machine where we should put in axioms at one end and take out theorems at the other, like that legendary machine in Chicago where pigs go in alive and come out transformed into hams and sausages. It is no more necessary for the mathematician than it is for these machines to know what he is doing.</p>
<p><span class="citation" data-cites="poincareScienceMethod1914">(<a href="#ref-poincareScienceMethod1914" role="doc-biblioref">Poincaré 1914, 147</a>)</span></p>
</blockquote>
<p>But what is taken as an <em>reductio ad absurdum</em> by one side is often a Roadmap for the Next 20 Yaers by the other. The mechanical logician came as soon as the electronic computers arrived.</p>
<p>During undergrad years, Edward Feigenbaum took a course “Mathematical Models in the Social Sciences” taught by Herbert Simon. One class, he walked in and annouced to the 6 students</p>
<blockquote class="blockquote">
<p>Over the Christmas holidays, Al Newell and I invented a thinking machine.</p>
</blockquote>
<p>Stunned, Feigenbaum asked Simon, whereupon he received a manual of IBM 701. Feigenbaum read it all through the night, and in the morning light, he felt a “born-again experience”. AI has won itself a new convert.</p>
<p>The thinking machine was Logic Theorist <span class="citation" data-cites="newellEmpiricalExplorationsLogic1957">(<a href="#ref-newellEmpiricalExplorationsLogic1957" role="doc-biblioref">A. Newell, Shaw, and Simon 1957</a>)</span>, perhaps the first AI mathematician.</p>
<blockquote class="blockquote">
<p>The Logic Theory Machine found proofs for 38 of the 52 theorems it was presented with from the Principia, in particular finding a straightforward proof of theorem 2.85 (a simple propositional logic theorem) where Whitehead and Russell had given a more cumbersome - indeed, defective – proof. Lord Russell was impressed… The editor of the prestigious <em>Journal of Symbolic Logic</em>, however. was not won over, and the journal refused to publish an article coauthored by the Logic Theory Machine describing the proof of theorem 2.85.</p>
<p><span class="citation" data-cites="mackenzieAutomationProofHistorical1995">(<a href="#ref-mackenzieAutomationProofHistorical1995" role="doc-biblioref">Mackenzie 1995</a>)</span></p>
</blockquote>
<p>The working of Logic Theorist was simple. It simply performs a tree search in the space of possible proofs. At the root of the tree is the theorem to be proved. Each branch then transforms the state of the proof, adding assumptions (which then become sub-goals that themselves need to be proved), substitute logical variables, quoting axioms, perform modus ponens, etc. If at some leaf-node, the list of goals is empty, then the solution is found, and the Logical Theorist backtracks to get the final proof.</p>
<p>As an example, it proved Theorem 2.17 as follows. The final proof had 7 steps, and took 89k basic operations to discover. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, 133</a>)</span></p>
<ul>
<li><span class="math inline">\(\mathrm{A} \supset \sim \sim \mathrm{A}\)</span> (Start with Theorem 2.17)</li>
<li><span class="math inline">\(\mathrm{P} \supset \sim \sim \mathrm{P}\)</span> (Theorem 2.12)</li>
<li>…</li>
<li><span class="math inline">\((\sim \mathrm{Q} \supset \sim \mathrm{P}) \supset(\mathrm{P} \supset \mathrm{Q})\)</span> (chain 7 and 5)</li>
</ul>
<p>A later version mechanized Poincaré’s nightmare by converting Euclidean geometry problems to symbolic logic, and managed to discover a particularly elegant proof that in a triangle <span class="math inline">\(ABC\)</span>, if <span class="math inline">\(AB = AC\)</span> then <span class="math inline">\(\angle ABC = \angle ACB\)</span>, by the SAS theorem. Only later did the authors discover that this was a previously known solution. <span class="citation" data-cites="mackenzieAutomationProofHistorical1995">(<a href="#ref-mackenzieAutomationProofHistorical1995" role="doc-biblioref">Mackenzie 1995</a>)</span></p>
</section>
<section id="information-processing-system" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="information-processing-system">Information Processing System</h3>
<p>Simon and Newell were unhappy with Logic Theorist, for the simple reason that when they read the trace-outs of its “thought process”, they noted that it is very different from how humans would go about proving the same problems. Patiently plodding, they brute forced through the whole search tree, whereas humans would tastefully pick some branches and search deeply, and others not at all.</p>
<p>In their magnum opus, <em>Human Problem Solving</em> (1972), they have compiled their decades of research into a definitive statement of what AI is about in their view. According to them, AI is logical AI, and the fundamental architecture for logical AI is Information Processing System. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972</a>)</span></p>
<p>The axioms of logical AI:</p>
<ul>
<li>It is symbols all the way down. Everything “sub-symbolic”, like the neural biology, are just implementation, and not part of what intelligence is about, much like software is independent of hardware.</li>
<li>Intelligent behavior is the combination of simple goals, simple algorithms, and complex environment.</li>
<li>Intelligent algorithms are fairly simple, and consist of serial, deterministic, heuristic search over the space of solutions.</li>
<li>The space of solutions is structured like a directed graph, where the edges are “generators” or “search operators”.</li>
<li>At each step, the search algorihm runs a “verifier” subroutine to check if a solution has been found. If so, then it backtracks to produce the full solution. If not, then it updates an internal state and decide how to grow the path towards the goal.</li>
<li>To grow the path towards the goal, it conducts “means-ends analysis”: Take a small forward step to a new place in the space of solutions (“means”), and move the goalpost by a small backward step, to a new goalpost closer to you (“ends”).</li>
</ul>
<p>They designed an algorithm according to the axioms and called it “General Problem Solver” (GPS), a grandiose title for a grandiose dream.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Simon_Newell_fig_4_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The architecture of the GPS. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, fig. 4.1</a>)</span></figcaption>
</figure>
</div>
<p>Curiously, they argued that Chomskyan linguistics and the IPS formalism are essentially the same:</p>
<table class="caption-top table">
<caption>Equivalence between Chomskyan linguistics and the IPS logical AI.</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>IPS logical AI</th>
<th>Chomskyan linguistics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Symbols</td>
<td>Symbols</td>
</tr>
<tr class="even">
<td>Problem input</td>
<td>Surface structure of a sentence</td>
</tr>
<tr class="odd">
<td>Symbolic representations</td>
<td>Deep structures; representations of meanings</td>
</tr>
<tr class="even">
<td>Problem space</td>
<td>Space of deep structures of strings</td>
</tr>
<tr class="odd">
<td>Problem solving</td>
<td>Parsing, or grammatical analyses from the surface structure to the deep structure</td>
</tr>
<tr class="even">
<td>Stored patterns</td>
<td>Stored words, phrases, syntax trees, etc</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>It should be evident from the discussion of symbols, symbol structures, the designation relation, and programs that an information processing system of the sort we have described in this chapter is, in some fundamental sense, a language processor. As a matter of historical fact, the basic concepts that have entered into our description of an IPS have almost the same origins as the concepts that underlie the formalized transformational grammars that linguists have developed over the past fifteen years <span class="citation" data-cites="chomskySyntacticStructures1957">(<a href="#ref-chomskySyntacticStructures1957" role="doc-biblioref">Chomsky 1957</a>)</span>… our theory of problem solving can properly be viewed as also a partial theory of linguistics-specifically, a theory of the nature of the deep structures used by the human IPS in the course of its problem solving activities.</p>
<p><span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, 38</a>)</span></p>
</blockquote>
<p>As we have seen and will see, the relation between Chomsky and logical AI runs deep.</p>
<p>The IPS is not just a logical framework AI, but also a psychological theory for what humans really do when they solve problems. As such, Simon and Newell spent over a decade carefully studying the behavior of real humans solving real problems, such as propositional logic proofs (the same task as Logic Theorist), cryptograms, chess puzzles, and so on. And by “detailed” I mean it. They had subjects working through problems in a lab, with the entire session tape-recorded, fully transcribed, annotated, and parsed into the form of a heuristic tree search. It was like looking at the debugger output to a human being.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/human_problem_solving_transcript.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Annotated transcript of a human subject solving a propositional logic puzzle. The session lasted about 40 minutes, and ends with a failure. The transcript has 535 lines. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, 533</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/human_problem_solving_behavior_graph.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The same transcript parsed into a heuristic tree search over the problem space. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, 534</a>)</span></figcaption>
</figure>
</div>
<p>In a popularization (well, as popular as abstract AI theories can get), Simon analogized their theory with a crawling ant:</p>
<blockquote class="blockquote">
<p>We watch an ant make his laborious way across a wind- and wave- molded beach. He moves ahead, angles to the right to ease his climb up a steep dunelet, detours around a pebble, stops for a moment to exchange information with a compatriot. Thus he makes his weaving, halting way back to his home. So as not to anthropomorphize about his purposes, I sketch the path on a piece of paper. It is a sequence of irregular, angular segments–not quite a random walk, for it has an underlying sense of direction, of aiming toward a goal. I show the unlabeled sketch to a friend. Whose path is it? An expert skier, perhaps, slaloming down a steep and somewhat rocky slope. Or a sloop, beating upwind in a channel dotted with islands or shoals. Perhaps it is a path in a more abstract space: the course of search of a student seeking the proof of a theorem in geometry… Human beings, viewed as behaving systems, are quite simple. The apparent complexity of our behavior over time is largely a reflection of the complexity of the environment in which we find ourselves.</p>
<p><span class="citation" data-cites="simonSciencesArtificial1996">(<a href="#ref-simonSciencesArtificial1996" role="doc-biblioref">Simon 1996, chap. 3</a>)</span></p>
</blockquote>
<p>If we squint at the following diagram, we can almost see it as they saw it: a human, as simple minded as an ant, crawling and stumbling through the problem space of logic.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Simon_Newell_1975_fig_10_13.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Searching over the problem space of propositional logic puzzles. <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972, 575</a>)</span></figcaption>
</figure>
</div>
<p>At this point, we might be seeing a pattern here. Checking every use of the word “learning” in the book, I confirmed that, indeed, they were uninterested in learning, other than claiming that learning consists of adding more symbols to the internal environment, which is just one more kind of environment. One can look up lemmas and formulas on an external book, or an internal blackboard. It is all the same. The ant of the brain just need to crawl over the inner landscape as much as it crawls over the outer landscape.</p>
<blockquote class="blockquote">
<p>We will deal hardly at all with earning phenomena in this book. Yet the approach to earning from the direction just illustrated, where we have the internal structure of the performing program laid out before us, shows clearly (1) that experience is simply one more source of information that can be exploited to attain adaptive performance and (2) that to affect performance experience must find some variable aspect of the performance program’s structure that it can specify.</p>
<p><span class="citation" data-cites="simonSciencesArtificial1996">(<a href="#ref-simonSciencesArtificial1996" role="doc-biblioref">Simon 1996, 137</a>)</span></p>
</blockquote>
<p>It is not that they completely ignored the problem of learning, but rather, they understood learning as a simple kind of associative memorization. Feigenbaum’s PhD project was the Elementary Perceiver and Memorizer (EPAM), an algorithmic model of human associative memory. As a concrete realization of the learning theory of Simon and Newell, we describe it to show how little learning their framework contained.</p>
<p>EPAM modeled people performing the following memorization task:</p>
<ul>
<li>“DAX” is displayed to the subject</li>
<li>Subject should say “JIR” in response</li>
<li>Regardless of what subject responds, “JIR” is displayed after a few seconds.</li>
<li>Repeat this until the subject manages to memorize all 12 pairs.</li>
</ul>
<p>During a session, every time EPAM sees a new stimulus-response pair, it stores the response, and updates its decision tree. Each node of the decision tree has two children, and which way EPAM goes is determined by testing one letter of the stimulus. It looks like</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> stimulus[<span class="dv">0</span>] <span class="op">==</span> <span class="st">"D"</span>:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"JIR"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> stimulus[<span class="dv">2</span>] <span class="op">==</span> <span class="st">"J"</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In short, what counts as a paradigm of learning is simply memorization, and updating a big if-then search tree, so that a stimulus results in going down the search tree and arriving at the correct response stored in the leaf node.</p>
</section>
<section id="the-drosophila-of-ai" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-drosophila-of-ai">The drosophila of AI</h3>
<blockquote class="blockquote">
<p>Within 10 years, a computer would routinely beat the world’s best player.</p>
<p>— Herbert Simon, 1957</p>
</blockquote>
<p>In introductions to AI or even just machine learning. Arthur Samuel’s checker program was usually given as the first great example of machine learning. In short, it performs alpha-beta search to a few plies<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> during playing, using up to 16 hand-crafted feature functions. It uses two learning rules <span class="citation" data-cites="samuelStudiesMachineLearning1959 russellArtificialIntelligenceModern1995">Sutton and Barto (<a href="#ref-suttonReinforcementLearningIntroduction2018" role="doc-biblioref">2018</a>)</span>:</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;Annoyingly I can’t find any information, but considering that an IBM 704 has <span class="math inline">\(5\times 10^4 \;\mathrm{MIP/sec}\)</span>, and checkers has a branching factor of 400, it would take on the order of 10 minute to search 2 plies. So my bet is 2 plies. Indeed, the paper appendix says it takes <span class="math inline">\(10^{-2} \;\mathrm{sec}\)</span> to play and evaluate one position, which means it takes about 500 instructions for one play and evaluation, and that searching 2 plies already takes 30 minutes.</p></div></div><ul>
<li>Rote learning: After performing an alpha-beta search, it would store the score for the root node. Later, if the root node is encountered during search, its score would be used without needing to search deeper. This allows it to increase the effective search depth over time, as it memorizes more and more positions’ values. To save memory, if a board does not reappear after a maximum number of moves, it is “forgotten”. The whole system managed to memorize 53,000 board positions (averaging 3.8 words each on a IBM 704)</li>
<li>Generalization learning: Something very similar to TD-learning in reinforcement learnig, except that the reward function is not whether the board is won (1 for winning, -1 for losing, 0 otherwise), but the <em>piece advantage</em> feature.</li>
</ul>
<p>The whole program ran on an <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, and took up about 8000 instructions.</p>
<p>Just when you thought there is finally some learning, nope. Samuel got the features from interviewing the checker experts. In fact, it had a formative influence on a later pioneer of expert systems:</p>
<blockquote class="blockquote">
<p>Art Samuel’s work on the checker player: Art had interviewed experts to understand… the feature vector and then he did a good deal of reading about checkers… And the influential part about that was.. his machine learning component – that once you had the expertise in, in a first-order form, it could be improved… automatically. That impressed me a great deal and I always wanted to be able to do that.</p>
<p><span class="citation" data-cites="brockLearningArtificialIntelligences2018">(<a href="#ref-brockLearningArtificialIntelligences2018" role="doc-biblioref">Brock 2018</a>)</span></p>
</blockquote>
<p>Compared to checkers, computer chess had been much more high-profile, and it has been a textbook example of logical AI. The three parts of computer chess are move generator, evaluation function, and search control, corresponding to the solution space, verifier, and heuristic search algorithm of the IPS.</p>
<p>The IPS framework, with its talk of heuristic search, resembles most of all how people play board games. Indeed, <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972</a>)</span> devoted over 100 pages to chess, “the drosophila of AI”. Indeed, chess seems like the perfect illustration: simply do an alpha-beta search with a heuristic evaluation function on it. This was essentially the algorithm proposed by Alan Turing in 1948 – the <a href="https://en.wikipedia.org/wiki/Turochamp">Turochamp</a>, and it was still the algorithm used in <a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">Deep Blue (1997)</a>. In fact, the architecture has changed so little that we can write a single “prototypical chess program”:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score(board):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return a real number</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> move_generator(board):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return a list of legal moves</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_move(board, move):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the next board</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search(board):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># do the minimax search, </span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># or the alpha-beta tree search, etc</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> moves <span class="kw">in</span> move_generator(board):</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_move</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Progress in chess computers has come from three sources: faster computers allowing bigger search trees, better scoring functions, and better heuristic tree search algorithms (from minimax to alpha-beta to tricks like singular extensions). As an illustrative example, here is (part of) the Turochamp scoring function <span class="citation" data-cites="newellHumanProblemSolving1972">(<a href="#ref-newellHumanProblemSolving1972" role="doc-biblioref">Allen Newell and Simon 1972</a>, pag 672)</span>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>material_value <span class="op">=</span> {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pawn"</span> : <span class="dv">1</span>, <span class="st">"Knight"</span>: <span class="dv">3</span>, <span class="st">"Bishop"</span>: <span class="fl">3.5</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Rook"</span>: <span class="dv">5</span>, <span class="st">"Queen"</span>: <span class="dv">10</span>, <span class="st">"Checkmate"</span>: <span class="dv">1000</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mobility(board, piece):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Square root of legal moves for the piece</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    legal_moves <span class="op">=</span> move_generator(board)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sqrt(<span class="bu">len</span>([move <span class="cf">for</span> move <span class="kw">in</span> legal_moves <span class="cf">if</span> piece <span class="kw">in</span> move]))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score(board):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    q_value <span class="op">=</span> mobility(board, <span class="st">"Queen"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> q_value <span class="op">+</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Like its predecessors, Deep Blue used alpha-beta tree search, except it searched <em>a lot of positions</em>. To support this, it used <a href="https://en.wikipedia.org/wiki/Application-specific_integrated_circuit">ASIC</a> <a href="https://en.wikipedia.org/wiki/Very-large-scale_integration">VLSI</a> “chess chips”,<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> each with four parts: the move generator, the smart-move stack, the evaluation function, and the search control. The move generator is a 8×8 combinational logic circuit, a chess board in miniature. <span class="citation" data-cites="hsuIBMsDeepBlue1999 campbellDeepBlue2002">(<a href="#ref-hsuIBMsDeepBlue1999" role="doc-biblioref">F.-H. Hsu 1999</a>; <a href="#ref-campbellDeepBlue2002" role="doc-biblioref">Campbell, Hoane Jr, and Hsu 2002</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;Just when you thought DARPA can’t possibly be behind this, guess what, Hsu developed the earlier iterations of chess chips by taking advantage of <a href="https://en.wikipedia.org/wiki/MOSIS">MOSIS</a>, which was part of the Strategic Computing Initiative <span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, chap. 4</a>)</span>. More on this <a href="#sec-sci">below</a>.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/chess_chip.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The flowchart of Deep Blue. <span class="citation" data-cites="hsuIBMsDeepBlue1999">(<a href="#ref-hsuIBMsDeepBlue1999" role="doc-biblioref">F.-H. Hsu 1999</a>)</span></figcaption>
</figure>
</div>
<p>Describing the software of Deep Blue in detail would be not particularly enlightening, so here’s a pseudocode sketch:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>opening_book <span class="op">=</span> ... <span class="co"># 4000 positions</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>extended_book <span class="op">=</span> ... <span class="co"># several million positions from 0.7M grandmaster games</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>endgame_table <span class="op">=</span> ... <span class="co"># all endgames with &lt;= 5 pieces, and many endgames with 6 pieces</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_function(board):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    weight_vector <span class="op">=</span> ... <span class="co"># contains 8000 real numbers</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    feature_vector <span class="op">=</span> features(board) <span class="co"># contains 8000 handcrafted terms</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weight_vector <span class="op">@</span> feature_vector</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> play(board):</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> board <span class="kw">in</span> opening_book:</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> retrieve_opening_move(board, opening_book)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> board <span class="kw">in</span> extended_book:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        best_score <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        best_move <span class="op">=</span> <span class="st">''</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> move <span class="kw">in</span> legal_moves(board):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> evaluate(move, board, extended_book)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> score <span class="op">&gt;</span> best_score:</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>                best_score <span class="op">=</span> score</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>                best_move <span class="op">=</span> move</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> size(board) <span class="op">&lt;=</span> <span class="dv">5</span> <span class="kw">or</span> (size(board) <span class="op">==</span> <span class="dv">6</span> <span class="kw">and</span> board <span class="kw">in</span> endgame_table):</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> retrieve_ending_move(board, endgame_table)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> alpha_beta_search(board, eval_function) <span class="co"># evaluate 200M pos/sec</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    play(move)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>I know you are eager to hear about how Deep Blue learned. So did I. The bad news is that it barely learned anything. First, its evaluation function was just a linear sum over ~8000 hand-crafted features,<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> with changeable linear weights. It actually had two evaluation functions, fast and slow. Only if the fast one already shows a clear advantage would the slow one be called. Further, the linear weights were mostly handcrafted too, except a small amount of automation:</p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;And there were a lot of features, with words I barely understand:</p>
<blockquote class="blockquote">
<p>The most significant part of the fast evaluation is the “piece placement” value, i.e., the sum of the basic piece values with square-based location adjustments. Positional features that can be computed quickly, such as “pawn can run”, are also part of the fast evaluation. The slow evaluation scans the chess board one column at a time, computing values for chess concepts such as square control, pins, X-rays, king safety, pawn structure, passed pawns, ray control, outposts, pawn majority, rook on the 7th, blockade, restraint, color complex, trapped pieces, development, and so on. The features recognized in both the slow and fast evaluation functions have programmable weights, allowing their relative importance to be easily adjusted.</p>
<p><span class="citation" data-cites="campbellDeepBlue2002">(<a href="#ref-campbellDeepBlue2002" role="doc-biblioref">Campbell, Hoane Jr, and Hsu 2002</a>)</span></p>
</blockquote>
</div></div><blockquote class="blockquote">
<p>The first tool had the goal of identifying features in the Deep Blue I evaluation function that were “noisy”, i.e., relatively insensitive to the particular weights chosen… A hill-climbing approach was used to explore selected features (or feature subsets), and those that did not converge were candidates for further hand examination… A second tool was developed with the goal of tuning evaluation function weights. This tool used a comparison training methodology to analyze weights related to pawn shelter. Training results showed that the hand-tuned weights were systematically too low, and they were increased prior to the 1997 match. There is some evidence that this change led to improved play.</p>
</blockquote>
<p>I didn’t understand it, so I turned to a previous paper <span class="citation" data-cites="hsuGrandmasterChessMachine1990">(<a href="#ref-hsuGrandmasterChessMachine1990" role="doc-biblioref">F. Hsu et al. 1990</a>)</span> that seems to explain it better, according to which they did two kinds of “automated” training, which were both supervised learning without backpropagation:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hill_climbing(t, games):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    search_depth <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> learning_rate <span class="op">*</span> random(t.shape)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    wins <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (board, move) <span class="im">from</span> random_sample(grandmaster_games, N):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        old_move <span class="op">=</span> alpha_beta_search(board, search_depth, evaluation_function, t)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        new_move <span class="op">=</span> alpha_beta_search(board, search_depth, evaluation_function, t <span class="op">+</span> dt)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        wins <span class="op">+=</span> (new_move <span class="op">==</span> move) <span class="op">-</span> (old_move <span class="op">==</span> move)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> wins <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        t <span class="op">+=</span> dt</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> comparison_training(t, games):</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> learning_rate <span class="op">*</span> random(t.shape)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    wins <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (board, move) <span class="im">from</span> random_sample(grandmaster_games, N):</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        moves <span class="op">=</span> legal_moves(board)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        next_board <span class="op">=</span> make_move(board, move)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        reference_score <span class="op">=</span> evaluation_function(t, next_board)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        old_scores <span class="op">=</span> []</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        new_scores <span class="op">=</span> []</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> alt_move <span class="kw">in</span> moves <span class="cf">if</span> alt_move <span class="op">!=</span> move:</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>            next_board <span class="op">=</span> make_move(board, alt_move)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            old_scores.append(evaluation_function(t, next_board))</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            new_scores.append(evaluation_function(t <span class="op">+</span> dt, next_board))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        wins <span class="op">+=</span> <span class="bu">all</span>(reference_score <span class="op">&gt;</span> new_scores) <span class="op">-</span> <span class="bu">all</span>(reference_score <span class="op">&gt;</span> old_scores)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> wins <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        t <span class="op">+=</span> dt</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Deep Blue contains 480 chess chips, each capable of <span class="math inline">\(2.5 \times 10^6 \;\mathrm{position/sec}\)</span>. But the total hardware had only a sustained peak rate <span class="math inline">\(2 \times 10^8 \;\mathrm{position/sec}\)</span>, meaning its utilization rate was only 16%.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> <span class="citation" data-cites="hsuCrackingGo2007">(<a href="#ref-hsuCrackingGo2007" role="doc-biblioref">F. Hsu 2007</a>)</span> To Hsu, it was an exercise in chip design. To Kasparov, it was a dirty business. To some journalists, it was another “Man vs Machine” story. And to us, it was the last great project of logical AI in the style of Simon and Newell.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;The <span class="math inline">\(R_{max}\)</span> of Deep Blue on LINPACK was 11.38 GFLOP according to <a href="https://web.archive.org/web/20090213103245/http://www.top500.org/list/1997/06/300">TOP500 List - June 1997</a>, meaning that each positional evaluation is worth 10 FLOP, although I have doubts about just how they managed to cram the LINPACK benchmark onto the chess chips.</p>
<p>An earlier report in 1995 <span class="citation" data-cites="hsuDeepBlueSystem1995">(<a href="#ref-hsuDeepBlueSystem1995" role="doc-biblioref">F. Hsu, Campbell, and Hoane 1995</a>)</span>, published a year before Deep Blue was assembled, estimated that a general-purpose computer would take 1000 FLOP to evaluate one position. It also estimated Deep Blue would take up around 1 kW of electric power.</p></div></div><blockquote class="blockquote">
<p>Deep Thought was not an “expert system”… Several members of the team would probably consider it an insult to call Deep Thought an expert system. In fact, at least two members of the team had used the word <em>bullshit</em> to describe “expert systems”, or for that matter, Artificial Intelligence. Second, the Deep Thought research was supported in part by the VLSI project, and none of the money came from the DARPA funding for expert systems research.</p>
<p><span class="citation" data-cites="hsuDeepBlueBuilding2002">(<a href="#ref-hsuDeepBlueBuilding2002" role="doc-biblioref">F.-H. Hsu 2002, 98</a>)</span></p>
</blockquote>
<p>10 years after the historic win, Hsu wrote a brief essay describing how to make a superhuman Go machine. He estimated that it was already possible to get a <em>single</em> Go-chip to evaluate <span class="math inline">\(2 \times 10^{10} \;\mathrm{position/sec}\)</span>, and so with 10 years of Moore’s law giving another 100×, a machine with 480 Go-chips would be able to evaluate <span class="math inline">\(10^{14} \;\mathrm{position/sec}\)</span> by 2017.</p>
<blockquote class="blockquote">
<p>… with some optimization a machine that can search a trillion positions per second would be enough to play Go at the very highest level. It would then be cheaper to build the machine out of FPGAs (field-programmable gate arrays) instead of the much more expensive and highly unwieldy full-custom chips. That way, university students could easily take on the challenge. At Microsoft Research Asia we are seeding university efforts in China with the goal of solving some of the basic problems.</p>
<p><span class="citation" data-cites="hsuCrackingGo2007">(<a href="#ref-hsuCrackingGo2007" role="doc-biblioref">F. Hsu 2007</a>)</span></p>
</blockquote>
<p>In 2016, AlphaGo defeated the 9-dan player Lee Sedol at 4 wins and 1 loss,<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> and it “[evaluated] thousands of times fewer positions than Deep Blue”. <span class="citation" data-cites="silverMasteringGameGo2016">(<a href="#ref-silverMasteringGameGo2016" role="doc-biblioref">Silver et al. 2016</a>)</span> The subsequent AlphaZero reached superhuman performance with just <span class="math inline">\(10^4\)</span> evaluated positions per move. <span class="citation" data-cites="silverGeneralReinforcementLearning2018">(<a href="#ref-silverGeneralReinforcementLearning2018" role="doc-biblioref">Silver et al. 2018</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;In game 2, AlphaGo played black. Media made much out of the 19th move of AlphaGo (“Move 37”), which the supervised learning policy network (which was supervise-trained to predict what a human would play, as according to a large dataset of human games) predicted a probability of <span class="math inline">\(10^{-4}\)</span>. This was given much media attention. Something similar happened with Deep Blue vs Kasparov, game 2, when Deep Blue (White) played 36.axb5, with immediate effect:</p>
<blockquote class="blockquote">
<p>so fluid was its play that the grandmasters in attendance all understood Benjamin’s contention that Blue “played real chess” that day. What really shook Garry Kasparov, though, was a move that the computer didn’t make. On Move 36, Blue had an opportunity to shift its queen to a devastating position – clearly the smart choice. Instead it took a subtler but superior tack that wound up to be near decisive in defeating Kasparov. After the champ resigned, he rushed back to his Plaza suite, cranked up his own computers and tried in vain to understand how a hunk of sand and metal could have understood chess so deeply. Apparently this puzzlement crossed into the realm of suspicion: the Kasparov camp was soon demanding to see Deep Blue’s printouts. “It was a masterpiece by computer”, said Kasparov second Michael Khodarkovsky. “We would like to understand why it was possible.” (Eventually, a neutral arbiter examined the printout.) Later Kasparov blurted out his real complaint. “Suddenly [Deep Blue] played like a god for one moment,” he said.</p>
<p><span class="citation" data-cites="levyBigBluesHand1997">(<a href="#ref-levyBigBluesHand1997" role="doc-biblioref">Levy 1997</a>)</span></p>
</blockquote>
</div></div></section>
</section>
<section id="expert-systems" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="expert-systems">Expert systems</h2>
<blockquote class="blockquote">
<p>The miracle product is knowledge, and the Japanese are planning to package and sell it the way other nations package and sell energy, food, or manufactured goods… The essence of the computer revolution is that the burden of producing the future knowledge of the world will be transferred from human heads to machine artifacts.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, chap. 4</a>)</span></p>
</blockquote>
<section id="dendral" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="dendral">DENDRAL</h3>
<p>Spectrometry means taking an unknown chemical, then do some physics experiment on it to obtain a line-graph, then discover what that chemical is based on that line-graph. A mathematician would write something like this:</p>
<p><span class="math display">\[
(\text{chemical}) \xrightarrow{\text{spectrometry}} (\mathbb{R}\to \mathbb{R}) \xrightarrow{\text{chemist}} (\text{chemical})
\]</span></p>
<p><a href="https://en.wikipedia.org/wiki/Mass_spectrometry">Mass spectrometry</a>, for example, breaks a chemical into fragments, and measures the mass-to-charge ratios of the fragments, in units of <span class="math inline">\(\frac{\text{atomic mass unit}}{\text{electron charge}}\)</span>. Many fragments carry just +1 electron charge, so the mass-to-charge ratio can be interpreted as roughly the atomic mass of the fragment. A peak at <span class="math inline">\(x\)</span>, for example, means when the chemical breaks, it often results in some fragments with mass <span class="math inline">\(x\)</span>. Trained chemists would be able to study a mass spectrometry plot and figure out what it means.</p>
<p>Given a chemical species, by standard <a href="https://en.wikipedia.org/wiki/Stoichiometry">stiochiometry</a> one can measure the chemical formula of the species, but it remains to discover its chemical structure. This is what DENDRAL<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> was designed to do: given the mass spectrometry, the chemical formula, and some additional information (a later version could incorporate the NMR spectrum), output possible molecular structures for the species.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;The full name is “heuristic dendritic algorithm”. It is “dendritic” because it originally only could process chemical structures with no cycles.</p></div></div><p>Like the IPS of Simon and Newell, DENDRAL started as a heuristic search program. Its problem space is enumerated by a structure generator, which, given a chemical formula, generates all chemically stable structures according to some chemical rules. For example, <a href="https://en.wikipedia.org/wiki/Geminal_diol">geminal diols</a> are unstable, so those are not enumerated. Each generated structure is then broken into fragments, again according to some heuristic rules. For example, in a ketone (R-(C=O)-R’), it is very unlikely for the C=O double bond to be broken, while it is quite easy for the R-(C=O) and the (C=O)-R’ bonds to be broken.</p>
<p>If that is all there is, then we have something not much better than exhaustive search, and would not scale. The breakthrough of DENDRAL was that the DENDRAL team had a professional chemist, who entered a large number of heuristic rules for interpreting mass spectrometry lines. These greatly decrease the number of solutions to verify.</p>
<p>Consider an illustrative example from <span class="citation" data-cites="feigenbaumGeneralityProblemSolving1970">(<a href="#ref-feigenbaumGeneralityProblemSolving1970" role="doc-biblioref">E. A. Feigenbaum, Buchanan, and Lederberg 1970</a>, table 1)</span>. Let <span class="math inline">\(m\)</span> be the mass of the whole molecule. Then there is a <a href="https://en.wikipedia.org/wiki/Ketone">ketone carbonyl group</a> (R-(C=O)-R’, mass 28) if there are 2 peaks at mass <span class="math inline">\(x_1, x_2\)</span> such that</p>
<ol type="1">
<li><span class="math inline">\(x_1+x_2 = m+28\)</span>,</li>
<li><span class="math inline">\(x_1 - 28\)</span> is a high peak,</li>
<li><span class="math inline">\(x_2 - 28\)</span> is a high peak,</li>
<li>At least one of <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span> is high.</li>
</ol>
<p>A molecule R-(C=O)-R’ containing a ketone group often breaks at the bond next to the carbonyl group. This results in 4 possible fragments: R-(C=O)-, -(C=O)-R’, R-, -R’. Since the -(C=O)- fragment has mass 28, the first 3 rules would be satisfied. The 4th rule ensures the fragments are statistically significant, not noise. (What counts as “high” is a parameter that the expert sets.)</p>
<p>The full architecture is as follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plan(chemical_formula, spectrometric_data):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use the rules and data to list plausible and implausible structural elements</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e.g., if the ketone carbonyl group is plausible, then put it into good_list</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># else, put it into the bad_list</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> good_list, bad_list</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate(chemical_formula, good_list, bad_list):</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># enumerate all plausible structures </span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># containing groups from the good_list, but not the bad_list</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> plausible_structures</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test(plausible_structures, spectrometric_data):</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    structures <span class="op">=</span> []</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> structure <span class="kw">in</span> plausible_structures:</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        simulated_data <span class="op">=</span> simulate_spectrometry(chemical_formula)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> distance(simulated_data, spectrometric_data)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        structures.append((score, structure))</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    structures.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">0</span>])</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> structures</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(chemical_formula, spectrometric_data):</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    good_list, bad_list <span class="op">=</span> plan(chemical_formula, spectrometric_data)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    plausible_structures <span class="op">=</span> generate(chemical_formula, good_list, bad_list)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    structures <span class="op">=</span> test(plausible_structures, spectrometric_data)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> structures</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/DENDRAL_flowchart.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="duffieldApplicationsArtificialIntelligence1969">(<a href="#ref-duffieldApplicationsArtificialIntelligence1969" role="doc-biblioref">Duffield et al. 1969, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>During the period of 1965 to 1969, DENDRAL’s performance increased steadily as more chemical knowledge was entered. In the discussion section, they summarized their lessons learned as a tradeoff. Whereas previous logical AI systems like GPS focused on generic heuristic search over solution spaces, they concluded that generality of the solver has a price being paid in speed and power of finding actual solutions.</p>
<blockquote class="blockquote">
<p>In recognition of these difficulties, a vienpoint at the other extreme has ewerged, informally called “the big switch hypothesis”… generality in problem solving is achieved by arraying specialists at the terminals of a big switch. The big switch is moved from specialist toi specialist as the problem solver switches its attention from one problem area to another… The general methods do solve DENDRAL problems, sometimes well as with some amino acid spectra, but they ara relatively weak and inefficient.</p>
<p>… This is remarkable. The planner, which is the specialist at “understanding” the data and inferrirg conditions on tho solution, is so powerful that the need for the general problem solving processes of the system is obviated. Another way to view this is that all the relevant theoretical knowledge to solve these <a href="https://en.wikipedia.org/wiki/Amine">amine</a> problems has been mapped over from its general form in the predictor (“first principles”) to efficient special forms in the planner (“cookbook recipes”).</p>
<p><span class="citation" data-cites="feigenbaumGeneralityProblemSolving1970">(<a href="#ref-feigenbaumGeneralityProblemSolving1970" role="doc-biblioref">E. A. Feigenbaum, Buchanan, and Lederberg 1970</a>)</span></p>
</blockquote>
<p>In another paper <span class="citation" data-cites="buchananRediscoveringProblemsArtificial1970">(<a href="#ref-buchananRediscoveringProblemsArtificial1970" role="doc-biblioref">B. Buchanan, Sutherland, and Feigenbaum 1970</a>)</span>, the authors expressed their surprise that they could split the program into two parts, which would become the “inference engine” and the “knowledge base”. It was as if they have discovered that, instead of manually writing in a lot of if-then statements, they could write a single <code>eval</code> function, and then just write a lot of entries in a giant database of rules in a uniform format, and run the <code>eval</code> function over the rules. It reminds me of von Neumann discovering the code is data, data is code idea, and thus avoid the trouble of having to physically rewire ENIAC every time the program changes.</p>
<p>It was reported to have been used in “terpenoid natural products from plant and marine animal sources, marine sterols, organic acids in human urine and other body fluids…” and was found to reach expert performance. What it lacked in knowledge it made up in thoroughness, and so it outperformed the experts when the sample is a mixture of several chemicals. <span class="citation" data-cites="buchananDendralMetaDendral1981">(<a href="#ref-buchananDendralMetaDendral1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981a</a>)</span></p>
</section>
<section id="meta-dendral" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="meta-dendral">Meta-DENDRAL</h3>
<p>The Meta-DENDRAL was an early example of a logical AI system that could learn from data. It was developed near the end of DENDRAL, when the number of rules became hard to manage. The team decided to see if they could design an expert system that is an expert at <em>learning</em> organic chemical mass spectrometric data – not <em>generic</em> learning from <em>generic</em> data. Their hypothesis was “knowledge acquisition is itself a knowledge-based task”. <span class="citation" data-cites="buchananDENDRALMetaDENDRALTheir1981">(<a href="#ref-buchananDENDRALMetaDENDRALTheir1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981b</a>)</span></p>
<ol type="1">
<li><code>INTSUM</code> (“interpretation and summary”) takes a list. Each list item is a molecular structure and its mass spectrum. It computes an explanation for the spetrum by molecular bond clevages and atomic transfers. It returns the cleavages, atomic transfers, and spectrum peaks as supporting evidence for each cleavage and transfer.</li>
<li><code>RULEGEN</code> (“rule generation”) takes the output from <code>INTSUM</code> and infer cleavage rules from it. For example, <code>X*X</code> means “any bond can be cleaved”, <code>-CO*NH-</code> means that “any peptide bond can be cleaved”, etc. It always starts with the most generic rule <code>X*X</code>, and then tree-searches for more and more specific rules by adding (never removing) more atoms or features to the rule, until reaching a rule whose child rules all perform less well than it.
<ul>
<li>Each atom, like the <code>X</code> in <code>X*C</code>, could be annotated with some or all features from a list of 4: atom type (<code>type</code>, could be carbon, oxygen…), the number of other carbons connected to (<code>nbrs</code>), numbers of hydrogens connected to (<code>nhs</code>), or number of multiple bonds (<code>dots</code>).</li>
<li>For example, <code>-CO*NH-</code> is similar (though not exactly the same) as <code>-X[type=C, dots=1]*X[type=N, nbrs=2, nhs=1, dots=0]-</code>.</li>
<li>How well a rule performs is measured by the number of positive examples (a predicted peak that is really there), negative examples (a predicted peak that is not there), and rule specificity (the more atoms or features, the better).</li>
</ul></li>
<li><code>RULEMOD</code> (“rule modification”) takes the rules output from <code>RULEGEN</code>, scores them according to how many positive and negative examples it has, merges near-duplicate rules by Robinson unification, and generalize them (with a penalty score if the generalized rule has more negative examples).</li>
</ol>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/meta-DENDRAL.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Architecture of Meta-DENDRAL. <span class="citation" data-cites="buchananDENDRALMetaDENDRALTheir1981">(<a href="#ref-buchananDENDRALMetaDENDRALTheir1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981b</a>)</span></figcaption>
</figure>
</div>
<p>In a 1978 report, they first verified that Meta-DENDRAL reproduced 8 well-known rules for <a href="https://en.wikipedia.org/wiki/Aliphatic_amine">aliphatic amines</a> and <a href="https://en.wikipedia.org/wiki/Estrogen">estrogens</a>, such as the famous <a href="https://en.wikipedia.org/wiki/Alpha_cleavage">α-cleavage</a>. Some new rules discovered by Meta-DENDRAL for classifying keto<a href="https://en.wikipedia.org/wiki/Androstane">androstanes</a>. An androstane has 11 ways for attaching a keto group, 55 ways to attach 2 ketos, etc, and though there was a mass of mass spectrometric data for them, there were few cleavage rules due to the complexity of the molecules.</p>
<blockquote class="blockquote">
<p>On the three classes of ketoandrostanes for which no general class rules have been reported, the mono-, di-, and triketoandrostanes, the program found general rules describing the mass spectrometric behavior of those classes… The program has discovered consistent fragmentation behavior in sets of molecules which have not appeared by manual examination to behave homogeneously in the mass spectrometer… it comes close to capturing in a computer program all we could discern by observing human problem-solving behavior. It is intended to relieve chemists of the need to exercise their personal heuristics over and over again, and thus we believe it can aid chemists in suggesting more novel extensions to existing theory.</p>
<p><span class="citation" data-cites="buchananDENDRALMetaDENDRALTheir1981">(<a href="#ref-buchananDENDRALMetaDENDRALTheir1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981b</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/meta-DENDRAL_diketoandrostane.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Cleavage and transfer rules for diketoandrostanes discovered by Meta-DENDRAL. <span class="citation" data-cites="buchananDENDRALMetaDENDRALTheir1981">(<a href="#ref-buchananDENDRALMetaDENDRALTheir1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981b</a>, table 4)</span></figcaption>
</figure>
</div>
<p>They concluded that it was already possible to create AI assistants to perform tedious tasks for organic chemists.</p>
</section>
<section id="mycin" class="level3">
<h3 class="anchored" data-anchor-id="mycin">MYCIN</h3>
<p>After the success of DENDRAL, another team developed MYCIN, an expert system for diagnosing bacterial infections like a doctor. Compared to DENDRAL, MYCIN’s main breakthrough was in allowing reasoning with uncertainty. Instead of using probability, it uses “Certainty Factors” (CF), which ranges from <span class="math inline">\([-1, +1]\)</span>, with <span class="math inline">\(-1\)</span> meaning “certainly false”, <span class="math inline">\(+1\)</span> “certainly true”, and <span class="math inline">\(0\)</span> “complete uncertainty”. Given two statements <span class="math inline">\(p, q\)</span> with CF <span class="math inline">\(x, y\)</span>, the CF for <span class="math inline">\(p \;\mathrm{AND} q\)</span> is combined according to</p>
<p><span class="math display">\[
CF(x, y)=\begin{cases} X+Y -XY   &amp; \text{if } X,Y&gt;0 \\
X+Y+XY &amp; \text{if } X,Y&lt;0 \\
\frac{X+Y}{1-\min(|X|,|Y|)} &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>This combination has these desirable properties:</p>
<ul>
<li>Combining unknown with anything leaves it unchanged.</li>
<li>Combining true with anything (except false) gives true. Similarly for false.</li>
<li>Combining true and false is a division-by-zero error.</li>
<li>Combining +x and -x gives unknown.</li>
<li>Combining two positives (except true) gives a larger positive. Similarly for negatives.</li>
<li>Combining a positive and a negative gives something in between.</li>
</ul>
<p>At this point, we strongly recommend that you try out MYCIN for yourself. Unfortunately, unlike the famous ELIZA, it is quite hard to get a working copy of DENDRAL or MYCIN. However, you can experience the fun of MYCIN by asking a modern LLM to roleplay as one. If you still want to do it the old-school way, follow the <a href="code/run_mycin.md">tutorial here</a>.</p>
<p>Done? Good. MYCIN is very cleanly implemented in Common Lisp for Chapter 16 of <em>Paradigms of artificial intelligence programming</em>, which is available on <a href="https://github.com/norvig/paip-lisp/tree/main">GitHub</a>. Like all expert systems, it has a logical inference engine (shell) and a knowledge base. The shell performs logical inference under uncertainty according to the rules of certainty factors, while the knowledge base consists of statemets of this kind:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode lisp code-with-copy"><code class="sourceCode commonlisp"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">;;;; File mycin-r.lisp: Sample parameter list and rulebase for mycin.</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>(requires <span class="st">"mycin"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">;;; Parameters for patient:</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>(defparm name patient <span class="kw">t</span> <span class="st">"Patient's name: "</span> <span class="kw">t</span> <span class="kw">read-line</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>(defparm sex patient (<span class="kw">member</span> male female) <span class="st">"Sex:"</span> <span class="kw">t</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>(defparm age patient <span class="kw">number</span> <span class="st">"Age:"</span> <span class="kw">t</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>(defparm burn patient (<span class="kw">member</span> no mild serious)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Is ~a a burn patient?  If so, mild or serious?"</span> <span class="kw">t</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>(defparm compromised-host patient yes/no</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Is ~a a compromised host?"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">;;;; ...</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>(defrule <span class="dv">165</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> (gram organism is pos)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>     (morphology organism is coccus)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>     (growth-conformation organism is chains)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  then .<span class="dv">7</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>     (<span class="kw">identity</span> organism is streptococcus))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The full MYCIN system reached impressive results:</p>
<blockquote class="blockquote">
<p>70% of MYCIN’s therapies were rated as acceptable by a majority of the evaluators…. 75% is in fact better than the degree of agreement that could generally be achieved by Stanford faculty being assessed under the same criteria.</p>
<p><span class="citation" data-cites="buchananRuleBasedExpert1984">(<a href="#ref-buchananRuleBasedExpert1984" role="doc-biblioref">B. G. Buchanan 1984, chap. 30</a>)</span></p>
</blockquote>
<p>Impressive enough to catch the eye of people outside of AI community. Here seemed like a system that might actually be commercialized and do the work of doctors. And not just doctors – what else might it do?</p>
<p>To explore this, EMYCIN (“empty MYCIN” or “extensible MYCIN”) was created, which was essentially MYCIN with its knowledge base removed, and some functions added so that one can enter new rules interactively. The experience of an EMYCIN session is that of being interviewed by some programmer who is trying to write down a precise program of how you do your job.</p>
<p>It is more fun, again, to try EMYCIN for yourself by creating a new knowledge base for whatever interests you, and it is easy to get an LLM to roleplay as an EMYCIN. If you prefer reading, then the following example comes from <span class="citation" data-cites="buchananRuleBasedExpert1984">(<a href="#ref-buchananRuleBasedExpert1984" role="doc-biblioref">B. G. Buchanan 1984, 325</a>)</span> (<code>&gt;</code> in front of user input), showing a user creating a new rule for diagnosing hemophilia:</p>
<pre><code>Enter Parms, Rules, Save changes, or Go?
&gt; Rules
Rule number of NEW: 
&gt; NEW
RULE025
PREMISE: 
&gt; (REASON = BLEEDING, SIGBLD, FINALDEF = COAGULATION,
&gt;  DEFPATH = INTRINSIC ~ INTERFERENCE)
RULE025
ACTION: 
&gt; (DX = DXHEMOPHILIA)
BLEEDING → BLEEDING-HISTORY? 
&gt; Yes
COAGULATION → COAGULATION-DEFECT?
&gt; Yes
Translate, No further changes, or prop name:</code></pre>
<p>After this rule is entered, it can be displayed as follows:</p>
<pre><code>RULE025
IF: 1) Bleeding-history is one of the reasons for this consultation,
    2) There is an episode of significant bleeding in the patient,
    3) Coagulation-defect is one of the bleeding disorders in the patient,
    4) The defective coagulation pathway of the patient is intrinsic, and
    5) There are not factors which interfere with the patient's normal bleeding

THEN: It is definite (1.0) that the following is one of the bleeding diagnoses of 
      the patient: The patient has one or more of the following conditions: Hemophilia A,
      von Willebrand's syndrome, an IX, XI, or XII deficiency, or a high molecular weight
      Kallikrein defect.

PREMISE: (AND (SAME CNTXT REASON BLEEDING-HISTORY)
              (SAME CNTXT SIGBLD)
              (SAME CNTXT FINALDEF COAGULATION-DEFECT)
              (SAME CNTXT DEFPATH INTRINSIC)
              (NOTSAME CNTXT INTERFERENCE))
ACTION: (CONCLUDETEXT CNTXT DX (TEXT DXHEMOPHILIA) TALLY 1000)</code></pre>
<p>The “MYCIN gang” summarized their lessons learned in <span class="citation" data-cites="buchananRuleBasedExpert1984">(<a href="#ref-buchananRuleBasedExpert1984" role="doc-biblioref">B. G. Buchanan 1984</a>)</span>. With certainty factors, shell, and knowledge base, the main pieces of the expert system boom have fallen into place.</p>
</section>
<section id="what-is-knowledge" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="what-is-knowledge">What is knowledge?</h3>
<p>Knowledge, in the context of expert systems, is basically object-oriented programming + relational database + first-order logic.</p>
<p>There, now I’ve said it. It explains why expert systems is so boring. The useful parts of it ended up being Java + SQL.</p>
<p>To see this, consider a few examples of what is “knowledge” in expert systems.</p>
<p>First-order predicate logic: it looks like</p>
<p><span class="math display">\[
\frac{\forall x, IsHuman(x)\to IsMortal(x) \quad IsHuman(Socrates)}{IsMortal(Socrates)}
\]</span></p>
<p>Robinson unification is an operation in first-order logic, where we have two formulas with variables in them, and unification finds a way to substitute the variables, so that the two formulas become equal. For example:</p>
<p><span class="math display">\[
\frac{\forall x, IsHuman(x)\to Hates(x, Java) \quad IsHuman(Socrates)}{Hates(Socrates, Java)}{(x \leftarrow Socrates)}
\]</span></p>
<p>The frame: Looks exactly like data types in Java.</p>
<p>A semantic graph: a network of frames. Looks exactly like a <a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language">UMD diagrams</a>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/frame_system.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A frame system. It looks exactly the same as those UMD diagram I hated back when I learned Java programming. <span class="citation" data-cites="russellArtificialIntelligenceModern1995">(<a href="#ref-russellArtificialIntelligenceModern1995" role="doc-biblioref">Russell and Norvig 1995, fig. 10.7</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="knowledge-principle" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="knowledge-principle">Knowledge Principle</h3>
<blockquote class="blockquote">
<p>[Edward Feigenbaum:] In 1968, I was writing a paper with Bruce [Buchanan] and Josh Lederberg in which we chose to summarize the evidence from the many DENDRAL experiments from mid-1965 to mid-1968. It was evident that the improvement in DENDRAL’s performance as a mass spectrum analyst was almost totally a function of the amount and quality of the knowledge that we had obtained from Djerassi’s experts, and that it was only weakly related to any improvements that the AI scientists like me and Bruce had made to the reasoning processes used in DENDRAL’s hypothesis formation. So in 1968, I called this observation the “Knowledge is Power Hypothesis.” One data point. Later, as the evidence accumulated from dozens of – or hundreds of – expert systems, I changed the word “hypothesis” to “principle.”</p>
<p>[Bruce Buchanan:] Art Samuel’s work on the checker player: Art had interviewed experts to understand … the feature vector and then he did a good deal of reading about checkers… That impressed me a great deal and I always wanted to be able to do that. [Meta-DENDRAL] did learn the rules of mass spectrometry from empirical data. A footnote on that. The data were very sparse. It took about one graduate student one year to obtain and interpret one mass spectrum, so we couldn’t ask for very much data. This was not a big data problem.</p>
<p>quoted in <span class="citation" data-cites="brockLearningArtificialIntelligences2018">(<a href="#ref-brockLearningArtificialIntelligences2018" role="doc-biblioref">Brock 2018</a>)</span></p>
</blockquote>
<p>What was new about expert systems? The previous approach to logical AI focused on general algorithms (usually search) and problem representation, guided by a small amount of heuristics. On the general algorithms side, examples included <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A* search</a> developed for Shakey the robot, <a href="https://en.wikipedia.org/wiki/Dynamic_time_warping">dynamic time warping</a> developed for speech recognition, <a href="https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm">KMP algorithm</a> for string matching, etc.</p>
<p>While it is anachronistic, a good example of non-trivial data representation for effective search is the <a href="https://www.chessprogramming.org/Bitboards">bitboard</a> used for computer chess. It represents the entire chess board with a bit array in a clever way, so that many operations, like finding which pieces are attacking a square, becomes bitwise operations, allowing fast game tree search.</p>
<p>Expert systems inverts this focus. Heuristics (in the form of expert knowledge) is placed front and center, while algorithm and representation was almost beside the point – they were all basically flavors of first-order predicate logic inference, and they distinguish themselves by how easy it is for the end user, and how fast it runs (often measured by “number of logical inferences per second”).</p>
<p>We can think of this as an early appearance of <em>dataset</em> in AI. From our scaling-hypothesis point of view, this was a step in the right direction, but it was yet incomplete, since the data was heavily distilled by human experts into rules. Many of the AI researchers recognized the problem, and worked on automatic rule-generation, but none succeeded in general.</p>
<p>Philosophically, expert systems has more in common with inductive, scientific reasoning, while the previous logical AI with deductive, mathematical reasoning <span class="citation" data-cites="lindsayDENDRALCaseStudy1993">(<a href="#ref-lindsayDENDRALCaseStudy1993" role="doc-biblioref">Lindsay et al. 1993</a>)</span>. In a position paper coauthored by Feigenbaum and Douglas Lenat, we have a clear statement of the assumptions behind expert systems AI.</p>
<blockquote class="blockquote">
<p>“Knowledge is Power” or, more cynically “Intelligence is in the eye of the (uninformed) beholder.”… The Knowledge Principle (KP): A system exhibits intelligent understanding and action at a high level of competence primarily because of the specific knowledge that it can bring to bear: the concepts, facts, representations, methods, models, metaphors, and heuristics about its domain of endeavor… Knowledge is often considered Compiled Search; despite that, the KP claims that only a small portion of the knowledge can be generalized so it applies across domains, without sacrificing most of its power.</p>
<p>Explicit Knowledge Principle: Much of the knowledge in an intelligent system needs to be represented explicitly.</p>
<p>The Competence Threshold: Difficult tasks succumb nonlinearly to knowledge. There is an ever greater “payoff” to adding each piece of knowledge, up to some level of competence (e.g., where an NP complete problem becomes Polynomial). Beyond that, additional knowledge is useful but not frequently needed (e.g., handling rare cases.). Crossing the Competence Threshold, one enters the realm of experts. There, the knowledge-search tradeoff is fairly evenly balanced.</p>
<p><span class="citation" data-cites="lenatThresholdsKnowledge2000">(<a href="#ref-lenatThresholdsKnowledge2000" role="doc-biblioref">D. Lenat and Feigenbaum 2000</a>)</span></p>
</blockquote>
<p>From the hindsight of deep learning, the first hypothesis has been amply justified, the second refuted, and the third appears to be differ case-by-case.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> Lenat, however, bet everything on the three assumptions, in a heroic 30-year-long journey to build <a href="#sec-cyc">Cyc, an expert system AGI</a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn19"><p><sup>19</sup>&nbsp;In self-driving cars, it is the long tail of rare events that take the longest to learn, yet they were what is required to get the car to drive at expert level. Further, the improvement is smooth: there is no “threshold” at which the value of one additional rare event drops suddenly. Similarly, <a href="https://gwern.net/scaling-hypothesis#:~:text=The%20last%20bits%20are%20deepest">Gwern argued that “the last bits are the deepest”</a>.</p></div></div></section>
<section id="ai-boom" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="ai-boom">AI boom</h3>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/expert_system_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A typical expert system architecture during the 1980s. <span class="citation" data-cites="harmonExpertSystemsBusiness2022">(<a href="#ref-harmonExpertSystemsBusiness2022" role="doc-biblioref">Harmon 2022, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>During the late 1970s, expert systems got noticed outside the small scholarly community, and as the 1980s went on, knowledge became money. The first wave of commercial AI arrived, and it lasted for about 10 years.</p>
<p>Instead of describing in detail these systems, we can just admire tha sudden explosion of commercial expert systems:</p>
<blockquote class="blockquote">
<p>analysis of physical objects (like buildings or bridges), SACON; determining the structure of proteins from X-ray crystallographic data, in collaboration with experts at UC San Diego, CRYSALIS; interpreting data about a person’s lung functioning coming from an instrument called a spirometer, in collaboration with a doctor at California Pacific Medical Center, PUFF; managing ventilator machines in intensive care units, another collaboration with a CPMC ICU lead physician, VM… Feigenbaum’s lab was funded by IBM to help them develop their first expert system—final diagnosis of errors in disk drives before they were shipped to the customer… GEO, to analyze and form hypotheses about the geology of the bore hole as drilling proceeded down inch by inch… [DARPA], which funded half of the research in Feigenbaum’s lab, wanted an expert system to hypothesize about the behavior of enemy submarines hiding in U.S. coastal waters, interpreting data from ocean noises, and reconnaissance aircraft sightings, and using a large compendium of mostly secret intelligence knowledge about those enemy submarines and their behaviors… the classified expert system HASP for enemy submarine surveillance. Importantly, it included explanations in English for all of its inferred hypotheses, thereby gaining the trust of the Navy personnel at the coastal stations.</p>
<p>…</p>
<p>By 1988, Paul Harmon, an expert systems newsletter editor, counted several thousand expert systems operating in fields as varied as construction, finance, heavy manufacturing, and computer configuration and sales.</p>
<p><span class="citation" data-cites="mccorduckScientificLifeEdward2022">(<a href="#ref-mccorduckScientificLifeEdward2022" role="doc-biblioref">McCorduck 2022</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>In 1980 John McDermott of Carnegie Mellon delivered to Digital Equipment Corporation the first version of XCON, an expert system designed to help the computer manufacturer configure its machines to suit customer demand; by the middle of the decade the company estimated it was sav- ing $40 million annually by use of XCON. The CBS Evening News re- ported in September 1983 that the expert system PROSPECTOR, instantiating the knowledge of nine geologists, had helped a company discover molybdenum deposits in Washington State’s Mount Tolman. Comparable stories proliferated. Companies scrambled to buy expert systems. New companies sprang up to service them. Bright students were lured away from graduate school with salary offers of $30,000.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 191</a>)</span></p>
</blockquote>
<p>The AI boom caught even the imagination of the experts themselves:</p>
<blockquote class="blockquote">
<p>at the moment the expert system takes hold of the expert’s own imagination. For weeks, perhaps longer, he has watched what is most charitably described as a burlesque of his thinking processes dancing across a display. All of a sudden (or so it seems) the burlesque sharpens into adroit imitation: there before him are the very reasoning processes he has originated, nourished, and cherished over a professional lifetime. His excitement mounts, and he becomes an enthusiastic partner in the last few steps of perfecting the electronic image of his mind. He becomes infected by the “immortality syndrome” as one researcher calls it—elation at the thought that what he knows, has so painstakingly acquired over a lifetime of experience, will live on beyond him.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 93</a>)</span></p>
</blockquote>
<p>A best-selling book was full of miraculous stories of growth and business profits:</p>
<blockquote class="blockquote">
<p>Mike-in-the-Box, “God in the works” (the captured expertise of an aging, irreplaceable blast furnace expert at Nippon-Kokan), ’’Geoff’s Book” (thousands of expert rules from the head of the senior, top estimator at building contractor Lend Lease of Australia), and J. A. Gilreath (Schlumberger’s ace oilfield data interpreter, whose expertise is now enshrined in that company’s Dipmeter Advisor system) are among the stars we meet. Much of the priceless skill of these experts has been captured by “knowledge engineer”: translators.</p>
<p>At IBM Burlington (the chip operation), a 10 to 20 percent increase in throughput has been realized; this adds up to tens of millions of dollars’ annual savings from just the one system. At the British National Health Service, a demanding and critical evaluation task that took six experts two hours is now done (better) in nine minutes. At American Express, the “decline rate” (decisions not to grant credit) has been reduced by fully one-third, and the value of the single, new AI system is already estimated at $27 million a year. A Westinghouse system (a new service which that firm sells to utilities), aimed at enhancing the utilization of giant electric power generation turbines, contributes a whopping $2 to $3 million per year per customer machine. Then there’s a sales support system at Digital, called XSEL, which has reduced a three-hour system configuration/alternative generation task to fifteen minutes; moreover, less than 1 percent of the systems so specified turn out not to be manufacturable, down from 30 percent before the system was installed—all of which is worth $70 million a year, says DEC, not including immeasurable added customer satisfaction that accrues from providing the customer with more options. And an AI system that aids product design at Canon has made scarce, highly skilled lens designers fully twelve times more productive!</p>
<p>…</p>
<p>For a customer, NKK Steel, IBM built a system that schedules the movement of materials and products and does the assignment of workers to tasks. The expert system was put into operation in September, 1987. It produces in half an hour a schedule that previously took ten hours to prepare and overall saves the company 100 million yen per year (about $700 thousand).</p>
<p>…</p>
<p>Force Requirements Expert System, an expert system to advise on the deployment of ships in the U.S. Pacific Fleet. According to TI, a typical deployment problem would take an experienced operations officer and his staff as much as a week to solve, but with the help of Fresh, the officer can produce a solution by himself in six to eight hours.</p>
<p><span class="citation" data-cites="feigenbaumRiseExpertCompany1988">(<a href="#ref-feigenbaumRiseExpertCompany1988" role="doc-biblioref">E. A. Feigenbaum, McCorduck, and Nii 1988</a>)</span></p>
</blockquote>
<p>Wait, the US Pacific Fleet? Yes! The military took on many expert systems. More on this <a href="#sec-sci">below</a>.</p>
<p>The market segmented into the following parts:</p>
<ul>
<li>Language: Some companies marketed basic language development and consulting, mainly in Lisp and Prolog.</li>
<li>Expert system building tools: Some companies marketed software for building expert systems. They might be expert system “shells” like the EMYCIN, with some extras to make it easier for non-researchers like engineers to enter their knowledge into the computer.</li>
<li>Application builders: Some companies would build expert systems on demand. They would send in knowledge engineers into the field and elicit knowledge from experts, by interview, observing, asking questions, etc. At the end of the process, they would deliver the finished expert system.</li>
</ul>
<p>However, there was a persistent confusion as to the point of expert systems, since even deep into the AI boom period, people still often thought the expert system shell was “the AI” that the AI companies were selling, even when it’s the knowledge engineering that they sold. It was kind of a <a href="https://en.wikipedia.org/wiki/Shell_game">shell game</a>.</p>
<blockquote class="blockquote">
<p>The idea was that there was a piece of magic that was the AI and that this magic, plus a software development environment that made it easy to build these things, was salable… Where was the AI? It wasn’t in the inference engine at all. These inference engines were, after all, pretty simple pieces of software that tested to see if the logic of the rules that the knowledge engineers wrote came up with any conclusions. The AI in complex expert systems was in the organization and representation of knowledge, the attempt to understand the domain under study, and the crystallization of what was important in the domain and how experts in the domain reasoned.</p>
<p><span class="citation" data-cites="schankWheresAI1991">(<a href="#ref-schankWheresAI1991" role="doc-biblioref">Schank 1991</a>)</span></p>
</blockquote>
</section>
<section id="the-knowledge-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="the-knowledge-bottleneck">The knowledge bottleneck</h3>
<p>If knowledge is power, then how does one acquire more power? The “knowledge bottleneck” already appeared in the earliest papers on DENDRAL:</p>
<blockquote class="blockquote">
<p>we could get rid of the “middle man” in the information transfer by educating a programmer in mass spectrometry or by educating a chemist in Lisp. Or we could replace the middle man with a program designed to perform the same function as B (the layman/programmer) in the dialog above. In effect, we have been moving slowly in all three of these directions at once. But what we would most like to pursue is the design of a program to elicit information from an expert who is not also a programmer.</p>
<p>One obvious reason for the encouragingly high level of performance of the computer is the large amount of mass spectrometry knowledge which chemists have imparted to the program. Yet this has been one of the biggest bottlenecks in developing the program… The preponderance of time was now spent by the chemist deciding how to change the rules in the table to bring the program’s behaviour more in line with real data.</p>
<p><span class="citation" data-cites="buchananRediscoveringProblemsArtificial1970">(<a href="#ref-buchananRediscoveringProblemsArtificial1970" role="doc-biblioref">B. Buchanan, Sutherland, and Feigenbaum 1970</a>)</span></p>
</blockquote>
<p>There were mainly two kinds of “knowledge acquisition”. Most of it was slow and painful, with knowledge engineers “eliciting” knowledge from experts by interviews and observations. It was a cottage industry for spinning out knowledge, and many recognized this as the great problem for scaling expert systems up. Much of the tooling came into making the cottage industry faster. MYCIN had taken 20 person-years to produce just 475 rules! In contrast, GASOIL in 1986 would take one person-year to produce 2,500 rules, a speed up of 100x. <span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 194</a>, page 370)</span></p>
<blockquote class="blockquote">
<p>Feigenbaum: I said, “Sato-san [CEO of Fujitsu Laboratories in Japan], what message would you like me to take back to the people in the US about your experience in expert systems?” He said, “Tell them it’s too hard to get the knowledge.”</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>From various reading, it seems to me that the largest possible expert systems assembled by such a cottage industry contained around 10,000 rules. For example, the XCON system had around 16,000 rules. <span class="citation" data-cites="barkerExpertSystemsConfiguration1989">(<a href="#ref-barkerExpertSystemsConfiguration1989" role="doc-biblioref">Barker et al. 1989</a>)</span> Anything bigger than that basically was too complicated for its own good. Except the Cyc.</p>
<blockquote class="blockquote">
<p>Feigenbaum: In 1973 there was a guy named Harold Cohen who made an intelligent painter. You guys should actually do some research on that… It was probably the longest-lived expert system in the history of expert systems. Harold died [in 2016]. It was a 15,000-rule system representing the rules that he got out of his own head.</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018a">(<a href="#ref-allenExpertSystemsPioneer2018a" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 8: <span>Artificial</span> Intelligence and Machine Learning in the 1990s</em> 2018</a>)</span></p>
</blockquote>
<p>There were many attempts at automatic knowledge acquisition, starting with Meta-DENDRAL, and culminating with Cyc. They all failed to scale up. We will do a detailed case-study of Cyc and its scalability problems.</p>
<blockquote class="blockquote">
<p>This is the stuff of excellent AI science. But did Meta-DENDRAL find any application in any industrial setting? No.&nbsp;Nor have any of the other complex machine learning procedures (however, machine induction based on algorithms of <a href="https://en.wikipedia.org/wiki/Ross_Quinlan">Quinlan</a> have had a marginal success). The industry of AI applications is still awaiting the dawn of an era of knowledge engineering significantly aided by machine learning.</p>
<p><span class="citation" data-cites="lindsayDENDRALCaseStudy1993">(<a href="#ref-lindsayDENDRALCaseStudy1993" role="doc-biblioref">Lindsay et al. 1993</a>)</span></p>
</blockquote>
</section>
<section id="where-did-it-go" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="where-did-it-go">Where did it go?</h3>
<p>Around mid-1990s, it was pretty much official: the Expert System hype died. According to the AI mythos, after this came the second AI winter. Where did it go?</p>
<blockquote class="blockquote">
<p>The new darling of the media – virtual reality – has supplanted AI as having the potential to merge science fiction with real-world applications… Patrick Albert… pointed out the main problem afflicting the AI industry: “companies have been marketing AI technologies, and not solutions.” … the more invisible AI becomes, the more palatable it becomes to the end-user. The day of generic expert system tools is probably over, Arjimand said, to be replaced by off-the-shelf applications.</p>
<p>Both Monte Zweben, President of Red Pepper Software (San Mateo, CA), and Tom Laffey, Chief Technology Officer of Talarian (Mountain View, CA), had similar stories to tell regarding the successful launch of companies selling real-time expert system tools: never, ever call the products “AI”. “Don’t mention AI if you want any venture capital money,” Laffey warned. “Call it something else, such as advanced decision systems. These days, people come to AI almost as a last resort.” Zweben’s company shared the same fate as Talarian: he had to remove or restate every mention of AI from the Red Pepper prospectus before investors would take him seriously. Despite the literally thousands of successfully deployed intelligent ap- plications, AI’s reputation continues to suffer because nobody is giving credit to the AI component. Zweben suggested wish- fully that AI companies insist on being recognized for their contribution to applications, perhaps even demanding an ‘AI inside’ label, it la Intel’s ‘Intel inside’ label on PCs.</p>
<p><span class="citation" data-cites="blanchardAAAI94StateAI1994">(<a href="#ref-blanchardAAAI94StateAI1994" role="doc-biblioref">Blanchard 1994</a>)</span></p>
</blockquote>
<p>Schank, writing near the end of the expert systems hype, argued that AI researchers missed the point about scaling. They thought AI is about designing an algorithm, when it is really quite tedious – real AI is 1% inspiration and 99% perspiration. He used the experience of getting ATRANS to work in practice, a program that read international bank money transfer messages:</p>
<blockquote class="blockquote">
<p>Any of Cognitive Systems’ programmers would have been justified in complaining that they had come to work there to do AI, and all they were doing was working on endless details about determining various abbreviations for bank names. They also asked, Where’s the AI? The lesson to be learned from ATRANS is simple enough… AI entails massive software engineering. To paraphrase Thomas Edison, “AI is 1-percent inspiration and 99-percent perspiration.” AI people will never build any real AI unless they are willing to make the tremendously complex effort that is involved in making sophisticated software work.</p>
<p>One serious problem in AI these days is that we keep producing researchers instead of builders. Every new Ph.D.&nbsp;recipient, it seems, wants to continue to work on some obscure small problem whose solution will benefit some mythical program that no one will ever write. We are in danger of creating a generation of computationally sophisticated philosophers.</p>
<p><span class="citation" data-cites="schankWheresAI1991">(<a href="#ref-schankWheresAI1991" role="doc-biblioref">Schank 1991</a>)</span></p>
</blockquote>
<p>Winograd argued that expert systems are structured like human bureaucracies, with formalized explicit rules, and so they have same strengths and weaknesses. This explains why they work only in stable and precise technical areas, where exceptions are not the rule. He gave an example expert system that was stuck in development hell for 15 years, presumably as it was in an era (internal medicine) that has too many exceptions to the rules:</p>
<blockquote class="blockquote">
<p>One system for medical diagnosis, called <a href="https://en.wikipedia.org/wiki/CADUCEUS_(expert_system)">CADUCEUS</a> (originally INTERNIST), has 500 disease profiles, 350 disease variations, several thousand symptoms, and 6,500 rules describing relations among symptoms. After 15 years of development, the system is still not on the market. According to one report, it gave a correct diagnosis in only 75 percent of its carefully selected test cases. Nevertheless, Myers, the medical expert who developed it, “believes that the addition of another 50 [diseases] will make the system workable and, more importantly, practical.”</p>
<p><span class="citation" data-cites="winograd10ThinkingMachines1991">(<a href="#ref-winograd10ThinkingMachines1991" role="doc-biblioref">Winograd 1991</a>)</span></p>
</blockquote>
<p>In 1992, Feigenbaum admitted that the hope of generally intelligent expert systems failed. They turned out to be like mesas: narrow, brittle, and isolated. They work well within the knowledge base, but immediately fail when even slightly outside of it. Every expert system was unique and custom-made. They couldn’t be mass-produced, and their knowledge bases are incompatible, so they couldn’t talk to each other or share each other’s knowledge. Although, he dreamed of a “Library of Congress of knowledge codified and represented for expert system use”, which he saw in the <a href="#sec-cyc">Cyc</a>. <span class="citation" data-cites="feigenbaumPersonalViewExpert1992">(<a href="#ref-feigenbaumPersonalViewExpert1992" role="doc-biblioref">E. A. Feigenbaum 1992</a>)</span></p>
<p>Many years later, in 2018 and 2022, some of the expert systems people reviewed to their younger days to find out what went wrong.</p>
<p>Harmon argued that expert systems failed to <a href="https://en.wikipedia.org/wiki/Crossing_the_Chasm">“cross the chasm”</a>. A new technology is adopted in two waves, with the first wave driven by small companies (“innovators” and “early adopters”) who were optimistic about its future, and the second wave driven by large companies that sell to the “majority” who have been convinced that it grows the bottom-line. The first wave typically appears at technology fairs, while the second wave typically appears at <a href="https://en.wikipedia.org/wiki/Trade_show">trade fairs</a>. The “chasm” between the two waves happen because some technologies never get past the “a good idea” stage, and end up being “a good idea that didn’t work out for most”, and it may remain in use only in niche places.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Moore_chasm.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Moore’s technology adoption life cycle curve. <span class="citation" data-cites="harmonExpertSystemsBusiness2022">(<a href="#ref-harmonExpertSystemsBusiness2022" role="doc-biblioref">Harmon 2022, fig. 3</a>)</span></figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>By the late 1990s, most expert systems vendors had disappeared. Some expert systems tool companies survived until later, and large companies like IBM simply shifted their emphasis to other product lines as demand changed. In essence, the expert systems market never really achieved take-off.</p>
<p><span class="citation" data-cites="harmonExpertSystemsBusiness2022">(<a href="#ref-harmonExpertSystemsBusiness2022" role="doc-biblioref">Harmon 2022</a>)</span></p>
</blockquote>
<p>Though expert systems don’t cost salary like human experts, they still have a high maintanence cost, because knowledge updates:</p>
<blockquote class="blockquote">
<p>Harmon: When you start to see attendance and vendors dropping off, you know that the market is closing down for some reason. That certainly happened in that expert systems array. The second thing is that expert systems knowledge isn’t a constant… If a company had a knowledge base and passed it to somebody else, it would be certainly at the cutting edge. But it would be out of date within a year or two anyway. The ability of these systems to be maintained, to have people bring them up to date is critical, too.</p>
<p>Feigenbaum: In 1987 dollars, to maintain the famous <a href="https://en.wikipedia.org/wiki/Xcon">DEC configuration system</a> cost DEC $2.7 million a year because the products kept changing.</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>The more powerful features of expert systems were too difficult to use for people untrained in computer science, and the features that outsiders could use were pretty simple and boring.</p>
<blockquote class="blockquote">
<p>Lenat: it was closer to what Ed and others were saying: the tools were too hard to use; the education and knowledge transfer to the people who would have to build the systems wasn’t there. I was on the <a href="https://en.wikipedia.org/wiki/Inference_Corporation">Inference</a> advisory board. and I loved ART [Automated Reasoning Tool, produced by Inference]. It had context and all sorts of wonderful features and truth maintenance. In general, the first thing that the customers would do is turn all that off because it was very complicated… They just used this narrow little tiny iris that wasn’t quite enough for them to get enough traction to make it cost-effective.</p>
<p>Friedland: People bought zillions of copies of ART probably about 1985 and right around the tradeshow in Los Angeles. The same thing, with IntelliCorp, people bought KEE [[Knowledge Engineering Environment](https://en.wikipedia.org/wiki/Knowledge_Engineering_Environment)] like chocolate candy bars, but it took really skilled people to use those tools effectively just as it takes really skilled people to use these things. NASA spent $1 billion on an SAP system and spent almost no money on consulting advice to use it. It took teams of people, and I was on one of the teams, five years to fix the mess that caused at NASA by buying SAP. It ending up with a system that totally ruined its financial management for years.</p>
<p>Haigh: If you’re Peter Hart or Ed Feigenbaum, you can do amazing things, but there aren’t that many Ed Feigenbaum’s and Peter Hart’s around… How do you scale that up if you sell the tool? You’re saying they turn off all the smart stuff. There isn’t a huge base of people out there who are smart enough and have the right background to do the things that the really smart people can.</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>From a purely business perspective, the profit margins were too thin. Those selling programming language support and generic shells died, because those quickly became commodities with thin profit margin, and could not compete with large incumbents (like IBM) who could run a loss leader.</p>
<blockquote class="blockquote">
<p>Allen: the first generation of expert system companies had an extremely skewed image of what the market was because the federal government was coming in and throwing tons of money into the thing… we shipped and the next month we were doing a million a month in revenue… Once that initial fact-finding effort had gone on within those organizations, they said, “Well, it’s either too expensive or we’re going to do it in-house.”</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>Those that survived, survived by pivoting:</p>
<ul>
<li>to object-oriented programming tools or databases, which are similar to knowledge bases;</li>
<li>to relational databases, which are similar to knowledge bases;</li>
<li>to <a href="https://en.wikipedia.org/wiki/Business_rule">business rules</a>, which are particularly cheap to construct, because instead of living inside expert heads, they are already written down as business policies and top-down procedural guidelines;</li>
<li>to consulting, building expert systems for their customers and keep maintaining it with new knowledge.</li>
</ul>
<p>And knowledge acquisition, the dream of machine learning breaking through the bottleneck? Some of it failed, and some of it was taken over by statistical machine learning and “data mining”, as discovering logical rules and decision trees over a large database. Data science for the 2000s.</p>
</section>
<section id="did-it-succeed-after-all" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="did-it-succeed-after-all">Did it succeed after all?</h3>
<p>True, the higher dreams of expert system AGI did not pan out, but small parts of AI had successfully broken out from the academia and become infrastructure: practical, invisible, even boring.</p>
<blockquote class="blockquote">
<p>Harmon: several of these old expert system tool vendors who then became business rule vendors became part of the business process tool market, and it exists there today… It’s a very easy kind of knowledge to capture. As opposed to interviewing an expert and trying to get them to give you heuristic information, these guys were dealing almost entirely with procedures that had already been stated in a rulebook. In any case, it’s just one variation of what people with this technology went out and found out a niche and did. There was a market for parts of the technology. It just didn’t happen to fit the big model.</p>
<p>Feigenbaum: rules-based systems lives on today, very strongly absorbed into the infrastructure of IT. Somebody mentioned yesterday that if you take off the back cover of some system and you look in there there’s a rule-based system in there… It’s not the full base. It’s not the full inference engine. It’s not the full expert system, but the business rules exist.</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>I imagine the world of knowledge in rings around a mineshaft. Directly inside the mineshaft are researchers, who send out cartloads of barely refined ore. These are then refined into shape by the technologists. Finally those ingots are hammered into shape, to be used by those in the business who just want to get a well-packaged modular piece of tech to do something reliably and cheaply.</p>
<p>Numerical computing started as research projects on the early giant mainframes, which are then turned into numerical programs written in C, which then gets turned into packaged systems like Matlab and Macsyma, usable by people outside the numerical computing community, who just need to calculate the pressure of an oil well or the tension in a building beam.</p>
<p>My guess is that the expert system boom took place because there was something genuinely new: it was the brith of non-numerical software engineering.</p>
<p>Mechanical calculators were present since the 19th century, and numerical methods such as finite elements, weather prediction, linear programming, cybernetics, etc, simply migrated wholesale to electronic computers in the 1940s, and the mathematics and engineering department could simply churn out numerical programmers by giving them a course in ALGOL – a name that means “[numerical] algorithm language”.</p>
<p>In contrast, there was very little <em>symbolic</em> algorithms before computers came around, and it was born essentially around the 1950s as “symbolic AI” or “computer science”. Entire university departments for computer science had to be invented. MIT’s CS department was established in 1963, MIT 1965, and Berkeley 1967. The story makes too much if we assume progress marches <a href="https://en.wikipedia.org/wiki/Planck's_principle">one generation at a time</a>:</p>
<ul>
<li>The heroic age: Preliminary theoretical AI studies by Turing, McCulloch, Pitts, etc, in the 1940s.</li>
<li>The classical age: Universities create a department of AI and CS and start teaching graduate students the subject with canonical textbooks, creating a reliable stream of professors and lecturers of the subject, in the 1960s.</li>
<li>The civilized age: The technology spills out into the commercial world, and universities create undergraduate degrees in computer science dedicated to churning out software engineers, as SWE becomes a professional class with stock options and a retirement plan, in the 1980s.</li>
</ul>
<p>In 1980, laypeople outside the computer community knew very well that computers can crunch statistical datasets and numerical simulations, and that they can perform if-then-else logical control flows, but they thought that’s <em>all</em> they could do. In the 1970s, expert systems with uncertainty quantification was something new in the research level, as barely refined ore. Around 1980, it had been roughly packaged up as EMYCIN by researchers and technologists, who had used EMYCIN to solve real problems. So, during 1980s, expert systems reached the last stage: to be hammered into a tool for business.</p>
<p>Indeed, at the start of the boom, there was a serious lack of computer science graduates who could write the expert systems. This seemed rather silly, now that we’ve seen that much of what expert systems did are now done by object-oriented programming and relational databases. But remember that back in 1980s, computer science was a purer science, unlike electric engineering. Software engineering was just getting started.</p>
<p>Similarly, there was also the promise of logic programming over imperative programming, of <a href="https://en.wikipedia.org/wiki/Program_synthesis">formal program synthesis</a>: the user specifies the results, and a logical inference engine would synthesize a way to get there. This was a development from robot planning (especially <a href="#sec-shakey">Shakey</a>), where the user would input a goal state of the world, and the planner would compute a motion plan to reach that state. This was also a revelation. Compared to the previous method of programming directly the motion plan like writing assembly code, this was like compiling a source code into assembly. This was a major promise of Prolog-based logic programming. I am less certain about where this has ended up, but my hypothesis is the same: When it is <em>possible</em> to specify a task domain by formal logic, then it works, and this lives today in logistical planning software, robotic path-finding, automated compiler design, etc. However, this does not work in domains not logically specified.</p>
<p>So what happened to expert systems? The working parts (knowledge representation, retrieval, logical inference, logistical planning, data dashboards, automatic industrial process control) got rolled into standard software engineering and became too boring to be considered AI. The not working parts (automatic knowledge acquisition, machine learning, vision, speech, translation) got abandoned, only to be resurrected again by statistical machine learning, and then deep learning.</p>
<blockquote class="blockquote">
<p>As soon as it works, no one calls it AI anymore.</p>
</blockquote>
<p>The working parts of expert systems live behind boring acronyms like Systems Applications and Products (SAP), Automated Reasoning Tool (ART), and Knowledge Management Systems (KMS).<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> As a pattern, the areas where expert systems succeeded include logistics planning, business rules, tax code, bureaucratic rules, while they failed basically at any kind of general intelligence in even slightly unstructured environments. The common intuition that they are fragile is largely correct, and they work precisely in standardized environments with minimal change, much like bureaucracies. Indeed, a good intuition is that expert systems are digitized bureaucracies, with the same strengths and weaknesses.</p>
<div class="no-row-height column-margin column-container"><div id="fn20"><p><sup>20</sup>&nbsp;Are you bored yet? Here are more! Knowledge base management system (KBMS), enterprise resource planning (ERP), business process management (BPM), process-oriented knowledge management (PKM), business process management system (BPMS), online transactional processing (OLTP), recency, frequency, monetary value analysis (RFM), earnings before interest, taxes, depreciation and amortization (EBITDA)… The last one was not about expert systems, but it might as well be, haha.</p></div></div><p>We also have another hint of what mattered in the old days. In the 1978 report on Meta-DENDRAL, the authors claimed that a serious problem was simply that software on one machine doesn’t run on another machine. “Just copy it” did not work, because the machines had incompatible, bespoke operating systems. The “write once, compile it everywhere” that we take for granted in software engineering only came around circa 1990.</p>
<blockquote class="blockquote">
<p>While the software is almost too complex to export, our research-oriented computer facility has too little capacity for import. Support of an extensive body of outside users means that resources (people as well as computers) must be diverted from the research goals of the project. At considerable cost in money and talent, it has been possible to export the programs to Edinburgh. But such extensive and expensive collaborations for technology transfer are almost never done in AI.</p>
<p><span class="citation" data-cites="buchananDENDRALMetaDENDRALTheir1981">(<a href="#ref-buchananDENDRALMetaDENDRALTheir1981" role="doc-biblioref">B. G. Buchanan and Feigenbaum 1981b</a>)</span></p>
</blockquote>
<p>Meanwhile, Feigenbaum left the MYCIN-gang life and became the Chief Scientist of <a href="https://en.wikipedia.org/wiki/United_States_Air_Force">US Air Force</a>, and tried to teach them about software engineering. With regard to technology, the military was still doing it the same way as they did in the 1950s. They prioritized hardware before software, and what software they developed was by the waterfall model they used for <a href="https://en.wikipedia.org/wiki/Semi_Automatic_Ground_Environment">SAGE</a> <span class="citation" data-cites="boehmView20th21st2006">(<a href="#ref-boehmView20th21st2006" role="doc-biblioref">Boehm 2006</a>)</span>. Needless to say, his attempts to teach them about post-1950s software engineering went nowhere. I feel like his story is somehow a reflection of this larger story of how expert system AI became boring software engineering.</p>
<blockquote class="blockquote">
<p>He recalls visiting the offices of a defense contractor working on a half-billion-dollar missile defense system under construction. While the innovative physics in the hardware seemed to be on track, the crucial and difficult software controlling the remarkable aiming system was being handled by only two software engineers, who admitted they hadn’t yet made much progress.</p>
<p><span class="citation" data-cites="mccorduckScientificLifeEdward2022">(<a href="#ref-mccorduckScientificLifeEdward2022" role="doc-biblioref">McCorduck 2022</a>)</span></p>
</blockquote>
<p>The non-working parts of expert systems were all about massive learning. It is fine to encode a few thousand rules by hand, but one does not simply write “a little grammar” for English text or speech. I have a mental picture of three rule-based regimes:</p>
<ul>
<li>A few large rules in the center, strongly held. These create the appearance of a rule-based system, and allows one to feel like “a little grammar” is all it takes. This is the Chomskyan and logical AI regime.</li>
<li>A network of many medium rules, weakly held. They are strongly interacting with each other, clobbering over each other, so that it is hard to make sure the network behaves correctly unless the priority weights are set correctly. If the interaction weights are too low, the system is not “contextual” enough. If the weights are too high, it would become “chaotic”. Expert systems are typcially stuck in this regime. Trying to extend beyond this regime leads to fragile systems and development hell.</li>
<li>Innumerable little rules and one-off corner cases, piercing through the network like so many porcupine spikes. This is the “unreasonable effectiveness of data” regime. Essentially all unstructured environments like speech, language, and vision are here.</li>
</ul>
</section>
<section id="but-why-the-hype" class="level3">
<h3 class="anchored" data-anchor-id="but-why-the-hype">But why the hype?</h3>
<p>In our perspective, expert systems seem like boring database and Java programming, and it is hard to imagine people getting hyped about databases or Java, so we tend to imagine the computer scientists promising some miracle technology they could not deliver. But it seems to me that, while they did overestimate what their technologies could deliver, the technologies themselves worked exactly as specified – databases, logical inference, and object-oriented programming!</p>
<p>So the problem now becomes: How could people have been hyped about such boring things?</p>
<p>Although computer scientists had long known that computers could perform symbolic and logical reasoning, in the 1980s, it was a genuine revelation to people outside.</p>
<blockquote class="blockquote">
<p>There is a certain inevitability to knowledge engineering and its applications. The cost of the computers will fall drastically during the coming two decades. As it does, many more of the practitioners of the world’s professions will be persuaded to turn to economical automatic information processing for assistance in managing the increasing complexity of their daily tasks. They will find, in most of computer science, help only for those of their problems that have a mathematical or statistical core, or are of a routine data-processing nature. But such problems will be rare, except in engineering and physical science. In medicine, biology, management – indeed in most of the world’s work – the daily tasks are those requiring symbolic reasoning with detailed professional knowledge. The computers that will act as “intelligent assistants” for these professionals must be-endowed with such reasoning capabilities and knowledge.</p>
<p><span class="citation" data-cites="feigenbaumKnowledgeEngineeringApplied1984">(<a href="#ref-feigenbaumKnowledgeEngineeringApplied1984" role="doc-biblioref">E. A. Feigenbaum 1984</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>even high-ranking computing executives. Many did not believe that computers could be programmed to reason and to reach uncertain conclusions. They were so familiar with lock-step algorithms that always reached the correct answer that anything less than certainty simply did not seem like real computing. In a similar way, AI languages like LISP and Prolog were nearly incomprehensible to those who had always imagined that Fortran and COBOL pretty much-defined software development. The excitement about AI and expert systems was almost as if experienced computer professionals were being asked to go back to college and learn computer science all over again.</p>
<p><span class="citation" data-cites="harmonExpertSystemsBusiness2022">(<a href="#ref-harmonExpertSystemsBusiness2022" role="doc-biblioref">Harmon 2022</a>)</span></p>
</blockquote>
<p>And while the grandest dreams of expert system AI did not pan out, it still offered incremental profit of a few million dollars at a time. The pieces that worked quickly became too boring to mention, and the pieces that didn’t work got forgotten, or returned to academia, where ideas hope for their eventual justification.</p>
<p>Except the thing called “Cyc”.</p>
</section>
</section>
<section id="sec-cyc" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-cyc">Cyc</h2>
<blockquote class="blockquote">
<p>He divided the universe in forty categories or classes, these being further subdivided into differences, which was then subdivided into species. He assigned to each class a monosyllable of two letters; to each difference, a consonant; to each species, a vowel. For example: <code>de</code>, which means an element; <code>deb</code>, the first of the elements, fire; <code>deba</code>, a part of the element fire, a flame. In a similar language invented by Letellier (1850) <code>a</code> means animal; <code>ab</code>, mammal; <code>abo</code>, carnivore; <code>aboj</code>, feline; <code>aboje</code>, cat; <code>abi</code>, herbivore; <code>abiv</code>, horse; etc… children would be able to learn this language without knowing it be artificial; afterwards, at school, they would discover it being an universal code and a secret encyclopaedia.</p>
<p>Once we have defined Wilkins’ procedure, it is time to examine a problem which could be impossible or at least difficult to postpone: the value of this four-level table which is the base of the language. Let us consider the eighth category, the category of stones. Wilkins divides them into common (silica, gravel, schist), modics (marble, amber, coral), precious (pearl, opal), transparent (amethyst, sapphire) and insolubles (chalk, arsenic). Almost as surprising as the eighth, is the ninth category. This one reveals to us that metals can be imperfect (cinnabar, mercury), artificial (bronze, brass), recremental (filings, rust) and natural (gold, tin, copper). Beauty belongs to the sixteenth category; it is a living brood fish, an oblong one.</p>
<p>— Borges, <em>The analytical language of John Wilkins</em></p>
</blockquote>
<p>Many years later, surrounded by the humming servers of the Cyc database, Douglas Lenat was to remember that distant afternoon when he first conceived of encoding all of common sense.</p>
<section id="am" class="level3">
<h3 class="anchored" data-anchor-id="am">AM</h3>
<p>Why AM and Eurisko Appear to Work</p>
<p>The Nature of Heuristics</p>
</section>
<section id="eurisko" class="level3">
<h3 class="anchored" data-anchor-id="eurisko">EURISKO</h3>
<p>AI alignment people often tell the legend of EURISKO, a program that discovered loopholes in a sci-fi ship-building tournament, allowing its creator to win two years in a row.</p>
<blockquote class="blockquote">
<p>AI has for many years understood enough about representation and inference to tackle this project, but no one has sat down and done it… only by pulling together the latest human interface tools, Lisp machines, ideas of enforced semantics, and funding for a decade-long effort could we attempt a project of this scale. <span class="citation" data-cites="lenatCycUsingCommon1985">(<a href="#ref-lenatCycUsingCommon1985" role="doc-biblioref">D. B. Lenat, Prakash, and Shepherd 1985</a>)</span></p>
</blockquote>
</section>
<section id="cyc" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cyc">Cyc</h3>
<p>In 1984, <a href="https://en.wikipedia.org/wiki/Douglas_Lenat">Douglas Lenat</a> began the Cyc project, an ambitious attempt to scale symbolic AI up to the real world. Like most expert systems, the Cyc project consists of a giant knowledge base encoded in a LISP-like symbolic logic language, upon which inference engines can be run to produce logical reasoning. Unlike most expert systems, the ambition of Cyc was universal: Its knowledge base would not be restricted to expert knowledge in a particular domain, but <em>all</em> commonsense knowledge in <em>all</em> domains that humans have commonsense about.</p>
<p>Even from the vantage point of 1985, it was clear to all that there was a lot of commonsense to code in, although few could have predicted that Lenat would persevere at it for over 30 years.</p>
<p>They themselves underestimated the difficulty. In 1990, they confidently titled a paper “Cyc: A midterm report” <span class="citation" data-cites="lenatCycMidtermReport1990">(<a href="#ref-lenatCycMidtermReport1990" role="doc-biblioref">D. Lenat and Guha 1990</a>)</span>, suggesting that they expected to be done around 1995.</p>
<p>The progress report in 1995 stated that, while the system is far from done, they have at least manually entered <span class="math inline">\(10^5\)</span> “general concepts” and <span class="math inline">\(10^6\)</span> “commonsense axioms” into Cyc, at the price of 100 person-years. <span class="citation" data-cites="lenatCycLargescaleInvestment1995">(<a href="#ref-lenatCycLargescaleInvestment1995" role="doc-biblioref">D. B. Lenat 1995</a>)</span></p>
<blockquote class="blockquote">
<p>Moreover, statistics, colocation, and frequency do not resolve such questions. But the task goes from impossible to trivial if one already knows a few things about boxes and pens, police and demonstrators, and water and teakettles. The same sort of chicken-and-egg relationship characterizes CYC and ML because learning occurs at the fringe of what one already knows. Therefore, in the early 1980s, when the rest of the world was so enthusiastic about Natural Language Understanding, Machine Learning, and AI in general, we were pessimistic. We concluded the only way out of this codependency would be to prime the pump by manually crafting a million axioms covering an appreciable fraction of the required knowledge. That knowledge would serve as a critical mass, enabling further knowledge collection through NLU and ML, beginning in the mid-1990s. Mary Shepherd and I embarked on that task in 1984, knowing we had little chance of success, but seeing no alternative but to try… we are now moving toward the transition point where NLU and ML are supported. The rest of the world is disillusioned and pessimistic about symbolic AI, but ironically, as CYC reaches closure, our hopes for NLU and ML in the next 10 years are very high.</p>
<p><span class="citation" data-cites="lenatCycLargescaleInvestment1995">(<a href="#ref-lenatCycLargescaleInvestment1995" role="doc-biblioref">D. B. Lenat 1995</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>… give CYC enough knowledge by the late 1990s to enable it to learn more by means of natural language conversations and reading. Soon thereafter, say by 2001, we planned to have it learning on its own, by automated-discovery methods guided by models or minitheories of the real world. To a large extent, that’s just what we did. At the end of 1994, the CYC program was mature enough to spin off from MCC as a new company – Cycorp – to commercialize the technology and begin its widespread deployment.</p>
<p><span class="citation" data-cites="lenat20012001Common2001">(<a href="#ref-lenat20012001Common2001" role="doc-biblioref">D. B. Lenat 2001</a>)</span></p>
</blockquote>
<p>In 2016, Lenat finally declared the Cyc project “done” and set about commercializing it.</p>
<blockquote class="blockquote">
<p>Having spent the past 31 years memorizing an astonishing collection of general knowledge, the artificial-intelligence engine created by Doug Lenat is finally ready to go to work… most of what is left to be added is relevant to a specific area of expertise, such as finance or oncology.</p>
<p>Among other projects, the company is developing a personal assistant equipped with Cyc’s general knowledge. This could perhaps lead to something similar to Siri… the CEO of Lucid says the new company is in talks with various others interested in using the Cyc knowledge base. Lucid has been working with the Cleveland Clinic, for example, to help automate the process of finding patients for clinical studies.</p>
<p><span class="citation" data-cites="knightAI30Years2016">(<a href="#ref-knightAI30Years2016" role="doc-biblioref">Knight 2016</a>)</span></p>
</blockquote>
<p>That was essentially the last we heard from Cyc.</p>
<p>When looking at this figure from 1985, one is simultaneously filled with respect and sadness, for they were facing impossible odds, and yet they charged right into it.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/cyc_project_ontology.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="lenatCycUsingCommon1985">(<a href="#ref-lenatCycUsingCommon1985" role="doc-biblioref">D. B. Lenat, Prakash, and Shepherd 1985, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>Their “midterm report” only accentuates this sense of tragedy, of seeing them fighting impossible odds, and losing. They saw with clarity that there is no shortcut to intelligence, no “Maxwell’s equations of thought”.</p>
<blockquote class="blockquote">
<p>The majority of work in knowledge representation has dealt with the technicalities of relating predicate calculus to other formalisms and with the details of various schemes for default reasoning. There has almost been an aversion to addressing the problems that arise in actually representing large bodies of knowledge with content. However, deep, important issues must be addressed if we are to ever have a large intelligent knowledge-based program: What ontological categories would make up an adequate set for carving up the universe? How are they related? What are the important facts and heuristics most humans today know about solid objects? And so on. In short, we must bite the bullet.</p>
<p>We don’t believe there is any shortcut to being intelligent, any yet-to-be-discovered Maxwell’s equations of thought, any AI Risc architecture that will yield vast amounts of problem-solving power. Although issues such as architecture are important, no powerful formalism can obviate the need for a lot of knowledge.</p>
<p>By knowledge, we don’t just mean dry, almanac-like or highly domain-specific facts. Rather, most of what we need to know to get by in the real world is prescientific (knowledge that is too commonsensical to be included in reference books; for example, animals live for a single solid interval of time, nothing can be in two places at once, animals don’t like pain), dynamic (scripts and rules of thumb for solving problems) and metaknowledge (how to fill in gaps in the knowledge base, how to keep it organized, how to monitor and switch among problem-solving methods, and so on). Perhaps the hardest truth to face, one that AI has been trying to wriggle out of for 34 years, is that there is probably no elegant, effortless way to obtain this immense knowledge base. Rather, the bulk of the effort must (at least initially) be manual entry of assertion after assertion. <span class="citation" data-cites="lenatCycMidtermReport1990">(<a href="#ref-lenatCycMidtermReport1990" role="doc-biblioref">D. Lenat and Guha 1990</a>)</span></p>
</blockquote>
</section>
</section>
<section id="robots" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="robots">Robots</h2>
<section id="eliza" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="eliza">ELIZA</h3>
<blockquote class="blockquote">
<p>Science promised man power. But as so often happens when people are seduced by promises of power … the price actually paid is servitude and impotence.</p>
<p>– the book jacket to <span class="citation" data-cites="weizenbaumComputerPowerHuman1976">(<a href="#ref-weizenbaumComputerPowerHuman1976" role="doc-biblioref">Weizenbaum 1976</a>)</span></p>
</blockquote>
<p>ELIZA is well-known as the first popular chatbot. Fortunately, unlike the others like EPAM or SHRDLU, ELIZA is so famous that it is available everywhere. We will simply describe how ELIZA works. The detailed code and further information is online at <a href="https://sites.google.com/view/elizagen-org/">ELIZAGEN</a>.</p>
<p>According to the original paper <span class="citation" data-cites="weizenbaumELIZAComputerProgram1966">(<a href="#ref-weizenbaumELIZAComputerProgram1966" role="doc-biblioref">Weizenbaum 1966</a>)</span>, ELIZA is essentially a word substitution program of minimal content, roleplaying as a Rogerian therapist. This role was chosen because a psychotherapist is one of the few roles that can pretend to know nothing about the world.</p>
<blockquote class="blockquote">
<p>If, for example, one were to tell a psychiatrist “I went for a long boat ride” and he responded “Tell me about boats”, one would not assume that he knew nothing about boats, but that he had some purpose in so directing the subsequent conversation.</p>
<p><span class="citation" data-cites="weizenbaumELIZAComputerProgram1966">(<a href="#ref-weizenbaumELIZAComputerProgram1966" role="doc-biblioref">Weizenbaum 1966</a>)</span></p>
</blockquote>
<p>ELIZA is programmable: It reads in an “ELIZA script” (a dialect of LISP) that looks like</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode lisp code-with-copy"><code class="sourceCode commonlisp"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>(SORRY ((<span class="dv">0</span>) (PLEASE DON<span class="dt">'T</span> APOLOGIZE)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>            (APOLOGIES ARE NOT NECESSARY)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>            (WHAT FEELINGS DO YOU HAVE WHEN YOU APOLOGIZE)))</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>(EVERYONE <span class="dv">2</span> ((<span class="dv">0</span> (<span class="op">*</span> EVERYONE EVERYBOOY NOBODY NOONE) <span class="dv">0</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>             (REALLY, <span class="dv">2</span>) (SURELY NOT <span class="dv">2</span>) </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>             (CAN YOU THINK OF ANYONE IN PARTICULAR) (WHO, FOR EXAMPLE)))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>(EVERYBODY <span class="dv">2</span> (<span class="op">=</span> EVERYONE))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>(NOBOOY <span class="dv">2</span> (<span class="op">=</span> EVERYONE))</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>(NOONE <span class="dv">2</span> (<span class="op">=</span> EVERYONE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This snippet shows several features of the ELIZA script. A script is a list of rules. Each rule begins with a keyword like <code>SORRY</code>, followed by an optional rank, which determines how early the rule applies. A higher-ranked rule would beat out a lower-ranked rule. If there is no rank, then whatever appears first in the script applies. After that, there is a list of rewrite rules, which were essentially the same as regex expressions. For example, <code>(0 (* EVERYONE EVERYBOOY NOBODY NOONE) 0)</code> would, in regex expression, be <code>(.*) (EVERYONE|EVERYBODY|NOBODY|NOONE) (.*)</code>, and the rewrite rule <code>(REALLY, 2)</code> then corresponds to <code>REALLY $2</code>.</p>
<p>Indeed, once we see this, we can write a short ELIZA in python:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>rules <span class="op">=</span> {</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"everyone"</span>: {</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rank"</span>: <span class="dv">2</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"decomposition"</span>: <span class="vs">r"(.*) (everyone|everybody|nobody|noone) (.*)"</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"reassembly"</span>: [<span class="st">"Really $2?"</span>, <span class="st">"Surely not $2?"</span>, <span class="st">"Can you think of anyone in particular?"</span>]</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"i am"</span>: {</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>         <span class="st">"rank"</span> : <span class="dv">1</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>         <span class="st">"decomposition"</span>: <span class="vs">r"(.*) i am (.*)"</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>         <span class="st">"reassembly"</span>: [<span class="st">"How long have you been $2?"</span>, <span class="st">"Do you believe you are $2?"</span>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"sorry"</span>: {</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rank"</span>: <span class="dv">0</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"decomposition"</span>: <span class="vs">r"(.*) sorry (.*)"</span>,</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"reassembly"</span>: [<span class="st">"Please don't apologize."</span>, <span class="st">"Apologies are not necessary."</span>]</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eliza_response(user_input):</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    user_input <span class="op">=</span> user_input.lower()</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    matched_rules <span class="op">=</span> []</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> keyword, rule <span class="kw">in</span> rules.items():</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        match <span class="op">=</span> re.match(rule[<span class="st">"decomposition"</span>], user_input)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> match:</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>            matched_rules.append(</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>               (rule[<span class="st">"rank"</span>], match, rule[<span class="st">"reassembly"</span>])</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> matched_rules:</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply precedence, fallback to first match if ranks are equal</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>        matched_rules.sort(reverse<span class="op">=</span><span class="va">True</span>, key <span class="op">=</span> <span class="kw">lambda</span> x : x[<span class="dv">0</span>])</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>        _, match, reassembly_options <span class="op">=</span> matched_rules[<span class="dv">0</span>]</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> reassembly_options[<span class="dv">0</span>]</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> response</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"I am not sure I understand you fully."</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    user_input <span class="op">=</span> <span class="bu">input</span>(<span class="st">"You: "</span>)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> user_input.lower() <span class="op">==</span> <span class="st">"quit"</span>:</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> eliza_response(user_input)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"&gt; "</span> <span class="op">+</span> response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The full ELIZA also has a single MEMORY keyword which allows it to refer to what the user has said previously, though the core idea is there: it is regex parsing and rewriting.</p>
<p>ELIZA was designed to be extensible, and extensions had been used by writing other ELIZA scripts. In the language of expert systems, ELIZA is a shell which can use the scripts as knowledge bases. See <a href="https://sites.google.com/view/elizagen-org/resources">ELIZAGEN</a> for some references to using ELIZA in education, such as for teaching poetry and the 4-vector. <span class="citation" data-cites="taylorAutomatedTutoringIts1968">(<a href="#ref-taylorAutomatedTutoringIts1968" role="doc-biblioref">Taylor 1968</a>)</span></p>
<p>Weizenbaum was dismayed to find that people treated ELIZA as if it understood what they said, and became increasly concerned with AI and started arguing against it in various ways. To us, the most interesting critique is that he rejected the philosophical position behind the Turing test, that to simulate understanding is to understand. After all, ELIZA knew nothing at all, yet people treated it as if it understood a lot. He pointed to Chomsky’s work as a good example of theory-guided AI science, contrasted with the “it seems to work” AI performance. In Chomsky’s terms, it is the contrast between <em>competence</em> and <em>performance</em>.</p>
<blockquote class="blockquote">
<p>After all, a plain typowriter in some sense mirrors the behavior of tic child (one types a question and gets no response whatever), but it does not help us to understand autism. A model must be made to stand or fall on the basis of its theory… The failure to make distinctions between descriptions, even those that “work,” and theories accounts in large part for the fact that those who refuse to accept the view of man as machine have been put on the defensive.</p>
<p>Recent advances in computer understanding of natural language offer an excellent case in point. Halle and Chomsky, to mention only the two with whom I am most familiar, have long labored on a theory of language which any model of language behavior must satisfy. Their aim is like that of the physicist who writes a set of differential equations that anyone riding a bicycle must satisfy. No physicist claims that a person need know, let alone be able to solve, such differential equations in order to become a competent cyclist. Neither do Halle and Chomsky claim that humans know or knowingly obey the rules they believe to govern language behavior. Halle and Chomsky also strive, as do physical theorists, to identify the constants and parameters of their theories with components of reality. Workers in computer comprehension of natural language operate in what is usually called performance mode. It is as if they are building machines that can ride bicycles by following heuristics like “if you feel a displacement to the left, move your weight to the left.”</p>
<p><span class="citation" data-cites="weizenbaumImpactComputerSociety1972">(<a href="#ref-weizenbaumImpactComputerSociety1972" role="doc-biblioref">Weizenbaum 1972</a>)</span></p>
</blockquote>
<p>So far, this is fairly standard critique of a performance-over-competence culture in AI. However, Weizenbaum was driven by a moral urgency as he looked into the deeper source for this mistake, and finding a moral-philosophical error:</p>
<ol type="1">
<li>There are multiple categories of things.</li>
<li>Humans (and perhaps sufficiently human-like objects, like chimpanzees) are the only category where morality makes sense.</li>
<li>If <span class="math inline">\(x\)</span> is an object in the human-like category, then asking “Is <span class="math inline">\(x\)</span> a meat machine?” is a category error, of treating objects in the human category as if they are objects in the technological category. The right answer is to reject this “technological question” and ask a “human question” instead, like “What is wrong with you to ask such a question?”.</li>
</ol>
<p>He was particularly incensed by Kenneth Colby’s DOCTOR program, which was similar to ELIZA, except intended for production. Colby was a psychiatrist who saw the plight of patients who saw therapists maybe once a month – if lucky. He argued that if an artificial DOCTOR could provide some help, it is better than nothing, and some people agreed.</p>
<blockquote class="blockquote">
<p>How is Al bad? Are we hurting people by doing it? I don’t know anyone who has suffered from it yet. (In fact, despite Weizenbaum’s arguments about Colby and automated psychotherapy, I remember a non-speaking adult and several autistic children who began to talk because they were talking to Colby’s non-threatening machine.)</p>
<p><span class="citation" data-cites="schankWeizenbaumControversy1976">(<a href="#ref-schankWeizenbaumControversy1976" role="doc-biblioref">Schank 1976</a>)</span></p>
</blockquote>
<p>To Weizenbaum, this is dehumanizing and disrespectful, a moral error, and whether it actually helps patients improve – as measured by quantitative evidence like whether non-verbal people started speaking again – is irrelevant. Thinking that it is a relevant question just shows confusion of the performance of therapy with the competence of therapy, and a deeply technological mentality:</p>
<blockquote class="blockquote">
<p>The question “Is the brain merely a meat machine?”, which Simon puts in a so much more sophisticated form, is typical of the kind of question formulated by, indeed formulatable only by, a technological mentality. Once it is accepted as legitimate, arguments as to what a computer can or cannot do “in principle” begin to rage and themselves become legitimate. But the legitimacy of the technological question – for example, is human behavior to be understood either in terms of the organization or of the physical properties of “components” - -need not be admitted in the first instance. A human question can be asked instead. Indeed, we might begin by asking what has already become of “the whole man” when he can conceive of computers organized in his own image… Whoever dictates the questions in large part determines the answers. In that sense, technology, and especially computer technology, has become a self-fulfilling nightmare… We must come to see that technology is our dream and that we must ultimately decide how it is to end.</p>
<p><span class="citation" data-cites="weizenbaumImpactComputerSociety1972">(<a href="#ref-weizenbaumImpactComputerSociety1972" role="doc-biblioref">Weizenbaum 1972</a>)</span></p>
</blockquote>
<p>He presented his full thesis in a book <em>Computer Power and Human Reason: From Judgment to Calculation</em> (1976), with the following theses:</p>
<ol type="1">
<li>Computers might be intelligent, but they will never be wise (or to feel emotions, to love, etc). To “calculate” requires just intelligence, but to “judge” requires wisdom.</li>
<li>The development of AI threatens to replace judgment with calculation, which will destroy human dignity. This replacement of judgment with calculation is an absurd political ideology, and must be resisted politically.</li>
<li>If, however, we do not resist, but keep following this political ideology, we would end up with the obviously absurd conclusion that “the brain is merely a meat machine”. <em>Reductio ad absurdum</em>.</li>
<li>This dangerous development of AI did not come from a wise scientific project of understanding how human intelligence works, but from a megalomaniac, obsessive-compulsive desire to make machine parodies of human behavior. The method of AI development was heuristic, empirical, a kind of “I wonder what the machine would do if I write this program…”, without a scientific theory.</li>
</ol>
<p>When the book came out, it received many reviews and counter-reviews, resulting in a “Weizenbaum controversy”. I found this reply by Weizenbaum the funniest:</p>
<blockquote class="blockquote">
<p>I have in mind also the teaching urged on us by some leaders of the AI community that there is nothing unique about the human species, that in fact, the embrace of the illusion of human uniqueness amounts to a kind of species prejudice and is unworthy of enlightened intellectuals. If we find nothing abhorrent in the use of artificially sustained, disembodied animal brains as computer components, and if there is nothing that uniquely distinguishes the human species from animal species, then – need I spell out where that idea leads?</p>
<p>quoted in <span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 370</a>)</span></p>
</blockquote>
<p>Apparently Weizenbaum, in his human-centered wisdom, rejected Darwinism as well. In any case, his critiques seem perennial,<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a> though irrelevant for the further evolution of technology, which is exactly the techno-drenched nightmare he was trying to warn us away from, to no effect. We sleepwalk yet deeper into this nightmare.</p>
<div class="no-row-height column-margin column-container"><div id="fn21"><p><sup>21</sup>&nbsp;Witness some modern critiques of AI, especially from the Critical Humanities. Though a few critical humanists really were critical <em>of</em> humanity, which brings the amusing prospect of <em>another</em> nightmare of Weizenbaum, this time from the opposite direcion of “We must come to see that humanity is our dream and that we must ultimately decide how it is to end.”</p>
<blockquote class="blockquote">
<p>As the archaeology of our thought easily shows, man is an invention of recent date. And one perhaps nearing its end. If those arrangements were to disappear as they appeared, if some event of which we can at the moment do no more than sense the possibility – without knowing either what its form will be or what it promises – were to cause them to crumble, as the ground of Classical thought did, at the end of the eighteenth century, then one can certainly wager that man would be erased, like a face drawn in sand at the edge of the sea.</p>
<p><span class="citation" data-cites="foucaultOrderThings2012">(<a href="#ref-foucaultOrderThings2012" role="doc-biblioref">Foucault 2012, 422</a>)</span></p>
</blockquote>
</div></div></section>
<section id="sec-shrdlu" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-shrdlu">SHRDLU</h3>
<p>During the early days, the only robots were “<a href="https://en.wikipedia.org/wiki/Unimate">Unimates</a>”, arms blindly performing preprogrammed motions, but there had always been the dream and hope of a robot that can see and act, wih proper hand-eye coordination. Perhaps even to speak.</p>
<p>By writing the famous SHRDLU, Terry Winograd took a small step towards this dream for his PhD in mathematics during 1968–1970, and published it in a long journal article <span class="citation" data-cites="winogradUnderstandingNaturalLanguage1972">(<a href="#ref-winogradUnderstandingNaturalLanguage1972" role="doc-biblioref">Winograd 1972</a>)</span>. Again like ELIZA, it is better played than explained, so please play with it now. In the program, the user carries on a conversation with the computer, moving objects, naming collections and querying the state of a simplified “blocks world”, essentially a virtual box filled with different blocks. It totaled ~500 KB of LISP code. I have saved the <a href="code/SHRDLU.zip">original code</a> for safe-keeping.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn22"><p><sup>22</sup>&nbsp;I really don’t recommend reading it. Though it was in a dialect of LISP, it was written in the impenetrable style of assembly code. I will just write some amusing discoveries in the code base:</p>
<blockquote class="blockquote">
<p>it occupies around 200k of core (caution: indiscriminately running a job that big in the middle of the day is a good way to make enemies!!!!! Alway check the level of system usage before loading…)</p>
<p>– <code>mannew</code> from the SHRDLU archive</p>
</blockquote>
<p>The original SHRDLU had some manual fixes in the compiled assembly code (!). Terry Winograd’s first research student rewrote much of SHRDLU so that it is portable. Some people sent letters (physical letters!) to request the code, and they would duly mail it out (by magnetic tape?). As one can imagine, only a few dozen source codes were mailed out, according to <a href="https://web.archive.org/web/20171117063022/http://www.semaphorecorp.com/misc/shrdlu.html">SHRDLU resurrection</a> (created in 2002, and last updated on 2013-08-22).</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/SHRDLU.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The result of typing “Will you please stack up both of the red blocks and either a green cube or a pyramid?” <span class="citation" data-cites="winogradUnderstandingNaturalLanguage1972">(<a href="#ref-winogradUnderstandingNaturalLanguage1972" role="doc-biblioref">Winograd 1972, fig. 5</a>)</span></figcaption>
</figure>
</div>
<p>The main part of SHRDLU has the following parts:</p>
<ul>
<li>A natural language understanding (NLU) module, which uses <code>DICTIONARY</code>, <code>GRAMMAR</code>, <code>SEMANTICS</code>, and so on, to parse user input into a logical expression.</li>
<li><code>PLANNER</code>, which takes the state of the world (as a logical expression) and the user input (as another logical expression), and compute a motion plan for the simulated arm.</li>
<li><code>MOVER</code>, which simulates a robot arm. It has only three kinds of commands: <code>MOVETO</code>, <code>GRASP</code>, <code>UNGRASP</code>.</li>
<li>Blocks world simulator.</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/SHRDLU_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Architecture of SHRDLU. The NLU module takes up most of the region on the right.<span class="citation" data-cites="winogradUnderstandingNaturalLanguage1972">(<a href="#ref-winogradUnderstandingNaturalLanguage1972" role="doc-biblioref">Winograd 1972, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>The key parts of the system are the NLU and the <code>PLANNER</code>.</p>
<p>The <code>PLANNER</code>, just like the GPS of Simon and Newell, starts with the goal as the root node, and searches for a chain of logical operations that would eventually lead to a leaf node equal to the current state of the world.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a> This was called “backward chaining”, though it was the same as the means-end analysis of GPS. It then stores this chain of logical operations, and converts it into a sequence of <code>MOVER</code> commands and sends them to <code>MOVER</code>. When asked “Why did you do it?”, it would convert this plan into an explanation in English.</p>
<div class="no-row-height column-margin column-container"><div id="fn23"><p><sup>23</sup>&nbsp;For a detailed exposition of how SHRDLU-like AI systems perform planning by symbolic logic, see <span class="citation" data-cites="russellArtificialIntelligenceModern2021">(<a href="#ref-russellArtificialIntelligenceModern2021" role="doc-biblioref">Russell and Norvig 2021, chap. 11.2</a>)</span>.</p></div></div><p>The NLU module parses the sentence into a tree by “systemic grammar” which while different from Chomskyan generative grammar in details, is the same in spirit.</p>
<p>For example, “Harry slept on the porch after he gave Alice the jewels.” is parsed to:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode lisp code-with-copy"><code class="sourceCode commonlisp"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>(#SLEEP :HARRY :RELl)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>(#LOCATION :REL1 :PORCH)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>(#GIVE :HARRY :ALICE :JEWELS :REL2)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>(#AFTER :REL1 :REL2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Instead of analyzing syntax and semantics independently, SHRDLU combines them closely to determine the correct parse of a sentence. For example, a user input “Pick up the red cube.” would only be parsed correctly if SHRDLU actually checks the state of the world that there really is exactly one <code>(#SHAPE :CUBE :REL1) (#COLOR :RED :REL1)</code>. If there are two, it would then reply “I don’t know which one you meant.” and if there are none, it would reply “I can’t pick up a nonexistent object.”.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/blocks_world_logic.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A blocks world much simpler than the one used by SHRDLU, along with its logical representation. Combination of <span class="citation" data-cites="russellArtificialIntelligenceModern2021">(<a href="#ref-russellArtificialIntelligenceModern2021" role="doc-biblioref">Russell and Norvig 2021, fig. 11.3</a>)</span> and <span class="citation" data-cites="russellArtificialIntelligenceModern2021">(<a href="#ref-russellArtificialIntelligenceModern2021" role="doc-biblioref">Russell and Norvig 2021, fig. 11.4</a>)</span>.</figcaption>
</figure>
</div>
<p>SHRDLU was a milestone, and perhaps it was too good to be true. Like the Georgetown–IBM demo, it attracted and impressed, but led to inevitable disappointment when the success failed to scale up. Why was there a hype in the first place, though?</p>
<p>In 1991, as the expert systems hype was dying down, Schank wrote an essay trying to diagnose the source of the hype. One source, he argued, was the focus on designing a good theoretical framework that is verified on small scale demos and “microworlds”, and expect it to simply scale up.</p>
<blockquote class="blockquote">
<p>Nevertheless, there were otherwise intelligent people claiming that Winograd’s (1972) SHRDLU program that worked on 31 examples had solved the natural language problem or that MYCIN (Shortliffe 1976) had solved the problem of getting expertise into a computer. Prior to 1982, it is safe to say that no one had really tried to build an AI program that was more than simply suggestive of what could be built. AI had a real definition then, and it was the gee whiz definition given earlier.</p>
<p><span class="citation" data-cites="schankWheresAI1991">(<a href="#ref-schankWheresAI1991" role="doc-biblioref">Schank 1991</a>)</span></p>
</blockquote>
<p>Winograd in an interview shortly afterwards concurred:</p>
<blockquote class="blockquote">
<p>WINOGRAD: Well, implementation and product are two stages. That is, implementation was always there as the coin of the realm. Implementation meant something you could show off. It didn’t mean something that somebody else could use… there was no attempt to get it to the point where you could actually hand it to somebody and they could use it to move blocks around… Pressure was for something you could demo… I think AI suffered from that a lot, because it led to “Potemkin villages”, things which – for the things they actually did in the demo looked good, but when you looked behind that there wasn’t enough structure to make it really work more generally.</p>
<p>NORBERG: Is that a question of size, or is it a question of the idea itself - the idea’s too small?</p>
<p>WINOGRAD: The idea of –?</p>
<p>NORBERG: Well, let’s say the ideas behind the blocks world, SHRDLU.</p>
<p>WINOGRAD: Well, I think it was based on a presupposition – at least an attitude – that making things work in the large, really working, was just like getting a demo except more details to be filled in. That is, if you had a basic idea and you could show it worked on something then it was just a sort of grubby, detail work to fill in all, you know, the hundreds of entries you would need to make it work for real. But that – an idea – and this is tied to the top-down, rationalistic way of approaching it, right. An idea which said, “here’s a nice logical way this should work – would work in practice if you just went far enough with the details.” And I think that’s been a problem with AI all along. It’s true in problem-solving, right? Problem-solving, as conceived by Newell and Simon and developed, and so on, has a certain realm of applicability but it’s very different from, you know, you coming to me and saying, “I have a problem. Would you help me solve it?”, in terms of – to take the most obvious things - the hard part is figuring out what the problem space is, not searching it.</p>
<p><a href="https://conservancy.umn.edu/server/api/core/bitstreams/a0a8ffa6-0149-4606-88e8-4eec0690d794/content#page=7">An Interview with Terry Allen Winograd (1991-12-11)</a></p>
</blockquote>
<p>Philosophically, it seems like the rational methodology of theoretical physics: One has a good theory, which can be checked in a precise experiment in a vacuum. If the observation is as predicted, then one assumes it would simply scale up. Similarly, if a theory, such as neural networks, cannot perform something as simple as testing for connectivity (as <a href="https://yuxi-liu-wired.github.io/essays/posts/reading-perceptron-book/index.html#chapter-13">Minsky and Papert argued</a>), then that theory is disproven. In this case, systemic grammar was the linguistic theory to be tested, and the blocks world of SHRDLU constituted a laboratory proof. That it never scaled up was a shame, but not something people expected back then.</p>
<p>This focus on toy models, “microworlds”, and proofs of concepts, was prevalent, and indeed the best way to obtain knowledge, if one accepts the rational methodology.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/minsky_robot_arm_blocks.jpg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Marvin Minsky and Builder the robot in a physical blocks world, which could use a camera to detect the shape of blocks in one pile, and replicate it with blocks in another pile. It was a microworld for studying hand-eye coordination. It’s hard to tell who is having more fun here.</figcaption>
</figure>
</div>
<p>We know better now. The actual trajectory of AI has destroyed faith this methodology, but why? It is still mysterious, and many still argue that we should not accept this.</p>
</section>
<section id="sec-shakey" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-shakey">Shakey</h3>
<p>In 1964-04, the Stanford Research Institute (SRI) submitted a proposal to ARPA to build a robot that could move through a cluttered room using its own cameras, with the unassuming name “Intelligent Automata” so that it did not appear to be a sci-fi project. It was later renamed to “Intelligent Automata to Reconnaissance”.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a> This resulted in Shakey the robot, developed during 1966–1972. Despite the deliberately unassuming name, it had the ambition of integrating all the subfields of AI as then understood into a single package.</p>
<div class="no-row-height column-margin column-container"><div id="fn24"><p><sup>24</sup>&nbsp;Annoyingly, I have checked all the official reports – the interim reports <a href="https://web.archive.org/web/20060316080944/http://www.ai.sri.com/pubs/files/rosen66-p5953-interim1.pdf">1</a>, <a href="https://web.archive.org/web/20060316081210/http://www.ai.sri.com/pubs/files/rosen67-p5953-interim2.pdf">2</a>, <a href="https://web.archive.org/web/20060316081226/http://www.ai.sri.com/pubs/files/rosen67-p5953-interim3.pdf">3</a>, <a href="https://web.archive.org/web/20060316081638/http://www.ai.sri.com/pubs/files/nilsson68-p5953-interim4.pdf">4</a>, and the <a href="https://web.archive.org/web/20060316081339/http://www.ai.sri.com/pubs/files/nilsson68-p5953-final.pdf">final report</a>, and <em>none</em> of them told me what it is supposed to reconnoiter for!</p></div></div><blockquote class="blockquote">
<p>to develop an experimental test bed for integrating all the subfields of artificial intelligence as then understood. SRI wanted to integrate in one system representation and reasoning, planning, machine learning, computer vision, natural language understanding, even speech understanding, for the first time.</p>
<p><span class="citation" data-cites="kuipersShakeyConceptionHistory2017">(<a href="#ref-kuipersShakeyConceptionHistory2017" role="doc-biblioref">Kuipers et al. 2017</a>)</span></p>
</blockquote>
<p>Even before it was finished, it became a celebrity. The <em>Life</em> magazine called Shakey the “first electronic person” <a href="https://gwern.net/doc/reinforcement-learning/robot/1970-darrach.pdf">in 1970</a>.<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> A <a href="https://www.youtube.com/watch?v=GmU7SimFkpU">1972 documentary</a> shows its operations, in which one can see its shaking motion, and how it stops after each straight-line motion. <span class="citation" data-cites="stanfordresearchinstituteShakeyExperimentRobot1972">(<a href="#ref-stanfordresearchinstituteShakeyExperimentRobot1972" role="doc-biblioref">Institute 1972</a>)</span> The shaking is due to the springs in two wheels, and the stopping is to wait for computer vision and planning to finish, and for the shaking to stop. Early during development, it was tethered. A bit later, the tether was removed, and the researchers found it to mysteriously rotate once in a while. It turned out to be a vestigial subroutine meant to untwist the tether. (Peter Hart, at 05:55)</p>
<div class="no-row-height column-margin column-container"><div id="fn25"><p><sup>25</sup>&nbsp;This article was considered sensational and misleading by most of the people who worked on Shakey.</p>
<blockquote class="blockquote">
<p>an article that was more than science fiction: the AI community feels it was victimized in this instance by outright lies. Said Rosen, <em>He came here and all of us spent a great deal of time being very honest and candid with him. Then he didn’t present the whole story. He picked the sensational things and left out the others…</em> Bert Raphael, who had spent a lot of time with Darrach, goes further: <em>…He wrote it as if he’d seen many things he never saw, and wrote about seeing Shakey going down the hall and hurrying from office to office, when in fact all the time he’d been here we were in the process of changing one computer system to another and never demonstrated anything for him. There were many direct quotes that were imaginary or completely out of context.</em></p>
<p><span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 273</a>)</span></p>
</blockquote>
</div></div><div id="fig-shakey" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-shakey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_original.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The original design of Shakey. It had two arms that got cancelled. Dimensions: <code>56''L; 35'' W; 57'' H</code>. <a href="https://www.computerhistory.org/revolution/artificial-intelligence-robotics/13/289/1239">Source</a>.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/SRI_Shakey_with_callouts.jpg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Shakey the robot in 1972. Standing <em>square</em>ly away from the uncanny valley, it is almost cute in its boxy appearance. Just watching it makes me want to make “beep-boop” sound. <a href="https://en.wikipedia.org/wiki/File:SRI_Shakey_with_callouts.jpg">Source</a></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_overview_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Schematic cleaned diagram of Shakey. <span class="citation" data-cites="slocumRobotExcessMachine2024">(<a href="#ref-slocumRobotExcessMachine2024" role="doc-biblioref">Slocum and Yablonina 2024, fig. 9</a>)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_overview_2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Why Shakey shakes: Shakey is moved by two diagonal drive wheels, and the other two diagonal wheels have springs on them to allow Shakey to go up slopes. Whenever it starts and stops, it shakes back and forth across the diagonal. <span class="citation" data-cites="slocumRobotExcessMachine2024">(<a href="#ref-slocumRobotExcessMachine2024" role="doc-biblioref">Slocum and Yablonina 2024, fig. 10</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_predicate_calculus.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="kuipersShakeyConceptionHistory2017">(<a href="#ref-kuipersShakeyConceptionHistory2017" role="doc-biblioref">Kuipers et al. 2017, fig. 4</a>)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_hierarchical_planning.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="kuipersShakeyConceptionHistory2017">(<a href="#ref-kuipersShakeyConceptionHistory2017" role="doc-biblioref">Kuipers et al. 2017, fig. 6</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_path_planning.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Ideally smoothed path (A), planned path (B), and actual shakey path (illustrative only) (C). <span class="citation" data-cites="slocumRobotExcessMachine2024">(<a href="#ref-slocumRobotExcessMachine2024" role="doc-biblioref">Slocum and Yablonina 2024, fig. 11</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-shakey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3
</figcaption>
</figure>
</div>
<p>It was a fine example of logical AI, and several classical algorithms were developed specifically for it, including the A* search for pathfinding on a graph, the Hough transform for its vision; and the visibility graph method specifically for pathfinding in a Euclidean plane with obstacles. Like SHRDLU, it represented the state of the world and the goal state using first-order predicate logic, and planned by logic programming (mostly backward chaining and <a href="https://en.wikipedia.org/wiki/Resolution_(logic)">Robinson resolution</a>). It also understood natural English commands. It had a primitive level of rote learning, in the sense that it memorized previous plans (“macros”), which could then be used as single components in later plans. These all worked and still continue to work.</p>
<p>Shakey also demonstrated the same lesson of expert systems against the generic logical AI approach:</p>
<blockquote class="blockquote">
<p>Shakey showed that you could not, for example, take a graph-searching algorithm from a chess program and hand-printed-character-recognizing algorithm from a vision program and, having attached them together, expect the robot to understand the world. As Raphael put it, there are serious questions about the interaction between knowledge in different domains… the overwhelming message–not always recognized by those doing the robotics work themselves–was that general principles of intelligence were insufficient… there was considerable resistance to that idea. Edward Feigenbaum and his [DENDRAL group] were coming to the same conclusion, but they felt very lonely in that discovery. Joel Moses, whose thesis had relied on expertise instead of general principles, remembers the frustration of trying to expound that point of view. “Papert almost cried once,” Moses remembers. “He said, ‘How can you get those guys to listen?’ That was 1966, maybe 1968.” But the robots seemed to prove the view beyond a shadow of a doubt.</p>
<p><span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 269–76</a>)</span></p>
</blockquote>
<p>But since AI is whatever doesn’t work yet, we will focus on what barely worked: its vision. Shakey’s natural habitat was a toy model of an office space, designed specifically to be as easy to see as possible. If computer vision could not approach the real world, the real world could approach computer vision.</p>
<blockquote class="blockquote">
<p>The project team was well aware of Shakey’s limited mechanical and sensory capabilities, and designed a correspondingly simple experimental environment consisting of half a dozen rooms populated with large, geometric blocks. The blocks were painted so that edges were visible to the low-resolution TV camera, while still being sufficiently reflective for our homemade laser rangefinder to work. We also used dark baseboards, again for visibility, and exploited them to update the position error that accumulated in the dead reckoning process that relied on Shakey’s stepping motors.</p>
<p><span class="citation" data-cites="kuipersShakeyConceptionHistory2017">(<a href="#ref-kuipersShakeyConceptionHistory2017" role="doc-biblioref">Kuipers et al. 2017</a>)</span></p>
</blockquote>
<p>Shakey’s vision system was “scene analysis”. In short, it analyzes a picture as a geometer would expect. It starts by discovering edges, then performs some computational geometry on them to recover outlines of basic shapes, such as cubes, then fills in the faces, then fills in the bodies between the faces. The algorithm had to do something clever to deal with occlusions. In the end, a complete 3D scene populated with 3D objects is recovered.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/guzman_1968.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Scene analysis. Figure from <span class="citation" data-cites="guzmanDecompositionVisualScene1968">(<a href="#ref-guzmanDecompositionVisualScene1968" role="doc-biblioref">Guzmán 1968</a>)</span></figcaption>
</figure>
</div>
<p>After converting a grayscale image to a line drawing, the system uses a “formal grammar” of line drawings (look up “Huffman–Clowes scene labeling”) to identify 4 kinds of objects: wedge, cube, wall, floor. For example, <code>Wedge = TRIANGLE OR TRIANGLE + QUAD</code>, while <code>Cube = QUAD + QUAD + QUAD</code>. The more grammatical rules, the more object classes the system could identify.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Shakey_vision.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The same 4 scenes in: digitized grayscale image, divided into sets of equal grayscale level, merged into regions, converted to line drawings. <span class="citation" data-cites="briceSceneAnalysisUsing1970">(<a href="#ref-briceSceneAnalysisUsing1970" role="doc-biblioref">Brice and Fennema 1970, fig. 7</a>, figure 8, figure 12, figure 14)</span></figcaption>
</figure>
</div>
<p>One might question why they decided to identy only 4 kinds of objects. The reality is that it is simply very difficult to perform scene analysis on anything more complicated. Indeed, in a 1972 PhD thesis, David Waltz extended scene analysis to shadows, and had to catalog “thousands of junctions, in order to deal with cracks and shadows”. [<span class="citation" data-cites="waltzSheddingLightShadows1972">Waltz (<a href="#ref-waltzSheddingLightShadows1972" role="doc-biblioref">1972</a>)</span>, page 48; nilssonQuestArtificialIntelligence2009, page 185]</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Waltz_1972_scene_analysis.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The junction rules used in analyzing a cube with a shadow. <span class="citation" data-cites="waltzSheddingLightShadows1972">(<a href="#ref-waltzSheddingLightShadows1972" role="doc-biblioref">Waltz 1972, 54</a>)</span></figcaption>
</figure>
</div>
<p>Still, since Shakey’s computer ran at just 0.3 MIPS, it was doing its best. As compute improves, the best paradigm changes from the logical approach, to the statistical, to the neural. This was another early instance of the bitter lesson.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/ISUPPOSEW.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A particular example computer vision system <code>ISUPPOSEW</code> (1971) that processes the scene as a list of line segments. I picked this mainly for its aesthetic quality. <span class="citation" data-cites="raphaelResearchApplicationsArtificial1971">(<a href="#ref-raphaelResearchApplicationsArtificial1971" role="doc-biblioref">Raphael et al. 1971, 197</a>)</span></figcaption>
</figure>
</div>
<p>Other than the difficulty of programming (enumerating thousands of rules can’t be fun), it was also very brittle. Moravec reports an early 1977 robot that featurizes camera images taken between two steps in the robot trajectory and compares them to triangulate the scene. It only worked on very clean and uncluttered scenes with sharp images:</p>
<blockquote class="blockquote">
<p>[early 1977] The program would take a picture and choose up to a hundred features. It would then drive the robot forward about a meter, stop, take another picture, and search for the same features in the second image. Then it would invoke the camera solver to find the robot movement and the three-dimensional locations of the features that explained their apparent motion from one image to the other. Despite much fine-tuning, the program’s error rate never dropped below about one wrong motion solution in four, meaning the robot could move about four meters before becoming confused about its position–discouraging. The camera solver repeatedly tweaked an estimate of the robot’s motion to make the features line up as well as possible, and threw away those that seemed too far off… 10–20% of the feature matches were wrong, often because an area chosen in a first image had, in a second image, been eclipsed or changed in appearance by point-of-view or lighting effects or camera noise… It was necessary to track about one hundred features to succeed even three steps in four, consuming several minutes of computer time. Months of fiddling with the program’s mathematics and assumptions made little difference.</p>
<p><span class="citation" data-cites="moravecRobotMereMachine1999">(<a href="#ref-moravecRobotMereMachine1999" role="doc-biblioref">Moravec 1999, 30</a>)</span></p>
</blockquote>
<p>In fact, there was a little bit of faking in the demo movie:</p>
<blockquote class="blockquote">
<p>its most impressive feat – moving a wedge to a block, ascending it, and pushing off a smaller block – was recorded on film piecemeal, requiring multiple takes – and several hours – for each error-prone stage… Shakey’s vision programs, as most others of the time, reduced images to a short list of geometric edges before doing anything else. The approach was quite inappropriate for outdoor scenes containing few simple edges, but many complicated shapes and color patterns.</p>
<p><span class="citation" data-cites="moravecRobotMereMachine1999">(<a href="#ref-moravecRobotMereMachine1999" role="doc-biblioref">Moravec 1999, 26</a> – 28)</span></p>
</blockquote>
<p>In 1973, Duda and Hart from the Shakey team published the famous “Duda and Hart” book on pattern classification <span class="citation" data-cites="dudaPatternClassificationScene1973">(<a href="#ref-dudaPatternClassificationScene1973" role="doc-biblioref">Duda and Hart 1973</a>)</span>. The book contained two halves. The first half was statistical: Bayes, nearest neighbors, perceptron, clustering, etc. The second half was on scene analysis. It is instructive to compare the first edition with the second, published in 2001 <span class="citation" data-cites="dudaPatternClassification2001">(<a href="#ref-dudaPatternClassification2001" role="doc-biblioref">Duda, Hart, and Stork 2001</a>)</span>, almost completely statistical. There were new chapters on neural networks, Boltzmann machines, decision trees, and so on. In contrast, scene analysis was completely removed. It says something about the obsolescence of scene analysis even in 2001, as Duda and Hart deleted half of their most famous book just to avoid talking about it. In fact, the only mention is a condemnation:</p>
<blockquote class="blockquote">
<p>Some of the earliest work on three-dimensional object recognition relied on complex grammars which described the relationships of corners and edges, in block structures such arches and towers. It was found that such systems were very brittle; they failed whenever there were errors in feature extraction, due to occlusion and even minor misspecifications of the model. For the most part, then, grammatical methods have been abandoned for object recognition and scene analysis.</p>
<p><span class="citation" data-cites="dudaPatternClassification2001">(<a href="#ref-dudaPatternClassification2001" role="doc-biblioref">Duda, Hart, and Stork 2001, sec. 8.8</a>)</span></p>
</blockquote>
<p>Concurrent to Shakey, in 1966, some undergraduate students were assigned to constructing “a significant part of a visual system” in a single summer. Of course, it failed at this task, as vision turned out to be the part of AI least amenable to logical approaches.</p>
<p>As of 2007, such logical AI programs for vision had been completely obsoleted by statistical methods:</p>
<blockquote class="blockquote">
<p>one prominent vision researcher told me that the “residue of model-based vision is close to zero”, and another told me that “most current robotic systems use vision hacks” instead of general-purpose, science-based scene-analysis methods.</p>
<p>— <span class="citation" data-cites="nilssonQuestArtificialIntelligence2009">(<a href="#ref-nilssonQuestArtificialIntelligence2009" role="doc-biblioref">Nilsson 2009, 20</a>)</span></p>
</blockquote>
</section>
</section>
<section id="the-fifth-generation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-fifth-generation">The Fifth Generation</h2>
<section id="japan-was-number-one" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="japan-was-number-one">Japan Was Number One</h3>
<blockquote class="blockquote">
<p>Tactically, the attack on Pearl Harbor was one of the most brilliantly executed strokes of the war. But politically, it was most unwise, for America fought back. Today, 40 years after the end of World War II, the Japanese are on the move again in one of history’s most brilliant commercial offensives, as they go about dismantling American industry. Whether they are still only smart, or have finally learned to be wiser than we, will be tested in the next 10 years. Only then will we know who finally won the war 50 years before.</p>
<p><span class="citation" data-cites="whiteDangerJapan1985">(<a href="#ref-whiteDangerJapan1985" role="doc-biblioref">White 1985</a>)</span></p>
</blockquote>
<p>In 1980, the Japanese was ready to take on the world. Despite the devastation of war, Japan quickly emerged as a peer competitor to America, leading to the Japan-panic symbolized by <a href="https://en.wikipedia.org/wiki/Japan_as_Number_One%3A_Lessons_for_America"><em>Japan as Number One</em> (1979)</a>. Cyberpunk stories tell of a neon future with equal mindshare in English and Japanese, where massive zaibatsus battle with conglomerates over the emergent planetary commercium. By GDP, Japan became Number 2 in 1968, and by 1990 it was just 30% smaller than America’s, and it had been growing about 1%/yr more. At this rate, it would have become Number 1 in 2020.</p>
<p>The future is now, and we were robbed of this cyberpunk future. Its GDP reached a high point in 1995, and . Many people gave many reasons, such as the liquidity trap, the demographic crisis, the Plaza Accords, and so on. For our purposes, we just need to know that Japan had been knocked out of the AI game after this.</p>
<p>Like how the American ARPA pushed behind the development of AI and computing, the Japanese <a href="https://en.wikipedia.org/wiki/Ministry_of_International_Trade_and_Industry">MITI</a> had coordinated the development of many industries in Japan, and seeing the rise of expert systems, the time seemed ripe for a coordinated attack on AI. On the back of great optimism, the Fifth Generation Computer System (FGCS) project launched in 1982, led by Kazuhiro Fuchi. Its goals was ambitious to the point of revolutionary, and so was its schedule.</p>
<blockquote class="blockquote">
<p>Even those who adore–the word is not too strong–their unusual director are often dismayed by him. A month after the center formally opened, the hardware committee met with Fuchi and showed him the fast-track two-year plan they’d devised for producing the prototype hardware scheduled for the first three-year phase. Instead of being pleased, Fuchi flew into a rage. That alone is unusual enough among Japanese managers, but what Fuchi wants is even more upsetting: cut that schedule down to a year and a half, he demands. The hardware committee is in shock. They already think themselves reckless in their two-year schedule. Fuchi will have none of it. “We have to manage to do this!” he says angrily. After a little while he calms down. “Go and think it over,” he says more reasonably. “If you absolutely have them. But see if it can’t be done in a year and a half. Loosen up on the quality assurance and give me a real machine in a year and a half.”</p>
<p>…</p>
<p>Everybody knows that Fuchi has irrevocably resigned from his former post at the Electrotechnical Laboratory, a startling step for any Japanese employee, all the more one with such seniority. A high roller, he’s placing all his bets on the Fifth Generation project. The legends add that Fuchi would have been eligible for a comfortable government pension if he’d only waited two or three months to resign his position at ETL, but he spurned anything so trivial as personal financial security to delay his project even by months. This is sensational to the young researchers who have grown up in the lifetime employment system of Japan.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 110–12</a>)</span></p>
</blockquote>
<div id="fig-fgcp-orgchart" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-fgcp-orgchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<div class="quarto-layout-row page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/FGCS_orgchart_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="aisoFifthGenerationComputer1988">(<a href="#ref-aisoFifthGenerationComputer1988" role="doc-biblioref">Aiso 1988, fig. 6</a>)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/FGCS_orgchart_2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 123</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-fgcp-orgchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Overall plan of the FGCS.
</figcaption>
</figure>
</div>
<p>The name “fifth generation” came from the idea of 4 generations of hardware: vacuum tube, transistor, integrated circuits, VLSI. The generation following these would be the fifth, consisting of massively parallel computers natively running logical programs, including logical AI systems. The project had the following parts: parallel logic programming, hardware, and AI.</p>
<p>The project saw the future, and it would be parallel logic programming, for which they decided on a variant of <a href="https://en.wikipedia.org/wiki/Prolog">Prolog</a> that uses “flat guarded Horn clauses”. <span class="citation" data-cites="feigenbaumJapaneseNationalFifth1993">(<a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>)</span> But why did they pick an obscure language, not the famed Lisp?</p>
<blockquote class="blockquote">
<p>“Prolog can be seen as an extension of Lisp.” He says Prolog provides the extra functionality of “pattern matching and non-determinism,” and is “capable of integrating interesting features of other languages such as Smalltalk, PS, and APL.”</p>
<p><span class="citation" data-cites="warrenViewFifthGeneration1982">(<a href="#ref-warrenViewFifthGeneration1982" role="doc-biblioref">Warren 1982</a>)</span></p>
</blockquote>
<p>Vague, but that is as good an explanation as I could find.</p>
<p>In terms of hardware, they planned for parallel computers that runs Prolog operations natively, aiming to eventually reach a target of <span class="math inline">\(10^9 \;\mathrm{LIPS}\)</span> – 1 giga logical inferences per second.<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a> They also aimed for VLSI chips of <span class="math inline">\(10^7\)</span> transistors per chip. Since in 1982, a standard computer could perform Prolog operations at <span class="math inline">\(10^5 \;\mathrm{LIPS}\)</span>, this implied they planned for a doubling time of 9 months. <span class="citation" data-cites="bramerFifthGenerationAnnotated1984">(<a href="#ref-bramerFifthGenerationAnnotated1984" role="doc-biblioref">Bramer 1984, 6</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="fn26"><p><sup>26</sup>&nbsp;A “logical inference” is technically defined as any Prolog procedure call, but can be thought of as any atomic logical operation, such as performing one <em>modus ponens</em>, one variable substitution, etc.</p></div></div><p>They aimed to develop multiple AI systems, each of which would be an expert system written in their version of Prolog. The inference engine would be a standard logic programming system, similar to the planner used in Shakey. The knowledge base was the key. It would be written in a “knowledge-base management software using relational algebra”, which probably meant a <a href="https://en.wikipedia.org/wiki/Relational_database">relational database</a>. They planned that, at the end of the project, they would have the software and the hardware to handle expert systems with <span class="math inline">\(10^4\)</span> rules and <span class="math inline">\(10^4\)</span> objects, with “semi-automated” knowledge acquisition. <span class="citation" data-cites="warrenViewFifthGeneration1982 feigenbaumJapaneseNationalFifth1993">(<a href="#ref-warrenViewFifthGeneration1982" role="doc-biblioref">Warren 1982</a>; <a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>)</span></p>
<p>Specific plans they had for AI systems <span class="citation" data-cites="feigenbaumJapaneseNationalFifth1993 moto-okaFifthGenerationComputers1984 feigenbaumFifthGenerationArtificial1984 bramerFifthGenerationAnnotated1984 feigenbaumRiseExpertCompany1988">(<a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>; <a href="#ref-moto-okaFifthGenerationComputers1984" role="doc-biblioref">Moto-oka 1984</a>; <a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 121–31</a>; <a href="#ref-bramerFifthGenerationAnnotated1984" role="doc-biblioref">Bramer 1984, 6</a>; <a href="#ref-feigenbaumRiseExpertCompany1988" role="doc-biblioref">E. A. Feigenbaum, McCorduck, and Nii 1988, 202–3</a>)</span>:</p>
<ul>
<li>Computer-readable dictionaries with around 2 million entries in total. These would include a word dictionary with 800K words, a “concept classification dictionary” of 400K concepts, including a general thesaurus, and a “concept description dictionary” of another 400K concepts. These would serve as a general-purpose knowledge base that any expert system could utilize.</li>
<li>English-Japanese translator with vocabulary size ≥100,000, at ≥90% accuracy (with the last 10% fixed up by humans).</li>
<li>Continuous ASR with vocabulary size ≥50,000 words and 95% per-word accuracy from at least “a few hundred” speakers, in both English and Japanese, at ≤3× real time.</li>
<li>A question-answering system built on top of the ASR system. It would converse with the user with synthesized speech in Japanese or English. The first planned system would handle document queries in the computing literature. It would have vocabulary size ≥5,000 and ≥10,000 inference rules. After its success, more systems would be built for other professional fields.</li>
<li>Natural language processing with vocabulary size ≤100,000, and ≤2000 grammatical rules, achieving ≥99% accuracy in syntactic analysis.</li>
<li>An image processing system with hardware featurizers, that can store ≥10,000 pieces of graphic and image information in its knowledge base. It would be applied to computer-aided design and manufacture and analysis of aerial and satellite images, medical images, etc.</li>
</ul>
</section>
<section id="autopsy" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="autopsy">Autopsy</h3>
<blockquote class="blockquote">
<p>ICOT set out to build a machine that could provide upwards of a 100 MLIPs of ‘symbol crunching’ power. However, there was no application whose clear need for such horsepower drove the development and whose success (or failure) would serve as the tangible evaluation of the effort. From our current perspective it is clear that there could not have been such an application, since any such application would necessarily have had to contain very large stores of knowledge; but in 1982 when the project began, there were no techniques available for capturing and managing such a large knowledge base. Even today, after more than a decade of research into knowledge representation, we have only a small base of experience and very few tested techniques for this task.</p>
<p><span class="citation" data-cites="feigenbaumJapaneseNationalFifth1993">(<a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>)</span></p>
</blockquote>
<p>After 10 years and $400M, the FGCS wrapped up in 1992. The MITI announced that it would give away the developed software for free.</p>
<blockquote class="blockquote">
<p>The problem for Japan is that the computer industry shifted so rapidly that the technological path the Fifth Generation took – which seemed a wise choice in 1982 – turned out to be at odds with the computer industry’s direction by 1992. In a sense, Japan’s ability to stay the course in pursuit of a long-term payoff – usually considered one of the country’s strongest assets – turned into a liability. A similar challenge for Japan may now be arising in high-definition television. Japan’s HDTV system, which has been in development for two decades, is now coming to market just as some engineers believe that a major shift to digital television technology will make the Japanese analog approach obsolete.</p>
<p>… “If it had really caught on, the Japanese companies would not have let it go,” said Edward Feigenbaum… While the project developed some interesting computer designs and software, he said, even in Japan “no one is using the technology.”</p>
<p><span class="citation" data-cites="pollackFifthGenerationBecame1992">(<a href="#ref-pollackFifthGenerationBecame1992" role="doc-biblioref">Pollack 1992</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>On the research side, it made little progress in AI, NLP, natural interface, knowledge acquisition, construction of large knowledge bases. On the commercial side, its architectures were a commercial failure as they require the user to use an unfamiliar paradigm (parallel logical programming) on hardware that is not better than standard hardware. The promised applied expert systems were not developed because the research did not progress as planned.</p>
<p><span class="citation" data-cites="feigenbaumJapaneseNationalFifth1993">(<a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>, table 2)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>The PIM hardware seems destined for the same fate. The processing elements in the PIMs have cycle times no better than 60 ns; even assuming that the features which provide direct support for XLI offer a speedup factor of 3, this leaves the uniprocessor performance lagging behind the best of today’s conventional microprocessors. Both HP and DEC have announced the imminent introduction of uniprocessors of between 100 and 200 MIPS. The interconnection networks in the PIMs do not seem to constitute an advance over those explored in other parallel systems. Finally, the PIMs are essentially ‘integer machines’; they do not have floating point hardware. While the interconnection networks of the PIMs have reasonable performance, this performance is comparable to that of commercial parallel machines in the US such as the CM-5.</p>
<p>But these days, few people want specialized computers for artificial intelligence, preferring powerful general-purpose machines like those made by Sun Microsystems Inc., a fast-growing Silicon Valley company that did not exist when the Fifth Generation Project was conceived. And a host of scrappy American companies have sprung up to sell massively parallel computers with tens of thousands of processors, far more than the Fifth Generation machines.</p>
<p><span class="citation" data-cites="pollackFifthGenerationBecame1992">(<a href="#ref-pollackFifthGenerationBecame1992" role="doc-biblioref">Pollack 1992</a>)</span></p>
</blockquote>
<p>THe fastest systems they built were the PIM/p with 512 processors at peak performance 156 MLIPS, and PIM/m with 256 processors at 153 MLIPS. Both had clock frequency 16 MHz. They sticked to the original estimate, made at the start of the project, that their logic-specific chips could run logical inferences at approximately 100 times faster than a general computer. <a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn27"><blockquote class="blockquote"><sup>27</sup>&nbsp;
<p>たとえば、512 台のプロセッサを持つ PIM モデル p ではピーク性能で156 MLIPS (1秒間に1億5600万回の推論処理を行なう速度)、256 台のプロセッサを持 つモデル m では153 MLIPSという、汎用大型機の約100倍に当たる世界最高の 推論処理速度を達成している。実際の応用システムでの利用でも、アルゴリズ ムの工夫とあいまって、512 台にいたるまでほぼプロセッサの台数に比例する並 列処理効果を得ている。</p>
<p><a href="https://www.ueda.info.waseda.ac.jp/AITEC_ICOT_ARCHIVES/ICOT/Museum/FinalReport/node17.html#SECTION03022300000000000000">第五世代コンピュータ・プロジェクト 最終評価報告書: 並列記号処理ハードウェア技術</a></p>
</blockquote>
<p><a href="https://www.ueda.info.waseda.ac.jp/AITEC_ICOT_ARCHIVES/ICOT/Museum/MACHINE/pim-spec-J.html">Top Page for FGCS Museum: ５つのＰＩＭの概要</a></p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/FGCS_scaling_plot.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The LIPS of computers produced by the FGCS at its ending in 1992, with forecasts up to 2000. <span class="citation" data-cites="FGCS_scaling_plot.png">(<a href="#ref-FGCS_scaling_plot.png" role="doc-biblioref"><strong>FGCS_scaling_plot.png?</strong></a>, figure 2)</span></figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="1 LIPS = 100 OPS?">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
1 LIPS = 100 OPS?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>From the start of the project, they assumed that 1 LIP takes about 100 operations on a conventional computer. They also planned that, at the end of the project, there should be a machine with 1000 processors achieving 1 GLIPS, implying at least 1 MLIPS per processor. <span class="citation" data-cites="feigenbaumJapaneseNationalFifth1993">(<a href="#ref-feigenbaumJapaneseNationalFifth1993" role="doc-biblioref">E. Feigenbaum and Shrobe 1993</a>)</span></p>
<p>According to <span class="citation" data-cites="bramerFifthGenerationAnnotated1984">(<a href="#ref-bramerFifthGenerationAnnotated1984" role="doc-biblioref">Bramer 1984, 6</a>)</span>, as of 1984, a conventional computer cound run Prolog at 10–100 KLIPS, and that 1 LIPS = 100–1000 OPS. Now, they did not state what counts as “conventional”, but probably they meant something between Sun-1 (0.5 MIPS) and Cray-1 (150 MIPS). Unfortunately, this gives us a ridiculously wide range of 1 LIPS = 5–1500 OPS.</p>
<p>As far as I see, they probably just got that number by running some Prolog programs on the computers they have available in 1982. Fortunately, someone did exactly this experiment and found that 1 LIPS = 53 OPS as of 1990 <span class="citation" data-cites="kellerGigaLIPFastEnough1990">(<a href="#ref-kellerGigaLIPFastEnough1990" role="doc-biblioref">Keller 1990</a>)</span>, so the 1 LIPS = 100 OPS rule is good enough.</p>
</div>
</div>
</div>
<p>Now, assuming that 1 LIPS = 100 OPS, then to reach 1 GLIPS on a conventional computer would require 100 GFLOPS. Now, according to <a href="https://www.top500.org/lists/top500/1993/11/">TOP500 list of 1993-11</a>, the second-fastest computer in the world was a 1024-core <a href="https://en.wikipedia.org/wiki/Connection_Machine">Connection Machine</a>-5 (developed by the <a href="#sec-sci">Strategic Computing Initiative</a>), which ran at 60 GFLOPS. So just by making a parallel computer with 1000 standard floating-point processors, they made something that reached the Japanese target of 1 GLIP/sec, without ever dealing with specialized hardware! Yet another example of specialized hardware overtaken by general computers, like Rosenblatt’s <a href="https://yuxi-liu-wired.github.io/essays/posts/perceptron-controversy/index.html#the-perceptron-controversy-1960s">Tobermory</a>, and the <a href="https://en.wikipedia.org/wiki/Lisp_machine">Lisp machines</a>.</p>
<p>Though the FGCS project was a failure, and Japan no longered mattered in AI since its end, it had an indirect effect. Feigenbaum and the long-time AI journalist <a href="https://en.wikipedia.org/wiki/Pamela_McCorduck">Pamela McCorduck</a> coauthored a book <span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984</a>)</span> that became the hottest book inside the Beltway. Ominously, they warned of imminent Japanese domination:</p>
<blockquote class="blockquote">
<p>We calculate that in 1982, the aggregate spent in the United States on artificial intelligence research from all sources – governmental and private – was about 50 million. This is just about equal to the amount the Japanese government expects to spend on an average per year over the next ten years for its Fifth Generation (and does not count Japanese internal industrial AI support that may double or triple the amount). If we continue as we have, we two nations will act as guinea pigs for an interesting experiment in planned, as opposed to unplanned, research… The Japanese have announced that in ten years they will produce knowledge information processors. Several options are open to Americans, but few of them offer truly palatable alternatives to undertaking our own version… The United States should form a national center for knowledge technology… The center we propose would be an expression and institutional embodiment of national will [like NASA].</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 261–69</a>)</span></p>
</blockquote>
<p>The hardware developed, but there was no use for it. Parallel logic programming was difficult for the outside programmers, used to serial imperative programming.</p>
<p>And they were not the first to raise the alarm:</p>
<blockquote class="blockquote">
<p>In January 1981, Professor <a href="https://en.wikipedia.org/wiki/Arvind_(computer_scientist)">Arvind</a> of MIT returned from Tokyo with an early report on the Fifth Generation Project, the same report Feigenbaum had put in his “to read sometime” pile at Stanford a few months earlier. Arvind showed it to <a href="https://en.wikipedia.org/wiki/Michael_Dertouzos">Michael Dertouzos</a>, a professor and director of the MIT Laboratory for Computer Science. Dertouzos recollected in notes: “I panic. My colleagues are (way too) relaxed about it and tell me that I am over-reacting.” One of the things that troubled Dertouzos was the similarities between the Japanese plan and long-range plans at MIT.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 199</a>)</span></p>
</blockquote>
<p>Partly as a result of this, multiple countries launched their own national AI projects,<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> the most notable of which was the <a href="#sec-sci">Strategic Computing Initiative</a>, funded by the ARPA – I mean, DARPA at this point – which would be much more successful.</p>
<div class="no-row-height column-margin column-container"><div id="fn28"><p><sup>28</sup>&nbsp;FGCS (Japan, 1982–1992), Alvey Programme (UK, 1984–1990), ESPRIT programs (Europe, 1983–1998), and the Strategic Computing Initiative (America, 1984–1993).</p></div></div></section>
</section>
<section id="intelligence-in-the-age-of-war-machines" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="intelligence-in-the-age-of-war-machines">Intelligence in the age of war machines</h2>
<section id="early-war-machines" class="level3">
<h3 class="anchored" data-anchor-id="early-war-machines">Early war machines</h3>
<p>The dream of peace produces war machines. Ancient Athenians dreamed of <a href="https://en.wikipedia.org/wiki/Talos">Talos</a>, a bronze giant who defended Crete, while the Jews of Prague dreamed of <a href="https://en.wikipedia.org/wiki/Golem#Etymology">Golem</a>. The ages has been too kind to Zhuge Liang, and his wheelbarrow, invented for carrying war supplies, became the legend of <a href="https://en.wikipedia.org/wiki/Wooden_ox">wooden robot oxen</a>.</p>
<p>The industrial revolution produced early ideas of feedback mechanism, such as the <a href="https://en.wikipedia.org/wiki/Centrifugal_governor">centrifugal governor</a> and the <a href="https://en.wikipedia.org/wiki/Gyroscopic_autopilot">gyro autopilot</a>. It took until WWII for someone to put together high explosives, slow burning fuel, and the feedback mechanism, to create the cruise missile. The first of its kind was the V-1 rocket, which already incorporates the basic features of all cruise missiles.</p>
<p>The V-1 looks like a small unmanned jet airplane. It has the following senses: roll (gyro), pitch (gyro), yaw (magnetic compass), altitude (barometer), distance traveled (vane anemometer). The roll, pitch, yaw, and altitude are maintained by negative feedback. So for example, if the missile is heading east to the set-point of yaw, a valve would open, and compressed gas would force the rudder to turn, which yaws the missile west. As soon as the vane anemometer has turned a designated number, the missile considers itself to have reached the target. It turns off the engine and sharply dives to the ground, and explodes upon impact.</p>
<p>Other than V-1 and V-2, there were no autonomous war machines during WWII, though there were several radio-controlled weapons such as <a href="https://en.wikipedia.org/wiki/Goliath_tracked_mine">explosive little tanks</a> and <a href="https://en.wikipedia.org/wiki/Radioplane_OQ-2">little planes for target practice</a>. Skinner, thinking outside (inside?) the box, worked on <a href="https://en.wikipedia.org/wiki/Project_Pigeon">Project Pigeon</a>. He trained pigeons in skinner boxes to peck at the ship appearing on a screen. If the pigeon is pecking on the top-left, then the missile would turn to the bottom-right. In effect, the pigeon becomes the negative feedback controller. Though it was cancelled, it would have been considerably cheaper than <a href="https://en.wikipedia.org/wiki/Kamikaze">the Japanese version</a> should it have ever reached production.</p>
<video controls="" width="100%">
<source src="figure/Project Pigeon.webm" type="video/webm">
</video>
<p>After WWII, some autonomous defense systems were developed and deployed, such as <a href="https://en.wikipedia.org/wiki/Close-in_weapon_system">close-in weapon systems</a> on ships. These detect incoming incoming missiles and enemy aircraft by radar, computes their trajectories, and shoots them down. Since they must operate on the time-scale of seconds, they are fully automatic with no human in the loop. Despite this, these are quite uncontroversial and do not typically earn the title of “killer robots”, presumably because compared to autonomous <em>offense</em>, defense is inherently more controllable and predictable in effect.</p>
</section>
<section id="nuclear-war-machines" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="nuclear-war-machines">Nuclear war machines</h3>
<blockquote class="blockquote">
<p>Deterrence is the art of producing in the mind of the enemy the fear to attack. And so, because of the automated and irrevocable decision making process which rules out human meddling, the doomsday machine is terrifying. It’s simple to understand. And completely credible, and convincing… When you merely wish to bury bombs, there is no limit to the size. After that they are connected to a gigantic complex of computers. Now then, a specific and clearly defined set of circumstances, under which the bombs are to be exploded, is programmed into a tape memory bank.</p>
<p>— <a href="https://en.wikipedia.org/wiki/Dr._Strangelove">Dr.&nbsp;Strangelove</a> (1964)</p>
</blockquote>
<p>During the Cold War, the following technological factors of nuclear weapons determined the grand nuclear strategy.</p>
<ol type="1">
<li>First-strike nuclear offense is impossible to defend against. Some bombs will get through all defense.</li>
<li>Nuclear weapon is so much more powerful than non-nuclear weapons, that the only proportionate deterrence to a nuclear attack is another nuclear attack.</li>
<li>First-strike capability is indistinguishable from second-strike capability.</li>
</ol>
<p>Because of (1) and (2), the only way to deter a nuclear first-strike was to threaten a nuclear second-strike. This is the <a href="https://en.wikipedia.org/wiki/Mutual_assured_destruction">MAD</a> nuclear deterrence doctrine. Because deterrence requires enough bombs to survive a first-strike, both sides would rather build up more second-strike bombs than the other side’s first-strike bombs. Because of (3), there aren’t “second-strike bombs” vs “first-strike bombs”, only bombs. Therefore, we have a positive feedback loop where both sides aim to have more bombs than the other – the <a href="https://en.wikipedia.org/wiki/Nuclear_arms_race">nuclear arms race</a>. Because having too many bombs increases the chance of accidents, both sides are motivated to slow down the race. Thus the <a href="https://en.wikipedia.org/wiki/Anti-Ballistic_Missile_Treaty">ABM Treaty</a>, where both sides agree to <em>not</em> build many missile defense systems! This paradoxical treaty was designed to make both sides <em>more</em> vulnerable to second-strike, meaning that less bombs are needed to ensure second-strike capability, thus complementing the <a href="https://en.wikipedia.org/wiki/Strategic_Arms_Limitation_Talks">SALT treaties</a> that limited the number of bombs.</p>
<p>Both sides’ nuclear technology went through several iterations, with increasing second-strike capability, and ended up with the “nuclear triad” of bombers that stay in the air 24/7, submarines hidden under the sea, and ICBMs hardened inside silos. Each of the three has different tradeoffs, necessitating all three to be maintained.</p>
<p>Of course, even if the triad survives the first-strike, it is no good if they won’t activate. The command center might be destroyed. The communication lines might be cut. The soldiers might refuse to launch based on their own conscience. All these dangers lead to the pressure to automate second-strike. The pinnacle of this logic was the <a href="https://en.wikipedia.org/wiki/Supersonic_Low_Altitude_Missile">Supersonic Low Altitude Missile (SLAM)</a>, a cruise missile powered by a nuclear engine. The nuclear engine is like a fission nuclear reactor in nuclear power plants, except that the fission power does not boil water, but heat up air, which expands and shoots out from the tail of the missile, allowing it to fly at Mach 3.</p>
<p>Despite having no GPS (it was the 1960s!), because the SLAM would fly <span class="math inline">\(\sim 200 \;\mathrm{m}\)</span> above ground, it could navigate itself by <a href="https://en.wikipedia.org/wiki/TERCOM">terrain contour matching</a>: It compares a height-scan of the local terrain against a stored copy of the terrain. Even after dropping all its nuclear warheads, it can remain airborne for weeks, destroying the ground with sonic booms as overkill. The project was shelved in 1964, apparently considered too destabilizing, and they settled for just drilling the nuclear launch routines into the missileers until they work like robots that would not hesitate to execute the launch command.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/TERCOM.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The terrain contour matching algorithm. By a curious coincidence, the algorithm typically attempts to find a line segment within the stored terrain map that minimizes the <a href="https://en.wikipedia.org/wiki/Average_absolute_deviation">Mean Absolute Deviation</a> with the local terrain of the missile… also with the “MAD” acronym. <span class="citation" data-cites="goldenTerrainContourMatching1980">(<a href="#ref-goldenTerrainContourMatching1980" role="doc-biblioref">Golden 1980, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>In the movie <em>Dr.&nbsp;Strangelove</em> (1964), nuclear deterrence was taken to its logical end point. In the movie, the Soviet Union built a “doomsday machine”, which is a Cobalt bomb that when exploded, makes enough fallout to render the entire earth uninhabitable for a century. This was then connected to sensors around the Soviet Union, so that any nuclear attack automatically triggers it. Finally, the machine triggers if it detects attempts to un-trigger it, thus closing the logic loop and making it a fully automatic deterrence machine.<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn29"><p><sup>29</sup>&nbsp;I was going to write something about the <a href="https://en.wikipedia.org/wiki/Dead_Hand">Dead Hand</a> system, but after a brief search, the available information looks too much like conspiracy theory and rumors, so I will not.</p></div></div></section>
<section id="intelligence" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="intelligence">Intelligence</h3>
<p>The previous sections has made it clear that ARPA has been inevitable behind every AI development since the 1960s. Indeed, ARPA funded 75–95% of all AI projects during the 1960s <span class="citation" data-cites="guiceControversyStateLord1998">(<a href="#ref-guiceControversyStateLord1998" role="doc-biblioref">Guice 1998</a>)</span>. Though this essay is on logical AI, a brief detour about neural network is in order.</p>
<p>During the Cold War, intelligence, in the sense of intelligence-gathering and reconnaissance was a vital area of artificial intelligence. Some of the early neural networks, such as MINOS II, was explicitly built with an objective of scanning aerial photographs for interesting military targets like tanks. <span class="citation" data-cites="nilssonQuestArtificialIntelligence2009">(<a href="#ref-nilssonQuestArtificialIntelligence2009" role="doc-biblioref">Nilsson 2009, 98–109</a>)</span> The CIA even <a href="https://www.cia.gov/readingroom/document/cia-rdp78b04770a002300030027-6">experimented with Rosenblatt’s Mark I Perceptron machine</a> for the same purpose <span class="citation" data-cites="irwinArtificialWorldsPerceptronic2024">(<a href="#ref-irwinArtificialWorldsPerceptronic2024" role="doc-biblioref">Irwin 2024</a>)</span>. As an example, <span class="citation" data-cites="kanalRecognitionSystemDesign1964">(<a href="#ref-kanalRecognitionSystemDesign1964" role="doc-biblioref">Kanal and Randall 1964</a>)</span> describes a two-layered perceptron network, of type <span class="math inline">\(\mathbb{R}^{N \times N} \to \{0, 1\}^{32\times 32} \to \{0, 1\}^{24} \to \{0, 1\}\)</span>. It works as follows:</p>
<ul>
<li>The grayscale photo is down-scaled and binarized by convolution with a <a href="https://en.wikipedia.org/wiki/Discrete_Laplace_operator">discrete Laplace filter</a>: <span class="math inline">\(\mathbb{R}^{N \times N} \to \{0, 1\}^{32\times 32}\)</span>.</li>
<li>The weights for the 24 hidden perceptrons are constructed by <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">linear discriminant analysis</a>: <span class="math inline">\(\{0, 1\}^{32\times 32} \to \{0, 1\}^{24}\)</span></li>
<li>The output perceptron is learned by the <a href="https://en.wikipedia.org/wiki/Perceptron#Learning_algorithm_for_a_single-layer_perceptron">perceptron learning rule</a>: <span class="math inline">\(\{0, 1\}^{24} \to \{0, 1\}\)</span>.</li>
</ul>
<div id="fig-kanal-1964-neural-tanks" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kanal-1964-neural-tanks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-tank-nontank-mosaic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-tank-nontank-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_tank_nontank_mosaic.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-tank-nontank-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Grayscale photos, some containing tanks, and some not.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-binary-image-tank" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-binary-image-tank-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_binary_image_tank.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-binary-image-tank-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) A picture of a tank after convolution with a discrete Laplace filter.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-kanal-1964-neural-tanks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-kanal-1964-neural-tanks-architecture" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-kanal-1964-neural-tanks-architecture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/kanal_1964_fig_architecture.png" class="img-fluid figure-img" data-ref-parent="fig-kanal-1964-neural-tanks">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-kanal-1964-neural-tanks-architecture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) The architecture of the network.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kanal-1964-neural-tanks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Images from <span class="citation" data-cites="kanalRecognitionSystemDesign1964">(<a href="#ref-kanalRecognitionSystemDesign1964" role="doc-biblioref">Kanal and Randall 1964</a>)</span>.
</figcaption>
</figure>
</div>
<p>Neural networks (such as Minsky’s <a href="https://en.wikipedia.org/wiki/Stochastic_Neural_Analog_Reinforcement_Calculator">SNARC</a> and Rosenblatt’s perceptrons) were funded by the Office of Naval Research (ONR) on the order of $50K, while logical AI was funded by ARPA, whose contracts were on the order of $500K. This made a real difference in the days of mainframes. <span class="citation" data-cites="guiceControversyStateLord1998">(<a href="#ref-guiceControversyStateLord1998" role="doc-biblioref">Guice 1998</a>)</span> See my essay on the <a href="https://yuxi-liu-wired.github.io/essays/posts/perceptron-controversy/"><em>Perceptron Controversy</em></a> for details.</p>
</section>
<section id="sec-sci" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-sci">Strategic Computing Project</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Strategic_Defense_Initiative">Strategic Defense Initiative</a> (SDI), better known as “Star Wars”, was announced by President Reagan in 1983. It aimed to shoot down Soviet ICBMs during their spaceflight with tools including lasers, particle-beam weapons, and ground and space-based missile systems. If this was successful, it would cripple Soviet second-strike capability. Although President Reagan claimed the project aimed to make nuclear weapons “impotent and obsolete”, it would be incredible, even <a href="https://en.wikipedia.org/wiki/Idealism_in_international_relations">idealists</a>, to suppose that other countries would believe it. Indeed, the Soviet Premier Andropov immediately condemned this, suspecting it was in fact a plan to make America the only nuclear power immune to a second-strike and become the global hegemon.</p>
<p>Though the SDI did not bring the Star Wars, or make plans for AI, it had an indirect effect on intelligence in the age of war machines. In the same year, the Strategic Computing Project (SCI) began, and its funding was facilitated by the SDI, as well as the Japan scare from the Fifth Generation, which was the hottest topic in the Beltway.</p>
<blockquote class="blockquote">
<p>It is tempting to regard all this as just another skirmish in the trade wars, where engagements have already taken place in steel, automobiles, and consumer electronics… our national self-interest, not to mention our economic security, does not allow us this luxury. Information processing is an $88-billion-per-year industry in the United States, and its loss would be disastrous. The default of this American industry, which has led the world for decades, would be a mortal economic wound… The superior technology usually wins the war – whether that war is martial, entrepreneurial, or cultural.</p>
<p><span class="citation" data-cites="feigenbaumFifthGenerationArtificial1984">(<a href="#ref-feigenbaumFifthGenerationArtificial1984" role="doc-biblioref">E. A. Feigenbaum and McCorduck 1984, 17–18</a>)</span></p>
</blockquote>
<p>It’s war. America could not lose the AI race. The congress approved the SCI, a 10-year project that would end up costing $1 billion funded by DARPA. The final plan was published in 1983-10 as <span class="citation" data-cites="darpaStrategicComputingNew1983">(<a href="#ref-darpaStrategicComputingNew1983" role="doc-biblioref">DARPA 1983</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/SCI_plan.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The SCI plan according to the bureaucrats. Yawn. <span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 77–78</a>)</span>, which were cleaned up from <span class="citation" data-cites="darpaStrategicComputingNew1983">(<a href="#ref-darpaStrategicComputingNew1983" role="doc-biblioref">DARPA 1983, fig. 4.1</a>, figure 4.2)</span></figcaption>
</figure>
</div>
<p>The project has 3 application areas: the “Battlem Management System” for the Navy, “Pilot’s Associate” for the Air Force, and “Autonomous Land Vehicle” (ALV) for the Army. To develop these areas, it would develop 4 technologies: speech (for Pilot’s Associate and Battle Management), language (for Battle Management), vision (for ALV), and general expert systems (for all). It would also develop massively parallel (≥1000 processors) teraFLOPS computers as its own bet on the fifth generation of computing.</p>
<p>How did it go? Spoiler: massively parallel computers at the teraOPS level succeeded, language abandoned, vision failed, self-driving cars improved but failed to reach the promise, generic expert systems failed, a few specific expert systems worked.</p>
</section>
<section id="computing" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="computing">Computing</h3>
<blockquote class="blockquote">
<p>Many veterans and supporters of the program believe that it was created in response to a compelling technological opportunity. In the early 1980s, advances in microelectronics design and manufacturing held out the promise of greatly improved computer chips. New concepts of computer architecture could conceivably exploit these chips in machines of unprecedented speed and power. Such computers might finally have the muscle necessary to achieve artificial intelligence – machine capabilities comparable to those of human thought.</p>
</blockquote>
<p>Near the end of SCI, computers were within 10x of the teraFLOPS goal. Congress approved the <a href="https://en.wikipedia.org/wiki/High_Performance_Computing_Act_of_1991">High Performance Computing Act of 1991</a> to fund the development of Internet infrastructure and more massively parallel computers – rebranded as “high performance computing”.</p>
<blockquote class="blockquote">
<p>By mid-1992 a completely new generation of computers have been introduced. Understanding this generation should make it possible to build the next-generation supercomputer class machine, that would reach a teraflop of peak power for a few, large-scale applications by the end of 1995.</p>
<p><span class="citation" data-cites="bellUltracomputersTeraflopIts1992">(<a href="#ref-bellUltracomputersTeraflopIts1992" role="doc-biblioref">Bell 1992</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Bell_1992_teraOPS.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Progress towards the teraFLOPS computer. <span class="citation" data-cites="bellUltracomputersTeraflopIts1992">(<a href="#ref-bellUltracomputersTeraflopIts1992" role="doc-biblioref">Bell 1992, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>The desired “1000 core computer” did come in 1991 as CM-5 at about 60 GFLOP/sec, 4300 FLOPS/$ <span class="citation" data-cites="bellUltracomputersTeraflopIts1992">(<a href="#ref-bellUltracomputersTeraflopIts1992" role="doc-biblioref">Bell 1992</a>)</span>, and a little late on schedule. The first teraFLOPS computer, <a href="https://en.wikipedia.org/wiki/ASCI_Red">ASCI Red</a>, arrived in 1996, with 9298 CPUs.<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a> It was designed for simulating nuclear bomb tests.</p>
<div class="no-row-height column-margin column-container"><div id="fn30"><p><sup>30</sup>&nbsp;I couldn’t find its price, but its successor ASCI White cost $110 million, so if we assume ASCI Red cost $100 million, then Gordon Bell’s prediction that a teraFLOPS computer would sell for about $40 million at 25 KFLOPS/$, in 1995 was nearly right. <span class="citation" data-cites="bellUltracomputersTeraflopIts1992">(<a href="#ref-bellUltracomputersTeraflopIts1992" role="doc-biblioref">Bell 1992</a>)</span></p></div></div><p>The previous paradigm of supercomputers were hitting the limits of what you can do with just ~10 cores and shared memory architectures. For example, the Cray-2, an exemplar of 1980s supercomputers, had only 8 processors. Experts saw that future supercomputers needed to be “massively parallel”, i.e.&nbsp;over 1000 cores. Indeed, the Japanese FGCS project produced parallel computers of up to 512 cores for the same rationale.</p>
<blockquote class="blockquote">
<p>During the 1980s, as the demand for computing power increased, the trend to a much larger number of processors began, ushering in the age of massively parallel systems, with distributed memory and distributed file systems, given that shared memory architectures could not scale to a large number of processors.</p>
<p>Greg Astfalk (1996). Applications on Advanced Architecture Computers. SIAM. pp.&nbsp;62.</p>
</blockquote>
<blockquote class="blockquote">
<p>Compared to existing expert systems running 2,000 rules at 50–100 rules per second, SCI promised” multiple cooperating expert systems with planning capability” running 30,000 rules firing at 12,000 rules per second and six times real time.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 195</a>)</span></p>
</blockquote>
<p>Other than massively parallel computers, there were also a few odds and ends. At the start of the program, there were brief efforts to get <a href="https://en.wikipedia.org/wiki/Gallium_arsenide">gallium arsenide (GaAs)</a> chips working. Compared to silicon, GaAs has a wider bandgap, thus it tolarates higher temperatures and generally more extreme conditions. It started a running joke that GaAs would be the big silicon-chip killer in the next 10 years. 40 years later, it has yet to happen.</p>
<p>More relevant was <a href="https://en.wikipedia.org/wiki/MOSIS">MOSIS</a>, an on-demand chip fabrication service that was affordable enough even for university projects, especially university courses that taught the new <a href="https://en.wikipedia.org/wiki/Very-large-scale_integration">VLSI</a> method – just send in the design and get your final project back! Indeed, Feng-hsiung Hsu fabbed earlier iterations of chess chips by MOSIS.</p>
</section>
<section id="pilots-associate" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="pilots-associate">Pilot’s associate</h3>
<p>There is little known about the Pilot’s Associate project. The original plan called for 10,000-rule, real-time expert systems, animated displays with <span class="math inline">\(10^8\)</span> polygons per second, 200-word speaker-independent speech input system that works in high-noise environments, and a 1,000-word speech output system. Though the systems were demonstrated three times, there was no applications or follow-up. <span class="citation" data-cites="nilssonQuestArtificialIntelligence2009">(<a href="#ref-nilssonQuestArtificialIntelligence2009" role="doc-biblioref">Nilsson 2009, 362–63</a>)</span></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Pilot_s_associate.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Concept art for Pilot’s Associate. <span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, fig. 7.1</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/pilot_s_assoctiate_1991.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The dataflow of Pilot’s Associate in 1991, at its third and final demo. <span class="citation" data-cites="banksPilotsAssociateCooperative1991">(<a href="#ref-banksPilotsAssociateCooperative1991" role="doc-biblioref">Banks and Lizza 1991, fig. 1</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="battle-management" class="level3">
<h3 class="anchored" data-anchor-id="battle-management">Battle management</h3>
<p>In the long-gone past, an army was like a clockwork toy. It can march, hold ground, or turn slowly. Frontlines were on the order of 1 km, since it would be hard to see the commander from farther away. The progress of warfare made the battlespace more complex.</p>
<p>Unsurprisingly, it was a secret thing. It was not described in detail anywhere. An expert system pioneer recalls:</p>
<blockquote class="blockquote">
<p>McCune: I built a system that I can’t say very much about. It was a signal analysis system. I built it for $1 million. Five years later the boss of the boss of the boss of my client said, “Thank you, Brian. You saved me $500 million.” That’s what I’m talking about ROI. He said, “What other systems can you build for me?” I built him two more systems. So, it did pay off for the military.</p>
<p><span class="citation" data-cites="allenExpertSystemsPioneer2018">(<a href="#ref-allenExpertSystemsPioneer2018" role="doc-biblioref"><em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018</a>)</span></p>
</blockquote>
<p>However, we know that the Navy did get what they wanted, and they did work.</p>
<blockquote class="blockquote">
<p>“Battle Management Ashore” was officially the Fleet Command Center Battle Management Program (FCCBMP). Like PA, FCCBMP was to consist of five expert systems. Each would perform a particular task for the headquarters of the Pacific Fleet at Pearl Harbor (Commander-In-Chief, Pacific Fleet, or CINCPACFLT ). First, the Force Requirements Expert System (FRESH) would monitor the readiness of the fleet and assist in allocating its forces according to the capabilities and status of the individual ships. The Capabilities Assessment Expert System (CASES), would compare the relative strength of United States and hostile forces. The Campaign Simulation Expert System (CAMPSIM) would simulate the outcome of different courses of action. The Operations Plan Generation Expert System (OPGEN) would develop operational plans according to specified strategies. Finally, the Strategy Generation and Evaluation Expert System (STRATUS) would assist in developing plans for theater-level strategy.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 218–19</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>In June 1986, FRESH Prototype One was installed in the test bed, and two months later it was demonstrated successfully to DARPA and the navy using the IRUS natural language generator developed by BBN, SAIC, and the Naval Ocean Systems Center (NOSC). At that time the IRUS vocabulary recognized 5,000 words, including proper names and naval terms; it successfully comprehended and responded to queries in terms usually used by the operations staff. By 1987 the enhanced system was performing in ninety minutes tasks that would usually take the CINCPACFLT staff fifteen hours. By then the navy employed the system routinely to monitor the readiness of its ships in the Pacific.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 265–66</a>)</span></p>
</blockquote>
<p>Lest some, out of moral integrity, claim that mixing military and AI only hurts everyone, there was one definite success story in practice: DART.</p>
<blockquote class="blockquote">
<p><a href="https://en.wikipedia.org/wiki/Gulf_War">Desert Shield/Storm</a> in 1990–91 [… had] no prior buildup of troops or supplies. The US Department of Defense sealifted 2.4 million tons of cargo during the first six months of Desert Shield – more than four times the cargo carried across the English Channel to Normandy during the D-Day invasion… About halfway through the six months of Desert Shield, Kral installed the system at the <a href="https://en.wikipedia.org/wiki/United_States_Transportation_Command">USTRANSCOM</a> transportation command and the <a href="https://en.wikipedia.org/wiki/United_States_European_Command">US European command</a>, where it was used for the duration.</p>
<p><span class="citation" data-cites="hedbergDARTRevolutionizingLogistics2002">(<a href="#ref-hedbergDARTRevolutionizingLogistics2002" role="doc-biblioref">Hedberg 2002</a>)</span></p>
</blockquote>
<p>We don’t have any pictures of this, or even source code, as it is probably a state secret. Still, it is described as</p>
<blockquote class="blockquote">
<p>a GUI-based scheduler that took a mainframe flat file of the details of all items to be moved–dates to move, places to move to and from, and so forth–and loaded the data into an Oracle database. The scheduling was done on a front-end Sun-4 workstation.</p>
<p><span class="citation" data-cites="hedbergDARTRevolutionizingLogistics2002">(<a href="#ref-hedbergDARTRevolutionizingLogistics2002" role="doc-biblioref">Hedberg 2002</a>)</span></p>
</blockquote>
<p>And did it work?</p>
<blockquote class="blockquote">
<p>It enabled users to examine schedules at a higher level of abstraction, because it could readily aggregate modules. Planners could run strategic transportation models using DART in a matter of minutes rather than in hours or days. This enabled them to consider more alternatives and develop a more realistic action plan in far less time… The DART scheduling application paid back all of DARPA’s 30 years of investment in AI in a matter of a few months, according to Victor Reis, Director of DARPA at the time.</p>
<p><span class="citation" data-cites="hedbergDARTRevolutionizingLogistics2002">(<a href="#ref-hedbergDARTRevolutionizingLogistics2002" role="doc-biblioref">Hedberg 2002</a>)</span></p>
</blockquote>
<p>I guess one can interpret it as either “wars are really expensive” or “DARPA had invested too little in AI”.</p>
</section>
<section id="autonomous-land-vehicle" class="level3">
<h3 class="anchored" data-anchor-id="autonomous-land-vehicle">Autonomous Land Vehicle</h3>
<p>If the other parts of SCI was shrouded in mystery, the Autonomous Land Vehicle (ALV) part made up for this. The ALV project was designed for the army, with a budget of $10 million contracted to multiple organizations, each taking care of part of the system. The project had yearly goals, starting with 10 km/h in 1985 and ending with 50 km/h in 1990.</p>
<div class="callout callout-style-default callout-note callout-titled" title="The exact yearly goals">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The exact yearly goals
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>1985 - Road Following Demonstration: Vehicle traverses a 2 km preset route on a paved road at speeds up to 10 km/h. Forward motion only and no obstacle avoidance required.</li>
<li>1986 - Obstacle Avoidance Demonstration: Vehicle traverses 5 km road course at speeds up to 20 km/h; must recognize and maneuver to avoid fixed objects that are small with respect to road width.</li>
<li>1987 - Cross-country Route Planning Demonstration: Vehicle plans and executes a 5 km traverse of open desert terrain at speeds up to 5 km/h. Demonstrates soil and ground cover typing.</li>
<li>1988 - Road Network Route Planning and Obstacle Avoidance Demonstration: Vehicle plans and executes a 20 km point-to-point traverse through a road network at speeds up to 20 km/h using landmarks as navigation aids. Demonstration includes map updating and off-road maneuvering to avoid obstacles.</li>
<li>1989 - Cross-country Traverse with Landmark Recognition Demonstration: Vehicle plans and executes a 20 km traverse through desert terraín with obstacles at speeds up to 10 km/h. Demonstration includes replanning when confronted with impassable obstacles.</li>
<li>1990 - Mixed road and Open Terrain Demonstration: Vehicle plans and executes a 20 km traverse in wooded terrain with isolated obstacles and a 50 km traverse on paved and unpaved roads at speeds up to 50 km/h. Route planning includes multiple goals.</li>
</ul>
</div>
</div>
</div>
<p>What did the army expect to gain from this? Reconnaissance, “offensive and defensive missions” with a platoon of vehicles, and robotic variants of the <a href="https://en.wikipedia.org/wiki/Armored_Systems_Modernization">Armored Family of Vehicles</a> that could execute missions “singularly, in packs, or in concert with manned vehicles”, sometime after 1991. <span class="citation" data-cites="leightyDevelopingTechnologiesArmy1986">(<a href="#ref-leightyDevelopingTechnologiesArmy1986" role="doc-biblioref">Leighty and Lane 1986</a>)</span></p>
<p>Out of these, we focus on the Navigation Lab (Navlab) at Carnegie Mellon University, since that one had the greatest impact.</p>
<p>Navlab started work on ALV in 1984. The first vehicle they produced was Navlab 1 (1986). Its sensors included cameras, a sonar, a lidar, and an inertial guidance system (this was before GPS). Its only actuator was a stepped motor for steering. In the middle was a <a href="https://en.wikipedia.org/wiki/Sun-3">Sun 3</a>, a standard workstation of the time, and optionally a <a href="https://en.wikipedia.org/wiki/WARP_(systolic_array)#Applications">Warp</a> computer, a <a href="https://en.wikipedia.org/wiki/Systolic_array">systolic array</a> developed as part of SCI.</p>
<p>A Warp computer is made of a chain of processors. Each processor is programmable, and data “pulses through” the processors like blood flowing through vessels. This allowed it to perform data parallel computations, like 2D convolutions and other computer vision tasks. You can think of it as a GPU for the 1980s. In a 10-core Warp computer, each core ran at 10 MIPS, and the whole thing could run a neural network at 17 million “connections per second”, meaning that it takes about <span class="math inline">\(\frac{1.7 \times 10^7}{N}\)</span> seconds to run one forward and backward pass over a neural network with <span class="math inline">\(N\)</span> weights. Impressively, this was 30% faster than even the 65K-core Connection Machine-1. <span class="citation" data-cites="blellochNetworkLearningConnection1987 pomerleauNeuralNetworkSimulation1988">(<a href="#ref-blellochNetworkLearningConnection1987" role="doc-biblioref">Blelloch and Rosenberg 1987</a>; <a href="#ref-pomerleauNeuralNetworkSimulation1988" role="doc-biblioref">Pomerleau et al. 1988</a>)</span></p>
<p>FIDO (Find Instead of Destroy Objects) was a <a href="https://en.wikipedia.org/wiki/Computer_stereo_vision">stereovision</a> algorithm. It takes as input two cameras’ images, and for each, uses a hand-designed “interest operator” to find landmark points, then use that to compute the 3D locations of the landmarks. These are sent to a path-planner. It ran at 4.8 sec/pass. No wonder the car could only drive 0.5 m/s. Work on FIDO stopped in 1987, since it was outclassed by the lidar. <span class="citation" data-cites="thorpeVisionNavigationCarnegie1990">(<a href="#ref-thorpeVisionNavigationCarnegie1990" role="doc-biblioref">Thorpe 1990, vol. 93, chap. 14</a>)</span></p>
<p>SCARF (Supervised Classification Applied to Road-Following) was developed since 1986. Schematically, the first version runs as follows. At each step, it compares each image pixel against a road color and an off-road color. It partitions an image’s pixels into connected blobs of “probably road” and “probably off-road” by a simple Bayes classifier. It then converts the blobs into polygons, and compare each polygonal edge with an idealized road model (a projective transform of a circular arc), minimizing change compared to the previous frame’s road model. It uses the best-fit road model to compute the new average on- and off-road pixel colors. It returns the fitted ideal road model, which is used to decide the turning angle.</p>
<p>In pseudocode:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SCARF:</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, ...):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_dist <span class="op">=</span> (road_color_mean, road_color_variance)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.off_road_dist <span class="op">=</span> (off_road_color_mean, off_road_color_variance)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_model <span class="op">=</span> initial_road_model</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_location <span class="op">=</span> <span class="va">None</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> process_image(<span class="va">self</span>, image):</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        pixels <span class="op">=</span> label_pixels(image, <span class="va">self</span>.road_color, <span class="va">self</span>.off_road_color)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        blobs <span class="op">=</span> connected_components(pixels)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        polygons <span class="op">=</span> fit_polygons(blobs)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        candidate_edges <span class="op">=</span> select_road_edges(polygons)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># update states</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_model, <span class="va">self</span>.road_location <span class="op">=</span> fit_road_model(candidate_edges, <span class="va">self</span>.road_model)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        road_pixels, off_road_pixels <span class="op">=</span> divide_image(image, <span class="va">self</span>.road_location)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_dist <span class="op">=</span> (mean(road_pixels), variance(road_pixels))</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.off_road_dist <span class="op">=</span> (mean(off_road_pixels), variance(off_road_pixels))</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.road_model, <span class="va">self</span>.road_location</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>SCARF ran at about 3 sec/pass. Later versions allowed multiple on- and off-road colors, and used <a href="https://en.wikipedia.org/wiki/Hough_transform">Hough transform</a> to directly fit the edges of the idealized road model to image.</p>
<p>ALVINN, the first neural network driver, began in February 1989. It was trained off-line on a Warp, using purely generated images and driving instructions, presumably because they could not afford to store real images on disk. A training run took 8 hours on the Warp, but inference just took 0.75 s/image on a Sun 3, so they would train it on a Warp in the lab, and run it on a Sun 3 in the car. Soon, it set the Navlab speed record <span class="math inline">\(1.3 \;\mathrm{m/s}\)</span> on 1989-03-16.</p>
<p>In 1989-06, they were greatly surprised to find that ALVINN could be trained rapidly online, so they started doing runs where for the first 10 minutes a human would drive while the ALVINN is trained online in the Warp computer in the back of the car (often carrying around a graduate student watching it train), then ALVINN would take over control. This was possibly the first successful imitation learning application. They also found that, because a human driver would never go off the lanes, ALVINN would not know what to do if it starts going off the lane, so they programmed a data augmentation method by shearing the image left and right by 5 angles each, and the real human steering angle is shifted accordingly. In this way, each example is augmented to 11 examples.</p>
<p>In 1989, Navlab 1 burned when conditioning system leaked liquid onto the computers. Navlab 2 was built in 1990 based on a <a href="https://en.wikipedia.org/wiki/Humvee">Humvee</a>, which could drive both on-road (110 km/h) and off-road (10 km/h). Information about the subsequent Navlab cars is scarce, but from what I gathered, they were generally statistical methods on handcrafted features, without neural networks, learned features, and with only a minimum amount of online learning.</p>
<p>In 1995, Navlab 5 drove across continental America “No Hands Across America” autonomously for 98% of the time at average speed 100 km/h. However, little happened subsequent this – until 2004, when DARPA issued a <a href="https://en.wikipedia.org/wiki/DARPA_Grand_Challenge">Grand Challenge</a> for self-driving again. The Stanford Team that won in 2005 later became <a href="https://en.wikipedia.org/wiki/Waymo">Google Waymo</a>.</p>
</section>
<section id="demo-or-die" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="demo-or-die">Demo or die</h3>
<p>Well, remember that the planners wanted a demo of ALV every year. So how did the demos go?</p>
<p>A team at Martin Marietta Denver Aerospace was responsible for putting together the demos, and they called their vehicle “Alvin” (no relation to ALVINN). Like Navlab 1, the system essentially has two parts: the vision part, which extracts the shape of the road from the camera video, and the planner. Unlike Navlab 1, the planner was a sophisticated expert system that uses the road model output by the vision and its knowledge base (location, map, known objects, goal location, etc) to compute a driving plan.</p>
<blockquote class="blockquote">
<p>The knowledge base consists of a priori map data, and a set of routines for accessing the data. Currently, the map data contains information describing the road network being used as the ALV test track. The map data contains coordinates which specify the location of the roadway, as well as various significant features along the road, such as intersections, sharp curves, and several local road features.</p>
<p><span class="citation" data-cites="turkVITSaVisionSystem1988">(<a href="#ref-turkVITSaVisionSystem1988" role="doc-biblioref">Turk et al. 1988</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Alvin_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The architecture of Alvin. It has a low-level vision model and a high-level expert system planner. <span class="citation" data-cites="turkVITSaVisionSystem1988">(<a href="#ref-turkVITSaVisionSystem1988" role="doc-biblioref">Turk et al. 1988, fig. 1</a>, figure 3)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Alvin_scene_representation.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">How Alvin represents the road. <span class="citation" data-cites="turkVITSaVisionSystem1988">(<a href="#ref-turkVITSaVisionSystem1988" role="doc-biblioref">Turk et al. 1988, fig. 4</a>, figure 5)</span></figcaption>
</figure>
</div>
<p>Alvin’s vision system was plagued by the same problem of logical AI: fragility. Every time a part upgrades, something breaks. Much of the high-level planning was written to deal with the fragility of the vision system. If the high-level planner detects that the scene model output by the vision system is probably nonsense, it simply discard it. The endless trouble encountered by Alvin deserves quotation in full:</p>
<blockquote class="blockquote">
<p>The vision system proved highly sensitive to environmental conditions–the quality of light, the location of the sun, shadows, and so on. The system worked differently from month to month, day to day, and even test to test. Sometimes it could accurately locate the edge of the road, sometimes not. The system reliably distinguished the pavement of the road from the dirt on the shoulders, but it was fooled by dirt that was tracked onto the roadway by heavy vehicles maneuvering around the ALV. In the fall, the sun, now lower in the sky, reflected brilliantly off the myriads of polished pebbles in the tarmac itself, producing glittering reflections that confused the vehicle. Shadows from trees presented problems, as did asphalt patches from the frequent road repairs made necessary by the harsh Colorado weather and the constant pounding of the eight-ton vehicle.</p>
<p>Perhaps more alarming to the Martin engineers was the early realization that there would not be one all-purpose, road-following algorithm. Different situations required different programs. The first road-following algorithm that Maryland installed on the vehicle, the “vanishing point” algorithm, had functioned satisfactorily in the lab but not on the road. Under certain conditions the vehicle thought the road had folded back under itself. This algorithm had to be replaced by the “flat-earth” algorithm, so-called because it worked by using a two-dimensional representation of the road and assuming that the road was perfectly flat. The algorithm was quick to run, but it was relatively inaccurate, and, not surprisingly, it worked only on flat ground. The third program, the “hill-and-dale” algorithm, used a three-dimensional representation of the road. It functioned better on uneven ground, but it did not work on curves. Maryland came up with a fourth algorithm, the “zero-bank” algorithm, which solved this problem; but it ran too slowly on the vehicle’s computers and had to be put off until phase II of the program…</p>
<p>Other problems were caused just by the sheer complexity of the system. By the November 1985 demonstration, 25,000–30,000 lines of code were running in real time on ten different processors… Each new feature and capability brought with it a host of unanticipated problems. A new panning system, installed in early 1986 to permit the camera to turn as the road curved, unexpectedly caused the vehicle to veer back and forth until it ran off the road altogether. The software glitch was soon fixed, but the panning system had to be scrapped anyway; the heavy, 40-pound camera stripped the device’s gears whenever the vehicle made a sudden stop.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 234–35</a>)</span></p>
</blockquote>
<p>Given such serious problem, the team opted to just “study for the test”. Like the many demos before and since then, it promises to do much more than it could, using techniques much less general than it should.</p>
<blockquote class="blockquote">
<p>Given such unanticipated difficulties and delays, Martin increasingly directed its efforts toward achieving just the specific capabilities required by the milestones, at the expense of developing more general capabilities… Martin’s selection of technology was conservative. It had to be, as the ALV program could afford neither the lost time nor the bad publicity that a major failure would bring… ADS’s obstacle-avoidance algorithm was so narrowly focused that the company was unable to test it in a parking lot; it worked only on roads.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 235</a>)</span></p>
</blockquote>
<p>Though Alvin passed one demo after another, the “demo or die” approach resulted in a series of demos made by “ad-hoc, off-the-shelf solutions” that did not generalize, or integrate the other technologies developed in the SCI.</p>
<blockquote class="blockquote">
<p>The experience with ALV mirrored what was going on elsewhere in the SC program. The applications failed to connect with the technology base. Instead, applications extemporized ad-hoc, off-the-shelf solutions to meet demonstration deadlines. Meanwhile, the many research projects in the technology base rose and fell on their own merits. Mutually incompatible, they seldom achieved integration, let alone transition… Takeo Kanade… criticized the program as “too much demo-driven… Instead of integrating the technologies developed in the SC tech base… effort is spent ‘shopping’ for existing techniques which can be put together just for the sake of a demonstration.” Based on the recommendations of the panel, DARPA quietly abandoned the milestones and ended the ALV’s development program.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 243–45</a>)</span></p>
</blockquote>
</section>
<section id="general-ai-technologies" class="level3">
<h3 class="anchored" data-anchor-id="general-ai-technologies">General AI technologies</h3>
<p>SCI called for three fields of basic AI in support of the above applications: speech recognition, computer vision, and general integration of logical AI techniques. Only speech recognition was a success.</p>
<p>The aspiration of the speech recognition task was to allow pilots to speak to the computer, so it eventually had to recognize continuous speech with noise. DARPA released a benchmark of 21000 sentences from 160 speakers reading out sentences “appropriate to a naval resource management task built around existing interactive database and graphics programs” <span class="citation" data-cites="priceDARPA1000wordResource1988">(<a href="#ref-priceDARPA1000wordResource1988" role="doc-biblioref">Price et al. 1988</a>)</span>. This was one of the first public benchmarks, instilling a benchmark-centric culture around ASR early on. The HMM-based models, similar to those developed by Jelinek <em>et al</em> at IBM, reached the goal.</p>
<blockquote class="blockquote">
<p>Throughout the program, speech recognition held to its original goal of 10,000-word continuous speech recognition, using speaker-independent natural grammar, moderate noise, and low stress… Such systems were up and running by the end of SC, being integrated into military applications and undergoing development for commercial applications.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 211</a>)</span></p>
<p>In January 1986 Carnegie Mellon had demonstrated a speech system that could recognize 250 words spoken continuously regardless of the speaker. By 1987 this system could cope with a 1,000-word vocabulary with 95 percent accuracy, operating at 10 times real time on a parallel system. Texas Instruments produced a robust 200-word connected-speech-recognition system that was installed on F-16 fighters for operational testing by pilots.</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 224</a>)</span></p>
</blockquote>
<p>The aspiration of the vision task was to allow armored vehicles to drive through hostile environments autonomously. Among</p>
<p>TODO David Marr’s theory</p>
<blockquote class="blockquote">
<p>Developments in vision were far more disappointing. Part of the reason is that expectations at the beginning of SC were so high. Prior research on computer vision may be grouped in three eras. In the 1950s and 1960s techniques from signal processing and statistical decision theory produced important developments in areas such as Synthetic Aperture Radar, image-enhancement, and terrain-matching, cruise-missile guidance. These were essentially ad hoc inventions, innocent of a conceptual paradigm.</p>
<p>In the late 1970s, when DARPA was funding an image-understanding program aimed at photo interpretation, a “signals-to-symbols” paradigm gained currency. It was, however, a theory of low-level, general-purpose vision, limited essentially to two-dimensional analysis. Optimism that this limitation might be breached grew in the late 1970s, culminating in the 1982 publication of David Marr’s pathbreaking study, <em>Vision</em>, just as the SC plan was taking shape.</p>
<p>As Noam Chomsky had done for speech in the 1950s, Marr refined a new paradigm based on modeling visual cues such as shading, stereopsis, texture, edges, and color to arrive at what he called a “2-D sketch.” His theoretical models, combined with the magnified computing power of SC’s new architectures, suggested to many researchers that high-level vision was within reach, that a computer would soon employ standard algorithms to distill visual and other signals into machine understanding of what it was “seeing.”</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 212</a>)</span></p>
</blockquote>
<p>As for the general AI integration, the idea was similar to Shakey. Just like Shakey integrated the main logical AI techniques up to 1970, SCI called for integrating the main logical AI techniques up to 1980s. The SCI planners thought that the success of expert systems had shown that the time was ripe for a concerted push for a general expert system that combines the best ideas so far: blackboards (developed during the ARPA-funded speech understanding project), forward and reverse chaining, default reasoning, etc. This integration proved a failure, like the dream of a generally intelligent expert system. <span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 243</a>)</span></p>
<p>In 1990, funding for AI was killed, because the new director of SCI believed there is no unified AI principle, only particular AI systems demonstrating particular intelligences.</p>
<blockquote class="blockquote">
<p>In a cold and devastating review of “The Limits of Artificial Intelligence” prepared for the 1987 edition of The Encyclopedia of Artificial Intelligence, <a href="https://en.wikipedia.org/wiki/Jacob_T._Schwartz">[Jacob] Schwartz</a> had argued that AI had yet to demonstrate “any unifying principles of self organization,” meaning that its “applications must still be seen as adaptations of diverse ideas rather than as systematic accomplishments of a still mythical AI technology.” … he believed that expert systems were achieving what success they had by clever programming, not by the application of any general principles. His analysis bode ill for the prospects of achieving a generic expert system of the kind envisioned by the SC program and the contracts with Teknowledge and IntelliCorp. Indeed, Schwartz believed that the same critique applied to AI in general; he concluded that “it may be necessary to develop a relatively large number of artificial systems that mimic particular types of reasoning and mental functions in cases specialized enough to have particularly efficient treatment.”</p>
<p><span class="citation" data-cites="rolandStrategicComputingDARPA2002">(<a href="#ref-rolandStrategicComputingDARPA2002" role="doc-biblioref">Roland and Shiman 2002, 204–8</a>)</span></p>
</blockquote>
</section>
</section>
<section id="philosophy" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="philosophy">Philosophy</h2>
<p>Astrophysicists, measuring the motion of galaxies, notice that the stars are rotating too fast. There is not enough matter to tether them, and they ought to fly out into the intergalactic emptiness. To solve this problem, they proposed “dark matter”, unknown matter that provides the missing gravitational force, and physicists ever since had been searching them.</p>
<p>Similarly, sometimes when you read through a field of study, you notice that the arguments seem to rotate around some kind of unspoken assumption that you might see if you just take all the books and throw them to the ground, so that they are all opened at random places. Then you turn your head and squint at the words refracted through the eyelids, the pupils, and the cornea, which you have repurposed as a primitive kind of optical computer. And you see the dark matter, the intellectual centers of gravity.</p>
<blockquote class="blockquote">
<p>Under an invisible spell, they will each start out anew, only to end up revolving in the same orbit once again… their thinking is not nearly as much a discovery as it is a recognition, remembrance, a returning and homecoming into a distant, primordial, total economy of the soul, from which each concept once grew: – to this extent, philosophizing is a type of atavism of the highest order.</p>
<p><span class="citation" data-cites="nietzscheGoodEvilPrelude2002">(<a href="#ref-nietzscheGoodEvilPrelude2002" role="doc-biblioref">Nietzsche, Horstmann, and Norman 2002, sec. 1.20</a>)</span></p>
</blockquote>
<section id="the-symbolic-hypothesis" class="level3">
<h3 class="anchored" data-anchor-id="the-symbolic-hypothesis">The Symbolic Hypothesis</h3>
<p>In <a href="https://yuxi-liu-wired.github.io/docs/posts/1975-herbert-simon-allen-newell/">their Turing award lecture of 1975</a>, Allen Newell and Herbert Simon gave a definitive statement of the Physical Symbol System Hypothesis for AI, which they had labored under, first unconsciously but then consciously, since the early 1950s.</p>
<p>They began by some examples of “qualitative structure” in science, which do not deal with numbers, but with symbols. For example, a basic statement of cell theory – “organisms are made of little cells that are mostly alike” – doesn’t contain a single number, yet it has great significance. Such non-numerical discrete statements are made of “symbols”, and they stated their <strong>Physical Symbol System Hypothesis</strong> (PSSH):</p>
<blockquote class="blockquote">
<p>A physical symbol system has the necessary and sufficient means for general intelligent action.</p>
</blockquote>
<p>where a physical symbol system is essentially a machine that can be built in our physical world, and that manipulates with symbols. As an example, a digital computer running a LISP interpreter is a physical symbol system. We can attach cameras and wheels to the computer, so that the camera sends into the interpreter a symbolic representation of what it sees, and the wheels receives symbolic commands for motion. This is basically a robot according to the PSSH.</p>
<p>They also gave a <strong>Heuristic Search Hypothesis</strong>:</p>
<blockquote class="blockquote">
<p>A physical symbol system exercises its intelligence in problem solving by search-that is, by generating and progressively modifying symbol structures until it produces a solution structure.</p>
</blockquote>
<p>What is not said is equally revealing. In the lecture, there were over 100 mentions of the word “search”, but the only statement about learning is… a mention of Plato’s theory of <a href="https://en.wikipedia.org/wiki/Anamnesis_(philosophy)">anamnesis</a>! For them, a symbolic system starts out already with a solution generator and a solution tester, and problem-solving is nothing but heuristically searching over the generated solutions until one passes the tester. Indeed, in their telling, AI research is just search, not learning.</p>
<blockquote class="blockquote">
<p>… During the first decade or so of artificial intelligence research, the study of problem solving was almost synonymous with the study of search processes. From our characterization of problems and problem solving, it is easy to see why this was so. In fact, it might be asked whether it could be otherwise. … There is no mystery where the information that guided the search came from. We need not follow Plato in endowing the symbol system with a previous existence in which it already knew the solution. A moderately sophisticated generator-test system did the trick without invoking reincarnation.</p>
</blockquote>
</section>
<section id="cognitivism" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cognitivism">Cognitivism</h3>
<p>There was a persistent legend about a certain psychologist, that he educated his own children with <a href="https://en.wikipedia.org/wiki/Operant_conditioning_chamber">skinner boxes</a>. While just a legend, the real B. F. Skinner did have a philosophy as radical as the legend suggests.</p>
<p>In the 1950s, Skinner dominated behaviorism, which dominated American psychology. In short, behaviorism models animal behavior as stimulus-response reflexes, which can be understood as parameterized functions <span class="math inline">\(a_\theta(o)\)</span>, where <span class="math inline">\(o\)</span> stands for the observational stimulus, <span class="math inline">\(\theta\)</span> the internal parameters of the animal, and <span class="math inline">\(a_\theta(o)\)</span> the response action. The parameters <span class="math inline">\(\theta\)</span> is a function of the previous history of stimuli and reward/punishments: <span class="math inline">\((o_0, a_0, r_0, o_1, a_1, r_1, \dots)\)</span>. The set up is the same as modern reinforcement learning (RL).</p>
<p>The great thing about skinner boxes is that they are standardized to be lightproof, soundproof, and whatever-proof, thus controlling for all confounding variables. Before skinner boxes, mouse experiments were full of confounding variables, and had a kind of replication crisis in the 1930s. With the skinner box, the degrees of rat freedom are minimized, turning rats into standardized systems. This finally allowed measurable progress, allowing the breakout success of behaviorism in the 1950s.<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn31"><p><sup>31</sup>&nbsp;<a href="https://gwern.net/maze">Feynman told of the following maze-running rat legend</a>:</p>
<blockquote class="blockquote">
<p>He had a long corridor with doors all along one side where the rats came in, and doors along the other side where the food was. He wanted to see if he could train the rats to go in at the third door down from wherever he started them off. No.&nbsp;The rats went immediately to the door where the food had been the time before. The question was, how did the rats know, because the corridor was so beautifully built and so uniform, that this was the same door as before? Obviously there was something about the door that was different from the other doors. So he painted the doors very carefully, arranging the textures on the faces of the doors exactly the same. Still the rats could tell. Then he thought maybe the rats were smelling the food, so he used chemicals to change the smell after each run. Still the rats could tell. Then he realized the rats might be able to tell by seeing the lights and the arrangement in the laboratory like any commonsense person. So he covered the corridor, and, still the rats could tell. He finally found that they could tell by the way the floor sounded when they ran over it. And he could only fix that by putting his corridor in sand. So he covered one after another of all possible clues and finally was able to fool the rats so that they had to learn to go in the third door. If he relaxed any of his conditions, the rats could tell.</p>
</blockquote>
</div></div><p>Skinner’s ambitions went far beyond rats. In 1957, he published <a href="https://en.wikipedia.org/wiki/Verbal_Behavior"><em>Verbal Behavior</em></a>, in which he explained human language as stimulus-response networks, built up piece by piece during child development. To give an example, when one searches for a book with a title “Verbal Behavior”, one would say “Verbal Behavior, Verbal Behavior, Verbal Behavior…” (a “self-echoic”) while the eye scans the shelf. When the visual stimulus matches the verbal stimulus, the “grab book” action is triggered (a “tact”). The touch of the hand with the book then stops self-echoic behavior. In Skinner’s terms, this verbal behavior is a “<a href="https://en.wikipedia.org/wiki/Autoclitic">descriptive autoclitic</a>”.</p>
<p>He was at his most radical in <a href="https://en.wikipedia.org/wiki/Beyond_Freedom_and_Dignity"><em>Beyond Freedom and Dignity</em> (1971)</a>, which essentially argued that human society will be reorganized according to behaviorist principles. Instead of the indirect and unreliable behavior control using verbal moral judgment, a society would use more direct operant conditioning methods that are experimentally proven by behaviorist psychologists.</p>
<p>Though behaviorism has remained alive and well to this day, linguistics took a sudden turn around 1960 thanks to Noam Chomsky. According to legend, Chomsky wrote a review of <em>Verbal Behavior</em> in 1959, in which he soundly routed behaviorist linguistics <span class="citation" data-cites="chomskyReviewSkinnersVerbal1959">(<a href="#ref-chomskyReviewSkinnersVerbal1959" role="doc-biblioref">Chomsky 1959</a>)</span>. The truth is more complicated, since Chomsky also wrote several other famous works like <a href="https://en.wikipedia.org/wiki/Syntactic_Structures"><em>Syntactic Structures</em> (1957)</a>, <a href="https://en.wikipedia.org/wiki/Aspects_of_the_Theory_of_Syntax"><em>Aspects of the Theory of Syntax</em> (1967)</a>, and the foundational papers on formal grammar like the <a href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">Chomsky hierarchy</a>.</p>
<p>Chomsky argued that there are two ways of doing research in psychology and linguistics: “empiricism” and “rationalism”. Skinner’s book was the best example of empiricism, and since Skinner’s book is wrong, the book becomes a <em>reductio ad absurdum</em> of empiricism. Instead, one must turn back to rationalist psychology and linguistics.</p>
<blockquote class="blockquote">
<p>I had intended this review not specifically as a criticism of Skinner’s speculations regarding language, but rather as a more general critique of behaviorist (I would now prefer to say “empiricist”) speculation as to the nature of higher mental processes… I do not, in other words, see any way in which his proposals can be substantially improved within the general framework of behaviorist or neobehaviorist, or, more generally, empiricist ideas that has dominated much of modern linguistics, psychology, and philosophy. The conclusion that I hoped to establish in the review, by discussing these speculations in their most explicit and detailed form, was that the general point of view was largely mythology, and that its widespread acceptance is not the result of empirical support, persuasive reasoning, or the absence of a plausible alternative.</p>
<p>– Preface to the 1967 reprint. <span class="citation" data-cites="chomskyReviewBFSkinners1967">(<a href="#ref-chomskyReviewBFSkinners1967" role="doc-biblioref">Chomsky 1967</a>)</span></p>
</blockquote>
<p>What is wrong with empiricism? Fundamentally, Chomsky’s argument is based on two properties that every human language has:</p>
<ul>
<li>Infinity: There exists infinitely many grammatical sentences, and infinitely many ungrammatical sentences.</li>
<li>Generativity: Humans can agree with each other whether a never-before-seen sentence is grammatical or ungrammatical.</li>
</ul>
<p>Plato observed that, though we have only seen imperfect geometric shapes, we have a concept of perfect circles, triangles and so on. He inferred from this that we are born with the ideal concepts within us, to be matched against imperfect shapes out there. Similarly, Chomsky argued that we are born with the ideal Universal Grammar within us, to be matched against the language observations in the world.</p>
<p>For example, in the Universal Grammar, there is a setting called “subject-verb-object order”, with 6 possible values: SVO, SOV, …, OVS. An infant need only observe a few dozen sentences to fix this setting. Chomsky extended this project to all of natural language grammar.</p>
<p>Chomsky made a multi-pronged rejection of empiricism:</p>
<ul>
<li>Poverty of stimulus: Humans learn language with just a few years of language instruction. This is impossible if they “start from scratch”. Thus, they have a lot of inborn grammar.</li>
<li>Colorless green ideas sleep furiously: Because there are many meaningless but grammatical sentences, grammar is independent of meaning. Thus, grammar, unlike meaning, can be a small closed system that fits inside a brain at birth.</li>
<li>Probability is meaningless: A sentence is either grammatical or not. THere is no in-between. Therefore it is meaningless to talk about the “probability of a sentence” like the empiricists.</li>
<li>Impersonal abstraction: Real humans can make mistakes, but language itself makes no mistake. A tired human might say “Ideas sleep furiously.” is ungrammatical 10% of the times, but the English language <em>itself</em> would always say it is grammatical. Thus, the probabilities measured from real human behavior is meaningless for theoretical linguistics.</li>
<li>Competence, not performance: Even if an empirical model of language, like the HMM, works 99% of the times, a single counterexample disproves it. To work “most of the times” is performance. To work all the time is competence. Linguistic science is about competence, and performance is sufficient only for engineering. Competence either/or, while performance is usually/rarely. Linguistics is about competence, and performance is left for the psychologists and engineers.</li>
</ul>
<p>The 60 years afterwards have been one long struggle against empiricism along these lines. For example, he had repeatedly simplified the Universal Grammar down to the minimalist core, so that it could possibly fit inside a single gene that appeared once in the evolution of humans, “switching on” language for humans and no other species. And by “60 years”, I meant it. He was nothing if not consistent:</p>
<blockquote class="blockquote">
<p>Evidently, one’s ability to produce and recognize grammatical utterances is not based on notions of statistical approximation and the like… a structural analysis cannot be understood as a schematic summary developed by sharpening the blurred edges in the full statistical picture… that grammar is autonomous and independent of meaning, and that probabilistic models give no particular insight into some of the basic problems of syntactic structure.</p>
<p><span class="citation" data-cites="chomskySyntacticStructures1957">(<a href="#ref-chomskySyntacticStructures1957" role="doc-biblioref">Chomsky 1957, 16–17</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>But it must be recognized that the notion of “probability of a sentence” is an entirely useless one, under any known interpretation of this term.</p>
<p><span class="citation" data-cites="chomskyEmpiricalAssumptionsModern1969">(<a href="#ref-chomskyEmpiricalAssumptionsModern1969" role="doc-biblioref">Chomsky 1969</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>It’s true there’s been a lot of work on trying to apply statistical models to various linguistic problems. I think there have been some successes, but a lot of failures. There is a notion of success … which I think is novel in the history of science. It interprets success as approximating unanalyzed data.</p>
<p>Chomsky at the MIT150: Brains, Minds and Machines Symposium (2011), quoted in <span class="citation" data-cites="norvigChomskyTwoCultures2017">(<a href="#ref-norvigChomskyTwoCultures2017" role="doc-biblioref">Norvig 2017</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>Well, first we should ask the question whether large language models have achieved anything, anything, in this domain? Answer: No! They’ve achieved zero… GPT-4 is coming along, which is supposed to going to have a trillion parameters. It will be exactly the same. It’ll use even more energy and achieve exactly nothing, for the same reasons. So there’s nothing to discuss.</p>
<p><a href="https://whimsical.com/question-1-large-language-models-such-as-gpt-3-DJmQ8R5kD8tqvsXxgCN9vK">Machine Learning Street Talk: The Ghost in the Machine and the Limits of Human Understanding (2022)</a></p>
</blockquote>
<p>Knowing his framework, we understand why he rejected both statistical models like n-grams or neural models like GPT-3 as “zero” in terms of advancing theoretical linguistics. They are empirically constructed: thousands of researchers were just trying things out, and eventually they started to work. Worse, both kinds of models assign <em>nothing but</em> probabilities to sentences!</p>
<p>When engaging with the modern Chomskyans (they still exist!), one notices a strategic ambiguity on the edge of competence vs performance. On one hand, Chomsky has simply defined scientific linguistics to be the study of language and competence. That is, he made the following kind of definition:</p>
<ul>
<li>Language is a kind of mathematical object with associated transformations of it (such as the transformation that converts a verb to a past tense).</li>
<li>A person or a computer, has competence for a language iff it can perform the correct transformations on a language object.</li>
<li>Scientific linguistics is the study of languages, and how competence is implemented in various algorithms.</li>
</ul>
<p>Chomsky’s definition deliberately draws a line between competence and performance. However, this line immediately gets crossed, because even immortals cannot subsist on only aether. Chomskyan scientific linguistics, to be scientific, still needs to gather empirical data and predict outcomes of empirical experiments, and thus was Chomsky able to influence AI developments, by an implicit empirical claim: “Building an AI like a generative grammar is how you get good empirical performance.”</p>
<p>Chomskyans have long engaged with AI. There have been Chomskyan language models, but the idea is very different. When Chomskyans do a language model, it is a scientific experiment to test a linguistic theory. If a program written according to a <a href="https://en.wikipedia.org/wiki/Merge_(linguistics)">merge-grammar</a> of verbs can convert verbs to the past tense correctly (on a small example of 200 verbs), then that shows merge-grammar theory of verbs is a good theory. The n-gram language model is <em>trivially</em> disproven,<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a> so even if an n-gram model achieves better performance according to the entropy, all a Chomskyan needs to do is point at that theorem, and say, “That’s not science, that’s engineering.”.</p>
<div class="no-row-height column-margin column-container"><div id="fn32"><p><sup>32</sup>&nbsp;The short explanation: English is not a regular language, so it can’t be modeled by a Markov chain.</p>
<p>The slightly longer explanation: English has <a href="https://en.wikipedia.org/wiki/Center_embedding">center embedding</a>, so English cannot be parsed by any finite state machine, while n-gram models are probabilistic finite state machines (aka Markov chains). Now prove the following theorem: If a language is not parsable by a finite state machine, then for any Markov model for the language, there exists sentences <span class="math inline">\(s_1, s_2, \dots\)</span> in the language, such that <span class="math inline">\(\lim_{n \to \infty} Pr(s_n) = 0\)</span>. To show this, prove that there exists arbitrarily long sentences that are so long that the Markov chain “forgets where it was”. The argument is similar to the <a href="https://en.wikipedia.org/wiki/Pumping_lemma_for_regular_languages">pumping lemma for regular languages</a>.</p></div><div id="fn33"><p><sup>33</sup>&nbsp;Some critics of recent large models, like Ted Chiang’s “blurry jpeg of the Internet”, and Emily Bender’s “stochastic parrot”, are analogous to the Chomskyan critique of “success as approximating unanalyzed data”. And Gary Marcus has been a committed Chomskyan since the 1990s, so analyzing his criticisms of AI in the Chomskyan framework is left as an exercise for the reader. Indeed, they had been much less circumspect compared to Chomsky, since they had been predicting the imminent <em>empirical</em> failure of large models at performance because of their lack of <em>rational</em> competence.</p></div></div><p>Now, when Chomsky took a look at GPT-4, all he saw was another “success as approximating unanalyzed data”, a <em>reductio ad absurdum</em> of empiricism at the price of $100 million. So there’s nothing to discuss.<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a></p>
<p>The influence of Chomsky had been immense, both in linguistics and psychology. Chomskyan linguistics is the theoretical foundation to early MT systems like Vanquois’ (TODO). In psychology, his approach became “cognitivism” TODO</p>
<table class="caption-top table">
<caption><span class="citation" data-cites="churchIntroductionSpecialIssue1993">(<a href="#ref-churchIntroductionSpecialIssue1993" role="doc-biblioref">K. W. Church and Mercer 1993</a>, Table 5)</span></caption>
<colgroup>
<col style="width: 28%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Rationalism</th>
<th>Empiricism</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Well-known Advocates:</td>
<td>Noam Chomsky, Marvin Minsky</td>
<td>Claude Shannon, B. F. Skinner, J. R. Firth, Zellig Harris</td>
</tr>
<tr class="even">
<td>Model:</td>
<td>Competence Model</td>
<td>Noisy Channel Model</td>
</tr>
<tr class="odd">
<td>Contexts of Interest:</td>
<td>Phrase Structure</td>
<td>N-grams</td>
</tr>
<tr class="even">
<td>Goals:</td>
<td>All and Only</td>
<td>Minimize Prediction Error (Entropy)</td>
</tr>
<tr class="odd">
<td></td>
<td>Explanatory</td>
<td>Descriptive</td>
</tr>
<tr class="even">
<td></td>
<td>Theoretical</td>
<td>Applied</td>
</tr>
<tr class="odd">
<td>Linguistic Generalizations:</td>
<td>Agreement and</td>
<td>Collocations and Word Associations</td>
</tr>
<tr class="even">
<td></td>
<td>Wh-movement</td>
<td></td>
</tr>
<tr class="odd">
<td>Parsing Strategies:</td>
<td>Principle-Based</td>
<td>Preference-Based</td>
</tr>
<tr class="even">
<td></td>
<td>CKY (Chart), ATNs,</td>
<td>Forward-Backward, Inside-Outside</td>
</tr>
<tr class="odd">
<td></td>
<td>Unification</td>
<td></td>
</tr>
<tr class="even">
<td>Applications:</td>
<td>Understanding</td>
<td>Recognition</td>
</tr>
<tr class="odd">
<td></td>
<td>Who did what to whom</td>
<td>Noisy Channel Applications</td>
</tr>
</tbody>
</table>
<p>Outside of linguistics and abstract science, Chomskyan ideas appeared as “<a href="https://en.wikipedia.org/wiki/Structuralism">structuralism</a>” of <a href="https://en.wikipedia.org/wiki/Claude_L%C3%A9vi-Strauss">Claude Lévi-Strauss</a>. As an example, the Kareira society was divided into 4 sections: Banaka (0), Karimera (1), Burung (2), Palyeri (3). A Banaka man can only marry a Palyeri woman, and their children will be Karimera. In total, we have a table:</p>
<table class="caption-top table">
<caption>Kareira kinship system</caption>
<thead>
<tr class="header">
<th>father</th>
<th>mother</th>
<th>child</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="even">
<td>1</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1</td>
<td>3</td>
</tr>
<tr class="even">
<td>3</td>
<td>0</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>This structure has the following good properties: - Exogamy. - Equal women exchange. Sections 0 and 3 exchange women. Sections 1 and 2 exchange women. - Equal child exchange. Sections 1 and 0 exchange children in the sense that a man in section 1 would have children in section 0, and vice versa. The same for 2 and 3. - Stable over time.</p>
<p>Lévi-Strauss found many such recurring structures across human societies, and proposed to analyze human mythologies with the same method as well (a pinnacle example was <a href="https://en.wikipedia.org/wiki/The_Hero_with_a_Thousand_Faces"><em>The Hero with a Thousand Faces</em></a> which literally proposed a single structure for all human mythologies). This then got picked up by sociologists and commentators, followed by the “post-structuralists” who had even less to contribute to AI than Dreyfus.</p>
</section>
<section id="the-sub-symbolic-hypothesis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-sub-symbolic-hypothesis">The Sub-symbolic Hypothesis</h3>
<blockquote class="blockquote">
<p>… we had two major misconceptions: first, that learning is a <em>problem</em> rather than a <em>solution</em>. If back at the beginning you asked an AI researcher what the major problem areas in the field were, they would have listed computer vision, inference, knowledge representation, understanding language, … and learning. You would no more set out to translate between languages by writing a program to learn how to do so than you would create a rocket that learned to go to the moon. When put that way, it seems like common sense, but it is wrong. Our second big mistake was our allegiance to the physical symbol hypothesis… Newell and Simon were the first to state this explicitly, but … virtually everyone believed it at that time–certainly your author.</p>
<p><span class="citation" data-cites="charniakAIIntellectualHistory2024">(<a href="#ref-charniakAIIntellectualHistory2024" role="doc-biblioref">Charniak 2024</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>AI research has foundered in a sea of incrementalism. No one is quite sure where to go save improving on earlier demonstrations of techniques in symbolic manipulation of ungrounded representations. At the same time, small AI companies are folding, and attendance is well down at national and international AI conferences… the <em>it symbol system hypothesis</em> upon which <em>it classical AI</em> is based is fundamentally flawed… Traditional AI has tried to demonstrate sophisticated reasoning in rather impoverished domains. The hope is that the ideas used will generalize to robust behavior in more complex domains. Nouvelle AI tries to demonstrate less sophisticated tasks operating robustly in noisy complex domains. The hope is that the ideas used will generalize to more sophisticated tasks.</p>
<p><span class="citation" data-cites="brooksElephantsDonPlay1990">(<a href="#ref-brooksElephantsDonPlay1990" role="doc-biblioref">Brooks 1990</a>)</span></p>
</blockquote>
<p>The dominance of the Symbolic Hypothesis was never complete. There were often objections to it.</p>
<p>In 1972, Hubert Dreyfus raised a fuss with a book <em>What Computers Can’t Do: The Limits of Artificial Intelligence</em>. Unfortunately, his work was based on the phenomenology of Merleau-Ponty and Heidegger, who wrote like <em>real and genuine</em> philosophers,<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a> so I just resorted to checking <a href="https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence">his Wikipedia article</a>. From what I gathered, his argument was that the Symbolic Hypothesis is flawed in the sense that it is too “closed”.</p>
<div class="no-row-height column-margin column-container"><div id="fn34"><p><sup>34</sup>&nbsp;Edward Feigenbaum’s reaction is representative of most AI scientists:</p>
<blockquote class="blockquote">
<p>What artificial intelligence needs is a good Dreyfus. The conceptual problems in AI are really rough, and a guy like that could be an enormous help… But Dreyfus bludgeons us over the head with stuff he’s misunderstood and is obsolete anyway – and every time you confront him with one more intelligent program, he says, “I never said a computer couldn’t do that.” And what does he offer us instead? Phenomenology! That ball of fluff! That cotton candy! <span class="citation" data-cites="mccorduckMachinesWhoThink2004">(<a href="#ref-mccorduckMachinesWhoThink2004" role="doc-biblioref">McCorduck 2004, 229–30</a>)</span></p>
</blockquote>
</div></div><p>Fortunately, before I gave up, someone pointed me to a better, previous report <span class="citation" data-cites="dreyfusAlchemyArtificialIntelligence1965">(<a href="#ref-dreyfusAlchemyArtificialIntelligence1965" role="doc-biblioref">Dreyfus 1965</a>)</span>:</p>
<blockquote class="blockquote">
<p>having read “Alchemy and Artificial Intelligence” for this investigation… It seems to me that Dreyfus’ 1965 critiques of 1960s AI approaches were largely correct, for roughly the right reasons, in a way that seems quite impressive in hindsight… Dreyfus’ arguments are inspired by his background in phenomenological philosophy, but he expresses his arguments in clear and straightforward language… the AI community hardly responded to Dreyfus’ critique at all – and when they did, they often misrepresented his claims and arguments in ways that are easy to detect if one merely checks Dreyfus’ original report.</p>
<p><span class="citation" data-cites="muehlhauserWhatShouldWe2016">(<a href="#ref-muehlhauserWhatShouldWe2016" role="doc-biblioref">Muehlhauser 2016</a>)</span></p>
</blockquote>
<p>With that, I managed to understand Dreyfus’ argument clearly. His main point is that logical AI, exemplified by Simon and Newell’s GPS, cannot reach human-level reasoning, because logical AI cannot perform 3 fundamental human forms of information processing: fringe consciousness, essence/accident discrimination, and ambiguity tolerance. These require brain-like computers to perform.</p>
<ul>
<li>Fringe consciousness: Chess players do not analyze positions like the GPS. Whereas the GPS performs a unified heuristic search, chess players seem to unconsciously scan a large number of positions, making some variations seem salient, which they then consciously “count out”. The unconscious scanning is <em>not</em> search, since otherwise why not perform unconscious search all the way to the finish line? The conscious “counting out” is captured by the GPS, but the unconscious “zeroing in” is not.</li>
<li>Essence/accident discrimination: Even on simple, well-defined problems like cryptogram puzzles, the GPS and humans reason very differently. Humans can simplify problems with symmetry like “for basically the same reason…”, and backtrack based on an understanding of the overall problem structure. Even Simon and Newell have labelled their human subjects’ reasoning steps as either “essential” or “inessential”. GPS solves a problem like humans do only if the programmers have so helpfully pre-structured the problem with the essential features. These all show that human reasoning distinguishes some as essential while others as accidental, and focuses their conscious problem solving over the essential features, something GPS cannot do.</li>
<li>Ambiguity tolerance: So far, machine translation and language understanding research had only worked on highly artificial and restricted domains, since none of them could handle the ambiguity in natural language. Humans can handle this massive ambiguity because humans process language not according to precise rules, but by unconscious processing that statistically combines context, goals, and background knowledge, and produces <em>precise enough</em> outputs.</li>
</ul>
<p>From our vantage point, chess ended up falling to the heuristic search of DeepBlue, but Go did require combining “fringe consciousness” with heuristic search in the CNN+MCTS architecture of AlphaGo. The three forms of information processing he singled out as requiring brain-like computing turned out to be precisely where neural networks achieved breakout success. Of course, the logical AI camp would not go down without a fight, and with “Parallel Distributed Processing” – the revival of neural networks in 1980s – there would be a bitter dispute, centered around, of all things, how to form the past tense of English verbs.<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn35"><p><sup>35</sup>&nbsp;Having checked out his latest writing, we regret to inform thee that he was a blind cat that caught a mice by an accidental swipe of the paw, but then starved to death by doing it again and again. He simply did not believe AI was possible at all, that human intelligence requires human existence (really showing off his existentialist colors there), and <em>all</em> apparent progress in AI are like climbing a tree and claiming progress on landing on the moon.</p>
<blockquote class="blockquote">
<p>The commonsense knowledge problem, which as Minsky says, stopped AI in the early 70ies, has never been solved; except for Lenat it has just been ignored. Yet Chalmers assumes incremental progress and confidently asserts that “Given the way that computer technology always advances, it is natural enough to think that once there is AI, AI? will be just around the corner.” But that just is the first step fallacy. AI is always just round the corner but, as Chalmers himself admits, never succeeds in turning that corner. There is, in fact, <em>no reason to think that we are making progress towards AI or, indeed, that AI is even possible, in which case claiming incremental progress towards it would make no sense.</em></p>
<p><span class="citation" data-cites="dreyfusHistoryFirstStep2012">(<a href="#ref-dreyfusHistoryFirstStep2012" role="doc-biblioref">Dreyfus 2012</a>)</span></p>
</blockquote>
</div><div id="fn36"><p><sup>36</sup>&nbsp;This example was given by Anatol Holt at ARPA Principal Investigators’ Conference in 1974, and quoted in <span class="citation" data-cites="winograd10ThinkingMachines1991">(<a href="#ref-winograd10ThinkingMachines1991" role="doc-biblioref">Winograd 1991</a>)</span>:</p>
<blockquote class="blockquote">
<p>A brilliant chess move while the room is filling with smoke because the house is burning down does not show intelligence. If the capacity for brilliant chess moves without regard to life circumstances deserves a name, I would naturally call it “artificial intelligence.”</p>
</blockquote>
</div></div><p><a href="https://en.wikipedia.org/wiki/Douglas_Hofstadter">Douglas Hofstadter</a> raised a similar objection, but from within the logical AI tradition. His essential point was that logical AI, as conceived by Simon and Newell, is a closed system. For example, a chess computer might play a perfect chess even when the room is on fire. The concept of fire, or indeed anything that is beyond the mathematical strucure of chess, does not feature in the computer’s symbolic universe, and so it does not exist for the computer.<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a> Whereas Dreyfus argued that intelligence is open by the “cotton candy” of phenomenology, sieging the head from the outside in, Hofstadter used the Gödel incompleteness theorems to break the head open, from the inside out.</p>
<p>The rough idea is that any symbolic system that is powerful enough would be incomplete, and furthermore, would “reflect” its own incompleteness. The incompleteness theorems state that in any sufficiently powerful formal system, there are statements that are true about the system that cannot be proven within the system. For example, let <span class="math inline">\(\Sigma\)</span> be the logical system of Peano arithmetics, then by the incompleteness theorems, there are sentences like <a href="https://en.wikipedia.org/wiki/Rosser%27s_trick">Rosser’s sentence</a>, or “PA is consistent”, which are <em>provably unprovable</em> assuming PA is consistent.</p>
<p>Stated in another way, arithmetical truth cannot be defined in arithmetic – <a href="https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem">Tarski’s undefinability</a>.</p>
<blockquote class="blockquote">
<p>O God, I could be bounded in a nut shell and count myself a king of infinite space, were it not that I have bad dreams.</p>
<p>— Hamlet, Act 2, Scene 2</p>
</blockquote>
<p>In the context of AI, this means that a symbolic system, no matter how complex, will always have limitations in representing and reasoning about the world, even if the world is but itself. We need not assume there is an “outside”. The symbolic system, even when floating in a mathematical vacuum, creates its own outside.</p>
<p>His solution was to add in some “strange loops”, which would both create general intelligence and create consciousness in one fell swoop. These strange loops are hierarchical structures where crossing levels leads back to the starting point. In the context of AI, Hofstadter proposed that implementing strange loops within a symbolic system would allow the system to refer to itself and its own structure, potentially leading to self-awareness and general intelligence. This self-referential capability would enable the system to overcome the limitations imposed by the incompleteness theorems and exhibit more flexible and human-like intelligence.</p>
<p>Hofstadter was a far better writer than Dreyfus, and his 1979 book <em>Gödel, Escher, Bach</em> was a popular hit among both the common people and the computer scientists. Despite this, the trajectory of AI did not go as he expected.</p>
<blockquote class="blockquote">
<p>There may be programs which can beat anyone at chess, but they will not be exclusively chess players. They will be programs of general intelligence, and they will be just as temperamental as people. “Do you want to play chess?” “No, I’m bored with chess. Let’s talk about poetry.” <span class="citation" data-cites="hofstadterGodelEscherBach1999">(<a href="#ref-hofstadterGodelEscherBach1999" role="doc-biblioref">Hofstadter 1999, 678</a>)</span></p>
</blockquote>
<p>In the preface to the second edition (1999), Hofstadter admitted that this prediction went way off, but still committed to the philosophical belief behind these. Unfortunately, the disappointments did not stop coming. In</p>
<p>With the rise of Transformer-based language models, . He expressed his confusion and traumatic response in a 2023 interview:</p>
<blockquote class="blockquote">
<p>[In 1960,] I knew how computers worked, and I knew how extraordinarily rigid they were. You made the slightest typing error and it completely ruined your program… It felt as if artificial intelligence was the art of trying to make very rigid systems behave as if they were fluid… I felt it would be hundreds of years before anything even remotely like a human mind would be asymptotically approaching the level of the human mind, but from beneath… But when certain systems started appearing maybe 20 years ago, they gave me pause. And then this started happening at an accelerating pace where unreachable goals and things that computers shouldn’t be able to do started toppling. The defeat of Gary Kasparov by Deep Blue, and then going on to Go systems, systems that could defeat some of the best Go players in the world. And then systems got better and better at translation between languages and then at producing intelligible responses to difficult questions in natural language, and even writing poetry.</p>
<p>My whole intellectual edifice, my system of beliefs–it’s a very traumatic experience when some of your most core beliefs about the world start collapsing… I think about it practically all the time, every single day… and it overwhelms me and depresses me in a way that I haven’t been depressed for a very long time.</p>
<p><a href="https://www.buzzsprout.com/222312/episodes/13125914">Reflections on AI</a>, interview with Douglas Hofstadter by Amy Jo Kim (2023-06-29)</p>
</blockquote>
</section>
<section id="statistical-learning-theory" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="statistical-learning-theory">Statistical learning theory</h3>
<p>In the 1960s, Vladimir Vapnik was working on a Ph.D.&nbsp;in statistics, but due to multiple political problems, he was forced to withdraw the thesis and republish it as a book, in which he laid out his vision of statistical learning theory.</p>
<blockquote class="blockquote">
<p>From the KGB’s point of view I was a wrong person to obtain the doctoral level: I was not a member of the Communist Party, I was Jewish, my PhD adviser, Alexander Lerner, had applied for immigration to Israel and became a “refusenik,” some of my friends were dissidents, and so on… The main message that I tried to deliver in the book was that classical statistics could not overcome the curse of dimensionality but the new approach could. I devoted three chapters of the book to different classical approaches and demonstrated that none of them could overcome the curse of dimensionality. Only after that did I describe the new theory.</p>
<p><span class="citation" data-cites="vapnikEstimationDependencesBased2006">(<a href="#ref-vapnikEstimationDependencesBased2006" role="doc-biblioref">Vapnik 2006</a>)</span></p>
</blockquote>
<p>In short, Vapnik’s theory is to on the one hand, minimize the training loss (“empirical risk minimization”) by any statistical model, but on the other hand, avoid overfitting by controlling capacity (“VC dimension”) of the model. This was a radical departure from the previous kind of “classical statistics”, which, while not Chomskyan, was very close in spirit.</p>
<blockquote class="blockquote">
<ol type="1">
<li><p>There is a group of philosophers who believe that the results of scientific discovery are the real laws that exist in nature. These philosophers are called the realists.</p></li>
<li><p>There is another group of philosophers who believe the laws that are discovered by scientists are just an instrument to make a good prediction. The discovered laws can be very different from the ones that exist in Nature. These philosophers are called the instrumentalists.</p></li>
</ol>
<p>The two types of approximations defined by classical discriminant analysis (using the generative model of data) and by statistical learning theory (using the function that explains the data best) reflect the positions of realists and instrumentalists in our simple model of the philosophy of generalization, the pattern recognition model. Later we will see that the position of philosophical instrumentalism played a crucial role in the success that pattern recognition technology has achieved.</p>
<p>[vapnikEstimationDependencesBased2006, page 415]</p>
</blockquote>
<p>Vapnik’s books were chock-full of philosophical musings, now rarely read. Leo Breiman’s philosophical musings, however, has remained famous. As a reference to <a href="https://en.wikipedia.org/wiki/The_Two_Cultures">C. P. Snow’s “Two Cultures” lecture of 1959</a>, Breiman wrote <span class="citation" data-cites="breimanStatisticalModelingTwo2001">(<a href="#ref-breimanStatisticalModelingTwo2001" role="doc-biblioref">Breiman 2001</a>)</span> to contrast the “data modeling culture” with the “algorithmic modeling culture”.</p>
<p>The data modeling culture first constructs a <a href="https://en.wikipedia.org/wiki/Generative_model">generative model</a> of the data with a few parameters <span class="math inline">\(\theta\)</span>, then construct <a href="https://en.wikipedia.org/wiki/Estimator">ways to estimate</a> <span class="math inline">\(\theta\)</span> from data, with provable guarantees. This culture includes both the frequestists and the Bayesians.</p>
<p>On the plus side, a generative model with a few parameters is easy to interpret. On the minus side, if the statistician were to interpret parameters subsequently,<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a> then the parameters had better mean something real, which requires the model to be close to reality. That is, the price for interpretability is eternal vigilance (against model misspecification).</p>
<div class="no-row-height column-margin column-container"><div id="fn37"><p><sup>37</sup>&nbsp;One can easily check this by opening a journal in economics or medicine and look at the “results” section of some papers. There one would find parameters decorated with error bars, followed by policy recommendations, such as “Since <span class="math inline">\(\theta_{6} &gt; 0\)</span> with statistical significance, we conclude that elevating melatonin has a positive impact…”. If <span class="math inline">\(\theta\)</span> in this imaginary example is used in a data model like <span class="math inline">\(y = \sum_i \theta_i x_i + \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is noise, then for the sake of this imaginary author, the real biological response of the human had better be sufficiently linear to <span class="math inline">\(x_1, x_2, \dots\)</span>, at least for those <span class="math inline">\(x\)</span> within the therapeutic range.</p></div></div><blockquote class="blockquote">
<p>This enterprise has at its heart the belief that a statistician, by imagination and by looking at the data, can invent a reasonably good parametric class of models for a complex mechanism devised by nature… If the model is a poor emulation of nature, the conclusions may be wrong. These truisms have often been ignored in the enthusiasm for fitting data models. A few decades ago, the commitment to data models was such that even simple precautions such as residual analysis or goodness-of-fit tests were not used.</p>
</blockquote>
<p>The algorithmic modeling culture in contrast is very empirical – if it works on the training set, and if statistical learning theory predicts that its train-test gap is low (“capacity control” again), then it works. Data modeling culture was stuck with generative models, unable to use tools that work despite not interpretable as generative models – random forests, boosting, bagging, neural networks, all the latest algorithms popping up in the 1990s.</p>
<p>Among the many replies to this bombshell of an editorial, <a href="https://en.wikipedia.org/wiki/David_Cox_(statistician)">David Cox</a> went directly for the philosophical:</p>
<blockquote class="blockquote">
<p>Professor Breiman takes a rather defeatist attitude toward attempts to formulate underlying processes; is this not to reject the base of much scientific progress?</p>
</blockquote>
<p>Whereas <a href="https://en.wikipedia.org/wiki/Bradley_Efron">Bradley Efron</a> was like “hopefully you are just playing devil’s advocate”:</p>
<blockquote class="blockquote">
<p>A third front seems to have been opened in the long-running <a href="https://en.wikipedia.org/wiki/Foundations_of_statistics#Bayesian_inference_versus_frequentist_inference">frequentist-Bayesian wars</a> by the advocates of algorithmic prediction, who don’t really believe in any inferential school… The whole point of science is to open up black boxes, understand their insides, and build better boxes for the purposes of mankind. Leo himself is a notably successful scientist, so we can hope that the present paper was written more as an advocacy device than as the confessions of a born-again black boxist.</p>
</blockquote>
<p>TODO</p>
</section>
<section id="connectionism-the-past-tense-debate-and-whatever" class="level3">
<h3 class="anchored" data-anchor-id="connectionism-the-past-tense-debate-and-whatever">Connectionism, the past tense debate, and whatever</h3>
<p><span class="citation" data-cites="bermudezCognitiveScienceIntroduction2020">(<a href="#ref-bermudezCognitiveScienceIntroduction2020" role="doc-biblioref">Bermúdez 2020, chap. 10</a>)</span></p>
<p>“Connectionism” is a word you don’t see much nowadays, but it was a big word back in the 1980s. It is hard to pin down, but if I summarize it, it is the result of philosophers in the 1980s noticing how researchers were trying neural networks on problems that had defied logical AI approaches, and somehow achieved state of the art, way past expectations. They say, “Weird! How is it possible for neural networks, written by people not having a deep knowledge of the problem domain, using such simplistic features, to work better than the best logical AI? I must philosophize this at once!”</p>
<p>Two clear camps immediately formed. On one side were the connectionists with <a href="https://en.wikipedia.org/wiki/Paul_Churchland">Paul Churchland</a>, <a href="https://en.wikipedia.org/wiki/Patricia_Churchland">Patricia Churchland</a>, <a href="https://en.wikipedia.org/wiki/Paul_Smolensky">Paul Smolensky</a>, <a href="https://en.wikipedia.org/wiki/Jeffrey_Elman">Jeffrey Elman</a>. On the other side were the cognitivists (or perhaps the rationalists) <a href="https://en.wikipedia.org/wiki/Jerry_Fodor">Jerry Fodor</a>, <a href="https://en.wikipedia.org/wiki/Zenon_Pylyshyn">Zenon Pylyshyn</a>, with the spirit of Noam Chomsky always present in the background.</p>
<p>Chapter 18 of <em>Parallel Distributed Processing</em> vol.&nbsp;2 bore the unassuming title “On learning the past tenses of verbs in English” <span class="citation" data-cites="rumelhartLearningTensesEnglish1986">(<a href="#ref-rumelhartLearningTensesEnglish1986" role="doc-biblioref">Rumelhart and McClelland 1986</a>)</span>. Nobody would have predicted that it ignited a long and bitter dispute “the past tense debate”.</p>
<p><span class="citation" data-cites="seidenbergQuasiregularityItsDiscontents2014">(<a href="#ref-seidenbergQuasiregularityItsDiscontents2014" role="doc-biblioref">Seidenberg and Plaut 2014</a>)</span></p>


<!-- -->


</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aisoFifthGenerationComputer1988" class="csl-entry" role="listitem">
Aiso, Hideo. 1988. <span>“The Fifth Generation Computer Systems Project.”</span> <em>Future Generation Computer Systems</em> 4 (3): 159–75.
</div>
<div id="ref-banksPilotsAssociateCooperative1991" class="csl-entry" role="listitem">
Banks, S. B., and C. S. Lizza. 1991. <span>“Pilot’s <span>Associate</span>: A Cooperative, Knowledge-Based System Application.”</span> <em>IEEE Expert</em> 6 (3): 18–29. <a href="https://doi.org/10.1109/64.87681">https://doi.org/10.1109/64.87681</a>.
</div>
<div id="ref-bar-hillelPresentStatusAutomatic1960" class="csl-entry" role="listitem">
Bar-Hillel, Yehoshua. 1960. <span>“The Present Status of Automatic Translation of Languages.”</span> <em>Advances in Computers</em> 1: 91–163.
</div>
<div id="ref-bar-hillelFutureMachineTranslation1964" class="csl-entry" role="listitem">
———. 1964. <span>“The Future of Machine Translation.”</span> <em>Hartley Rogers, <span>é</span>diteur, Language and Information–Selected Essays on Their Theory and Application, Logic</em>, 180–84.
</div>
<div id="ref-barkerExpertSystemsConfiguration1989" class="csl-entry" role="listitem">
Barker, Virginia E., Dennis E. O’Connor, Judith Bachant, and Elliot Soloway. 1989. <span>“Expert Systems for Configuration at <span>Digital</span>: <span>XCON</span> and Beyond.”</span> <em>Communications of the ACM</em> 32 (3): 298–318. <a href="https://doi.org/10.1145/62065.62067">https://doi.org/10.1145/62065.62067</a>.
</div>
<div id="ref-barrosoWebSearchPlanet2003" class="csl-entry" role="listitem">
Barroso, Luiz André, Jeffrey Dean, and Urs Holzle. 2003. <span>“Web Search for a Planet: <span>The Google</span> Cluster Architecture.”</span> <em>IEEE Micro</em> 23 (2): 22–28.
</div>
<div id="ref-bellUltracomputersTeraflopIts1992" class="csl-entry" role="listitem">
Bell, Gordon. 1992. <span>“Ultracomputers: A Teraflop Before Its Time.”</span> <em>Communications of the ACM</em> 35 (8): 26–47. <a href="https://doi.org/10.1145/135226.135227">https://doi.org/10.1145/135226.135227</a>.
</div>
<div id="ref-bermudezCognitiveScienceIntroduction2020" class="csl-entry" role="listitem">
Bermúdez, José Luis. 2020. <em>Cognitive Science: An Introduction to the Science of the Mind</em>. Third edition. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/9781108339216">https://doi.org/10.1017/9781108339216</a>.
</div>
<div id="ref-blanchardAAAI94StateAI1994" class="csl-entry" role="listitem">
Blanchard, David. 1994. <span>“<span>AAAI</span>’94: The State of the <span>AI</span> Industry, 1994.”</span> <em>Expert Systems</em> 11 (4): 253–53. <a href="https://doi.org/10.1111/j.1468-0394.1994.tb00334.x">https://doi.org/10.1111/j.1468-0394.1994.tb00334.x</a>.
</div>
<div id="ref-blellochNetworkLearningConnection1987" class="csl-entry" role="listitem">
Blelloch, Guy, and Charles R. Rosenberg. 1987. <span>“Network Learning on the Connection Machine.”</span> In <em>Proceedings of the 10th International Joint Conference on <span>Artificial</span> Intelligence - <span>Volume</span> 1</em>, 323–26. <span>IJCAI</span>’87. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</div>
<div id="ref-boehmView20th21st2006" class="csl-entry" role="listitem">
Boehm, Barry. 2006. <span>“A View of 20th and 21st Century Software Engineering.”</span> In <em>Proceedings of the 28th International Conference on <span>Software</span> Engineering</em>, 12–29. Shanghai China: ACM. <a href="https://doi.org/10.1145/1134285.1134288">https://doi.org/10.1145/1134285.1134288</a>.
</div>
<div id="ref-boldyrevCulturesMathematicalEconomics2017" class="csl-entry" role="listitem">
Boldyrev, Ivan, and Olessia Kirtchik. 2017. <span>“The Cultures of Mathematical Economics in the Postwar <span>Soviet Union</span>: <span>More</span> Than a Method, Less Than a Discipline.”</span> <em>Studies in History and Philosophy of Science</em> 63: 1–10.
</div>
<div id="ref-bramerFifthGenerationAnnotated1984" class="csl-entry" role="listitem">
Bramer, M. A. (Max A. ). 1984. <em>The Fifth Generation : An Annotated Bibliography</em>. Wokingham, England ; Reading, Mass. : Addison-Wesley.
</div>
<div id="ref-brantsLargeLanguageModels2007" class="csl-entry" role="listitem">
Brants, Thorsten, Ashok Popat, Peng Xu, Franz Josef Och, and Jeffrey Dean. 2007. <span>“Large Language Models in Machine Translation.”</span> In <em>Proceedings of the 2007 <span>Joint Conference</span> on <span>Empirical Methods</span> in <span>Natural Language Processing</span> and <span>Computational Natural Language Learning</span> (<span>EMNLP-CoNLL</span>)</em>, 858–67.
</div>
<div id="ref-breimanStatisticalModelingTwo2001" class="csl-entry" role="listitem">
Breiman, Leo. 2001. <span>“Statistical Modeling: <span>The</span> Two Cultures (with Comments and a Rejoinder by the Author).”</span> <em>Statistical Science</em> 16 (3): 199–231.
</div>
<div id="ref-briceSceneAnalysisUsing1970" class="csl-entry" role="listitem">
Brice, Claude R., and Claude L. Fennema. 1970. <span>“Scene Analysis Using Regions.”</span> <em>Artificial Intelligence</em> 1 (3): 205–26. <a href="https://doi.org/10.1016/0004-3702(70)90008-1">https://doi.org/10.1016/0004-3702(70)90008-1</a>.
</div>
<div id="ref-brockLearningArtificialIntelligences2018" class="csl-entry" role="listitem">
Brock, David C. 2018. <span>“Learning from <span>Artificial Intelligence</span>’s <span>Previous Awakenings</span>: <span>The History</span> of <span>Expert Systems</span>.”</span> <em>AI Magazine</em> 39 (3): 3–15.
</div>
<div id="ref-brooksElephantsDonPlay1990" class="csl-entry" role="listitem">
Brooks, Rodney A. 1990. <span>“Elephants Don’t Play Chess.”</span> <em>Robotics and Autonomous Systems</em> 6 (1-2): 3–15. <a href="https://doi.org/10/bk6">https://doi.org/10/bk6</a>.
</div>
<div id="ref-buchananRuleBasedExpert1984" class="csl-entry" role="listitem">
Buchanan, Bruce G. 1984. <em>Rule <span>Based Expert Systems</span>: <span>The Mycin Experiments</span> of the <span>Stanford Heuristic Programming Project</span></em>. Edited by Edward H. Shortliffe. First Edition. Reading, Mass: Addison-Wesley.
</div>
<div id="ref-buchananDendralMetaDendral1981" class="csl-entry" role="listitem">
Buchanan, Bruce G., and Edward A. Feigenbaum. 1981a. <span>“Dendral and <span>Meta-Dendral</span>.”</span> In <em>Readings in <span>Artificial Intelligence</span></em>, 313–22. Elsevier. <a href="https://doi.org/10.1016/B978-0-934613-03-3.50026-X">https://doi.org/10.1016/B978-0-934613-03-3.50026-X</a>.
</div>
<div id="ref-buchananDENDRALMetaDENDRALTheir1981" class="csl-entry" role="listitem">
———. 1981b. <span>“<span>DENDRAL</span> and <span>Meta-DENDRAL</span>: <span>Their</span> Applications Dimension.”</span> In <em>Readings in Artificial Intelligence</em>, 313–22. Elsevier.
</div>
<div id="ref-buchananRediscoveringProblemsArtificial1970" class="csl-entry" role="listitem">
Buchanan, B., G. Sutherland, and E. Feigenbaum. 1970. <span>“Rediscovering <span>Some Problems</span> of <span>Artificial Intelligence</span> in the <span>Context</span> of <span>Organic Chemistry</span>.”</span> In <em>Machine <span>Intelligence</span></em>, 5:253–80. Edinburgh University Press.
</div>
<div id="ref-campbellDeepBlue2002" class="csl-entry" role="listitem">
Campbell, Murray, A. Joseph Hoane Jr, and Feng-hsiung Hsu. 2002. <span>“Deep Blue.”</span> <em>Artificial Intelligence</em> 134 (1-2): 57–83.
</div>
<div id="ref-charniakAIIntellectualHistory2024" class="csl-entry" role="listitem">
Charniak, Eugene. 2024. <em><span>AI</span> &amp; <span>I</span>: <span>An Intellectual History</span> of <span>Artificial Intelligence</span></em>. MIT Press.
</div>
<div id="ref-chomskySyntacticStructures1957" class="csl-entry" role="listitem">
Chomsky, Noam. 1957. <em>Syntactic Structures</em>. The Hague : Mouton.
</div>
<div id="ref-chomskyReviewSkinnersVerbal1959" class="csl-entry" role="listitem">
———. 1959. <span>“A <span>Review</span> of <span>B</span>. <span>F</span>. <span>Skinner</span>’s <span>Verbal Behavior</span>.”</span> <em>Language</em> 35 (1): 26–58. <a href="https://doi.org/10.2307/411334">https://doi.org/10.2307/411334</a>.
</div>
<div id="ref-chomskyReviewBFSkinners1967" class="csl-entry" role="listitem">
———. 1967. <span>“A <span>Review</span> of <span>BF Skinner</span>’s <span>Verbal Behavior</span>.”</span> In <em>Readings in the <span>Psychology</span> of <span>Language</span></em>, edited by Murray S. Miron and Leon A. Jakobovits.
</div>
<div id="ref-chomskyEmpiricalAssumptionsModern1969" class="csl-entry" role="listitem">
———. 1969. <span>“Some <span>Empirical Assumptions</span> in <span>Modern Philosophy</span> of <span>Language</span>.”</span> In <em>Philosophy, Science, and Method</em>, edited by Ernest Nagel, Sidney Morgenbesser, Patrick Suppes, and Morton White. St. Martin’s Press.
</div>
<div id="ref-chorowskiEndtoendContinuousSpeech2014" class="csl-entry" role="listitem">
Chorowski, Jan, Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. <span>“End-to-End <span>Continuous Speech Recognition</span> Using <span class="nocase">Attention-based Recurrent NN</span>: <span>First Results</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1412.1602">https://doi.org/10.48550/arXiv.1412.1602</a>.
</div>
<div id="ref-churchPendulumSwungToo2011" class="csl-entry" role="listitem">
Church, Kenneth. 2011. <span>“A Pendulum Swung Too Far.”</span> <em>Linguistic Issues in Language Technology</em> 6.
</div>
<div id="ref-churchIntroductionSpecialIssue1993" class="csl-entry" role="listitem">
Church, Kenneth W., and Robert L. Mercer. 1993. <span>“Introduction to the <span>Special Issue</span> on <span>Computational Linguistics Using Large Corpora</span>.”</span> Edited by Julia Hirschberg. <em>Computational Linguistics</em> 19 (1): 1–24.
</div>
<div id="ref-automaticlanguageprocessingadvisorycommitteeLanguageMachinesComputers1966" class="csl-entry" role="listitem">
Committee, Automatic Language Processing Advisory, Division of Behavioral Sciences, National Research Council, and National Academy of Sciences. 1966. <span>“Language and <span>Machines</span>: <span>Computers</span> in <span>Translation</span> and <span>Linguistics</span>.”</span> 1416. Washington, D. C.
</div>
<div id="ref-dantzigDietProblem1990" class="csl-entry" role="listitem">
Dantzig, George B. 1990. <span>“The <span>Diet Problem</span>.”</span> <em>Interfaces</em> 20 (4): 43–47. <a href="https://doi.org/10.1287/inte.20.4.43">https://doi.org/10.1287/inte.20.4.43</a>.
</div>
<div id="ref-darpaStrategicComputingNew1983" class="csl-entry" role="listitem">
DARPA. 1983. <em>Strategic <span>Computing</span>: <span>New Generation Computing Technology</span>, a <span>Strategic Plan</span> for <span>Its Development</span> and <span>Application</span> to <span>Critical Problems</span> in <span>Defense</span></em>. Defense Advanced Research Projects Agency.
</div>
<div id="ref-denesDesignOperationMechanical1959" class="csl-entry" role="listitem">
Denes, P. 1959. <span>“The Design and Operation of the Mechanical Speech Recognizer at <span>University College London</span>.”</span> <em>Journal of the British Institution of Radio Engineers</em> 19 (4): 219–29. <a href="https://doi.org/10.1049/jbire.1959.0027">https://doi.org/10.1049/jbire.1959.0027</a>.
</div>
<div id="ref-dreyfusAlchemyArtificialIntelligence1965" class="csl-entry" role="listitem">
Dreyfus, Hubert L. 1965. <span>“Alchemy and <span>Artificial Intelligence</span>.”</span> RAND Corporation.
</div>
<div id="ref-dreyfusHistoryFirstStep2012" class="csl-entry" role="listitem">
———. 2012. <span>“A <span>History</span> of <span>First Step Fallacies</span>.”</span> <em>Minds and Machines</em> 22 (2): 87–99. <a href="https://doi.org/10.1007/s11023-012-9276-0">https://doi.org/10.1007/s11023-012-9276-0</a>.
</div>
<div id="ref-dudaPatternClassificationScene1973" class="csl-entry" role="listitem">
Duda, Richard O., and Peter E. Hart. 1973. <em>Pattern Classification and Scene Analysis</em>. New York: Wiley.
</div>
<div id="ref-dudaPatternClassification2001" class="csl-entry" role="listitem">
Duda, Richard O., Peter E. Hart, and David G. Stork. 2001. <em>Pattern Classification</em>. 2nd ed. New York: Wiley.
</div>
<div id="ref-duffieldApplicationsArtificialIntelligence1969" class="csl-entry" role="listitem">
Duffield, Alan M., Alexander V. Robertson, Carl Djerassi, Bruce G. Buchanan, Georgia L. Sutherland, Edward A. Feigenbaum, and Joshua Lederberg. 1969. <span>“Applications of Artificial Intelligence for Chemical Inference. <span>II</span>. <span>Interpretation</span> of Low-Resolution Mass Spectra of Ketones.”</span> <em>Journal of the American Chemical Society</em> 91 (11): 2977–81. <a href="https://doi.org/10.1021/ja01039a026">https://doi.org/10.1021/ja01039a026</a>.
</div>
<div id="ref-ermanHearsayIISpeechUnderstandingSystem1980" class="csl-entry" role="listitem">
Erman, Lee D., Frederick Hayes-Roth, Victor R. Lesser, and D. Raj Reddy. 1980. <span>“The <span>Hearsay-II Speech-Understanding System</span>: <span>Integrating Knowledge</span> to <span>Resolve Uncertainty</span>.”</span> <em>ACM Computing Surveys</em> 12 (2): 213–53. <a href="https://doi.org/10.1145/356810.356816">https://doi.org/10.1145/356810.356816</a>.
</div>
<div id="ref-allenExpertSystemsPioneer2018" class="csl-entry" role="listitem">
<em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 7: <span>Why</span> Did the Expert Systems Industry Decline?</em> 2018. <span>AI</span>: <span>Expert Systems Pioneer Meeting</span>. Mountain View, CA, USA: Computer History Museum.
</div>
<div id="ref-allenExpertSystemsPioneer2018a" class="csl-entry" role="listitem">
<em>Expert <span>Systems Pioneer Meeting</span>, Day 2 Session 8: <span>Artificial</span> Intelligence and Machine Learning in the 1990s</em>. 2018. <span>AI</span>: <span>Expert Systems Pioneer Meeting</span>. Mountain View, CA, USA: Computer History Museum.
</div>
<div id="ref-feigenbaumKnowledgeEngineeringApplied1984" class="csl-entry" role="listitem">
Feigenbaum, Edward A. 1984. <span>“Knowledge <span>Engineering</span>: <span>The Applied Side</span> of <span>Artificial Intelligence</span>.”</span> <em>Annals of the New York Academy of Sciences</em> 426 (1): 91–107. <a href="https://doi.org/10.1111/j.1749-6632.1984.tb16513.x">https://doi.org/10.1111/j.1749-6632.1984.tb16513.x</a>.
</div>
<div id="ref-feigenbaumPersonalViewExpert1992" class="csl-entry" role="listitem">
———. 1992. <em>A Personal View of Expert Systems: <span>Looking</span> Back and Looking Ahead</em>. Knowledge Systems Laboratory, Department of Computer Science, Stanford <span>…</span>.
</div>
<div id="ref-feigenbaumGeneralityProblemSolving1970" class="csl-entry" role="listitem">
Feigenbaum, Edward A., Bruce G. Buchanan, and Joshua Lederberg. 1970. <span>“On Generality and Problem Solving: <span>A</span> Case Study Using the <span>DENDRAL</span> Program.”</span>
</div>
<div id="ref-feigenbaumFifthGenerationArtificial1984" class="csl-entry" role="listitem">
Feigenbaum, Edward A., and Pamela McCorduck. 1984. <em>The <span>Fifth Generation</span>: <span>Artificial Intelligence</span> and <span>Japan</span>’s <span>Computer Challenge</span> to the <span>World</span></em>. Revised. New American Library.
</div>
<div id="ref-feigenbaumRiseExpertCompany1988" class="csl-entry" role="listitem">
Feigenbaum, Edward A., Pamela McCorduck, and H. P. Nii. 1988. <em>The Rise of the Expert Company: How Visionary Companies Are Using Artificial Intelligence to Achieve Higher Productivity and Profits</em>. London: Macmillan London.
</div>
<div id="ref-feigenbaumJapaneseNationalFifth1993" class="csl-entry" role="listitem">
Feigenbaum, Edward, and Howard Shrobe. 1993. <span>“The <span>Japanese</span> National <span>Fifth Generation</span> Project: Introduction, Survey, and Evaluation.”</span> <em>Future Generation Computer Systems</em> 9 (2): 105–17.
</div>
<div id="ref-foucaultOrderThings2012" class="csl-entry" role="listitem">
Foucault, Michel. 2012. <em>The Order of Things.</em> Hoboken: Taylor &amp; Francis.
</div>
<div id="ref-gardnerLVKantorovichPrice1990" class="csl-entry" role="listitem">
Gardner, Roy. 1990. <span>“<span>LV Kantorovich</span>: The Price Implications of Optimal Planning.”</span> <em>Journal of Economic Literature</em> 28 (2): 638–48. <a href="https://www.jstor.org/stable/2727266">https://www.jstor.org/stable/2727266</a>.
</div>
<div id="ref-goldenTerrainContourMatching1980" class="csl-entry" role="listitem">
Golden, Joe P. 1980. <span>“Terrain Contour Matching (<span>TERCOM</span>): A Cruise Missile Guidance Aid.”</span> In <em>Image Processing for Missile Guidance</em>, 238:10–18. SPIE.
</div>
<div id="ref-gordinDostoevskyMachineGeorgetown2016" class="csl-entry" role="listitem">
Gordin, Michael D. 2016. <span>“The <span>Dostoevsky Machine</span> in <span>Georgetown</span>: Scientific Translation in the <span>Cold War</span>.”</span> <em>Annals of Science</em> 73 (2): 208–23. <a href="https://doi.org/10.1080/00033790.2014.917437">https://doi.org/10.1080/00033790.2014.917437</a>.
</div>
<div id="ref-gordinForgettingRediscoverySoviet2020" class="csl-entry" role="listitem">
———. 2020. <span>“The <span>Forgetting</span> and <span>Rediscovery</span> of <span>Soviet Machine Translation</span>.”</span> <em>Critical Inquiry</em> 46 (4): 835–66. <a href="https://doi.org/10.1086/709226">https://doi.org/10.1086/709226</a>.
</div>
<div id="ref-gravesConnectionistTemporalClassification2006" class="csl-entry" role="listitem">
Graves, Alex, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber. 2006. <span>“Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks.”</span> In <em>Proceedings of the 23rd International Conference on <span>Machine</span> Learning - <span>ICML</span> ’06</em>, 369–76. Pittsburgh, Pennsylvania: ACM Press. <a href="https://doi.org/10.1145/1143844.1143891">https://doi.org/10.1145/1143844.1143891</a>.
</div>
<div id="ref-guiceControversyStateLord1998" class="csl-entry" role="listitem">
Guice, Jon. 1998. <span>“Controversy and the <span>State</span>:: <span>Lord ARPA</span> and <span>Intelligent Computing</span>.”</span> <em>Social Studies of Science</em> 28 (1): 103–38. <a href="https://doi.org/10.1177/030631298028001004">https://doi.org/10.1177/030631298028001004</a>.
</div>
<div id="ref-guzmanDecompositionVisualScene1968" class="csl-entry" role="listitem">
Guzmán, Adolfo. 1968. <span>“Decomposition of a Visual Scene into Three-Dimensional Bodies.”</span> In <em>Proceedings of the <span>December</span> 9-11, 1968, Fall Joint Computer Conference, Part <span>I</span> on - <span>AFIPS</span> ’68 (<span>Fall</span>, Part <span>I</span>)</em>, 291. San Francisco, California: ACM Press. <a href="https://doi.org/10.1145/1476589.1476631">https://doi.org/10.1145/1476589.1476631</a>.
</div>
<div id="ref-harmonExpertSystemsBusiness2022" class="csl-entry" role="listitem">
Harmon, Paul. 2022. <span>“The <span>Expert Systems Business</span>: <span>How It Grew</span> and <span>Died</span>.”</span> <em>IEEE Annals of the History of Computing</em> 44 (1): 31–43. <a href="https://doi.org/10.1109/MAHC.2022.3149465">https://doi.org/10.1109/MAHC.2022.3149465</a>.
</div>
<div id="ref-harrisStudyBuildingBlocks1953" class="csl-entry" role="listitem">
Harris, Cyril M. 1953. <span>“A Study of the Building Blocks in Speech.”</span> <em>The Journal of the Acoustical Society of America</em> 25 (5): 962–69.
</div>
<div id="ref-hedbergDARTRevolutionizingLogistics2002" class="csl-entry" role="listitem">
Hedberg, Sara Reese. 2002. <span>“<span>DART</span>: <span>Revolutionizing</span> Logistics Planning.”</span> <em>IEEE Intelligent Systems</em> 17 (3): 81–83.
</div>
<div id="ref-heppenheimerComputerTalkAmazing1984" class="csl-entry" role="listitem">
Heppenheimer, T. S. 1984. <span>“Computer <span>Talk</span>: <span>Amazing</span> New Realism in Synthetic Speech.”</span> <em>Popular Science</em>, January, 42–48.
</div>
<div id="ref-hofstadterGodelEscherBach1999" class="csl-entry" role="listitem">
Hofstadter, Douglas R. 1999. <em>G<span>ö</span>del, <span>Escher</span>, <span>Bach</span>: An Eternal Golden Braid</em>. 20th-anniversary ed., [Repr.]. New York: Basic Books.
</div>
<div id="ref-hsuIBMsDeepBlue1999" class="csl-entry" role="listitem">
Hsu, Feng-Hsiung. 1999. <span>“<span>IBM</span>’s <span>Deep Blue Chess</span> Grandmaster Chips.”</span> <em>IEEE Micro</em> 19 (2): 70–81. <a href="https://doi.org/10.1109/40.755469">https://doi.org/10.1109/40.755469</a>.
</div>
<div id="ref-hsuDeepBlueBuilding2002" class="csl-entry" role="listitem">
———. 2002. <em>Behind <span>Deep Blue</span>: <span>Building</span> the Computer That Defeated the World Chess Champion</em>. Princeton University Press.
</div>
<div id="ref-hsuCrackingGo2007" class="csl-entry" role="listitem">
Hsu, Feng-hsiung. 2007. <span>“Cracking <span>Go</span>.”</span> <em>IEEE Spectrum</em> 44 (10): 50–55. <a href="https://doi.org/10.1109/MSPEC.2007.4337666">https://doi.org/10.1109/MSPEC.2007.4337666</a>.
</div>
<div id="ref-hsuGrandmasterChessMachine1990" class="csl-entry" role="listitem">
Hsu, Feng-hsiung, Thomas Anantharaman, Murray Campbell, and Andreas Nowatzyk. 1990. <span>“A Grandmaster Chess Machine.”</span> <em>Scientific American</em> 263 (4): 44–51. <a href="https://www.jstor.org/stable/24997060">https://www.jstor.org/stable/24997060</a>.
</div>
<div id="ref-hsuDeepBlueSystem1995" class="csl-entry" role="listitem">
Hsu, Feng-hsiung, Murray S. Campbell, and A. Joseph Hoane. 1995. <span>“Deep <span>Blue</span> System Overview.”</span> In <em>Proceedings of the 9th International Conference on <span>Supercomputing</span> - <span>ICS</span> ’95</em>, 240–44. Barcelona, Spain: ACM Press. <a href="https://doi.org/10.1145/224538.224567">https://doi.org/10.1145/224538.224567</a>.
</div>
<div id="ref-huangHistoricalPerspectiveSpeech2014" class="csl-entry" role="listitem">
Huang, Xuedong, James Baker, and Raj Reddy. 2014. <span>“A Historical Perspective of Speech Recognition.”</span> <em>Communications of the ACM</em> 57 (1): 94–103. <a href="https://doi.org/10.1145/2500887">https://doi.org/10.1145/2500887</a>.
</div>
<div id="ref-hutchinsALPACFamousReport2003" class="csl-entry" role="listitem">
Hutchins, John. 2003. <span>“<span>ALPAC</span>: The (in) Famous Report.”</span> <em>Readings in Machine Translation</em> 14: 131–35.
</div>
<div id="ref-hutchinsFirstPublicDemonstration2005" class="csl-entry" role="listitem">
———. 2005. <span>“The First Public Demonstration of Machine Translation: The <span>Georgetown-IBM</span> System, 7th <span>January</span> 1954.”</span>
</div>
<div id="ref-hutchinsMachineTranslationConcise2007" class="csl-entry" role="listitem">
———. 2007. <span>“Machine Translation: <span>A</span> Concise History.”</span> <em>Computer Aided Translation: Theory and Practice</em> 13 (29-70): 11.
</div>
<div id="ref-stanfordresearchinstituteShakeyExperimentRobot1972" class="csl-entry" role="listitem">
Institute, Stanford Research. 1972. <span>“Shakey : <span>An Experiment</span> in <span>Robot Planning</span> and <span>Learning</span>.”</span>
</div>
<div id="ref-irwinArtificialWorldsPerceptronic2024" class="csl-entry" role="listitem">
Irwin, Julia A. 2024. <span>“Artificial <span>Worlds</span> and <span>Perceptronic Objects</span>: <span>The CIA</span>’s <span class="nocase">Mid-century Automatic Target Recognition</span>.”</span> <em>Grey Room</em>, no. 97 (September): 6–35. <a href="https://doi.org/10.1162/grey_a_00415">https://doi.org/10.1162/grey_a_00415</a>.
</div>
<div id="ref-jelinekSelfOrganizedContinuousSpeech1982" class="csl-entry" role="listitem">
Jelinek, Frederick. 1982. <span>“Self-<span>Organized Continuous Speech Recognition</span>.”</span> In <em>Automatic <span>Speech Analysis</span> and <span>Recognition</span></em>, edited by Jean-Paul Haton, 231–38. Dordrecht: Springer Netherlands. <a href="https://doi.org/10.1007/978-94-009-7879-9_14">https://doi.org/10.1007/978-94-009-7879-9_14</a>.
</div>
<div id="ref-jelinekMyBestFriends2005" class="csl-entry" role="listitem">
———. 2005. <span>“Some of <span>My Best Friends Are Linguists</span>.”</span> <em>Language Resources and Evaluation</em> 39 (1): 25–34. <a href="https://www.jstor.org/stable/30200539">https://www.jstor.org/stable/30200539</a>.
</div>
<div id="ref-jelinekDawnStatisticalASR2009" class="csl-entry" role="listitem">
———. 2009. <span>“The <span>Dawn</span> of <span>Statistical ASR</span> and <span>MT</span>.”</span> <em>Computational Linguistics</em> 35 (4): 483–94. <a href="https://doi.org/10.1162/coli.2009.35.4.35401">https://doi.org/10.1162/coli.2009.35.4.35401</a>.
</div>
<div id="ref-jurafskySpeechLanguageProcessing2023" class="csl-entry" role="listitem">
Jurafsky, Dan, and James H. Martin. 2023. <em>Speech and <span>Language Processing</span>: <span>An Introduction</span> to <span>Natural Language Processing</span>, <span>Computational Linguistics</span> and <span>Speech Recognition</span></em>. 3rd ed.
</div>
<div id="ref-kanalRecognitionSystemDesign1964" class="csl-entry" role="listitem">
Kanal, Laveen N., and Neil C. Randall. 1964. <span>“Recognition System Design by Statistical Analysis.”</span> In <em>Proceedings of the 1964 19th <span>ACM</span> National Conference</em>, 42–501.
</div>
<div id="ref-kayProperPlaceMen1997" class="csl-entry" role="listitem">
Kay, Martin. 1997. <span>“The <span>Proper Place</span> of <span>Men</span> and <span>Machines</span> in <span>Language Translation</span>.”</span> <em>Machine Translation</em> 12 (1/2): 3–23. <a href="https://doi.org/10.1023/A:1007911416676">https://doi.org/10.1023/A:1007911416676</a>.
</div>
<div id="ref-kellerGigaLIPFastEnough1990" class="csl-entry" role="listitem">
Keller, Tom W. 1990. <span>“Is a <span>GigaLIP Fast Enough</span>?”</span> <em>Computer Science in Economics and Management</em> 3 (2): 137–45. <a href="https://doi.org/10.1007/BF00436711">https://doi.org/10.1007/BF00436711</a>.
</div>
<div id="ref-klattReviewARPASpeech1977" class="csl-entry" role="listitem">
Klatt, Dennis H. 1977. <span>“Review of the <span>ARPA</span> Speech Understanding Project.”</span> <em>The Journal of the Acoustical Society of America</em> 62 (6): 1345–66.
</div>
<div id="ref-klattReviewTexttospeechConversion1987" class="csl-entry" role="listitem">
———. 1987. <span>“Review of Text-to-Speech Conversion for <span>English</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 82 (3): 737–93.
</div>
<div id="ref-knightAI30Years2016" class="csl-entry" role="listitem">
Knight, Will. 2016. <span>“An <span>AI</span> with 30 <span>Years</span>’ <span>Worth</span> of <span>Knowledge Finally Goes</span> to <span>Work</span>.”</span> <em>MIT Technology Review</em>, March.
</div>
<div id="ref-kuipersShakeyConceptionHistory2017" class="csl-entry" role="listitem">
Kuipers, Benjamin, Edward A. Feigenbaum, Peter E. Hart, and Nils J. Nilsson. 2017. <span>“Shakey: <span>From Conception</span> to <span>History</span>.”</span> <em>AI Magazine</em> 38 (1): 88–103. <a href="https://doi.org/10.1609/aimag.v38i1.2716">https://doi.org/10.1609/aimag.v38i1.2716</a>.
</div>
<div id="ref-leightyDevelopingTechnologiesArmy1986" class="csl-entry" role="listitem">
Leighty, R. D., and G. R. Lane. 1986. <span>“Developing Technologies for Army Autonomous Land Vehicles.”</span> In <em>1986 <span>Army Science Conference</span>, <span>West Point</span>, <span>New York</span></em>. Vol. 6.
</div>
<div id="ref-lenatCycLargescaleInvestment1995" class="csl-entry" role="listitem">
Lenat, Douglas B. 1995. <span>“Cyc: A Large-Scale Investment in Knowledge Infrastructure.”</span> <em>Communications of the ACM</em> 38 (11): 33–38. <a href="https://doi.org/10.1145/219717.219745">https://doi.org/10.1145/219717.219745</a>.
</div>
<div id="ref-lenat20012001Common2001" class="csl-entry" role="listitem">
———. 2001. <span>“From 2001 to 2001: <span>Common Sense</span> and the <span>Mind</span> of <span>HAL</span>.”</span> <em>HAL’s Legacy</em>, 193–209.
</div>
<div id="ref-lenatCycUsingCommon1985" class="csl-entry" role="listitem">
Lenat, Douglas B., Mayank Prakash, and Mary Shepherd. 1985. <span>“Cyc: <span>Using</span> Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks.”</span> <em>AI Magazine</em> 6 (4): 65–65.
</div>
<div id="ref-lenatThresholdsKnowledge2000" class="csl-entry" role="listitem">
Lenat, Douglas, and E. Feigenbaum. 2000. <span>“On the Thresholds of Knowledge.”</span> <em>Artificial Intelligence: Critical Concepts</em> 2: 298.
</div>
<div id="ref-lenatCycMidtermReport1990" class="csl-entry" role="listitem">
Lenat, Douglas, and Ramanathan V. Guha. 1990. <span>“Cyc: <span>A</span> Midterm Report.”</span> <em>AI Magazine</em> 11 (3): 32–32.
</div>
<div id="ref-leontiefStructureDevelopment1963" class="csl-entry" role="listitem">
Leontief, Wassily. 1963. <span>“The <span>Structure</span> of <span>Development</span>.”</span> <em>Scientific American</em> 209 (3): 148–67. <a href="https://www.jstor.org/stable/24936290">https://www.jstor.org/stable/24936290</a>.
</div>
<div id="ref-levyBigBluesHand1997" class="csl-entry" role="listitem">
Levy, Steven. 1997. <span>“Big <span>Blue</span>’s <span>Hand Of God</span>.”</span> <em>Newsweek</em>, May.
</div>
<div id="ref-liTheresNoData2023" class="csl-entry" role="listitem">
Li, Xiaochang. 2023. <span>“<span>‘<span>There</span>’s <span>No Data Like More Data</span>’</span>: <span>Automatic Speech Recognition</span> and the <span>Making</span> of <span>Algorithmic Culture</span>.”</span> <em>Osiris</em> 38 (July): 165–82. <a href="https://doi.org/10.1086/725132">https://doi.org/10.1086/725132</a>.
</div>
<div id="ref-libermanObituaryFredJelinek2010" class="csl-entry" role="listitem">
Liberman, Mark. 2010. <span>“Obituary: <span>Fred Jelinek</span>.”</span> <em>Computational Linguistics</em> 36 (4): 595–99.
</div>
<div id="ref-lindsayDENDRALCaseStudy1993" class="csl-entry" role="listitem">
Lindsay, Robert K., Bruce G. Buchanan, Edward A. Feigenbaum, and Joshua Lederberg. 1993. <span>“<span>DENDRAL</span>: <span>A</span> Case Study of the First Expert System for Scientific Hypothesis Formation.”</span> <em>Artificial Intelligence</em> 61 (2): 209–61. <a href="https://doi.org/10.1016/0004-3702(93)90068-M">https://doi.org/10.1016/0004-3702(93)90068-M</a>.
</div>
<div id="ref-lyleInterviewJohnRobinson1979" class="csl-entry" role="listitem">
Lyle, Harriett. 1979. <span>“Interview with <span>John Robinson Pierce</span>,”</span> April.
</div>
<div id="ref-mackenzieAutomationProofHistorical1995" class="csl-entry" role="listitem">
Mackenzie, D. 1995. <span>“The Automation of Proof: A Historical and Sociological Exploration.”</span> <em>IEEE Annals of the History of Computing</em> 17 (3): 7–29. <a href="https://doi.org/10.1109/85.397057">https://doi.org/10.1109/85.397057</a>.
</div>
<div id="ref-mccorduckMachinesWhoThink2004" class="csl-entry" role="listitem">
McCorduck, Pamela. 2004. <em>Machines Who Think: A Personal Inquiry into the History and Prospects of Artificial Intelligence</em>. 25th anniversary update. Natick, Mass: A.K. Peters.
</div>
<div id="ref-mccorduckScientificLifeEdward2022" class="csl-entry" role="listitem">
———. 2022. <span>“The <span>Scientific Life</span> of <span>Edward A</span>. <span>Feigenbaum</span>.”</span> <em>IEEE Annals of the History of Computing</em> 44 (01): 123–28. <a href="https://doi.org/10.1109/MAHC.2022.3145216">https://doi.org/10.1109/MAHC.2022.3145216</a>.
</div>
<div id="ref-medeirosHowIntelGave2015" class="csl-entry" role="listitem">
Medeiros, João. 2015. <span>“How <span>Intel Gave Stephen Hawking</span> a <span>Voice</span>.”</span> <em>Wired</em>, January.
</div>
<div id="ref-medressSpeechUnderstandingSystems1977" class="csl-entry" role="listitem">
Medress, Mark F., Franklin S. Cooper, Jim W. Forgie, C. C. Green, Dennis H. Klatt, Michael H. O’Malley, Edward P. Neuburg, Allen Newell, D. R. Reddy, and B. Ritea. 1977. <span>“Speech Understanding Systems: <span>Report</span> of a Steering Committee.”</span> <em>Artificial Intelligence</em> 9 (3): 307–16.
</div>
<div id="ref-moravecRobotMereMachine1999" class="csl-entry" role="listitem">
Moravec, Hans P. 1999. <em>Robot: Mere Machine to Transcendent Mind</em>. Oxford University Press.
</div>
<div id="ref-moto-okaFifthGenerationComputers1984" class="csl-entry" role="listitem">
Moto-oka, Tohru. 1984. <span>“Fifth Generation Computers and Very Large Scale Integration.”</span> <em>Endeavour</em> 8 (2): 95–100. <a href="https://doi.org/10.1016/0160-9327(84)90045-0">https://doi.org/10.1016/0160-9327(84)90045-0</a>.
</div>
<div id="ref-muehlhauserWhatShouldWe2016" class="csl-entry" role="listitem">
Muehlhauser, Luke. 2016. <span>“What <span>Should We Learn</span> from <span>Past AI Forecasts</span>?”</span> <em>Open Philanthropy</em>.
</div>
<div id="ref-newellSpeechUnderstandingSystems1973" class="csl-entry" role="listitem">
Newell, Allen, Jeffrey Barnett, James W. Forgie, Cordell Green, Dennis Klatt, J. C. R. Licklider, John Munson, D. Raj Reddy, and William A. Woods. 1973. <em>Speech Understanding Systems: <span>Final</span> Report of a Study Group</em>. North-Holland Amsterdam.
</div>
<div id="ref-newellHumanProblemSolving1972" class="csl-entry" role="listitem">
Newell, Allen, and Herbert Alexander Simon. 1972. <em>Human Problem Solving</em>.
</div>
<div id="ref-newellEmpiricalExplorationsLogic1957" class="csl-entry" role="listitem">
Newell, A., J. C. Shaw, and H. A. Simon. 1957. <span>“Empirical Explorations of the Logic Theory Machine: A Case Study in Heuristic.”</span> In <em>Papers Presented at the <span>February</span> 26-28, 1957, Western Joint Computer Conference: <span>Techniques</span> for Reliability on - <span>IRE-AIEE-ACM</span> ’57 (<span>Western</span>)</em>, 218–30. Los Angeles, California: ACM Press. <a href="https://doi.org/10.1145/1455567.1455605">https://doi.org/10.1145/1455567.1455605</a>.
</div>
<div id="ref-nietzscheGoodEvilPrelude2002" class="csl-entry" role="listitem">
Nietzsche, Friedrich Wilhelm, Rolf-Peter Horstmann, and Judith Norman. 2002. <em>Beyond Good and Evil: Prelude to a Philosophy of the Future</em>. Cambridge Texts in the History of Philosophy. Cambridge ; New York: Cambridge University Press.
</div>
<div id="ref-nilssonQuestArtificialIntelligence2009" class="csl-entry" role="listitem">
Nilsson, Nils J. 2009. <em>The <span>Quest</span> for <span>Artificial Intelligence</span></em>. 1st edition. Cambridge ; New York: Cambridge University Press.
</div>
<div id="ref-norvigChomskyTwoCultures2017" class="csl-entry" role="listitem">
Norvig, Peter. 2017. <span>“<span>On Chomsky and the Two Cultures of Statistical Learning</span>.”</span> In <em><span>Berechenbarkeit der Welt? Philosophie und Wissenschaft im Zeitalter von Big Data</span></em>, edited by Wolfgang Pietsch, Jörg Wernecke, and Maximilian Ott, 61–83. Wiesbaden: Springer Fachmedien. <a href="https://doi.org/10.1007/978-3-658-12153-2_3">https://doi.org/10.1007/978-3-658-12153-2_3</a>.
</div>
<div id="ref-ornsteinMechanicalTranslationNew1955" class="csl-entry" role="listitem">
Ornstein, Jacob. 1955. <span>“Mechanical <span>Translation</span>: <span>New Challenge</span> to <span>Communication</span>.”</span> <em>Science</em> 122 (3173): 745–48. <a href="https://doi.org/10.1126/science.122.3173.745">https://doi.org/10.1126/science.122.3173.745</a>.
</div>
<div id="ref-pierceWhitherSpeechRecognition1969" class="csl-entry" role="listitem">
Pierce, John R. 1969. <span>“Whither Speech Recognition?”</span> <em>The Journal of the Acoustical Society of America</em> 46 (4B): 1049–51.
</div>
<div id="ref-poincareScienceMethod1914" class="csl-entry" role="listitem">
Poincaré, Henri. 1914. <em>Science and Method</em>. London : T. Nelson.
</div>
<div id="ref-pollackFifthGenerationBecame1992" class="csl-entry" role="listitem">
Pollack, Andrew. 1992. <span>“’<span>Fifth Generation</span>’ <span>Became Japan</span>’s <span>Lost Generation</span>.”</span> <em>The New York Times</em>, June.
</div>
<div id="ref-pomerleauNeuralNetworkSimulation1988" class="csl-entry" role="listitem">
Pomerleau, Gusciora, Touretzky, and Kung. 1988. <span>“Neural Network Simulation at <span>Warp</span> Speed: How We Got 17 Million Connections Per Second.”</span> In <em><span>IEEE</span> 1988 <span>International Conference</span> on <span>Neural Networks</span></em>, 143–150 vol.2. <a href="https://doi.org/10.1109/ICNN.1988.23922">https://doi.org/10.1109/ICNN.1988.23922</a>.
</div>
<div id="ref-priceDARPA1000wordResource1988" class="csl-entry" role="listitem">
Price, P., W. M. Fisher, J. Bernstein, and D. S. Pallett. 1988. <span>“The <span>DARPA</span> 1000-Word Resource Management Database for Continuous Speech Recognition.”</span> In <em><span>ICASSP-88</span>., <span>International Conference</span> on <span>Acoustics</span>, <span>Speech</span>, and <span>Signal Processing</span></em>, 651, 652, 653, 654–51, 652, 653, 654. IEEE Computer Society. <a href="https://doi.org/10.1109/ICASSP.1988.196669">https://doi.org/10.1109/ICASSP.1988.196669</a>.
</div>
<div id="ref-raphaelResearchApplicationsArtificial1971" class="csl-entry" role="listitem">
Raphael, BERTRAM, R. E. Fikes, L. J. Chaitin, P. E. Hart, R. O. Duda, and N. J. Nilsson. 1971. <span>“Research and Applications: <span>Artificial</span> Intelligence.”</span>
</div>
<div id="ref-reddySpeechRecognitionMachine1976" class="csl-entry" role="listitem">
Reddy, D. R. 1976. <span>“Speech Recognition by Machine: <span>A</span> Review.”</span> <em>Proceedings of the IEEE</em> 64 (4): 501–31. <a href="https://doi.org/10.1109/PROC.1976.10158">https://doi.org/10.1109/PROC.1976.10158</a>.
</div>
<div id="ref-reddyMachineModelsSpeech1980" class="csl-entry" role="listitem">
Reddy, Raj. 1980. <span>“Machine Models of Speech Perception.”</span> <em>Perception and Production of Fluent Speech", Cole, Ed., Erlbaum, NJ</em>, 215–42.
</div>
<div id="ref-reiflerSolutionMTLinguistic1960" class="csl-entry" role="listitem">
Reifler, Erwin. 1960. <span>“The Solution of <span>MT</span> Linguistic Problems Through Lexicography.”</span> In <em>Proceedings of the <span>National Symposium</span> on <span>Machine Translation</span></em>.
</div>
<div id="ref-rolandStrategicComputingDARPA2002" class="csl-entry" role="listitem">
Roland, Alex, and Philip Shiman. 2002. <em>Strategic Computing: <span>DARPA</span> and the Quest for Machine Intelligence, 1983-1993</em>. History of Computing. Cambridge, Mass: MIT Press.
</div>
<div id="ref-rumelhartLearningTensesEnglish1986" class="csl-entry" role="listitem">
Rumelhart, D. E., and J. L. McClelland. 1986. <span>“On Learning the Past Tenses of <span>English</span> Verbs.”</span> In <em>Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 2: Psychological and Biological Models</em>, 216–71. Cambridge, MA, USA: MIT Press.
</div>
<div id="ref-russellArtificialIntelligenceModern1995" class="csl-entry" role="listitem">
Russell, Stuart J., and Peter Norvig. 1995. <em>Artificial Intelligence: A Modern Approach</em>. 1st ed. Prentice <span>Hall</span> Series in Artificial Intelligence. Upper Saddle River: Prentice Hall.
</div>
<div id="ref-russellArtificialIntelligenceModern2021" class="csl-entry" role="listitem">
———. 2021. <em>Artificial Intelligence: A Modern Approach</em>. 4th ed. Pearson Series in Artificial Intelligence. Hoboken: Pearson.
</div>
<div id="ref-samuelStudiesMachineLearning1959" class="csl-entry" role="listitem">
Samuel, A. L. 1959. <span>“Some Studies in Machine Learning Using the Game of Checkers.”</span> <em>IBM Journal of Research and Development</em> 44 (1.2): 206–26. <a href="https://doi.org/10.1147/rd.441.0206">https://doi.org/10.1147/rd.441.0206</a>.
</div>
<div id="ref-schankWeizenbaumControversy1976" class="csl-entry" role="listitem">
Schank, Roger C. 1976. <span>“The <span>Weizenbaum</span> Controversy.”</span> <em>ACM SIGART Bulletin</em>, no. 59 (August): 7–11. <a href="https://doi.org/10.1145/1045270.1045271">https://doi.org/10.1145/1045270.1045271</a>.
</div>
<div id="ref-schankWheresAI1991" class="csl-entry" role="listitem">
———. 1991. <span>“Where’s the <span>AI</span>?”</span> <em>AI Magazine</em> 12 (4): 38–38.
</div>
<div id="ref-seidenbergQuasiregularityItsDiscontents2014" class="csl-entry" role="listitem">
Seidenberg, Mark S., and David C. Plaut. 2014. <span>“Quasiregularity and <span>Its Discontents</span>: <span>The Legacy</span> of the <span>Past Tense Debate</span>.”</span> <em>Cognitive Science</em> 38 (6): 1190–1228. <a href="https://doi.org/10.1111/cogs.12147">https://doi.org/10.1111/cogs.12147</a>.
</div>
<div id="ref-sheridanResearchLanguageTranslation1955" class="csl-entry" role="listitem">
Sheridan, Peter. 1955. <span>“Research in Language Translation on the <span>IBM</span> Type 701.”</span> <em>IBM Technical Newsletter</em> 9: 5–24.
</div>
<div id="ref-silverMasteringGameGo2016" class="csl-entry" role="listitem">
Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et al. 2016. <span>“Mastering the Game of <span>Go</span> with Deep Neural Networks and Tree Search.”</span> <em>Nature</em> 529 (7587): 484–89. <a href="https://doi.org/10/f77tw6">https://doi.org/10/f77tw6</a>.
</div>
<div id="ref-silverGeneralReinforcementLearning2018" class="csl-entry" role="listitem">
Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, et al. 2018. <span>“A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and <span>Go</span> Through Self-Play.”</span> <em>Science</em> 362 (6419): 1140–44. <a href="https://doi.org/10.1126/science.aar6404">https://doi.org/10.1126/science.aar6404</a>.
</div>
<div id="ref-simonSciencesArtificial1996" class="csl-entry" role="listitem">
Simon, Herbert A. 1996. <em>The <span>Sciences</span> of the <span>Artificial</span></em>. 3rd ed. Cambridge, Massachusetts: The MIT Press.
</div>
<div id="ref-skorinkinABBYYsBitterLesson2024" class="csl-entry" role="listitem">
Skorinkin, Daniil. 2024. <span>“<span>ABBYY’s Bitter Lesson: How Linguists Lost the Last Battle for NLP</span>.”</span> <em>System Block</em>.
</div>
<div id="ref-slocumRobotExcessMachine2024" class="csl-entry" role="listitem">
Slocum, Brian, and Maria Yablonina. 2024. <span>“Robot Excess: Machine Histories and a Hermeneutics of Movement.”</span> <em>Construction Robotics</em> 8 (2): 18. <a href="https://doi.org/10.1007/s41693-024-00129-7">https://doi.org/10.1007/s41693-024-00129-7</a>.
</div>
<div id="ref-spuffordRedPlenty2010" class="csl-entry" role="listitem">
Spufford, Francis. 2010. <em>Red Plenty</em>. London: <span>Faber and Faber</span>.
</div>
<div id="ref-stiglerCostSubsistence1945" class="csl-entry" role="listitem">
Stigler, George J. 1945. <span>“The <span>Cost</span> of <span>Subsistence</span>.”</span> <em>Journal of Farm Economics</em> 27 (2): 303–14. <a href="https://doi.org/10.2307/1231810">https://doi.org/10.2307/1231810</a>.
</div>
<div id="ref-suttonReinforcementLearningIntroduction2018" class="csl-entry" role="listitem">
Sutton, Richard S., and Andrew G. Barto. 2018. <em>Reinforcement Learning: <span>An</span> Introduction</em>. MIT press.
</div>
<div id="ref-taylorAutomatedTutoringIts1968" class="csl-entry" role="listitem">
Taylor, Edwin F. 1968. <span>“Automated <span>Tutoring</span> and <span>Its Discontents</span>.”</span> <em>American Journal of Physics</em> 36 (6): 496–504. <a href="https://doi.org/10.1119/1.1974953">https://doi.org/10.1119/1.1974953</a>.
</div>
<div id="ref-thorpeVisionNavigationCarnegie1990" class="csl-entry" role="listitem">
Thorpe, Charles E., ed. 1990. <em>Vision and <span>Navigation</span>: <span>The Carnegie Mellon Navlab</span></em>. Vol. 93. The <span>Kluwer International Series</span> in <span>Engineering</span> and <span>Computer Science</span>. Boston, MA: Springer US. <a href="https://doi.org/10.1007/978-1-4613-1533-9">https://doi.org/10.1007/978-1-4613-1533-9</a>.
</div>
<div id="ref-turkVITSaVisionSystem1988" class="csl-entry" role="listitem">
Turk, M. A., D. G. Morgenthaler, K. D. Gremban, and M. Marra. 1988. <span>“<span class="nocase">VITS-a</span> Vision System for Autonomous Land Vehicle Navigation.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 10 (3): 342–61. <a href="https://doi.org/10.1109/34.3899">https://doi.org/10.1109/34.3899</a>.
</div>
<div id="ref-vapnikEstimationDependencesBased2006" class="csl-entry" role="listitem">
Vapnik, Vladimir. 2006. <em>Estimation of <span>Dependences Based</span> on <span>Empirical Data</span></em>. Information <span>Science</span> and <span>Statistics</span>. New York, NY: Springer. <a href="https://doi.org/10.1007/0-387-34239-7">https://doi.org/10.1007/0-387-34239-7</a>.
</div>
<div id="ref-waltzSheddingLightShadows1972" class="csl-entry" role="listitem">
Waltz, David L. 1972. <span>“Shedding <span>Light</span> on <span>Shadows</span>.”</span> Working {{Paper}}. MIT Artificial Intelligence Laboratory.
</div>
<div id="ref-warrenViewFifthGeneration1982" class="csl-entry" role="listitem">
Warren, David HD. 1982. <span>“A View of the Fifth Generation and Its Impact.”</span> <em>AI Magazine</em> 3 (4): 34–34.
</div>
<div id="ref-weizenbaumELIZAComputerProgram1966" class="csl-entry" role="listitem">
Weizenbaum, Joseph. 1966. <span>“<span>ELIZA</span>—a Computer Program for the Study of Natural Language Communication Between Man and Machine.”</span> <em>Communications of the ACM</em> 9 (1): 36–45. <a href="https://doi.org/10.1145/365153.365168">https://doi.org/10.1145/365153.365168</a>.
</div>
<div id="ref-weizenbaumImpactComputerSociety1972" class="csl-entry" role="listitem">
———. 1972. <span>“On the <span>Impact</span> of the <span>Computer</span> on <span>Society</span>.”</span> <em>Science</em> 176 (4035): 609–14. <a href="https://www.jstor.org/stable/1734465">https://www.jstor.org/stable/1734465</a>.
</div>
<div id="ref-weizenbaumComputerPowerHuman1976" class="csl-entry" role="listitem">
———. 1976. <span>“Computer Power and Human Reason: <span>From</span> Judgment to Calculation.”</span> <em>San Francisco</em>.
</div>
<div id="ref-whiteDangerJapan1985" class="csl-entry" role="listitem">
White, Theodore H. 1985. <span>“The <span>Danger</span> from <span>Japan</span>.”</span> <em>The New York Times</em>, July.
</div>
<div id="ref-winogradUnderstandingNaturalLanguage1972" class="csl-entry" role="listitem">
Winograd, Terry. 1972. <span>“Understanding Natural Language.”</span> <em>Cognitive Psychology</em> 3 (1): 1–191. <a href="https://doi.org/10.1016/0010-0285(72)90002-3">https://doi.org/10.1016/0010-0285(72)90002-3</a>.
</div>
<div id="ref-winogradComputerSoftwareWorking1984" class="csl-entry" role="listitem">
———. 1984. <span>“Computer <span>Software</span> for <span>Working</span> with <span>Language</span>.”</span> <em>Scientific American</em> 251 (3): 130–45. <a href="https://www.jstor.org/stable/24920349">https://www.jstor.org/stable/24920349</a>.
</div>
<div id="ref-winograd10ThinkingMachines1991" class="csl-entry" role="listitem">
———. 1991. <span>“10. <span>Thinking Machines</span>: <span>Can There Be</span>? <span>Are We</span>?”</span> In <em>The <span>Boundaries</span> of <span>Humanity</span></em>, edited by James J. Sheehan and Morton Sosna, 198–223. University of California Press. <a href="https://doi.org/10.1525/9780520313118-013">https://doi.org/10.1525/9780520313118-013</a>.
</div>
<div id="ref-woodRecollectionsJohnRobinson1991" class="csl-entry" role="listitem">
Wood, Patte, and John Robinson Pierce. 1991. <span>“Recollections with <span>John Robinson Pierce</span>.”</span> <em>Computer Music Journal</em> 15 (4): 17–28. <a href="https://www.jstor.org/stable/3681066">https://www.jstor.org/stable/3681066</a>.
</div>
<div id="ref-yeangFilteringNoiseAntiaircraft2023" class="csl-entry" role="listitem">
Yeang, Chen-Pang. 2023. <span>“Filtering <span>Noise</span> for <span>Antiaircraft Gunfire Control</span>.”</span> In <em>Transforming <span>Noise</span>: <span>A History</span> of <span>Its Science</span> and <span>Technology</span> from <span>Disturbing Sounds</span> to <span>Informational Errors</span>, 1900-1955</em>, edited by Chen-Pang Yeang, 0. Oxford University Press. <a href="https://doi.org/10.1093/oso/9780198887768.003.0011">https://doi.org/10.1093/oso/9780198887768.003.0011</a>.
</div>
<div id="ref-yngveModelHypothesisLanguage1960" class="csl-entry" role="listitem">
Yngve, Victor H. 1960. <span>“A <span>Model</span> and an <span>Hypothesis</span> for <span>Language Structure</span>.”</span> <em>Proceedings of the American Philosophical Society</em> 104 (5): 444–66. <a href="https://www.jstor.org/stable/985230">https://www.jstor.org/stable/985230</a>.
</div>
<div id="ref-youngFrederickJelinek193220102010" class="csl-entry" role="listitem">
Young, S. 2010. <span>“Frederick <span>Jelinek</span> 1932-2010: <span>The Pioneer</span> of <span>Speech Recognition Technology</span>.”</span> <em>Speech and Language Processing Technical Committee Newsletter</em>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/yuxi-liu-wired\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Eulogy to Logical AI"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yuxi Liu"</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-01-23"</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2024-01-23"</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [AI, scaling, history]</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Good Old-Fashioned AI never die. They just fade away."</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co"># image: "figure/banner.png"</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "wip"</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "likely"</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 3</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../utils/blog_utils/_macros.tex &gt;}}</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Translation</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One naturally wonders if the problem of translation could conceivably be treated as a problem in cryptography. When I look at an article in Russian, I say: "This is really written in English, but it has been coded in some strange symbols. I will now proceed to decode."</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- Warren Weaver, Letter to Norbert Wiener, 1947-03-04</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>During WWII, the science of communication and control took on a life-and-death importance. The mathematically perfect Enigma forced Allied mathematicians to turn their art of code into the science of information, so as to extract every last bit of information leaked out from the unknown enemy who was less than mathematically perfect, who made mistakes, who stuttered with verbal tics like <span class="in">`WETTER`</span> or <span class="in">`KEINE BESONDEREN EREIGNISSE`</span>. On two sides of the Atlantic, Alan Turing of computer science, and Claude Shannon of information theory, fought in this information warfare.</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>Before the war, some feared that the bombers would finally be the ultimate weapon, as a fleet of <span class="co">[</span><span class="ot">them will always get through</span><span class="co">](https://en.wikipedia.org/wiki/The_bomber_will_always_get_through)</span>. Bombing was becoming a cyborg activity. The bombers were flying so high and so fast, the bombardiers needed <span class="co">[</span><span class="ot">intricate bombsights</span><span class="co">](https://en.wikipedia.org/wiki/Norden_bombsight)</span> filled with mechanical calculators, just to calculate the correct time to drop the bombs.</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>But the bombers would not go through after all, as radar screens and flak cannons raised invisible walls in the sky, and the anti-aircraft fire became another cyborg activity. Norbert Wiener developed his control theory in the context of anti-aircraft fire and radar screening. He thought of both as a form of deadly communication. A radar speaks to the aircraft, "Who and where are you?" Despite itself, the aircraft must answer. The radar's job is to speak clearly with the right ping and listen carefully with the right filter. In this context, he developed the <span class="co">[</span><span class="ot">Wiener filter</span><span class="co">](https://en.wikipedia.org/wiki/Wiener_filter)</span>.</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>Anti-aircraft (AA) seems even less like a deadly communication, yet Wiener made it work. To shoot down an aircraft, one must predict where it will be a few seconds into the future, since that is how long bullets take to fly that high. The AA looks to the sky and asks, "Where are you going?". Despite itself, the aircraft speaks with where it had been in the past few seconds, as if writing a cursive word in the sky. The AA reads and understands this writing, and act accordingly. The past is a code for the future, like the Enigma is a code for the plaintext. <span class="co">[</span><span class="ot">@yeangFilteringNoiseAntiaircraft2023</span><span class="co">]</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>If the soldiers are always preparing to fight the previous war, the same seems true for some mathematicians. Wiener and his collaborator, Warren Weaver, decided to tackle the problem of machine translation with the same tools they developed for war. If information theory helps with breaking the Enigma code, would it not also help with breaking the language codes?</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>The wartime metaphor would become ominously appropriate with the Cold War.</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="fu">### Georgetown--IBM experiment</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>During the 1950s, electronic computers were mainly understood and used as tools for real-valued calculations, such as simulating nuclear explosions, the aerodynamics of ballistic missiles, macroeconomic planning, and other important real-valued functions that are necessary to safeguard freedom. However, there was already early attempts at using computers for symbolic calculations.</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>In a sense, this was quite old. Whereas Charles Babbage designed his computer as an arithmetic mill to grind out numerical tables, Ada Lovelace speculated that computers can grind out symbolic music too, as long as music and its transformation rules are encoded into integers.</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>On 1954-01-07, the world's first non-human translator appeared in the body of an IBM 701. At least, that is what the newspapers made it seam to be.</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>Back in 1952-06, at a MIT conference on machine translation (MT),<span class="ot">[^mt-acronym]</span> Leon Dostert was convinced that instead of arguments about whether MT works *in theory*, they needed to try it out on an actual problem to see if it would work *in practice*. This led to the <span class="co">[</span><span class="ot">Georgetown--IBM experiment</span><span class="co">](https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment)</span> 1.5 years later. It was the first public demonstration of machine translation -- from Russian to English, and was widely reported with titles like "Electronic brain translates Russian" or "Robot brain translates Russian into King's English".</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="ot">[^mt-acronym]: </span>The acronym "MT" now stands for "machine translation", but in the early days, it stood for "mechanical translation".</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>To put some meat to the bones, consider the following hardware specs for the IBM 701 and the demo:</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The IBM 701 machine operated at $2000 \;\mathrm{FLOP/s}$</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It performed read/write speed $3.6 \;\mathrm{kB/s}$ (in the form of 80-column punched cards).</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The program took up $2400 \;\mathrm{instruction} \times 18 \;\mathrm{bit/instruction} = 5.4 \;\mathrm{kB}$</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The dictionary took up $6000 \;\mathrm{word} \times 36 \;\mathrm{bit/word} = 27 \;\mathrm{kB}$.</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>The dictionary is a table with 6 columns: Russian, English equivalent I, English equivalent II, Code 1, Code 2, Code 3. As we see, each Russian word has 1 or 2 possible English translations. The three <span class="in">`Code`</span>s are essentially grammar categories. As an example, the suffix <span class="in">`-a`</span> is coded as <span class="in">`(-a, of, , 131, 222, 25)`</span>, while the word stem <span class="in">`ugl-`</span> is coded as <span class="in">`(ugl-, coal, angle, 121, ***, 25)`</span>.</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>The dictionary contains just 250 lexical items (stems and endings). Its grammar has just 6 rules. All input sentences must be made of words that are of form either <span class="in">`stem`</span> or <span class="in">`stem-ending`</span>. Some example translations included:</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Mi pyeryedayem mislyi posryedstvom ryechyi.</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We transmit thoughts by means of speech.</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a><span class="al">![A punched card from the demo. The Russian sentence is encoded with the hole patterns and then read by the IBM 701. The output was not by punched cards, but by a printer.](figure/Georgetown-IBM_punched_card.png)</span></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>The algorithm is essentially a word-substitution program, using the 6 rules to disambiguate, and to decide whether to switch a word with a previous word. The word-order switch is necessary since Russian puts prepositions as word suffixes. For example, <span class="in">`ugl-a`</span> would be word-substituted to <span class="in">`angle-by`</span>, but must be translated as <span class="in">`by angle`</span>.</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>The experiment was a hit, and there were some predictions of imminent breakthrough <span class="co">[</span><span class="ot">@hutchinsFirstPublicDemonstration2005</span><span class="co">]</span>:</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Such a device should be ready within three to five years... As soon as cards for Russian are completed, sets will be made for German and French. Then other Slavic, Germanic and Romance languages can be set up at will.</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>100 rules would be needed to govern 20,000 words for free translation.</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>From our perspective, these seem painfully optimistic. However, it was a common belief that electronic computers, like the IBM 701, were designed for numerical computation, something that is more difficult than natural language processing. As such, a machine translator needed not faster computers, but more data. Yet among the general optimism, there was a disquieting note:</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; the formulation of logic required to convert word meanings properly even in a small segment of two languages necessitates two and a half times as many instructions to the computer as are required to simulate the flight of a guided missile.</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">"701 Translator", IBM Press release</span><span class="co">](https://aclanthology.org/www.mt-archive.info/IBM-1954.pdf)</span><span class="at"> (1954-01-08)</span></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Give me code or give me nothing!" collapse="true" }</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>One thing I dislike about some technical histories and overviews is that I keep getting a cotton-like, vaporwave feeling in the brain after reading them. It is easy to read an abstract story. </span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>For example, many AI papers by OpenAI after 2020 has become like that. In any case, I looked up the program, which appeared in <span class="co">[</span><span class="ot">@ornsteinMechanicalTranslationNew1955</span><span class="co">]</span> as a single giant flowchart. I didn't read the spaghetti code in detail, but it seems to me that it first parses the input sequence into words and sub-words, then it starts from left to right, for each word/sub-word, find the rule that applies to it. Executing the rule would pick an English translation for that word/sub-word, and either switch that fragment of translation with the previous fragment, or not. There are 6 rules, of which I just copy one, since the others look similarly boring:</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Choice-Rearrangement. If first code is </span><span class="in">`131`</span><span class="at">, is third code of preceding complete word or either portion (root or ending) of preceding subdivided word equal to </span><span class="in">`23`</span><span class="at">? If so, adopt English equivalent II of word carrying </span><span class="in">`131`</span><span class="at"> and retain order of appearance of words in output; if not, adopt English equivalent I and reverse order of appearance of words in output.</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>The following is a rough Python sketch. It just implements half of rule 3, but gives you an idea of how the program would go. I estimate that it should take about 100 lines to implement a fully correct version. Even this rough sketch tells you that it is a very 1950s kind of program, with imperatives and if-then statements everywhere, combined with table lookups.</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> {</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ugl-"</span>: (<span class="st">"coal"</span>, <span class="st">"angle"</span>, <span class="dv">121</span>, <span class="dv">0</span>, <span class="dv">25</span>),</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-a"</span>: (<span class="st">"of"</span>, <span class="st">""</span>, <span class="dv">131</span>, <span class="dv">222</span>, <span class="dv">25</span>), </span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>stems <span class="op">=</span> [word[:<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> word <span class="kw">in</span> dictionary.keys() <span class="cf">if</span> word[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="st">'-'</span>]</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>suffixes <span class="op">=</span> [word[<span class="dv">0</span>:] <span class="cf">for</span> word <span class="kw">in</span> dictionary.keys() <span class="cf">if</span> word[<span class="dv">0</span>] <span class="op">=</span> <span class="st">'-'</span>]</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="kw">class</span> Word:</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, word, stems, suffixes):</span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.stem <span class="op">=</span> word</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.suffix <span class="op">=</span> <span class="st">''</span></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> stem <span class="kw">in</span> stems:</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> suffix <span class="kw">in</span> suffixes:</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> word <span class="op">=</span> stem <span class="op">++</span> suffix:</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.stem <span class="op">=</span> stem</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.suffix <span class="op">=</span> suffix</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse(sentence, stems, suffixes):</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> sentence.split(<span class="st">' '</span>)</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [Word(word, stems, suffixes) <span class="cf">for</span> word <span class="kw">in</span> words]</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate(words, dictionary):</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>    translation <span class="op">=</span> []</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(words):</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>        word <span class="op">=</span> words[i]</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word.suffix <span class="op">=</span> <span class="st">''</span>:</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dictionary[word.stem][<span class="st">'code 1'</span>] <span class="op">==</span> <span class="dv">131</span>:</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>                    previous_word <span class="op">=</span> words[i<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> dictionary[previous_word.stem][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span> <span class="kw">or</span> (previous_word.suffix <span class="op">!=</span> <span class="st">''</span> <span class="kw">and</span> dictionary[previous_word.suffix][<span class="st">'code 3'</span>] <span class="op">==</span> <span class="dv">23</span>):</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>                        flag <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>                        flag <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>                    flag <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> flag <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>                    translation.append(dictionary[word.stem][<span class="st">'code 1'</span>])</span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a>                    translation[<span class="op">-</span><span class="dv">2</span>:<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> [translation[<span class="op">-</span><span class="dv">1</span>], translation[<span class="op">-</span><span class="dv">2</span>]]</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>                    translation.append(dictionary[word.stem][<span class="st">'code 2'</span>])</span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Translate stem, then suffix. It's a bit tedious.</span></span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> translation.join(<span class="st">' '</span>)</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>The exact details on how the program was implemented on the IBM was non-trivial, since both the machine and the programming environment around it were designed for numerical computations, not discrete symbolic manipulations. <span class="co">[</span><span class="ot">@sheridanResearchLanguageTranslation1955</span><span class="co">]</span> described the details. The programming language LISP must wait until 1960 to appear. Dedicated to symbolic manipulations. It would dominate most of AI research until the 1980s.</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>Another interesting fact is the amount of restrictions placed on the demo: 250 words, each word having just 1 or 2 possible translations, and each Russian word is either a full word or a <span class="in">`stem-suffix`</span>, etc. An even deeper restriction was entirely hidden from view: pronouns. In Russian, pronouns are often dropped when the verb form makes it clear. To avoid this problem, for all demonstrated sentences, the English pronouns occur only in translations of verbs in the third person plural.</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Subsequent work</span></span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>The Georgetown--IBM demo worked. The CIA started funding MT research at Georgetown University (eventually up to \$1,500,000), and other MT groups sprang up in America, Europe, and the Soviet Union. In general, their approaches could be divided into three parts: word-for-word, syntax, and eclectic.</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>The idea of word-for-word translation is essentially a direct scale-up of the Georgetown--IBM demo, just with a much bigger dictionary and a few more local word-reordering rules. True, there are some ambiguities like "The vodka was good, but the meat was rotten.", but we can just pick the most likely translation, or translate a multi-word Russian phrase directly to a multi-word English phrase, etc. Erwin Reifler exemplified the "solved by lexicography" approach:</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Papers on MT are nowadays heavily weighted on the side of the development of structural linguistic procedures for the solution of MT problems, and very rightly so. But many of these problems can be solved by lexicography... in certain types of cases of higher frequency it is possible to solve grammatical and non-grammatical problems by lexicography and lexicographical procedures alone--that is, without the necessity of logical procedures and logical machine operations. Since our sponsors had asked us to concentrate, at least during the initial phases of our project, on the elaboration of a bilingual lexicon, we decided to try to achieve an optimum of lexicography which would solve as many of our bilingual problems as possible. The results of this lexicographical work were... almost 170,000 MT-operational Russian-English entries.</span></span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@reiflerSolutionMTLinguistic1960</span><span class="co">]</span></span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>This was the <span class="co">[</span><span class="ot">AN/GSQ-16 translator</span><span class="co">](https://en.wikipedia.org/wiki/AN/GSQ-16_Automatic_Language_Translator)</span>, which would eventually be subsumed by SYSTRAN.</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>Similarly, at RAND corporation, they performed large-scale statistical analysis of corpus, used the analysis to write some Russian-English dictionary and reordering rules. Ran the program, checked the output, rewrote the dictionary and rules, etc. It was kind of a RAND-om gradient descent.</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>At MIT under Victor Yngve, the research agenda was fully based on syntax. A sentence in the source language is parsed into a syntax tree, then the syntax tree is transformed by some rotation, grafting, cutting, and pasting, and finally the leaf-words are substituted into the target language. To see an example use of this, consider the German sentence »Hans kommt heute abend an.«, which translates to "Hans arrives this evening".. Here, "arrives" corresponds to »kommt ... an«, and the distance between the two pieces of the verb can be arbitrarily long, thus no local transformation rule would work. However, though this is similar in spirit to Chomskyan linguistics, Chomsky was only briefly in the group, and his generative grammar was not used.</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Some example syntax trees according to Yngve. They show "discontinuous constituents", much like the German example of »Hans kommt heute abend an.«. [@yngveModelHypothesisLanguage1960, figure 31]</span><span class="co">](figure/Yngve_1960_fig_31.png)</span></span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>At Georgetown, the approach was more eclectic, with some syntax parsing and some statistical analysis with dictionary. Like most eclectic systems, it defies summary.</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>Meanwhile in the Soviet Union, MT research was based on a deep analysis of language at multiple levels (phonetic, phonemic, morphemic, surface syntactic, deep syntactic, semantic), similar to the <span class="co">[</span><span class="ot">Vauquois triangle</span><span class="co">](https://en.wikipedia.org/wiki/Bernard_Vauquois#Vauquois_triangle)</span>, though they called it "<span class="co">[</span><span class="ot">Meaning--Text Theory</span><span class="co">](https://en.wikipedia.org/wiki/Meaning%E2%80%93text_theory)</span>".</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a><span class="al">![The Vauquois triangle.](figure/Vauquois%20triangle.png)</span></span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>For details on this period, I refer to <span class="co">[</span><span class="ot">@hutchinsMachineTranslationConcise2007</span><span class="co">]</span>.</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a><span class="fu">### Winter comes</span></span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a>Around 1964, there was an uneasy feeling around AI. The post-war flood of governmental funds was slowing as the optimistic "Science, the Endless Frontier" lost its shine. There were much bigger projects to do, like sending 2 men to the moon or 3 million to Vietnam. The general atmosphere was subdued. Eventually funding would be cut even more with the Mansfield Amendments of 1973, which limited ARPA to only funding projects directly relevant to military applications.</span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By 1966, it was estimated that roughly 20 million dollars (in contemporary dollars) had been spent on MT in the US, with Georgetown, at 1,317,239 dollars (93.5 percent from the CIA, 6.5 percent from the NSF) being the largest.. "In comparison, let us notice that in June 1952, when the First conference on Machine Translation convened at MIT, there was probably one person in the world engaged more than half-time in work on MT, namely myself </span><span class="sc">\[</span><span class="at">Bar-Hillel</span><span class="sc">\]</span><span class="at">". The budget had been roughly ten thousand dollars.</span></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gordinForgettingRediscoverySoviet2020</span><span class="co">]</span></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a>In 1964, the US government created the ALPAC committee of 7 linguists "to advise the Department of Defense, the Central Intelligence Agency, and the National Science Foundation on research and development in the general field of mechanical translation of foreign languages". The roster of names makes it clear that MT was a matter of state security. It was all well and good if MT could eventually reach human level performance in a few centuries, or if MT research could *right now* inform the science of linguistics and assist the universe's ceaseless striving to rationally know itself, but let us never confuse the universal with the here and now.</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Are you looking for the Secret Name, Scharlach?" ... in his voice Lönnrot detected a fatigued triumph, a hatred the size of the universe, a sadness no smaller than that hatred. "No. I am looking for something more ephemeral and slippery, I am looking for Erik Lönnrot..."</span></span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Borges, *Death and the Compass* (1942)</span></span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a>The Georgetown--IBM experiment proved to be *too* good of a demo. The sentences were picked to present it in the best light, and the rules were written so that the machine would translate the sentences correctly. Subsequent MT research could not match the demo, and skeptics appeared.</span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Dorset is "a great conversationalist ... but as a researcher I was unsure about him, whether he was just a figurehead or whether he was a bit of a fraud -- the Georgetown MT demonstrations seemed always to be contrived; they made impressive publicity for the sponsors, but they soured the atmosphere by raising expectations that nobody could possibly fulfill." ... MT colleague Winifred Lehmann was overheard describing him as "a wart on the field of linguistics".</span></span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Old gossips quoted in </span><span class="co">[</span><span class="ot">@gordinDostoevskyMachineGeorgetown2016</span><span class="co">]</span></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a>The ALPAC committee worked for 2 more years before presenting the final report in 1966 <span class="co">[</span><span class="ot">@automaticlanguageprocessingadvisorycommitteeLanguageMachinesComputers1966</span><span class="co">]</span>. Most of the report is not on whether MT is possible, but on the economics of translating technical documents from Russian to English, and whether MT would be economically good enough for this within the next few years. For example, it calculated that since a machine-translated document takes longer to read, if a document were to be read by more than 20 people, human translation is more economical. What the report says about MT itself is fairly brief:</span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Machine Translation" presumably means going by algorithm from machine-readable source text to useful target text, without recourse to human translation or editing. In this context, there has been no machine translation of general scientific text, and none is in immediate prospect. The contention that there has been no machine translation of general scientific text is supported by the fact that when, after 8 years of work, the Georgetown University MT project tried to produce useful output in 1962, they had to resort to post-editing. The post-edited translation took slightly longer to do and was more expensive than conventional human translation.</span></span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... Early machine translations of simple or selected text, such as those given above, were as deceptively encouraging as "machine translations" of general scientific text have been uniformly discouraging. However, work toward machine translation has produced much valuable linguistic knowledge and insight that we would not otherwise have attained.</span></span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;...  it is wise to press forward undaunted, in the name of science, but that the motive for doing so cannot sensibly be any foreseeable improvement in practical translation. Perhaps our attitude might be different if there were some pressing need for machine translation, but we find none.</span></span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>Despite this, it resulted in a swift deep cut in governmental funding for MT research, not just in America, but also in the Soviet Union. Quite understandable. However, like the concurrent loss of funding for neural network research, it resulted in an AI winter for MT, and a general impression that MT had been debunked.</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Its effect was to bring to an end the substantial funding of MT research in the United States for some twenty years. More significantly, perhaps, was the clear message to the general public and the rest of the scientific community that MT was hopeless. For years afterwards, an interest in MT was something to keep quiet about; it was almost shameful. To this day, the 'failure' of MT is still repeated by many as an indisputable fact... from time to time in the next decades researchers would discuss among themselves whether "another ALPAC" might not be inflicted upon MT.</span></span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hutchinsALPACFamousReport2003</span><span class="co">]</span></span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The effect of the ALPAC report in 1966 was as great in the Soviet Union as in the United States. Many projects were not funded any more; machine translation went into decline. The authorities had seen the ALPAC documents and concluded that if the Americans did not think it worthwhile to support MT, if they did not think there was any hope of MT, then nor should we... </span><span class="sc">\[</span><span class="at">But</span><span class="sc">\]</span><span class="at"> we had never pretended that we were doing actual machine translation, we were doing formal linguistics.</span></span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Igor A. Mel'čuk</span><span class="co">](https://en.wikipedia.org/wiki/Igor_Mel'%C4%8Duk)</span><span class="ot">[^igor-melchuk]</span><span class="at"> (2000), quoted in </span><span class="co">[</span><span class="ot">@gordinForgettingRediscoverySoviet2020</span><span class="co">]</span></span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a><span class="ot">[^igor-melchuk]</span>: </span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a>    Melchuk was one of the founders of Meaning--Text Theory, which as you might imagine, believed in deep theoretical understanding, not in programs that seemed to work in practice. In a 2024 interview:</span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; 60 years later, this problem has been solved in a completely different way... Today's machine translation using artificial intelligence is admirable, but it has nothing to do with the science of language. The machine translates brilliantly, but we learn nothing new about linguistics from it... In general, I am a typical armchair scientist. I am interested in knowing, not in being able to do something practical.</span></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [Igor Melchuk on non-traditional linguistics and machine translation — "System Block"](https://sysblok.ru/interviews/menja-interesuet-znat-a-ne-prosto-umet-igor-melchuk-o-netradicionnoj-lingvistike-mashinnom-perevode-i-zhizni-v-kanade/)</span></span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a><span class="in">    Such attitude will appear again and again among the "Chomskyans" or "Rationalists", as we will see throughout this essay, is the common trend underlying logical AI research.</span></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Yehoshua Bar-Hillel</span><span class="co">](https://en.wikipedia.org/wiki/Yehoshua_Bar-Hillel)</span> against machine translation -- what he called FAHQT (Fully Automatic High-Quality Translation, or as I imagine him saying it, "Machine translation? Ah, FAHQT."). The argument goes like:</span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>FAHQT requires general world understanding, because natural language is full of ambiguities that require general world understanding.</span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>General world understanding is "utterly chimerical and hardly deserves any further discussion'.</span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a>The standard example he gave was "The box is in the pen.", where the issue is how to disambiguate the word "pen". Does it mean the writing instrument, or an enclosure? For a machine to pick the right meaning, it must know that a pen cannot contain a box, while an enclosure can. This cannot be done by merely looking up every word in a dictionary, or drawing up its the syntax tree. It must have general world understanding, or common sense.</span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Assume, for simplicity's sake, that *pen* in English has only the following two meanings: (1) a certain writing utensil, (2) an enclosure where small children can play. I now claim that no existing or imaginable program will enable an electronic computer to determine that the word *pen* in the given sentence within the given context has the second of the above meanings, whereas every reader with a sufficient knowledge of English will do this "automatically".</span></span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Whenever I offered </span><span class="sc">\[</span><span class="at">the challenge</span><span class="sc">\]</span><span class="at"> to one of my colleagues working on MT, their first reaction was: "But why not envisage a system which will put this knowledge at the disposal of the translation machine?" ... What such a suggestion amounts to, if taken seriously, is the requirement that a translation machine should not only be supplied with a dictionary but also with a universal encyclopedia. This is surely utterly chimerical and hardly deserves any further discussion... Reasonable goals are then either fully automatic, low quality translation or partly automatic, high quality translation. Both are theoretically feasible and, for certain language pairs, attainable today though not yet on a commercial scale.</span></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@bar-hillelPresentStatusAutomatic1960</span><span class="co">]</span></span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a>If FAQHT is impossible for all "existing or imaginable" programs, there can exist only two proper kinds of machine translation. One was automatic low-quality translation, and another was explicitly designed as a help, not a replacement, to human translators. The first kind was all there was, and Bar-Hillel called for researchers to work on the second kind.</span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a>Interestingly, it has mentioned "learning machines" only to not discuss it further, even though machine learning would turn out to be the key to general world understanding. This dismissal of machine learning would continue for quite some more years.</span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a>He presented his opinion more forcefully 4 years later in an editorial:</span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It seems now quite certain to some of us, a small but apparently growing minority, that with all the progress made in hardware (i.e., apparatus), programming techniques and linguistic insight, the quality of fully autonomous mechanical translation, even when restricted to scientific or technological material, will never approach that of qualified human translators and that therefore Machine Translation will only under very exceptional circumstances be able to compete with human translation.</span></span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... there is no prospect whatsoever that the employment of electronic digital computers in the field of translation will lead to any revolutionary changes. A complete automation of the activity is wholly utopian, since the fact that books and papers are usually written for readers with a certain background knowledge and an ability for logical deduction and plausible reasoning cannot be over-ridden by even the cleverest utilization of all formal features of a discourse. The hopes to the contrary which many of us had a decade ago just turned out to be by and large unrealizable. The quicker this is understood, the better are the chances that more attention will be paid to finding efficient ways of improving the status of scientific and technological translation--I am not qualified to discuss literary translation--including a judicious and modest use of *mechanical aids*.</span></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@bar-hillelFutureMachineTranslation1964</span><span class="co">]</span>  </span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a>Bar-Hillel's objection is reminiscent of the <span class="co">[</span><span class="ot">Winograd schema challenge</span><span class="co">](https://en.wikipedia.org/wiki/Winograd_schema_challenge)</span>, which also tests for general world understanding. Indeed, even Terry Winograd had a tentative guess that the Winograd challenge is too challenging, though it is clearly just a weak guess, not a firm prediction like the previous quotes.</span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The limitations on the formalization of contextual meaning make it impossible at present -- and conceivably forever -- to design computer programs that come close to full mimicry of human language understanding.</span>  </span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@winogradComputerSoftwareWorking1984</span><span class="co">]</span>  </span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a>What do we make of such criticism? At that point in time, there were three possible replies:</span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Intelligence amplification: Instead of the mirage of replacing human translators, try to build little programs that augment human translators. </span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Brute force logical programming: Scale up commonsense by hiring more linguists to program in increasingly large chunks of the world.</span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>AI is a mirage, and the failures of MT is a symptom of that.</span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>From our vantage point, the actual solution turned out to be:</span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The bitter lesson: Wait a few decades, then train a giant neural network on a trillion words from the Internet to give it general world knowledge.</span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a>There is a common mistake about the bitter lesson, that even Richard Sutton makes. It is not just that the bitter lesson is bitter, but also that it is *difficult*. People did not believe in it, not because they were afraid of bitterness, but because it was obviously stupid, a kind of straw man's argument.</span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a>Consider the arguments of a latter-day Bar-Hillel:</span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The case against machine translation as a solution to practical problems is overwhelming and has been made many times. I do not propose to repeat it in any detail here. It will, however, be worth a few words to make a *prima facie* case for the implausibility of practical machine translation if only so that the contrast with realistic approaches to the problem will be more striking... There is a great deal that computer scientists and linguists could contribute to the practical problem of producing translations, but, in their own interests as well as those of their customers, they should **never** be asked to provide an engineering solution to a problem that they only dimly understand.</span></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I want to advocate a view of the problem in which machines are gradually, almost imperceptibly, allowed to take over certain functions in the overall translation process. First they will take over functions not essentially related to translation. Then, little by little, they will approach translation itself. The keynote will be *modesty*. At each stage, we will do only what we know we can do reliably.</span></span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@kayProperPlaceMen1997</span><span class="co">]</span></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a>Now we know that "engineering solutions to a problem they only dimly understand" was precisely the breakthrough in multiple fields. In this essay we would this appearing in <span class="co">[</span><span class="ot">speech recognition</span><span class="co">](#sec-speech)</span>, TODO, TODO, and TODO. It also happened with AlphaGo, made by a team who only had Go amateurs, or diffusion artists made by engineers with minimal understanding of art. However, just try saying out loud, "I'll solve translation just by training a sequence to sequence neural network, on a few million pairs of English-German sentence pairs. It won't have a probabilistic interpretation, or a syntax tree, or morphological constraints. In fact I haven't even taken a course in intermediate linguistics. But I have trained many neural networks. Surely if I can get the loss low enough, it will work." The reasonable reply would be, "What hubris, to tackle a problem that has stumped decades of linguistic science with the brute reason of engineering! What Goodhart law, to expect minimizing loss will lead to the thing you actually want, which is translation? What alchemy, to expect to put in nothing but data and compute, and somehow create understanding in a machine, an understanding that you don't have yourself?".<span class="ot">[^feynman-kac]</span></span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a><span class="ot">[^feynman-kac]</span></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>    Perhaps the <span class="co">[</span><span class="ot">Feynman--Kac</span><span class="co">](https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula)</span> anecdote illustrates this better.</span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; Kac went to Pasadena to lecture at the California Institute of Technology. Richard Feynman was in the audience. After the lecture, Feynman got up and announced: "If all mathematics disappeared, it would set physics back precisely one week." Without a pause, Kac responded: "Precisely the week in which God created the world."</span></span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt;</span></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@cohenLifeImmeasurableMind1986]</span></span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a><span class="in">    So perhaps...</span></span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; "If we fired all the linguists, it would set machine translation back precisely one week."</span></span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; "Precisely the week in which God struck down the Tower of Babel."</span></span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>To end this section, I quote from one of the authors of the ALPAC report an amusing anecdote about Yngve, which was an omen of the ultimate fate of logical MT:</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There's sometimes a strong scholastic emphasis, or current, which causes some psychologists to produce very closely reasoned ideas that aren't checked at every point with experiment. Some of the theoretical linguists are like that. They are extremely plausible. But I know a fellow, </span><span class="co">[</span><span class="ot">Victor Yngve</span><span class="co">](https://en.wikipedia.org/wiki/Victor_Yngve)</span><span class="at">, who tried to write a transformational grammar of the English language, a reasonably complete one. It took him years and years and he never got it written. He kept finding difficulties that don't appear when you have a few nice examples of what a transformation of grammar is supposed to be all about.</span></span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; John Pierce, quoted in </span><span class="co">[</span><span class="ot">@lyleInterviewJohnRobinson1979</span><span class="co">]</span></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a><span class="fu">### The alignment problem</span></span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a>The decade after ALPAC was more subdued. MT research continued, but with minimal government funding, and it often continued as a kind of computational study in service of basic research in linguistics. They typically followed the approach of Vauquois, that is, to take a sentence from one language, and parse it into higher and higher levels of abstraction, reaching an "interlingua" stage that is fully language-independent, then move back down again until one lands safely in the other language. It reminds me of taking an airplane across an ocean.</span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a>But MT was about to take a sudden turn away from theory.</span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a>In 1986, speech recognition was solved. Well, not exactly, but during the period of 1976--1986, a group of researchers in IBM managed to produce speech recognition systems better than ever before, by "firing the linguists", and returning to the information-theoretic approach that Shannon and Weaver had back in the 1950s. Armed with compute, data, and a disregard for linguistic science, they got it to work, and in 1986, they decided to try the same trick, but this time with MT.</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>In our language, the idea was encoder-decoder translation, using Bayesian probability. Suppose we want to translate a sentence in foreign language $f$ to an English sentence $e$. We imagine that the foreign speaker was really trying to speak English, but somehow, words came out *encoded* as a foreign language, and our goal is to *decode* from it. This gives us 3 components:</span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>English language model: $Pr(e)$, the prior probability of the speaker wanting to say $e$.</span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Encoder model: $Pr(f | e)$, the conditional probability that the speaker would end up saying $f$, if they wanted to say $e$.</span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Decoder: $f \mapsto e$, the translator we want to construct.</span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>The decoder is the maximum a posteriori solution:</span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a>e^*(f) := \argmax_e Pr(f|e) Pr(e)</span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The encoder-decoder translation architecture. [@jelinekMyBestFriends2005, figure 3]</span><span class="co">](figure/source-channel_model_MT.png)</span></span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a>Once we have both $Pr(f|e)$ and $Pr(e)$, we have a machine translator. To obtain $Pr(f|e)$ and $Pr(e)$, the team used simple statistical models, not much more complex than n-gram models, with parameters estimated by <span class="co">[</span><span class="ot">expectation-maximization algorithm</span><span class="co">](https://en.wikipedia.org/wiki/Expectation-maximization_algorithm)</span>.<span class="ot">[^ibm-alignment]</span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a><span class="ot">[^ibm-alignment]: </span>We are skipping over the word-alignment part of the IBM models, which tells you which words in $f$ corresponds to which words in $e$. We still have an encoder-decoder architecture, but it's more complicated.</span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a>The IBM team worked on this from 1986 to the early 1990s, and their state of the art performance led to a statistical revolution in MT. Compared to the theoretically principled MT of the past, the IBM language model was obviously wrong: languages are obviously impossible to be correctly modelled by an n-gram model, or the slightly more complex upgraded models they used. Where are the syntax trees, the constituencies, etc? Yet it did work, and it took over practical MT research.</span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a>Their primary dataset was the Canadian <span class="co">[</span><span class="ot">Hansard</span><span class="co">](https://en.wikipedia.org/wiki/Hansard)</span> corpus -- transcripts of proceedings from the Canadian parliament which were available in both English and French due to Canada's bilingual policy. The Hansard parallel corpus contained around 3 million sentence pairs at the time. While substantial, it pales in comparison to monolingual English corpora to train $Pr(e)$. English text was abundant from government documents, news archives, books, etc. In short, the encoder-decoder structure was adapted for the data regime of abundant monolingual (used to train $Pr(e)$) but limited parallel text (used to train $Pr(f|e)$).</span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>In the introduction to a "Special Issue on Computational Linguistics Using Large Corpora", <span class="co">[</span><span class="ot">@churchIntroductionSpecialIssue1993</span><span class="co">]</span> argued that "Rationalism", having been reigning since 1970s, was facing legitimate challenge by "Empiricism" again, for three reasons: more compute, more data, and a culture centered on evaluation.</span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The emphasis today on empirical methods in the speech recognition community is a reaction to the failure of knowledge-based approaches of the 1970s. It has become popular once again to focus on high-level natural language constraints in order to reduce the search space. But this time, n-gram methods have become the methods of choice because they seem to work better than the alternatives, at least when the search space is measured in terms of entropy. Ideally, we might hope that someday parsers might reduce entropy beyond that of n-grams, but right now, parsers seem to be more useful for other tasks such as understanding who did what to whom, and less useful for predicting what the speaker is likely to say.</span></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Someday parsers might help squeeze out some of this remaining half bit between the trigram model and Shannon's bound, but thus far, parsing has had little impact... The issue remains as controversial as ever, as evidenced by the lively debate on rationalism versus empiricism at TMI-92, a recent conference on MT... The information theoretic approach to MT may fail for reasons advanced by Chomsky and others in the 1950s. But regardless of its ultimate success or failure, there is a growing community of researchers in corpus-based linguistics who believe that it will produce a number of lexical resources that may be of great value.</span></span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@churchIntroductionSpecialIssue1993</span><span class="co">]</span></span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a>That was 1993. And the Internet was coming, and it kept coming, and it is still coming, and it just won't stop coming.</span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a>When a user makes a search request like "IBM", Google's servers must retrieve not only website urls like <span class="in">`www.ibm.com`</span>, but also a snippet view like "...**IBM** has been a global technology innovator...".  Therefore, Google had been crawling the Internet and storing a plain-text copy of the Internet regularly, with a size on the order of 100 TB as of 2003. <span class="co">[</span><span class="ot">@barrosoWebSearchPlanet2003</span><span class="co">]</span> Once with such a large dataset, what could be done with it?</span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a>In 2006, Google Translate was launched. Early reactions were a mixture of fascination and sarcasm, leading to memes of hilarious Google translations that has survived to this day, even though the improvements has made it very difficult to do nowadays. Despite this, it was agreed that Google had achieved state of the art in statistical machine translation. How did it do it? By brutally scaling up.</span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a>In <span class="co">[</span><span class="ot">@brantsLargeLanguageModels2007</span><span class="co">]</span>, the authors described how Google achieved such a feat. Despite possibly lower quality than a more sophisticated algorithm, the "stupid backoff" allowed them to train on 60× more data and run 10000× faster during inference. The largest model was trained on a dump of the Internet (January 2006) with 2 trillion tokens, 300M 5-grams, 16M vocab, 1.8 TB language model, took 1 day to train on 1500 machines. They noted that the more data they used, the higher the BLEU score got, and simply drew a straight line, expecting the model to keep improving if they did it on even more data. </span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a>The title was "Large Language Models in Machine Translation". 10 years later, Large Language Models would be reborn in the guise of the Transformer, again out of research efforts to improve Google Translate.</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a><span class="fu">### ABBYY's last stand</span></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a>18 years after his introduction <span class="co">[</span><span class="ot">@churchIntroductionSpecialIssue1993</span><span class="co">]</span>, Kenneth Church proposed in 2011 a 20-year cycle between Empiricism and Rationalism, and argued that we were on the brink of a return to Rationalism:</span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1950s: Empiricism (Shannon, Skinner, Firth, Harris)</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1970s: Rationalism (Chomsky, Minsky)</span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1990s: Empiricism (IBM Speech Group, AT&amp;T Bell Labs)</span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>2010s: A Return to Rationalism?</span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The shift from Rationalism to Empiricism, as measured by the proportion of statistical papers submitted to the Association for Computational Linguistics. Based on two independent surveys by Bob Moore and Fred Jelinek. [@churchPendulumSwungToo2011, figure 1]</span><span class="co">](figure/Kenneth_2011_fig_1.png)</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; When we revived empiricism in the 1990s, we chose to reject the position of our teachers for pragmatic reasons. Data had become available like never before. What could we do with it? We argued that it is better to do something simple than nothing at all. Let's go pick some low hanging fruit. While trigrams cannot capture everything, they often work better than the alternatives... That argument made a lot of sense in the 1990s, especially given unrealistic expectations that had been raised during the previous </span><span class="sc">\[</span><span class="at">expert systems</span><span class="sc">\]</span><span class="at"> boom. But today's students might be faced with a very different set of challenges in the not-too-distant future. What should they do when most of the low hanging fruit has been pretty much picked over? ... we should expect Machine Translation research to make more and more use of richer and richer linguistic representations. So too, there will soon be a day when stress will become important for speech recognition.</span></span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@churchPendulumSwungToo2011</span><span class="co">]</span></span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a>It has been 15 years. The pendulum is still probing the unknown depths of Empiricism.</span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a>In 1989, ABBYY was founded in Moscow. Its first product was an electronic dictionary, followed by an <span class="co">[</span><span class="ot">ABBYY FineReader optical character recognition (OCR)</span><span class="co">](https://en.wikipedia.org/wiki/ABBYY_FineReader)</span>, which became an international hit. With such a stable cash flow, ABBYY aimed higher: It would develop Compreno, a "Natural Language <span class="co">[</span><span class="ot">Compiler</span><span class="co">](https://en.wikipedia.org/wiki/Compiler)</span>" (NLC) based on linguistic theory. Compreno would take the lowest level of Vauquois triangle (actual language) to the highest level (language-independent meaning, interlingua), which can then be decompiled to another language. It was Meaning--Text Theory in action.</span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a>The founders of ABBYY were students of <span class="co">[</span><span class="ot">Moscow PhysTech</span><span class="co">](https://en.wikipedia.org/wiki/Moscow_Institute_of_Physics_and_Technology)</span>, and ABBYY already had hired linguists to work on its dictionaries and OCR, so it seemed only natural to implement the natural language compiler based on the science of linguistics.</span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Along with the programmers and machine learning specialists who held profitable products like FineReader and FlexiCapture (a smart, customizable payment recognition system for banks) on their shoulders, this cozy office houses dozens, and at its peak, hundreds of linguists. All of them are engaged in the formal description of the language within the semantic hierarchy of ABBYY NLC / Compreno. </span></span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a><span class="al">![Formal analysis of an English sentence in the ABBYY NLC / Compreno model.](figure/ABBYY_Compreno_sentence_analysis.jpg)</span></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a>In the early 2010s, the cost of Compreno had reached \$80 million, yet the finished Compreno translator was as distant as ever. Previews of the translator impressed journalists with cherry-picked examples, but they knew they could not compete with Google Translate. Still, too many had sunk their loving labor into Compreno to abandon it, so ABBYY pivoted it to what looks like <span class="co">[</span><span class="ot">CYC</span><span class="co">](#sec-cyc)</span>, something that boasts homonym resolution, filling in the blanks, information retrieval (in corporate archives) and extracting information from text.</span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a><span class="al">![A graph display of semantic information extracted by ABBYY Compreno.](figure/ABBYY_Compreno_semantic_graph.png)</span></span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a>It proved brittle like all logical AI systems do:</span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We had customers who needed, for example, to extract data on transaction participants from document scans in which the text was written in a kind of "legal dialect" of American English. When this text (with recognition errors, extra dots due to breadcrumbs on the scan and other artifacts) flew into the sophisticated NLC / Compreno analyzer, the output was most often an absolutely unpredictable mess with a bunch of messages about parsing errors... The variety of syntactic-semantic structures was almost greater than the (comparatively more predictable) variety of simple word chains of the source text. At some point, I realized that most of the time I was engaged in a war with Compreno output using regular expressions and other crutches, and I thought that I needed to leave ABBYY.</span></span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; After leaving the company, I once took HSE computer linguistics students on a tour of ABBYY... One of the students, Pasha, joked that ABBYY employees climb up there during a thunderstorm and shout “I’m making a correct parser in 2018,” after which lightning strikes them. It was a cruel joke, but it hit the mark.</span></span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Despite the success of Transformers,</span><span class="sc">\]</span><span class="at"> ABBYY continued to cling to this "suitcase without a handle", trying to combine the handwritten language model of Compreno and neural network approaches. And they probably would have continued further, if not for 2022.</span></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a>After Russia invaded Ukraine in 2022, to avoid Western sanctions, ABBYY quickly distanced itself from its Russian origins, claiming to be a fully American company. To make good on this claim, it finally fired all its Russian employees and became a fully American company in 2024-10. Thus ended Compreno, 20 years and \$80 million later, <span class="co">[</span><span class="ot">ABBYY's bitter lesson</span><span class="co">](https://sysblok.ru/blog/gorkij-urok-abbyy-kak-lingvisty-proigrali-poslednjuju-bitvu-za-nlp/)</span> <span class="co">[</span><span class="ot">@skorinkinABBYYsBitterLesson2024</span><span class="co">]</span></span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a>The essay was in Russian, and I read it by pure Google Translate. It worked perfectly.</span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a><span class="fu">## Speech {#sec-speech}</span></span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a><span class="fu">### Early days</span></span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a>Automatic speech recognition (ASR) is the conversion of speech audio to text. Its history resembles the history of MT. </span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a>It is hard to know what is closest at hand. Speaking is so natural that it takes effort to even notice that there is structure within the smallest sound, and it required the invention of the phonograph to notice the fine details of even a single vowel. In the early 20th century, as AT&amp;T connected all of America with telephone lines, it funded research into efficient coding of speech, with the hopeful goal of saving on bandwidth. The rough idea is similar to the idea of mp3: If the engineers knew what mattered and what didn't matter in human speech recognition, then they could squeeze more telephone calls within the same line.</span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a>Concretely, one could imagine a device on a telephone that converts all the richness of a speech-stream into just 20 bit-streams, then braid those 20 bit-streams into a narrow frequency band, send it all the way across America, whereupon it gets decompressed back to the speech-stream, impoverished but still perfectly recognizable.</span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a>It began with recognition of individual spoken words, which was possible by featurizing the sound, then match that sequence of feature vectors against the template feature vectors.</span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a>An illustrative example of this early period of ASR was reported in <span class="co">[</span><span class="ot">@denesDesignOperationMechanical1959</span><span class="co">]</span>. It could spell individual word phonetically (i.e. "cartoon" spelled as "katun") -- if the word is made out of only 4 vowels and 9 consonants, in an alternating fashion (i.e. no two vowels together, or two consonants together).</span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a>The machine first uses a filter bank to featurize the input sound. Pairs of outputs from the filter bank are then multiplied to measure how likely the sound is a phoneme. For example, the outputs from 200 Hz and 320 Hz are multiplied together, and that measures how likely the sound is "m", because the two principal frequencies of "m" are close to 200 Hz and 320 Hz. Finally, a computer selects the most likely phoneme, based on the multiplied results and a simple statistical model of how likely a phoneme is to follow the previous phoneme.</span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a>The following pseudocode describes how the system works:</span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> featurize(audio_segment):</span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a>    filter_bank_features <span class="op">=</span> filter_bank(audio_segment)</span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a>        <span class="st">"m"</span>: filter_bank_features[<span class="st">"200 Hz"</span>] <span class="op">*</span> filter_bank_features[<span class="st">"320 Hz"</span>],</span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a>        <span class="st">"i"</span>: filter_bank_features[<span class="st">"250 Hz"</span>] <span class="op">*</span> filter_bank_features[<span class="st">"3200 Hz"</span>],</span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_phoneme(audio_segment, previous_phoneme, phoneme_probability_model):</span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> featurize(audio_segment)</span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a>    phoneme_probabilities <span class="op">=</span> phoneme_probability_model(previous_phoneme)</span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a>    best_score <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a>    best_phoneme <span class="op">=</span> <span class="st">''</span></span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> phoneme <span class="kw">in</span> features.keys():</span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> features[phoneme] <span class="op">*</span> phoneme_probabilities[phoneme]</span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> score <span class="op">&gt;</span> best_score:</span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a>            best_phoneme <span class="op">=</span> phoneme</span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a>            best_score <span class="op">=</span> score</span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_phoneme</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@denesDesignOperationMechanical1959, figure 8</span><span class="co">]</span>](figure/Denes_1959_fig_8.png)</span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logical ASR</span></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a>In typical generative grammar of language, you start with a <span class="in">`SENTENCE`</span>, and repeatedly rewrite it until you end up with a sentence like <span class="in">`Did you hit Tom?`</span></span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a>Here, we push this one level deeper. After a sentence is generated, you substitute each word with its standard pronunciation, resulting in a sequence like <span class="in">`dɪd/juː/hɪt/tɒm`</span>. Next, apply more rewriting rules to account for the fact that we don't pronounce a whole sentence like individual words, but always "glide two words together". For example, <span class="in">`did you`</span> would actually be pronounced like <span class="in">`dija`</span>, so we account for this with a rewriting rule <span class="in">`d/juː -&gt; jə`</span>. Similarly, the double <span class="in">`t`</span> in <span class="in">`hit Tom`</span> would be merged to a single <span class="in">`t`</span>, so we add a rewriting rule <span class="in">`t/t -&gt; t`</span>. And there is no gliding at <span class="in">`ə/h`</span>, so we add <span class="in">`əh -&gt; əh`</span>.</span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a>After this transformation, we obtain <span class="in">`dɪjəhɪtɒm`</span></span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a>This is the basic idea of text-to-speech via generative grammar. For speech-to-text, one would first convert the speech audio into a sequence of phonemes,<span class="ot">[^phone-vs-phoneme]</span> then reverse the generative grammar in the same way as one uses generative grammar to parse the syntax tree of a sentence.</span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a><span class="ot">[^phone-vs-phoneme]: </span>Sometimes you see people distinguish "phone" from "phoneme". In those cases, they make a finer distinction between what the speaker *intends to say* vs what actually comes out of their mouth. In this example, the phoneme would be <span class="in">`...`</span> while the phone would be <span class="in">`...`</span>. This precision is too annoying to me, so instead I will just say that the "phone" is just another "phoneme", and the speaker intends to say the phoneme sequence <span class="in">`...`</span>, which the speaking cortex in the brain encodes into the phoneme sequence <span class="in">`...`</span> to save work for the throat muscles.</span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a>Unlike other aspects of natural language processing, speech-to-text had never abandoned statistics. Even the most ardent logical AI researcher admit that speech is filled with dirty random noise, and so must be processed by statistical filtering before it is clean enough to run symbolic programs over.</span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a>There were many logical ASR systems tried, but most of them consisted of 3 layers:</span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Filter and segment speech into phone-like units, usually in steps of 10 milliseconds (because vowel <span class="co">[</span><span class="ot">formants</span><span class="co">](https://en.wikipedia.org/wiki/Formant)</span> are on the order of 100 Hz).</span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Use pattern recognition to identify the segments</span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Find the utterance that best fits the identified segment string.</span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a>Roughly speaking, "the fit" is usually measured by how many rules are broken, with the rules written by expert linguists. Some examples would make the structure clear.</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a><span class="fu">### ARPA Speech Understanding Project</span></span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a>Like MT, there was also plenty of funding for ASR from the government. And we have not seen the last of John Pierce! 5 years after the ALPAC report debunked MT, he took aim at ASR with mostly the same arguments, but with even sharper language.</span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; speech recognition is attractive to money. The attraction is perhaps similar to the attraction of schemes for turning water into gasoline, extracting gold from the sea, curing cancer, or going to the moon... It is clear that glamor and any deceit in the field of speech recognition blind the takers of funds as much as they blind the givers of funds. Thus, we may pity workers whom we cannot respect. People who work in the field are full of innocent (in their own view) enthusiasm. What particular considerations have led to this enthusiasm?</span></span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... Most recognizers behave, not like scientists, but like mad inventors or untrustworthy engineers. The typical recognizer gets it into his head that he can solve "the problem." The basis for this is either individual inspiration (the "mad inventor" source of knowledge) or acceptance of untested rules, schemes, or information (the untrustworthy engineer approach).</span></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@pierceWhitherSpeechRecognition1969</span><span class="co">]</span></span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a>Pierce gave the same answer as he gave in the ALPAC report. True ASR is impossible until a machine has a general understanding of language, which was very far away. What *appears* to be ASR is actually "artful deceit" made by mere engineering, not science. A true science of ASR is possible, by having a good scientific theory, then testing it, perhaps by building a device according to the theory, and see if it works as predicted.</span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The typical recognizer will have none of this. He builds or programs an elaborate system that either does very little or flops in an obscure way. A lot of money and time are spent. No simple, clear, sure knowledge is gained. The work has been an experience, not an experiment.</span></span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@pierceWhitherSpeechRecognition1969</span><span class="co">]</span></span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a>I don't know what caused Pierce to fire off this fiery missive 3 years after the ALPAC report, but it did cause funding to decrease. <span class="co">[</span><span class="ot">@jelinekMyBestFriends2005</span><span class="co">]</span> Partly in reaction to this, ARPA started the Speech Understanding Project, a $15 million project to produce ASR, from 1971 to 1976. It funded 4 teams in 4 organizations, with the following goal: Demo a system that can do ASR on a fragment of English limited to 1000 words of vocabulary, and a single tiny domain. Accept new speakers after finetuning. At &lt;10% semantic error, at 100 MIPSS (100 million instructions per second of speech).<span class="ot">[^arpa-sur-full-specification]</span></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a><span class="ot">[^arpa-sur-full-specification]</span>: </span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>    The full specification is</span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; Accept continuous speech from many cooperative speakers of the general American dialect, in a quiet room over a good quality microphone, allowing slight tuning of the system per speaker, but requiring only natural adaptation by the user, permitting a slightly selected vocabulary of 1,000 words, with a highly artificial syntax, and a task like the data management or computer status tasks (but not the computer consultant task), with a simple psychological model of the user, providing graceful interaction, tolerating less than 10% semantic error, in a few times real time, and be demonstrable in 1976 with a moderate chance of success.</span></span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt;</span></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@newellSpeechUnderstandingSystems1973, figure 1.1]</span></span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a><span class="in">    but as noted in [@medressSpeechUnderstandingSystems1977, footnote 8], the report forgot to add in "100 MIPSS".</span></span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a>By the end of 1976, the results were out:</span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@ermanHearsayIISpeechUnderstandingSystem1980, figure 13</span><span class="co">]</span>](figure/DARPA_SUR_final_results.png)</span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a>Out of the 4 teams, only Harpy achieved the target -- barely. It could recognize 1011 words, at 5% semantic error. It has size 1.2 MB. It costs 30 MIP to process one second of speech, and since it ran on a 0.4 MIPS PDP-KAI0, it takes about 5 minutes to process a single 4-second sentence, costing about \$5 to process one sentence. Fine-tuning for a single speaker takes about 30 minutes, or \$30.<span class="ot">[^harpy-price]</span></span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a><span class="ot">[^harpy-price]</span>:</span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a>    According to <span class="co">[</span><span class="ot">Cost of CPU Performance Through Time 1944-2003</span><span class="co">](https://www.jcmit.net/cpu-performance.htm)</span>, it cost \$500,000 to rent a PDP-KAI0 for 1 year, or about \$1 per minute.</span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a><span class="in">    As of 2024, the SOTA ASR model is OpenAI Whisper, which OpenAI offers at a price of $\$10^{-4}$ per second. Since \$1 can buy you 1 hour of AI00 at $10^{20} \;\mathrm{FLOP/hour}$, and assuming hardware utilization 10\%, we have about $10^{15} \;\mathrm{FLOP}$ to process 1 second of speech.</span></span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a><span class="in">    I took a double take on this. Are we really throwing 1 million times more compute on ASR compared to Harpy? But the numbers are numbers, and it does seem to checkout: OpenAI Whisper large has $1.55\times 10^9$ parameters, and it featurizes 1 second of speech into $100$ tokens of $80$ dimensions each. So even if we ignore the quadratic scaling of attention, we would take $10^{13} \;\mathrm{FLOP}$ to process 1 second of speech.</span></span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a><span class="in">    And $10^{15}$ is also the number of synapses in the brain. The numbers all seem to come together *too* well. Sound-bite for thought...</span></span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a>Who would be willing to pay \$5 to transcribe one sentence? Still, since the target was so ambitious, the project was still considered a great success:</span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In 1971, when the program started, perhaps the majority of informed technical opinion put general speech recognition by computers as not possible in the foreseeable future and perhaps not possible at all... Informed technical opinion can now be that general cost-effective speech input to computers is an attainable goal. That is now our opinion.</span></span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@medressSpeechUnderstandingSystems1977</span><span class="co">]</span></span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "How hard is the sentence understanding problem in the limited contexts investigated during the ARPA project?" In 1970, when compared with isolated word recognition, the problems seemed immense. After the limited success of Harpy, one becomes more optimistic about the abilities of future systems.</span></span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@klattReviewARPASpeech1977</span><span class="co">]</span></span>
<span id="cb18-496"><a href="#cb18-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-497"><a href="#cb18-497" aria-hidden="true" tabindex="-1"></a>Harpy had the simplest architecture, with just two parts. </span>
<span id="cb18-498"><a href="#cb18-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-499"><a href="#cb18-499" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The lower divides the input audio into 10 ms segments. Each segment is featurized to a single $\R^{14}$ vector by <span class="co">[</span><span class="ot">Linear Predictive Coding</span><span class="co">](https://en.wikipedia.org/wiki/Linear_predictive_coding)</span>. If two segments have similar features, they are merged.</span>
<span id="cb18-500"><a href="#cb18-500" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The upper part is a 15000-state transition graph. Each graph node is an annotated sound symbol. There are 98 sound symbols like <span class="in">`G BURST 1`</span> or <span class="in">`IY`</span>. The annotations allow the system to convert any path through the graph into a text sentence, like "Give me a textbook by Gauss.".</span>
<span id="cb18-501"><a href="#cb18-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-502"><a href="#cb18-502" aria-hidden="true" tabindex="-1"></a>They first designed a complete context-free grammar that incorporates phonetics, syntax, and semantics for making document retrieval requests in a highly simplified and stilted syntax. The 98 sound symbols were constructed by "careful analysis of 747 sentences". After the design was complete, the grammar was automatically compiled into the 15000-state transition graph.</span>
<span id="cb18-503"><a href="#cb18-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-504"><a href="#cb18-504" aria-hidden="true" tabindex="-1"></a>To perform speech recognition, the lower part gives the upper part the featurized sequence of the audio $v_1, v_2, \dots, v_n$, and the upper part beam-searches for a path $x_1, x_2, \dots, x_n$ that approximately minimizes $\sum_i \| v_i - v(x_n)\|$, where $v(x_i)$ is the template feature vector for the sound $x_i$.</span>
<span id="cb18-505"><a href="#cb18-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-506"><a href="#cb18-506" aria-hidden="true" tabindex="-1"></a>To finetune the system for a new speaker, the new speaker simply speaks 20 sentences designed for finetuning, and the system would recalculate the 98 template feature vectors.</span>
<span id="cb18-507"><a href="#cb18-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-508"><a href="#cb18-508" aria-hidden="true" tabindex="-1"></a>::: {#fig-harpy layout-ncol=2}</span>
<span id="cb18-509"><a href="#cb18-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-510"><a href="#cb18-510" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Overall design of Harpy. Note how semantic, syntactic, lexical, and word juncture rules are all compiled into a single network. [@reddyMachineModelsSpeech1980, figure 9.4]</span><span class="co">](figure/Reddy_1980_fig_9_4.png)</span></span>
<span id="cb18-511"><a href="#cb18-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-512"><a href="#cb18-512" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A small fragment of Harpy's network. [@reddyMachineModelsSpeech1980, figure 9.5]</span><span class="co">](figure/Reddy_1980_fig_9_5.png)</span></span>
<span id="cb18-513"><a href="#cb18-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-514"><a href="#cb18-514" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Example of beam search used in Harpy. [@reddyMachineModelsSpeech1980, figure 9.8]</span><span class="co">](figure/Reddy_1980_fig_9_8.png)</span></span>
<span id="cb18-515"><a href="#cb18-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-516"><a href="#cb18-516" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-517"><a href="#cb18-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-518"><a href="#cb18-518" aria-hidden="true" tabindex="-1"></a>Significantly, despite using a beam search, Harpy did *not* use a probabilistic model of language. It essentially treats language as Chomsky-nonrandom, and all the randomness comes from imperfect matching between the real feature vectors and the template feature vectors. Despite this, it out-performed other systems that did. It seems that the problem was that there was insufficient data to estimate the probabilities in a probabilistic language model.</span>
<span id="cb18-519"><a href="#cb18-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-520"><a href="#cb18-520" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Several of the speech understanding systems used estimates of the probability of a phonetic or lexical decision given the acoustic data in scoring the goodness of a theory, and each seems to have gotten into trouble by so doing. The problem is to analyze enough data to be sure of the probability of infrequent confusions. This is nearly impossible if one wants to take into consideration factors such as phonetic environment.</span></span>
<span id="cb18-521"><a href="#cb18-521" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-522"><a href="#cb18-522" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@klattReviewARPASpeech1977</span><span class="co">]</span></span>
<span id="cb18-523"><a href="#cb18-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-524"><a href="#cb18-524" aria-hidden="true" tabindex="-1"></a>Just as significant, there was a lot of artificial intelligence, but very little machine learning. All the formal grammars were hand-written. It is revealing that in a comprehensive review of ASR <span class="co">[</span><span class="ot">@reddySpeechRecognitionMachine1976</span><span class="co">]</span>, "knowledge acquisition" took up less than 2% of the whole paper. And what little it said comes down to that learning-based methods require a large dataset of carefully and densely annotated audio, which was expensive and did not exist.</span>
<span id="cb18-525"><a href="#cb18-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-526"><a href="#cb18-526" aria-hidden="true" tabindex="-1"></a>The last great attempt at logical ASR was the Hearsay-II, a further development from Hearsay, an unsuccessful entrant to the ARPA Speech Understanding Project. It was a towering giant with 7 levels, from "data base interface" and "phrase" all the way down to the "segment" and "parameter" and 15 knowledge sources (collection of rules) for going up and down the levels of abstraction. To handle this pandemonium of knowledge sources, it uses a "shared blackboard" architecture, so that each source can chime in about whatever is currently being interpreted. This allowed it to still work even if some sources are removed, and to improve whenever any source gets added or upgraded.</span>
<span id="cb18-527"><a href="#cb18-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-528"><a href="#cb18-528" aria-hidden="true" tabindex="-1"></a>On one hand, it is great for interpretability, as one can trace through the entire structure and see exactly how any spoken sentence is parsed into a textual sentence. On the other hand, the interpretation took 39 steps and looks like:</span>
<span id="cb18-529"><a href="#cb18-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-530"><a href="#cb18-530" aria-hidden="true" tabindex="-1"></a><span class="in">```txt</span></span>
<span id="cb18-531"><a href="#cb18-531" aria-hidden="true" tabindex="-1"></a><span class="in">Step 23. KS: PREDICT &amp; VERIFY*.</span></span>
<span id="cb18-532"><a href="#cb18-532" aria-hidden="true" tabindex="-1"></a><span class="in">Stimulus: BY+FEIGENBAUM+AND+FELDMAN+]* (phrase).</span></span>
<span id="cb18-533"><a href="#cb18-533" aria-hidden="true" tabindex="-1"></a><span class="in">Action: Predict ten preceding words. Reject five: ABSTRACTS, ARE, BOOKS, PAPERS, REFERENCED. Find two already on the blackboard: </span></span>
<span id="cb18-534"><a href="#cb18-534" aria-hidden="true" tabindex="-1"></a><span class="in">    ANY* (65,24: 49),</span></span>
<span id="cb18-535"><a href="#cb18-535" aria-hidden="true" tabindex="-1"></a><span class="in">    THESE (25, 28:49).</span></span>
<span id="cb18-536"><a href="#cb18-536" aria-hidden="true" tabindex="-1"></a><span class="in">Verify three more:</span></span>
<span id="cb18-537"><a href="#cb18-537" aria-hidden="true" tabindex="-1"></a><span class="in">    ARTICLE (25, 9:52),</span></span>
<span id="cb18-538"><a href="#cb18-538" aria-hidden="true" tabindex="-1"></a><span class="in">    WRITTEN (25, 24:52),</span></span>
<span id="cb18-539"><a href="#cb18-539" aria-hidden="true" tabindex="-1"></a><span class="in">    ARTICLES (10, 9:52).</span></span>
<span id="cb18-540"><a href="#cb18-540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-541"><a href="#cb18-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-542"><a href="#cb18-542" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The levels and knowledge sources of Hearsay-II as of 1976-09. Knowledge sources are indicated by vertical arcs with the circled ends indicating the input level and the pointed ends indicating output level. [@ermanHearsayIISpeechUnderstandingSystem1980, figure 2]</span><span class="co">](figure/Hearsay-II_levels.png)</span></span>
<span id="cb18-543"><a href="#cb18-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-544"><a href="#cb18-544" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Overall architecture of Hearsay-II. [@ermanHearsayIISpeechUnderstandingSystem1980, figure 4]</span><span class="co">](figure/Hearsay-II_architecture.png)</span></span>
<span id="cb18-545"><a href="#cb18-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-546"><a href="#cb18-546" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The example utterance. (a) the waveform of "Are any by Feigenbaum and Feldman?"; (b) the correct words (for reference), (c) segments; (d) syllable classes; (e) words (created by MOW), (f) words (created by VERIFY), (g) word sequences, (h) phrases. [@ermanHearsayIISpeechUnderstandingSystem1980, figure 5]</span><span class="co">](figure/Hearsay-II_example_sentence.png)</span></span>
<span id="cb18-547"><a href="#cb18-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-548"><a href="#cb18-548" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linguists fired</span></span>
<span id="cb18-549"><a href="#cb18-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-550"><a href="#cb18-550" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Every time I fire a linguist, the performance of our speech recognition system goes up.</span></span>
<span id="cb18-551"><a href="#cb18-551" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-552"><a href="#cb18-552" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Frederick Jelinek (1988) (not apocryphal!)</span></span>
<span id="cb18-553"><a href="#cb18-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-554"><a href="#cb18-554" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Frederick Jelinek</span><span class="co">](https://en.wikipedia.org/wiki/Frederick_Jelinek)</span> would go down in history as the one who fired linguists, but he did not start his life this way. In 1961, he sat in Chomsky's lectures, and "got the crazy notion that I should switch from Information Theory to Linguistics". His PhD advisor forbade him, so he remained in information theory. After graduation, he tried collaborating with the eminent linguist <span class="co">[</span><span class="ot">Charles Hockett</span><span class="co">](https://en.wikipedia.org/wiki/Charles_F._Hockett)</span>, bu Hockett then turned to composing operas. "Discouraged a second time, I devoted the next 10 years to Information Theory." <span class="co">[</span><span class="ot">@jelinekDawnStatisticalASR2009</span><span class="co">]</span></span>
<span id="cb18-555"><a href="#cb18-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-556"><a href="#cb18-556" aria-hidden="true" tabindex="-1"></a>In 1972, he left academia and joined IBM, where he worked on ASR. The project started with two linguists, but they got frustrated and left of their own accord, leaving behind engineers and physicists with little understanding of linguistics.<span class="ot">[^jelinek-famous-last-words]</span></span>
<span id="cb18-557"><a href="#cb18-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-558"><a href="#cb18-558" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; When our Continuous Speech Recognition group started its work at IBM Research, the management wanted to make sure that our endeavors were guided by strict scientific principle. They therefore placed into the group two linguists who were going to guide our progress. Both linguists were quite self-confident, sure that fast progress will be possible. For instance, when we (trained as engineers or physicists) were at a loss how to construct a language model, one of the linguists declared "I'll just write a little grammar."... After about a year of frustration the linguists left our group, returned to their basic research, and we were free to pursue our self-organized, data driven, statistical dream... mostly of engineers and physicists. Only 3 or 4 people out of 10 had any previous experience with speech. None had graduate training in that field. But several of us had a background in Information Theory and that influenced our thinking.</span></span>
<span id="cb18-559"><a href="#cb18-559" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-560"><a href="#cb18-560" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekMyBestFriends2005</span><span class="co">]</span></span>
<span id="cb18-561"><a href="#cb18-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-562"><a href="#cb18-562" aria-hidden="true" tabindex="-1"></a>It was unclear what exactly frustrated the linguists, but probably it was because they did not want, or did not have, the stamina to produce generative grammar for non-toy English:</span>
<span id="cb18-563"><a href="#cb18-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-564"><a href="#cb18-564" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In the 1970s NLP and ASR research was dominated by an artificial intelligence approach. Programs were rule-based, expert systems were beginning to take over... The purest linguists based their work on self-constructed examples, not on the prevalence of phenomena in observed data. As already mentioned, strict distinction between training and test was frequently ignored. Grammars were being written that applied to less than dozen verbs.</span></span>
<span id="cb18-565"><a href="#cb18-565" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-566"><a href="#cb18-566" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekMyBestFriends2005</span><span class="co">]</span></span>
<span id="cb18-567"><a href="#cb18-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-568"><a href="#cb18-568" aria-hidden="true" tabindex="-1"></a>This dedication to toys and "microworlds" rather than would appear again later in the saga of <span class="co">[</span><span class="ot">SHRDLU</span><span class="co">](#sec-shrdlu)</span>.</span>
<span id="cb18-569"><a href="#cb18-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-570"><a href="#cb18-570" aria-hidden="true" tabindex="-1"></a><span class="ot">[^jelinek-famous-last-words]</span>:</span>
<span id="cb18-571"><a href="#cb18-571" aria-hidden="true" tabindex="-1"></a>    More details about this funny episode:</span>
<span id="cb18-572"><a href="#cb18-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-573"><a href="#cb18-573" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; When handling natural speech, the main question was how to estimate the language model $Pr(W)$. There was no simple way of achieving this. We thought that the right approach ought to be somehow related to English grammar. The linguist Stan Petrick, while he still was with us, said "Don't worry, I will just make a little grammar." Of course he never did, and the phrase acquired a mythical status in the manner of "famous last words."</span></span>
<span id="cb18-574"><a href="#cb18-574" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-575"><a href="#cb18-575" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@jelinekDawnStatisticalASR2009]</span></span>
<span id="cb18-576"><a href="#cb18-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-577"><a href="#cb18-577" aria-hidden="true" tabindex="-1"></a>The group naturally reproduced the information-theoretic framework for MT proposed by Shannon and Weaver, and adapted it directly to ASR.<span class="ot">[^reproduced-shannon-weaver]</span> In the framework, there are 4 components:</span>
<span id="cb18-578"><a href="#cb18-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-579"><a href="#cb18-579" aria-hidden="true" tabindex="-1"></a><span class="ot">[^reproduced-shannon-weaver]</span>: </span>
<span id="cb18-580"><a href="#cb18-580" aria-hidden="true" tabindex="-1"></a>    Apparently the idea was obvious as soon as you think about ASR in the mindset of information theory.</span>
<span id="cb18-581"><a href="#cb18-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-582"><a href="#cb18-582" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; As to our problem formulation, we were later somewhat surprised when it was revealed to be almost common sense. In fact, it was probably Bob Mercer who found the following quotations in an article by Weaver (1995): </span></span>
<span id="cb18-583"><a href="#cb18-583" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-584"><a href="#cb18-584" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; &gt; When I look at an article in Russian I say: This is really written in English but it has been coded in some strange symbols. I will now proceed to decode it... the matter is probably absolutely basic -- namely the statistical character of the problem.</span></span>
<span id="cb18-585"><a href="#cb18-585" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-586"><a href="#cb18-586" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@jelinekDawnStatisticalASR2009]</span></span>
<span id="cb18-587"><a href="#cb18-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-588"><a href="#cb18-588" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>A language model: $Pr(\text{text})$. This models how a human thinks up what to say in its head.</span>
<span id="cb18-589"><a href="#cb18-589" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>A model of the speaker: $Pr(\text{sound}|\text{text})$. This models how the text to be spoken gets converted into actual sound out of its mouth.</span>
<span id="cb18-590"><a href="#cb18-590" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Audio preprocessor: $\text{sound} \mapsto \text{features}$</span>
<span id="cb18-591"><a href="#cb18-591" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Decoder: $\text{features} \mapsto \text{text}$</span>
<span id="cb18-592"><a href="#cb18-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-593"><a href="#cb18-593" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@jelinekMyBestFriends2005, figure 2</span><span class="co">]</span>](figure/source-channel_model_ASR.png)</span>
<span id="cb18-594"><a href="#cb18-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-595"><a href="#cb18-595" aria-hidden="true" tabindex="-1"></a>Step 3 is "feature engineering", and it has been fairly static in speech processing: apply some high-pass filter, compute the spectrogram, do some more filtering, etc. Step 4 is maximum a posteriori estimation, exactly the same as in the IBM alignment model:<span class="ot">[^ibm-alignment-model-asr]</span></span>
<span id="cb18-596"><a href="#cb18-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-597"><a href="#cb18-597" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-598"><a href="#cb18-598" aria-hidden="true" tabindex="-1"></a>\text{text} = \argmax_{\text{text}} Pr(\text{text}) Pr(\text{sound}|\text{text})</span>
<span id="cb18-599"><a href="#cb18-599" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-600"><a href="#cb18-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-601"><a href="#cb18-601" aria-hidden="true" tabindex="-1"></a><span class="ot">[^ibm-alignment-model-asr]</span>:</span>
<span id="cb18-602"><a href="#cb18-602" aria-hidden="true" tabindex="-1"></a>    Not a coincidence. The IBM team did ASR first, and once that succeeded, proceeded to trying the same trick with MT in 1986.</span>
<span id="cb18-603"><a href="#cb18-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-604"><a href="#cb18-604" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; we embarked on MT in 1986 when we sought a new area to which to apply our statistical, self organized techniques. Besides, we had 15 years of ASR work behind us and those who switched were also attracted by the change as well as the possibility of picking some "low hanging fruit". We had two ideas: to use the noisy channel paradigm to formulate the problem (see Figure 3), and to base our learning on parallel texts. [@jelinekMyBestFriends2005]</span></span>
<span id="cb18-605"><a href="#cb18-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-606"><a href="#cb18-606" aria-hidden="true" tabindex="-1"></a>Step 1 of this framework turned out to be the critical idea. In the pure Chomskyan viewpoint, step 1 is illegitimate. In the information-theoretic viewpoint, step 1 is essential.</span>
<span id="cb18-607"><a href="#cb18-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-608"><a href="#cb18-608" aria-hidden="true" tabindex="-1"></a>TODO Write about how this forced them to think about a different way to measure success. If they gave up the idea of either-or, then how does one tell if the program was improving? Inspired by Harpy, they decided to measure the branching factor ... then perplexity.</span>
<span id="cb18-609"><a href="#cb18-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-610"><a href="#cb18-610" aria-hidden="true" tabindex="-1"></a>It was of course possible, and even obvious, that one can combine the best of both worlds, to combine both linguistic insights and statistical methods, such as a probabilistic CFG. However, they simply trained a dumb trigram language model on a large corpus. From what Jelinek said later,<span class="ot">[^never-reluctant-linguistic]</span> my guess is that they did try such "best of both worlds" approach, but the dumb trigram model just worked better.</span>
<span id="cb18-611"><a href="#cb18-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-612"><a href="#cb18-612" aria-hidden="true" tabindex="-1"></a><span class="ot">[^never-reluctant-linguistic]</span>:</span>
<span id="cb18-613"><a href="#cb18-613" aria-hidden="true" tabindex="-1"></a>    <span class="at">&gt; We were never reluctant to include linguistic knowledge or intuition into our systems: if we didn't succeed, it was because we didn't find an efficient way to do include it.</span></span>
<span id="cb18-614"><a href="#cb18-614" aria-hidden="true" tabindex="-1"></a><span class="at">    &gt;</span></span>
<span id="cb18-615"><a href="#cb18-615" aria-hidden="true" tabindex="-1"></a><span class="at">    &gt; </span><span class="co">[</span><span class="ot">@jelinekMyBestFriends2005</span><span class="co">]</span></span>
<span id="cb18-616"><a href="#cb18-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-617"><a href="#cb18-617" aria-hidden="true" tabindex="-1"></a>The IBM project, compared to the others, was definitely big-data. This served them well for statistical ASR, and would soon serve them well again for statistical MT. They started with a toy model of language called "New Rayleigh", which is essentially a Markov chain model that generates sentences up to 8 words long, from a vocabulary of 250 words.<span class="ot">[^old-rayleigh]</span></span>
<span id="cb18-618"><a href="#cb18-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-619"><a href="#cb18-619" aria-hidden="true" tabindex="-1"></a><span class="ot">[^old-rayleigh]</span>: </span>
<span id="cb18-620"><a href="#cb18-620" aria-hidden="true" tabindex="-1"></a>    It was called such because the team took over a previous logical ASR system called "Rayleigh". Its design was typical Chomskyan:</span>
<span id="cb18-621"><a href="#cb18-621" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-622"><a href="#cb18-622" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; The front end of the Raleigh system converted the speech signal... into a sequence of phoneme-like labels (100 labels per second), using an elaborate set of hand-tuned rules that would soon be replaced with an automatically trained procedure. The back end converted these labels into a sequence of words using an artificial finite-state grammar that was so small that the finite-state machine could be written down on a single piece of paper... very often phones were simply mislabeled. The back end was designed to overcome these problems by navigating through the finite-state network, applying a complicated set of hand-tuned penalties and bonuses to the various paths in order to favor those paths where the low-level acoustics matched the high-level grammatical constraints. </span></span>
<span id="cb18-623"><a href="#cb18-623" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-624"><a href="#cb18-624" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@churchIntroductionSpecialIssue1993]</span></span>
<span id="cb18-625"><a href="#cb18-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-626"><a href="#cb18-626" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The New Rayleigh toy language. [@jelinekDawnStatisticalASR2009, figure 1]</span><span class="co">](figure/New_Rayleigh_toy_language.png)</span></span>
<span id="cb18-627"><a href="#cb18-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-628"><a href="#cb18-628" aria-hidden="true" tabindex="-1"></a>They soon produced an ASR model that achieved perfect accuracy on this, so they had to go bigger. The next dataset they obtained was the "laser patent corpus", consisting of 2 million words of patent applications in laser technology, with a vocabulary size of 10,000, twice as large as the <span class="co">[</span><span class="ot">Brown Corpus (1961)</span><span class="co">](https://en.wikipedia.org/wiki/Brown_Corpus)</span>. They used this to train a 3-gram language model. The road to this dataset was quite circuitous, which anyone who has tried making a non-toy dataset can relate:</span>
<span id="cb18-629"><a href="#cb18-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-630"><a href="#cb18-630" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The struggle to compile a suitable training corpus featured throughout the CSR </span><span class="sc">\[</span><span class="at">Continuous Speech Recognition</span><span class="sc">\]</span><span class="at"> group's first decade. The researchers first considered using a collection of digitized IBM manuals, but found the vocabulary to be too extensive as well as so technical that it proved "difficult to pass ... off as English." They attempted to produce their own corpus, enlisting the wife of a lab staff member to type approximately a million words of text from children's novels, but there, too, the vocabulary proved too large for their purposes. Next, the group acquired a collection of laser patent text from the US Patent Office, which was both sufficiently extensive in size and sufficiently narrow in vocabulary that they were finally able to extract a million words of running text confined to a thousand-word vocabulary. Though the laser patent corpus was considered "naturally occurring," it was in fact meticulously constructed, even before researchers discarded all sentences containing vocabulary outside of the thousand most frequently occurring words. The complete patent text had to be first "subjected to intensive hand and computerized editing": eliminating duplicates, merging spelling variations, and substituting scientific symbols and formulas. The claims sections of the patents proved especially problematic due to "highly stylized" legal language, and were ultimately excised entirely.</span></span>
<span id="cb18-631"><a href="#cb18-631" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-632"><a href="#cb18-632" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By the 1980s hardware improvements allowed the IBM researchers to expand their recognition vocabulary to five thousand words. They also compiled over 100 million words of data from a variety of sources, including public domain books and magazines from the American Printing House for the Blind, the records of the Amoco oil corporation, and 2.5 million words of office correspondence supplied by physicist Richard Garwin, who, with the aid of four secretaries, maintained computer-formatted duplicates of all of his correspondence. The most substantial collection in this period, however, came as a direct result of IBM's unique industry dominance: the landmark federal antitrust lawsuit filed against the company in 1969. The case, which spanned thirteen years before it was finally dismissed in 1982, included testimony from 974 witnesses with resulting transcripts that totaled over one hundred thousand pages. The operation to digitize the deposition transcripts during the trial was so prodigious that it required a staff of dedicated keypunch operators large enough to fill a facility the size of a football field in White Plains, New York, where IBM's Data Processing Division was headquartered. While the suit itself proved extremely costly for IBM, its transcript digitization efforts provided the CSR group with their largest and most robust text collection, resulting in a corpus of one hundred million words. Finally, the CSR group discovered the Hansard corpus, a collection of digitized transcripts of the Canadian Parliament official proceedings in both English and French, in the mid-1980s and incorporated an additional hundred million words from its English text into their language model.</span></span>
<span id="cb18-633"><a href="#cb18-633" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-634"><a href="#cb18-634" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@liTheresNoData2023</span><span class="co">]</span></span>
<span id="cb18-635"><a href="#cb18-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-636"><a href="#cb18-636" aria-hidden="true" tabindex="-1"></a>In 1976, their ASR system had already reached state of the art performance. On the same task as the ARPA project, it reached higher accuracy, and only took 30 MIP to process 1 second of speech. <span class="co">[</span><span class="ot">@reddySpeechRecognitionMachine1976</span><span class="co">]</span> Though logical ASR continued with systems like Hearsay-II (1980), as the 1980s went on, none could deny the practical success of statistical ASR anymore, even if, compared to logical ASR, statistical ASR was far from linguistic theories of human speech recognition.</span>
<span id="cb18-637"><a href="#cb18-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-638"><a href="#cb18-638" aria-hidden="true" tabindex="-1"></a>In the 1990s, all state of the art ASR were statistical, usually HMM-based. Such a model has multiple levels.</span>
<span id="cb18-639"><a href="#cb18-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-640"><a href="#cb18-640" aria-hidden="true" tabindex="-1"></a>At the top level, there is a Markov chain that serves as a language model, which emits individual words. This is usually an n-gram model, where $n$ is usually 3. In such a model, each node is a 3-gram. For example, the model can have state transitions like "- - what" → "- what is" → "what is the" → "is the last" → ..., and it would emit "what", "is", "the", "last", ...</span>
<span id="cb18-641"><a href="#cb18-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-642"><a href="#cb18-642" aria-hidden="true" tabindex="-1"></a>This sequence of words is then converted to a sequence of phonemes, like "wɒtɪzðəlɑːst". Each phoneme, like "ɪ", corresponds to a trained Markov chain. That is, we have a Markov chain with around 3 to 5 states that emits feature vectors corresponding to a possible pronunciation of "ɪ". </span>
<span id="cb18-643"><a href="#cb18-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-644"><a href="#cb18-644" aria-hidden="true" tabindex="-1"></a>We can even hand-write such a Markov chain, as an example. We would start by collecting many recordings of "ɪ", then cut these into three parts: the start, the middle, and the end. We convert each part into a feature vector: $v_0, v_1, v_2$. We give each feature vector a state in the Markov chain. A trajectory through the Markov chain would start at $v_0$, stay there for a short while, then randomly jump to $v_1$, stay there for a long while, and then randomly jump to $v_2$, stay there for a short while, and finally jump to the "END" state. We would assign the transition probability $Pr(v_2 | v_2)$ to be roughly $1-1/N$, where $N$ is the average number of 10-ms segments that it takes to pronounce the middle of "ɪ".</span>
<span id="cb18-645"><a href="#cb18-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-646"><a href="#cb18-646" aria-hidden="true" tabindex="-1"></a>The above system is the basic idea. It does not handle the effect of gliding between phonemes, like how "did you" would be pronounced as "dija". The standard way to handle this was the triphone model. The triphone model accounts for how a phoneme is changed by its two neighbors. For example, in the previous example, the "ɪ" should really be pronounced in the context of "tɪz". So, we would have a Markov chain just for "tɪz", which would generate a sequence of feature vectors that corresponds to how "ɪ" would be pronounced if it appears in the context of "tɪz". Since English has about 50 phonemes, a triphone model need ~2500 Markov chains, which explains why quad-phone models, or more, had not been popular. Even if one had the appetite for it, there was not enough data to train them.</span>
<span id="cb18-647"><a href="#cb18-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-648"><a href="#cb18-648" aria-hidden="true" tabindex="-1"></a>By late 1990s, the ASR technology stabilized around the gaussian mixture HMM <span class="co">[</span><span class="ot">@huangHistoricalPerspectiveSpeech2014</span><span class="co">]</span>, where the lowest level of HMM does not emit a feature vector $v$, but a <span class="co">[</span><span class="ot">gaussian mixture distribution</span><span class="co">](https://en.wikipedia.org/wiki/Mixture_model)</span> $\sum_i p_i \mathcal N(\mu_i, \Sigma_i)$ of feature vectors. You can add even more epicycles upon epicycles to account for more complex features like omitting phonemes, phonotactic constraints, prosody, etc.</span>
<span id="cb18-649"><a href="#cb18-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-650"><a href="#cb18-650" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Rough sketch of HMM ASR. [Source](https://www.cs.cmu.edu/~roni/10601-slides/hmm-for-asr-whw.pdf)</span><span class="co">](figure/HMM_ASR.png)</span></span>
<span id="cb18-651"><a href="#cb18-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-652"><a href="#cb18-652" aria-hidden="true" tabindex="-1"></a>Unlike in the case of MT, the collapse of logical AI in ASR was decisive. Statistical ASR completely replaced logical ASR in the 1990s, after which logical ASR was never revived. There were two reasons for this. One is the familiar scaling story of data and compute:</span>
<span id="cb18-653"><a href="#cb18-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-654"><a href="#cb18-654" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; As computers increased in power, ever greater tracts of the heuristic wasteland opened up for colonization by probabilistic models. As greater quantities of recorded data became available, these areas were tamed by automatic training techniques. Today... almost every aspect of most speech recognition systems is dominated by probabilistic models with parameters determined from data.</span></span>
<span id="cb18-655"><a href="#cb18-655" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-656"><a href="#cb18-656" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@churchIntroductionSpecialIssue1993</span><span class="co">]</span></span>
<span id="cb18-657"><a href="#cb18-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-658"><a href="#cb18-658" aria-hidden="true" tabindex="-1"></a>Another is the public benchmark culture. The ARPA SUR project not only demonstrated that ASR was possible, but also gave rise to the benchmark-focused culture of ASR, which allowed the best methods to rapidly spread through the community:</span>
<span id="cb18-659"><a href="#cb18-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-660"><a href="#cb18-660" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ARPA (and then DARPA) funded a number of new speech research programs, beginning with 1000-word speaker-independent read-speech tasks like "Resource Management" (Price et al., 1988), recognition of sentences read from the Wall Street Journal (WSJ), Broadcast News domain (LDC 1998, Graff 1997) (transcription of actual news broadcasts, including quite difficult passages such as on-the-street interviews) and the Switchboard, CallHome, CallFriend, and Fisher domains (Godfrey et al. 1992, Cieri et al. 2004) (natural telephone conversations between friends or strangers). The ARPA competitions resulted in wide-scale borrowing of techniques among labs since it was easy to see which ideas reduced errors the previous year, and the competitions were probably an important factor in the eventual spread of the HMM paradigm. </span></span>
<span id="cb18-661"><a href="#cb18-661" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-662"><a href="#cb18-662" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jurafskySpeechLanguageProcessing2023, pages 352--353</span><span class="co">]</span></span>
<span id="cb18-663"><a href="#cb18-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-664"><a href="#cb18-664" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Progress of ASR benchmarks during 1988--2012. Each time one benchmark was saturated, it was replaced by a harder one. The green dot was the 2012 SOTA for the Switchboard task. [@huangHistoricalPerspectiveSpeech2014, figure 1]</span><span class="co">](figure/ASR_benchmark_progress_1988--2012.jpg)</span></span>
<span id="cb18-665"><a href="#cb18-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-666"><a href="#cb18-666" aria-hidden="true" tabindex="-1"></a>This was not the end of the history, however. Once ASR became a statistical problem, one immediately has the problem of feature engineering. Here, the history is similar to that of vision. One begins by imitating the human phoneticians with a nearest-neighbor matching to phonemes, and proceeds to handcrafted features computed over the audio spectrogram, to NN features learned over transforms of the spectrogram, and finally to NN features learned directly over the spectrogram. <span class="co">[</span><span class="ot">@huangHistoricalPerspectiveSpeech2014</span><span class="co">]</span> However, the story must be left for a future essay.</span>
<span id="cb18-667"><a href="#cb18-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-668"><a href="#cb18-668" aria-hidden="true" tabindex="-1"></a><span class="fu">### A farewell to linguists</span></span>
<span id="cb18-669"><a href="#cb18-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-670"><a href="#cb18-670" aria-hidden="true" tabindex="-1"></a>What was so radical about Jelinek's approach?</span>
<span id="cb18-671"><a href="#cb18-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-672"><a href="#cb18-672" aria-hidden="true" tabindex="-1"></a>One, to believe in the probabilistic system at all was a breakthrough during the Chomskyan period. As Liberman recounts in an anecdote in the 1970s:</span>
<span id="cb18-673"><a href="#cb18-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-674"><a href="#cb18-674" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Kenneth Church was</span><span class="sc">\]</span><span class="at"> applying context-free parsing to phonotactic speech recognition, assuming a non-stochastic grammar. I suggested that Ken should find or create a collection of phonetic transcriptions, and use it to associate probabilities with his rewrite rules. Ken's response was to quote Richard Nixon's remark about Daniel Ellsberg: "We could kill him--but that would be wrong." Further discussion elicited a quote from one of his AI lab professors: "If you need to count higher than one, you've made a mistake."</span></span>
<span id="cb18-675"><a href="#cb18-675" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-676"><a href="#cb18-676" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@libermanObituaryFredJelinek2010</span><span class="co">]</span></span>
<span id="cb18-677"><a href="#cb18-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-678"><a href="#cb18-678" aria-hidden="true" tabindex="-1"></a>Two, to throw away preconceptions of what the language model could be, and let results speak. He proceeded directly to using a 3-gram not because it resembles anything like how people really produce language, but because it works.</span>
<span id="cb18-679"><a href="#cb18-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-680"><a href="#cb18-680" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In the future the design of a LM for a naturally generated text will probably involve considerations of syntax. semantics. and discourse pragmatics. So far no one has accomplished this.</span></span>
<span id="cb18-681"><a href="#cb18-681" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-682"><a href="#cb18-682" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekSelfOrganizedContinuousSpeech1982</span><span class="co">]</span><span class="at"> </span></span>
<span id="cb18-683"><a href="#cb18-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-684"><a href="#cb18-684" aria-hidden="true" tabindex="-1"></a>Three, to believe in the power of big data and big compute.</span>
<span id="cb18-685"><a href="#cb18-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-686"><a href="#cb18-686" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Our models are derived from as much actual speech data as we can obtain and handle computationally. We have devised methods of automatic model computation, thus minimizing or completely eliminating human intervention. Our strategies are not based on rules developed from trying to intuit how people recognize sentences (as is prevalent elsewhere), although the basic structure of our models is, of course, man-made. This approach is both more accurate and more flexible; as the speaker or the components of the system change, our self-organizing programs remain valid, and computer time is all that is required to adjust to a new configuration.</span></span>
<span id="cb18-687"><a href="#cb18-687" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-688"><a href="#cb18-688" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekSelfOrganizedContinuousSpeech1982</span><span class="co">]</span></span>
<span id="cb18-689"><a href="#cb18-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-690"><a href="#cb18-690" aria-hidden="true" tabindex="-1"></a>More presciently, he was even considering the possibility of throwing away the preconceptions of what the features could be, and let data speak:</span>
<span id="cb18-691"><a href="#cb18-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-692"><a href="#cb18-692" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Because we have found it more fruitful to view the acoustic processor as a data compressor than as an artificial phonetician, we do not attempt to identify phonetic segments in the continuous speech.</span></span>
<span id="cb18-693"><a href="#cb18-693" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-694"><a href="#cb18-694" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekSelfOrganizedContinuousSpeech1982</span><span class="co">]</span></span>
<span id="cb18-695"><a href="#cb18-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-696"><a href="#cb18-696" aria-hidden="true" tabindex="-1"></a>Previous MT systems typically performs multi-step processing on a raw audio signal, and somewhere in the middle, the audio signal would be transformed into a phonetic transcription. Jelinek, instead of following tradition and featurize audio into a list of phonemes ("an artificial phonetician"), just proposed to featurize audio in whatever way that seemed to work better for the system. As far as I see, this was not used in HMM ASR during the 1990s, but we know that automatic feature learning would finally be vindicated by neural networks around 2010 as the encoder-decoder architectures trained fully end-to-end <span class="co">[</span><span class="ot">@gravesConnectionistTemporalClassification2006; @chorowskiEndtoendContinuousSpeech2014</span><span class="co">]</span></span>
<span id="cb18-697"><a href="#cb18-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-698"><a href="#cb18-698" aria-hidden="true" tabindex="-1"></a>In 2005, near the end of his life, Jelinek admitted that his quote was, despite his best hopes, genuine. </span>
<span id="cb18-699"><a href="#cb18-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-700"><a href="#cb18-700" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; *Whenever I fire a linguist our system performance improves.* I have hoped for many years that this quote was only apocryphal, but at least two reliable witnesses have recently convinced me that I really stated this publicly in a conference talk (Jelinek, 1998). Accepting then that I really said it, I must first of all affirm that I never fired anyone, and a linguist least of all. So my motivation is defensive: to show that neither I nor my colleagues at IBM ever had any hostility to linguists or linguistics. In fact, we all hoped that linguists would provide us with needed help. We were never reluctant to include linguistic knowledge or intuition into our systems: if we didn't succeed, it was because we didn't find an efficient way to do include it.</span></span>
<span id="cb18-701"><a href="#cb18-701" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-702"><a href="#cb18-702" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@jelinekMyBestFriends2005</span><span class="co">]</span></span>
<span id="cb18-703"><a href="#cb18-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-704"><a href="#cb18-704" aria-hidden="true" tabindex="-1"></a>Reflecting on a lifetime of multiple near-linguistic experiences, Jelinek seemed regretful. It is not that he wanted to fire linguists, it was simply that, somehow, attempting to incorporate linguistic expertise hurt performance. He died in 2010, just in time to miss the deep learning revolution that fired the last linguists.</span>
<span id="cb18-705"><a href="#cb18-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-706"><a href="#cb18-706" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; the statistical model of language with which he had so successfully replaced linguistic rules was a simple word trigram – i.e. a very crude model of three word sequences. Whilst it was obvious to everyone that this model was hopelessly impoverished, in practice it had proved almost impossible to improve on. However, in the year 2000, Fred published a paper with one of his students called "Structured language modeling for speech recognition". It sets out a principled way to incorporate linguistics into a statistical framework and as well as representing a significant step forward in language modeling, it has helped bridge the gap between speech engineers and the hitherto diverging computational linguistics community. In 2002, it received a "Best Paper" award and the citation read "for work leading to significant advances in the representation and automatic learning of syntactic structure in statistical language models". It seemed somehow fitting that 25 years after starting the movement towards statistical approaches, Fred sought to re-engage with aspects of more traditional linguistics. I hope Chomsky read the paper and enjoyed it as much as we speech technologists did.</span></span>
<span id="cb18-707"><a href="#cb18-707" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-708"><a href="#cb18-708" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@youngFrederickJelinek193220102010</span><span class="co">]</span></span>
<span id="cb18-709"><a href="#cb18-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-710"><a href="#cb18-710" aria-hidden="true" tabindex="-1"></a><span class="fu">### Text to speech</span></span>
<span id="cb18-711"><a href="#cb18-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-712"><a href="#cb18-712" aria-hidden="true" tabindex="-1"></a>While this section is titled "Speech", we have only discussed speech-to-text. Naturally, there is also the direction of text-to-speech (TTS). Here the history is more compressed, if for the simple reason that humans are *really good* at understanding speech. Even the most primitive kinds of text-to-speech was usable, and it was merely a matter of making it cheaper and less robotic-sounding. Indeed, a very early TTS synthesized speech by gluing together magnetic tape recordings and playing the whole thing at once. <span class="co">[</span><span class="ot">@harrisStudyBuildingBlocks1953</span><span class="co">]</span></span>
<span id="cb18-713"><a href="#cb18-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-714"><a href="#cb18-714" aria-hidden="true" tabindex="-1"></a>At the forefront of speech synthesis research was Bell Labs, which was trying to compress and decompress speech to fit more telephone calls into telephone cables. In 1961 at Bell Labs, an IBM 7094 sang "Daisy Bell". Arthur Clarke, while visiting his friend John Pierce (this is the last time we'll see him), saw a demo of this, and he was so impressed that he put this scene into *2001: A Space Odyssey* (1968). <span class="co">[</span><span class="ot">@woodRecollectionsJohnRobinson1991</span><span class="co">]</span></span>
<span id="cb18-715"><a href="#cb18-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-716"><a href="#cb18-716" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The family tree of TTS systems up to 1987. [@klattReviewTexttospeechConversion1987, figure 4]</span><span class="co">](figure/TTS_family_tree.png)</span></span>
<span id="cb18-717"><a href="#cb18-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-718"><a href="#cb18-718" aria-hidden="true" tabindex="-1"></a>In 1983, Digital Equipment Corporation started selling one of the first commercially successful TTS system, the <span class="co">[</span><span class="ot">DECTalk</span><span class="co">](https://en.wikipedia.org/wiki/DECtalk)</span>, at the low price of $4000. It was based on the Klattalk formant synthesizer of Dennis Klatt, who had dedicated his life to research on speech, and had the best TTS system available at the time. In a 1987 review of TTS <span class="co">[</span><span class="ot">@klattReviewTexttospeechConversion1987</span><span class="co">]</span>, Klatt stayed close to the Chomskyan orthodoxy and described TTS as a problem of writing the generative grammar deeper down, from text all the way to the spectrogram of the physical sound.</span>
<span id="cb18-719"><a href="#cb18-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-720"><a href="#cb18-720" aria-hidden="true" tabindex="-1"></a>::: {#fig-klatt-1987 layout-ncol=2}</span>
<span id="cb18-721"><a href="#cb18-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-722"><a href="#cb18-722" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">General architecture of a TTS system according to the Chomskyan orthodoxy. [@klattReviewTexttospeechConversion1987, figure 2]</span><span class="co">](figure/Klatt_1987_fig_2.png)</span>{#fig-todo}</span>
<span id="cb18-723"><a href="#cb18-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-724"><a href="#cb18-724" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Architecture of Klattalk. [@klattReviewTexttospeechConversion1987, figure 3]</span><span class="co">](figure/Klatt_1987_fig_3.png)</span>{#fig-todo}</span>
<span id="cb18-725"><a href="#cb18-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-726"><a href="#cb18-726" aria-hidden="true" tabindex="-1"></a>TODO</span>
<span id="cb18-727"><a href="#cb18-727" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-728"><a href="#cb18-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-729"><a href="#cb18-729" aria-hidden="true" tabindex="-1"></a>In his literature review, Klatt did take notice of two upstart systems from the statistical side, one being <span class="co">[</span><span class="ot">NETtalk of Sejnowski</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/index.html#terence-sejnowski)</span>, a neural network model, and another being a statistical TTS system very similar to the IBM alignment model, by the same IBM team. He brushed both off as being inferior to a logical TTS system:</span>
<span id="cb18-730"><a href="#cb18-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-731"><a href="#cb18-731" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; When evaluated on the words of this training set, </span><span class="sc">\[</span><span class="at">NETtalk</span><span class="sc">\]</span><span class="at"> was correct for about 90% of the phonemes and stress patterns. In some sense, this is a surprisingly good result in that so much knowledge could be embedded in a moderate number of about 25000 weights, but the performance is not nearly as accurate as that of a good set of letter-to-sound rules (performing without use of an exceptions dictionary, but with rules for recognizing common affixes)... </span><span class="sc">\[</span><span class="at">The IBM alignment</span><span class="sc">\]</span><span class="at"> approach still results in an inferior words-correct error rate compared with traditional rule systems. Even a very powerful statistical package cannot yet discover much of the underlying structure in a process as complex as natural language... given the attention that NETtalk and other neuron-like devices have received recently, it is disturbing that NETtalk does not learn training set data perfectly, appears to make generalizations suboptimally, and has an overall performance that is not acceptable for a practical system. Furthermore, it is unlikely that larger training lexicons would converge to a more acceptable performance.</span></span>
<span id="cb18-732"><a href="#cb18-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-733"><a href="#cb18-733" aria-hidden="true" tabindex="-1"></a>Indeed, though the word "rules" appears over 200 times in the review, the above dismissal was the only thing he had to say about learning-based methods. Hostility towards machine learning is a recurring feature among the Chomskyans. However, unlike the Chomskyans, Klatt was not going to be satisfied with writing toy respected the extreme complexity of a proper system of rules. And try he did:</span>
<span id="cb18-734"><a href="#cb18-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-735"><a href="#cb18-735" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The hard part of text-to-speech synthesis is to calculate a string of LPC data, or formant-synthesis parameters, not from recorded speech, but from the letters and symbols of typed text... It's possible to write a simple program for this task, which produces robotlike speech-hard to understand and unpleasant to listen to. The alternative, which only Dennis Klatt and a few others have pursued, is to invest years of effort in devising an increasingly lengthy and subtle set of rules to eliminate the robotic accent.</span></span>
<span id="cb18-736"><a href="#cb18-736" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-737"><a href="#cb18-737" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; He turns to a table with two volumes about the size of large world atlases, each stuffed with speech spectrograms... Spectrograms usually feature subtle and easily changing patterns. Klatt's task has been to reduce these subtleties to rules so that a computer can routinely translate ordinary text into appropriate spectrograms. "I've drawn a lot of lines on these spectrograms, made measurements by ruler, tabulated the results, typed in numbers, and done computer analyses," says Klatt.</span></span>
<span id="cb18-738"><a href="#cb18-738" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-739"><a href="#cb18-739" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; As Klatt puts it, "Why doesn't DECtalk sound more like my original voice, after years of my trying to make it do so? According to the spectral comparisons, I'm getting pretty close. But there's something left that's elusive, that I haven't been able to capture. It has been possible to introduce these details and to resynthesize a very good quality of voice. But to say, 'here are the rules, now I can do it for any sentence' -- that's the step that's failed miserably every time."</span></span>
<span id="cb18-740"><a href="#cb18-740" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-741"><a href="#cb18-741" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; But he has hope: "It's simply a question of finding the right model."</span></span>
<span id="cb18-742"><a href="#cb18-742" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-743"><a href="#cb18-743" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@heppenheimerComputerTalkAmazing1984</span><span class="co">]</span></span>
<span id="cb18-744"><a href="#cb18-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-745"><a href="#cb18-745" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Formant transitions for `[g]` as a function of preceding and following vowels. [@klattReviewTexttospeechConversion1987, figure 29]</span><span class="co">](figure/Klatt_1987_fig_29.png)</span></span>
<span id="cb18-746"><a href="#cb18-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-747"><a href="#cb18-747" aria-hidden="true" tabindex="-1"></a>Klatt had been progressively losing his voice from thyroid cancer, and died in 1988. His voice was the template for "Perfect Paul" in DECTalk, which was the voice of Stephen Hawking, which he kept using even after better TTS systems were available. <span class="co">[</span><span class="ot">@medeirosHowIntelGave2015</span><span class="co">]</span></span>
<span id="cb18-748"><a href="#cb18-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-749"><a href="#cb18-749" aria-hidden="true" tabindex="-1"></a><span class="fu">## Vision</span></span>
<span id="cb18-750"><a href="#cb18-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-751"><a href="#cb18-751" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logic and logistics</span></span>
<span id="cb18-752"><a href="#cb18-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-753"><a href="#cb18-753" aria-hidden="true" tabindex="-1"></a><span class="fu">### Planning</span></span>
<span id="cb18-754"><a href="#cb18-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-755"><a href="#cb18-755" aria-hidden="true" tabindex="-1"></a>WWII was said to be a war of the physicists, or the code-breakers. It could equally said to be a war of the economists. The side that could sustain a higher industrial output slowly but surely ground down the other side, as strategic bombing destroyed industrial production.</span>
<span id="cb18-756"><a href="#cb18-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-757"><a href="#cb18-757" aria-hidden="true" tabindex="-1"></a>It is either a myth or an obvious point that the soviet union had a bad economic system. In either case, there were two Soviet Nobel laureates in economics. The first was Wassily Leontief, who saw economics not as a simple feedforward network of wheat-to-bread-to-stomach, but as a feedback network of hundreds of industries making commodities for and taking commodities from each other, as made clear in his PhD thesis *The Economy as Circular Flow* (1928).</span>
<span id="cb18-758"><a href="#cb18-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-759"><a href="#cb18-759" aria-hidden="true" tabindex="-1"></a>Leaving the Soviet Union as a dissident in 1925, he settled in America and performed his input-output analysis of the American economy. Let us divide the economy into $N$ sectors, from "agriculture" to "electricity" to "rubber". For simplicity, suppose each sector $i$ only makes one kind of commodity $x_i$ -- "agriculture" only outputs a generic kind of "food", etc. Each sector $i$, in order to create one unit of commodity $x_i$, requires some commodities $A_{1i}, A_{2i}, \dots, A_{Ni}$ as inputs. Then, if the entire economy produces $x_1, x_2, \dots, x_N$, then it requires total input $Ax$, where $A$ is the demand matrix. With this we have the fundamental equation:</span>
<span id="cb18-760"><a href="#cb18-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-761"><a href="#cb18-761" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-762"><a href="#cb18-762" aria-hidden="true" tabindex="-1"></a>x = Ax + y</span>
<span id="cb18-763"><a href="#cb18-763" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-764"><a href="#cb18-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-765"><a href="#cb18-765" aria-hidden="true" tabindex="-1"></a>where $y$ is the surplus that comes out of the economy, which Leontieff calls "demand", since that is what is demanded by consumers outside of the economic production. It seems simplistic -- just a linear equation? Yet this was the origin of linear programming.</span>
<span id="cb18-766"><a href="#cb18-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-767"><a href="#cb18-767" aria-hidden="true" tabindex="-1"></a>In 1949, Leontief used an early computer at Harvard and data from the U.S. Bureau of Labor Statistics to divide the U.S. economy into 500 sectors, and balanced the linear equation on the grand scale.</span>
<span id="cb18-768"><a href="#cb18-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-769"><a href="#cb18-769" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Part of an input-output matrix drawn by Leontief. [@leontiefStructureDevelopment1963, page 150]</span><span class="co">](figure/Leontieff_matrix.png)</span></span>
<span id="cb18-770"><a href="#cb18-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-771"><a href="#cb18-771" aria-hidden="true" tabindex="-1"></a>Near the end of the war, Stigler wrote a paper calculating what is the cheapest possible nutritionally complete diet. He concluded that at 1939 prices, a minimal viable diet cost \$40 per year for an adult American man, which was 1/3 the price of previous results. He concluded that the previous dieticians were not ruthless enough, and confused biological needs with cultural needs:</span>
<span id="cb18-772"><a href="#cb18-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-773"><a href="#cb18-773" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The dieticians take account of the palatability of foods, variety of diet, prestige of various foods, and other cultural facets of consumption. Primarily on such grounds can one explain their emphasis on meats and the inclusion of sugar... If the dieticians persist in presenting minimum diets, they should at least report separately the physical and cultural components of these diets.</span></span>
<span id="cb18-774"><a href="#cb18-774" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-775"><a href="#cb18-775" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@stiglerCostSubsistence1945</span><span class="co">]</span></span>
<span id="cb18-776"><a href="#cb18-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-777"><a href="#cb18-777" aria-hidden="true" tabindex="-1"></a>In 1947, George Dantzig was tasked with the US Air Force to mechanize its planning. Inspired by the paper as well as Leontief's input-output analysis, he thought that constraint-optimization with linear algebra was just the tool to use. As a start, he attacked the same problem of diet, and from there, he developed the <span class="co">[</span><span class="ot">simplex method</span><span class="co">](https://en.wikipedia.org/wiki/Simplex_algorithm)</span>. <span class="co">[</span><span class="ot">@dantzigDietProblem1990</span><span class="co">]</span></span>
<span id="cb18-778"><a href="#cb18-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-779"><a href="#cb18-779" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In the fall of 1947 ... undertook as a test of the newly proposed simplex method the determination of a least cost adequate diet based on Stigler's data. It was the first "large scale" computation in the field. The system consisted of 9 equations in 77 unknowns. Jack parcelled out a different 8 or 9 columns (of the 77 columns) to each of the 9 clerks who were assigned to process them. Using hand-operated desk calculators... the 9 clerks took approximately 120 man-days to obtain an optimal solution of \$39.69. Stigler's heuristic solution was only off from the true annual optimal cost by 24 cents: not bad!</span></span>
<span id="cb18-780"><a href="#cb18-780" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-781"><a href="#cb18-781" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@dantzigDietProblem1990</span><span class="co">]</span></span>
<span id="cb18-782"><a href="#cb18-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-783"><a href="#cb18-783" aria-hidden="true" tabindex="-1"></a>While linear programming became the great success story of early AI -- when it was still considered as the "mechanization of thought process", and often subsumed under operations research -- and was quickly taken up by military logisticians and business managers, its original application in diet planning was less successful. Dantzig recounts how he unsuccessfully tried to go on a diet by running a 500-ingredient linear programming problem on an IBM 701. Hilarity ensues.</span>
<span id="cb18-784"><a href="#cb18-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-785"><a href="#cb18-785" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One day I said to Anne, my wife, "Today is Der Tag, whatever the 701 says that's what I want you to feed me each day starting with supper tonight." ... I then read off the amounts of foods in the optimal diet. Her reaction: "The diet is a bit weird but conceivable. Is that it?" "Not exactly," I replied, "AND 500 gallons of vinegar." ... It turned out that our data source listed vinegar as a very weak acid with water content = zero. Therefore, according to the way the model was formulated the more vinegar you drank the greater would be your feeling of feeling full. I decided that vinegar wasn't a food.</span></span>
<span id="cb18-786"><a href="#cb18-786" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-787"><a href="#cb18-787" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The next day the above scene was repeated except this time ... calling for the consumption of 200 bouillon cubes per day... I called my doctor and asked him how come the nutritional requirements didn't show a limit on the amount of salt? "Isn't too much salt dangerous?" He replied that it wasn't necessary; most people had enough sense not to consume too much. I placed an upper bound of three on the number of bouillon cubes consumed per day. That was how upper bounds on variables in linear programming first began.</span></span>
<span id="cb18-788"><a href="#cb18-788" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-789"><a href="#cb18-789" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The next day the above scene was repeated, except this time the diet called, among other things, for two pounds of bran per day... The model was revised with an upper bound put on the amount of bran. The next day the proposed menu was almost exactly the same except this time it was two pounds of blackstrap molasses which substituted for the bran... she said, "I have been studying the various menus the computer has been generating. There are some good ideas there that I can use. I'll put you on MY diet. She did and I lost 22 pounds.</span></span>
<span id="cb18-790"><a href="#cb18-790" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-791"><a href="#cb18-791" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@dantzigDietProblem1990</span><span class="co">]</span></span>
<span id="cb18-792"><a href="#cb18-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-793"><a href="#cb18-793" aria-hidden="true" tabindex="-1"></a>In our hindsight, we say that the AI performed an adversarial attack on the input data and the reward model misspecification, something that gaming and planning AI are wont to do.</span>
<span id="cb18-794"><a href="#cb18-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-795"><a href="#cb18-795" aria-hidden="true" tabindex="-1"></a>The second Soviet Nobel laureate, Leonid Kantorovich, managed to win it while remaining *within* the USSR. This was no small feat, for in the USSR, the academic study of economics meant only *political* economy, and mathematical economics was merely a minor branch of political economy, with mathematical economists having to frame their research as a "critique of bourgeois economic thought". <span class="co">[</span><span class="ot">@boldyrevCulturesMathematicalEconomics2017</span><span class="co">]</span></span>
<span id="cb18-796"><a href="#cb18-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-797"><a href="#cb18-797" aria-hidden="true" tabindex="-1"></a>Like Dantzig, Kantorovich discovered linear programming in the context of a practical problem. Feeling burnt out by too much pure math, he decided to do something practical for a change of scenery, and to do something about the imminent threat of Nazi Germany. So he went to a plywoord factory in 1937, and worked on how to cut plywood sheets in such a way as to meet a specified assortment of pieces with minimum waste. And just like Dantzig, he reduced the problem to a maximization problem with linear objective and linear inequality constraints. </span>
<span id="cb18-798"><a href="#cb18-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-799"><a href="#cb18-799" aria-hidden="true" tabindex="-1"></a>Dizzy with success, he tried the same trick again and again, and accidentally improved efficiency so much that he almost ended up in jail.</span>
<span id="cb18-800"><a href="#cb18-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-801"><a href="#cb18-801" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... one of the major materials handling operations at the Leningrad E. I. Egorov Railroad Car Building Plant was the cutting of sheet metal for railroad cars. Ordinarily, this cutting produced tremendous quantities of scrap. After introducing Kantorovich's solution technique to the problem of minimizing waste, officials were able to reduce the amount of scrap by 50%. This had the unfortunate side effect of greatly reducing the amount of scrap metal available to steel plants in the region, and Kantorovich was ordered to appear at Leningrad party headquarters for allegedly sabotaging the economy. In this instance, he was rescued by the military, which needed him for its atomic program.</span></span>
<span id="cb18-802"><a href="#cb18-802" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-803"><a href="#cb18-803" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; According to Stalin, the planned economy of the USSR was already "</span><span class="co">[</span><span class="ot">dizzy with success</span><span class="co">](https://ru.wikipedia.org/wiki/Головокружение_от_успехов)</span><span class="at">"; hence any criticism of it was anti-Soviet propaganda, a serious crime. In particular, anyone openly suggesting that waste could be cut substantially was at great personal risk. Nevertheless, Kantorovich ... wrote a letter to Gosplan suggesting a reform of the price system used in planning. </span></span>
<span id="cb18-804"><a href="#cb18-804" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-805"><a href="#cb18-805" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gardnerLVKantorovichPrice1990</span><span class="co">]</span></span>
<span id="cb18-806"><a href="#cb18-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-807"><a href="#cb18-807" aria-hidden="true" tabindex="-1"></a>Being a socially clueless nerd was not the stuff of romantic comedy in Soviet Russia, but gallows comedy. Fortunately for mathematical economics, his luck held:</span>
<span id="cb18-808"><a href="#cb18-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-809"><a href="#cb18-809" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Gosplan wrote back saying that no such reform was necessary. This outcome was rather fortunate for its author, as similar letters critical of the authorities -- for example, one by Solzhenitsin -- landed their authors promptly in jail.</span></span>
<span id="cb18-810"><a href="#cb18-810" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-811"><a href="#cb18-811" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gardnerLVKantorovichPrice1990</span><span class="co">]</span></span>
<span id="cb18-812"><a href="#cb18-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-813"><a href="#cb18-813" aria-hidden="true" tabindex="-1"></a>Reading Kantorovich's repeated attempts to reform Soviet economy, I imagined those old silent movies where a protagonist stumbles around, blindfolded, crossing a highway where the cars always *just missed*. Accidental economic sabotage was not the end of his misadventures, however. His luck was really tested when it came to the "shadow price" affair.</span>
<span id="cb18-814"><a href="#cb18-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-815"><a href="#cb18-815" aria-hidden="true" tabindex="-1"></a>Consider the problem of managing a factory. It has some input constraints (fuel, woods, etc), and the objective of maximizing the total utility of output goods. This is simply solved by the Lagrangian multiplier method, and it turns out that the Lagrangian multipliers themselves have a natural interpretation: the multiplier $\lambda_i$ is the amount of extra utility that the factory can achieve, if the factory were to obtain one more unit of constraint $i$.</span>
<span id="cb18-816"><a href="#cb18-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-817"><a href="#cb18-817" aria-hidden="true" tabindex="-1"></a>So Kantorovich had the great idea of calling it the "shadow price",<span class="ot">[^shadow-price-kantorovich]</span> and considered it a way to find the proper price of something, better than the free market mechanism. The free market mechanism leads to maximizing some kind of utility function, but that utility function is not designed by anyone. In contrast, the shadow price naturally falls out of attempts to maximize a social utility function designed by the <span class="co">[</span><span class="ot">Gosplan (State Planning Committee)</span><span class="co">](https://en.wikipedia.org/wiki/Gosplan)</span>. It is a utility designed by humans, for humans, not a utility function emergent from capitalism, for capitalism.</span>
<span id="cb18-818"><a href="#cb18-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-819"><a href="#cb18-819" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shadow-price-kantorovich]: </span>In his original terms, "objectively determined valuation" <span class="sc">\[</span>объективно обусловленные оценки<span class="sc">\]</span>, where the "objectively" means "according to an objective function (the social utility function)".</span>
<span id="cb18-820"><a href="#cb18-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-821"><a href="#cb18-821" aria-hidden="true" tabindex="-1"></a>This is, in short, how market socialism should work, according to Kantorovich:</span>
<span id="cb18-822"><a href="#cb18-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-823"><a href="#cb18-823" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Design a social utility function (the "social" part of "socialism").</span>
<span id="cb18-824"><a href="#cb18-824" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Collect data on how the factories *should ideally* work (big data).</span>
<span id="cb18-825"><a href="#cb18-825" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Compute the shadow prices by linear programming (big compute).</span>
<span id="cb18-826"><a href="#cb18-826" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Set the prices on every commodity.</span>
<span id="cb18-827"><a href="#cb18-827" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Let the factories compete on this market for goods and money, secure in the knowledge that this socialist market would maximize a properly designed social utility, and the market mechanism would allow only the factories that achieve the highest efficiency: The slackers are competed out, and only those who can perform as efficiently as the "ideal factories" (see step 2) can make a profit and thus survive.</span>
<span id="cb18-828"><a href="#cb18-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-829"><a href="#cb18-829" aria-hidden="true" tabindex="-1"></a>The whole thing is not hard to prove in a simple model of economy, where all factories are linear functions, and the social utility function is also a linear function. Then the proof is just writing down the "<span class="co">[</span><span class="ot">linear duality theorem</span><span class="co">](https://en.wikipedia.org/wiki/Dual_linear_program)</span>", and interpreting it as economics.</span>
<span id="cb18-830"><a href="#cb18-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-831"><a href="#cb18-831" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Boyarskii:</span><span class="sc">\]</span><span class="at"> You write, "any increase in the requirements of some article entails a corresponding increase in costs and consequently in its o.d. valuation. A decrease in requirements entails a reduction in its o.d. valuation." What is this, what can this possibly be, but a suggestion that value is determined by supply and demand? Supply and demand, for heaven’s sake: bourgeois ideology’s most transparent disguise for exploitation!</span></span>
<span id="cb18-832"><a href="#cb18-832" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-833"><a href="#cb18-833" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ...</span></span>
<span id="cb18-834"><a href="#cb18-834" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-835"><a href="#cb18-835" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Kantorovich:</span><span class="sc">\]</span><span class="at"> It’s true that there is a formal resemblance, but they have a completely different origin, and therefore a completely different meaning. Whereas market prices are formed spontaneously, objective valuations -- shadow prices -- must be computed on the basis of an optimal plan. As the plan targets change, the valuations change. They are subordinate to the very different production relationships of a socialist society. Yet, yet, the scope for their use is actually bigger under socialism. The capitalists actually agree with you, Dr Boyarskii, that the mathematical methods we’re talking about should only be applied on the small scale, on the level of the individual firm. They have no choice: there is no larger structure, in the economy of West Germany or the United States, in which they can be set to work. They have had some success, I believe. I’m sorry to say that, since George Danzig and Tjalling Koopmans made their discoveries of “linear programming” in America during the war, the techniques have been adopted there far more eagerly, far more quickly, than in the Soviet Union. Linear programmers in the USA calculate routes for airlines, and devise the investment policies of Wall Street corporations. But we still have an opportunity before us which is closed to the capitalists. Capitalism cannot calculate an optimum for a whole economy at once. We can. There is a fundamental harmony between optimal planning and the nature of socialist society.</span></span>
<span id="cb18-836"><a href="#cb18-836" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-837"><a href="#cb18-837" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@spuffordRedPlenty2010, chapter 5</span><span class="co">]</span></span>
<span id="cb18-838"><a href="#cb18-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-839"><a href="#cb18-839" aria-hidden="true" tabindex="-1"></a>Though he kept trying to propose his idea of socialist optimal planning, and kept sending letters to leaders from Stalin to Andropov, his idea remained a linear programmer's fanatsy.</span>
<span id="cb18-840"><a href="#cb18-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-841"><a href="#cb18-841" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mechanizing Mathematics</span></span>
<span id="cb18-842"><a href="#cb18-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-843"><a href="#cb18-843" aria-hidden="true" tabindex="-1"></a>Circa 1900, as mathematicians learned to manufacture paradoxes, mathematics modernized, upgraded paranoia, and tried to get a grip. The angel of topology and the devil of abstract algebra fought for the soul of each individual mathematical domain in this "Foundational Crisis". With palpable disdain, Poincaré deplored the Hilbert school of formal logic that threatened to bleed even geometry of meaning:</span>
<span id="cb18-844"><a href="#cb18-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-845"><a href="#cb18-845" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;  "Imagine," says Hilbert," three kinds of things, which we will call points, straight lines, and planes; let us agree that a straight line shall be determined by two points, and that, instead of saying that this straight line is determined by these two points, we may say that it passes through these two points, or that these two points are situated on the straight line." What these things are, not only do we not know, but we must not seek to know... We might replace geometry by the reasoning piano imagined by Stanley Jevons; or, if we prefer, we might imagine a machine where we should put in axioms at one end and take out theorems at the other, like that legendary machine in Chicago where pigs go in alive and come out transformed into hams and sausages. It is no more necessary for the mathematician than it is for these machines to know what he is doing.</span></span>
<span id="cb18-846"><a href="#cb18-846" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-847"><a href="#cb18-847" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@poincareScienceMethod1914, page 147</span><span class="co">]</span></span>
<span id="cb18-848"><a href="#cb18-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-849"><a href="#cb18-849" aria-hidden="true" tabindex="-1"></a>But what is taken as an *reductio ad absurdum* by one side is often a Roadmap for the Next 20 Yaers by the other. The mechanical logician came as soon as the electronic computers arrived.</span>
<span id="cb18-850"><a href="#cb18-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-851"><a href="#cb18-851" aria-hidden="true" tabindex="-1"></a>During undergrad years, Edward Feigenbaum took a course "Mathematical Models in the Social Sciences" taught by Herbert Simon. One class, he walked in and annouced to the 6 students</span>
<span id="cb18-852"><a href="#cb18-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-853"><a href="#cb18-853" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Over the Christmas holidays, Al Newell and I invented a thinking machine.</span></span>
<span id="cb18-854"><a href="#cb18-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-855"><a href="#cb18-855" aria-hidden="true" tabindex="-1"></a>Stunned, Feigenbaum asked Simon, whereupon he received a manual of IBM 701. Feigenbaum read it all through the night, and in the morning light, he felt a "born-again experience". AI has won itself a new convert.</span>
<span id="cb18-856"><a href="#cb18-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-857"><a href="#cb18-857" aria-hidden="true" tabindex="-1"></a>The thinking machine was Logic Theorist <span class="co">[</span><span class="ot">@newellEmpiricalExplorationsLogic1957</span><span class="co">]</span>, perhaps the first AI mathematician.</span>
<span id="cb18-858"><a href="#cb18-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-859"><a href="#cb18-859" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The Logic Theory Machine found proofs for 38 of the 52 theorems it was presented with from the Principia, in particular finding a straightforward proof of theorem 2.85 (a simple propositional logic theorem) where Whitehead and Russell had given a more cumbersome - indeed, defective -- proof. Lord Russell was impressed... The editor of the prestigious *Journal of Symbolic Logic*, however. was not won over, and the journal refused to publish an article coauthored by the Logic Theory Machine describing the proof of theorem 2.85.</span></span>
<span id="cb18-860"><a href="#cb18-860" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-861"><a href="#cb18-861" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mackenzieAutomationProofHistorical1995</span><span class="co">]</span></span>
<span id="cb18-862"><a href="#cb18-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-863"><a href="#cb18-863" aria-hidden="true" tabindex="-1"></a>The working of Logic Theorist was simple. It simply performs a tree search in the space of possible proofs. At the root of the tree is the theorem to be proved. Each branch then transforms the state of the proof, adding assumptions (which then become sub-goals that themselves need to be proved), substitute logical variables, quoting axioms, perform modus ponens, etc. If at some leaf-node, the list of goals is empty, then the solution is found, and the Logical Theorist backtracks to get the final proof.</span>
<span id="cb18-864"><a href="#cb18-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-865"><a href="#cb18-865" aria-hidden="true" tabindex="-1"></a>As an example, it proved Theorem 2.17 as follows. The final proof had 7 steps, and took 89k basic operations to discover. <span class="co">[</span><span class="ot">@newellHumanProblemSolving1972, page 133</span><span class="co">]</span></span>
<span id="cb18-866"><a href="#cb18-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-867"><a href="#cb18-867" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathrm{A} \supset \sim \sim \mathrm{A}$ (Start with Theorem 2.17)</span>
<span id="cb18-868"><a href="#cb18-868" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathrm{P} \supset \sim \sim \mathrm{P}$ (Theorem 2.12)</span>
<span id="cb18-869"><a href="#cb18-869" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>...</span>
<span id="cb18-870"><a href="#cb18-870" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$(\sim \mathrm{Q} \supset \sim \mathrm{P}) \supset(\mathrm{P} \supset \mathrm{Q})$ (chain 7 and 5)</span>
<span id="cb18-871"><a href="#cb18-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-872"><a href="#cb18-872" aria-hidden="true" tabindex="-1"></a>A later version mechanized Poincaré's nightmare by converting Euclidean geometry problems to symbolic logic, and managed to discover a particularly elegant proof that in a triangle $ABC$, if $AB = AC$ then $\angle ABC = \angle ACB$, by the SAS theorem. Only later did the authors discover that this was a previously known solution. <span class="co">[</span><span class="ot">@mackenzieAutomationProofHistorical1995</span><span class="co">]</span></span>
<span id="cb18-873"><a href="#cb18-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-874"><a href="#cb18-874" aria-hidden="true" tabindex="-1"></a><span class="fu">### Information Processing System</span></span>
<span id="cb18-875"><a href="#cb18-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-876"><a href="#cb18-876" aria-hidden="true" tabindex="-1"></a>Simon and Newell were unhappy with Logic Theorist, for the simple reason that when they read the trace-outs of its "thought process", they noted that it is very different from how humans would go about proving the same problems. Patiently plodding, they brute forced through the whole search tree, whereas humans would tastefully pick some branches and search deeply, and others not at all.</span>
<span id="cb18-877"><a href="#cb18-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-878"><a href="#cb18-878" aria-hidden="true" tabindex="-1"></a>In their magnum opus, *Human Problem Solving* (1972), they have compiled their decades of research into a definitive statement of what AI is about in their view. According to them, AI is logical AI, and the fundamental architecture for logical AI is Information Processing System. <span class="co">[</span><span class="ot">@newellHumanProblemSolving1972</span><span class="co">]</span></span>
<span id="cb18-879"><a href="#cb18-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-880"><a href="#cb18-880" aria-hidden="true" tabindex="-1"></a>The axioms of logical AI:</span>
<span id="cb18-881"><a href="#cb18-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-882"><a href="#cb18-882" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It is symbols all the way down. Everything "sub-symbolic", like the neural biology, are just implementation, and not part of what intelligence is about, much like software is independent of hardware.</span>
<span id="cb18-883"><a href="#cb18-883" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Intelligent behavior is the combination of simple goals, simple algorithms, and complex environment.</span>
<span id="cb18-884"><a href="#cb18-884" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Intelligent algorithms are fairly simple, and consist of serial, deterministic, heuristic search over the space of solutions.</span>
<span id="cb18-885"><a href="#cb18-885" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The space of solutions is structured like a directed graph, where the edges are "generators" or "search operators".</span>
<span id="cb18-886"><a href="#cb18-886" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>At each step, the search algorihm runs a "verifier" subroutine to check if a solution has been found. If so, then it backtracks to produce the full solution. If not, then it updates an internal state and decide how to grow the path towards the goal.</span>
<span id="cb18-887"><a href="#cb18-887" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To grow the path towards the goal, it conducts "means-ends analysis": Take a small forward step to a new place in the space of solutions ("means"), and move the goalpost by a small backward step, to a new goalpost closer to you ("ends").</span>
<span id="cb18-888"><a href="#cb18-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-889"><a href="#cb18-889" aria-hidden="true" tabindex="-1"></a>They designed an algorithm according to the axioms and called it "General Problem Solver" (GPS), a grandiose title for a grandiose dream.</span>
<span id="cb18-890"><a href="#cb18-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-891"><a href="#cb18-891" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The architecture of the GPS. [@newellHumanProblemSolving1972, figure 4.1]</span><span class="co">](figure/Simon_Newell_fig_4_1.png)</span></span>
<span id="cb18-892"><a href="#cb18-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-893"><a href="#cb18-893" aria-hidden="true" tabindex="-1"></a>Curiously, they argued that Chomskyan linguistics and the IPS formalism are essentially the same:</span>
<span id="cb18-894"><a href="#cb18-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-895"><a href="#cb18-895" aria-hidden="true" tabindex="-1"></a>| IPS logical AI | Chomskyan linguistics |</span>
<span id="cb18-896"><a href="#cb18-896" aria-hidden="true" tabindex="-1"></a>|-----|-----|</span>
<span id="cb18-897"><a href="#cb18-897" aria-hidden="true" tabindex="-1"></a>| Symbols | Symbols  |</span>
<span id="cb18-898"><a href="#cb18-898" aria-hidden="true" tabindex="-1"></a>| Problem input | Surface structure of a sentence |</span>
<span id="cb18-899"><a href="#cb18-899" aria-hidden="true" tabindex="-1"></a>| Symbolic representations | Deep structures; representations of meanings |</span>
<span id="cb18-900"><a href="#cb18-900" aria-hidden="true" tabindex="-1"></a>| Problem space | Space of deep structures of strings |</span>
<span id="cb18-901"><a href="#cb18-901" aria-hidden="true" tabindex="-1"></a>| Problem solving | Parsing, or grammatical analyses from the surface structure to the deep structure |</span>
<span id="cb18-902"><a href="#cb18-902" aria-hidden="true" tabindex="-1"></a>| Stored patterns | Stored words, phrases, syntax trees, etc |</span>
<span id="cb18-903"><a href="#cb18-903" aria-hidden="true" tabindex="-1"></a>: Equivalence between Chomskyan linguistics and the IPS logical AI.</span>
<span id="cb18-904"><a href="#cb18-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-905"><a href="#cb18-905" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It should be evident from the discussion of symbols, symbol structures, the designation relation, and programs that an information processing system of the sort we have described in this chapter is, in some fundamental sense, a language processor. As a matter of historical fact, the basic concepts that have entered into our description of an IPS have almost the same origins as the concepts that underlie the formalized transformational grammars that linguists have developed over the past fifteen years </span><span class="co">[</span><span class="ot">@chomskySyntacticStructures1957</span><span class="co">]</span><span class="at">... our theory of problem solving can properly be viewed as also a partial theory of linguistics-specifically, a theory of the nature of the deep structures used by the human IPS in the course of its problem solving activities.</span></span>
<span id="cb18-906"><a href="#cb18-906" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-907"><a href="#cb18-907" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@newellHumanProblemSolving1972, page 38</span><span class="co">]</span></span>
<span id="cb18-908"><a href="#cb18-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-909"><a href="#cb18-909" aria-hidden="true" tabindex="-1"></a>As we have seen and will see, the relation between Chomsky and logical AI runs deep.</span>
<span id="cb18-910"><a href="#cb18-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-911"><a href="#cb18-911" aria-hidden="true" tabindex="-1"></a>The IPS is not just a logical framework AI, but also a psychological theory for what humans really do when they solve problems. As such, Simon and Newell spent over a decade carefully studying the behavior of real humans solving real problems, such as propositional logic proofs (the same task as Logic Theorist), cryptograms, chess puzzles, and so on. And by "detailed" I mean it. They had subjects working through problems in a lab, with the entire session tape-recorded, fully transcribed, annotated, and parsed into the form of a heuristic tree search. It was like looking at the debugger output to a human being.</span>
<span id="cb18-912"><a href="#cb18-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-913"><a href="#cb18-913" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Annotated transcript of a human subject solving a propositional logic puzzle. The session lasted about 40 minutes, and ends with a failure. The transcript has 535 lines. [@newellHumanProblemSolving1972, page 533]</span><span class="co">](figure/human_problem_solving_transcript.png)</span></span>
<span id="cb18-914"><a href="#cb18-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-915"><a href="#cb18-915" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The same transcript parsed into a heuristic tree search over the problem space. [@newellHumanProblemSolving1972, page 534]</span><span class="co">](figure/human_problem_solving_behavior_graph.png)</span></span>
<span id="cb18-916"><a href="#cb18-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-917"><a href="#cb18-917" aria-hidden="true" tabindex="-1"></a>In a popularization (well, as popular as abstract AI theories can get), Simon analogized their theory with a crawling ant:</span>
<span id="cb18-918"><a href="#cb18-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-919"><a href="#cb18-919" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We watch an ant make his laborious way across a wind- and wave- molded beach. He moves ahead, angles to the right to ease his climb up a steep dunelet, detours around a pebble, stops for a moment to exchange information with a compatriot. Thus he makes his weaving, halting way back to his home. So as not to anthropomorphize about his purposes, I sketch the path on a piece of paper. It is a sequence of irregular, angular segments--not quite a random walk, for it has an underlying sense of direction, of aiming toward a goal. I show the unlabeled sketch to a friend. Whose path is it? An expert skier, perhaps, slaloming down a steep and somewhat rocky slope. Or a sloop, beating upwind in a channel dotted with islands or shoals. Perhaps it is a path in a more abstract space: the course of search of a student seeking the proof of a theorem in geometry... Human beings, viewed as behaving systems, are quite simple. The apparent complexity of our behavior over time is largely a reflection of the complexity of the environment in which we find ourselves.</span></span>
<span id="cb18-920"><a href="#cb18-920" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-921"><a href="#cb18-921" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@simonSciencesArtificial1996, chapter 3</span><span class="co">]</span></span>
<span id="cb18-922"><a href="#cb18-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-923"><a href="#cb18-923" aria-hidden="true" tabindex="-1"></a>If we squint at the following diagram, we can almost see it as they saw it: a human, as simple minded as an ant, crawling and stumbling through the problem space of logic.</span>
<span id="cb18-924"><a href="#cb18-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-925"><a href="#cb18-925" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Searching over the problem space of propositional logic puzzles. [@newellHumanProblemSolving1972, page 575]</span><span class="co">](figure/Simon_Newell_1975_fig_10_13.png)</span></span>
<span id="cb18-926"><a href="#cb18-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-927"><a href="#cb18-927" aria-hidden="true" tabindex="-1"></a>At this point, we might be seeing a pattern here. Checking every use of the word "learning" in the book, I confirmed that, indeed, they were uninterested in learning, other than claiming that learning consists of adding more symbols to the internal environment, which is just one more kind of environment. One can look up lemmas and formulas on an external book, or an internal blackboard. It is all the same. The ant of the brain just need to crawl over the inner landscape as much as it crawls over the outer landscape.</span>
<span id="cb18-928"><a href="#cb18-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-929"><a href="#cb18-929" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We will deal hardly at all with earning phenomena in this book. Yet the approach to earning from the direction just illustrated, where we have the internal structure of the performing program laid out before us, shows clearly (1) that experience is simply one more source of information that can be exploited to attain adaptive performance and (2) that to affect performance experience must find some variable aspect of the performance program's structure that it can specify.</span></span>
<span id="cb18-930"><a href="#cb18-930" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-931"><a href="#cb18-931" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@simonSciencesArtificial1996, page 137</span><span class="co">]</span></span>
<span id="cb18-932"><a href="#cb18-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-933"><a href="#cb18-933" aria-hidden="true" tabindex="-1"></a>It is not that they completely ignored the problem of learning, but rather, they understood learning as a simple kind of associative memorization. Feigenbaum's PhD project was the Elementary Perceiver and Memorizer (EPAM), an algorithmic model of human associative memory. As a concrete realization of the learning theory of Simon and Newell, we describe it to show how little learning their framework contained.</span>
<span id="cb18-934"><a href="#cb18-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-935"><a href="#cb18-935" aria-hidden="true" tabindex="-1"></a>EPAM modeled people performing the following memorization task:</span>
<span id="cb18-936"><a href="#cb18-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-937"><a href="#cb18-937" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"DAX" is displayed to the subject</span>
<span id="cb18-938"><a href="#cb18-938" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Subject should say "JIR" in response</span>
<span id="cb18-939"><a href="#cb18-939" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Regardless of what subject responds, "JIR" is displayed after a few seconds.</span>
<span id="cb18-940"><a href="#cb18-940" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Repeat this until the subject manages to memorize all 12 pairs.</span>
<span id="cb18-941"><a href="#cb18-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-942"><a href="#cb18-942" aria-hidden="true" tabindex="-1"></a>During a session, every time EPAM sees a new stimulus-response pair, it stores the response, and updates its decision tree. Each node of the decision tree has two children, and which way EPAM goes is determined by testing one letter of the stimulus. It looks like </span>
<span id="cb18-943"><a href="#cb18-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-944"><a href="#cb18-944" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-945"><a href="#cb18-945" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> stimulus[<span class="dv">0</span>] <span class="op">==</span> <span class="st">"D"</span>:</span>
<span id="cb18-946"><a href="#cb18-946" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"JIR"</span></span>
<span id="cb18-947"><a href="#cb18-947" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> stimulus[<span class="dv">2</span>] <span class="op">==</span> <span class="st">"J"</span>:</span>
<span id="cb18-948"><a href="#cb18-948" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb18-949"><a href="#cb18-949" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-950"><a href="#cb18-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-951"><a href="#cb18-951" aria-hidden="true" tabindex="-1"></a>In short, what counts as a paradigm of learning is simply memorization, and updating a big if-then search tree, so that a stimulus results in going down the search tree and arriving at the correct response stored in the leaf node.</span>
<span id="cb18-952"><a href="#cb18-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-953"><a href="#cb18-953" aria-hidden="true" tabindex="-1"></a><span class="fu">### The drosophila of AI</span></span>
<span id="cb18-954"><a href="#cb18-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-955"><a href="#cb18-955" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Within 10 years, a computer would routinely beat the world's best player.</span></span>
<span id="cb18-956"><a href="#cb18-956" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-957"><a href="#cb18-957" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Herbert Simon, 1957</span></span>
<span id="cb18-958"><a href="#cb18-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-959"><a href="#cb18-959" aria-hidden="true" tabindex="-1"></a>In introductions to AI or even just machine learning. Arthur Samuel's checker program was usually given as the first great example of machine learning. In short, it performs alpha-beta search to a few plies<span class="ot">[^samuel-checkers-plies]</span> during playing, using up to 16 hand-crafted feature functions. It uses two learning rules <span class="co">[</span><span class="ot">@samuelStudiesMachineLearning1959, @suttonReinforcementLearningIntroduction2018, chapter 16.2; @russellArtificialIntelligenceModern1995, pages 616--617</span><span class="co">]</span>:</span>
<span id="cb18-960"><a href="#cb18-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-961"><a href="#cb18-961" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Rote learning: After performing an alpha-beta search, it would store the score for the root node. Later, if the root node is encountered during search, its score would be used without needing to search deeper. This allows it to increase the effective search depth over time, as it memorizes more and more positions' values. To save memory, if a board does not reappear after a maximum number of moves, it is "forgotten". The whole system managed to memorize 53,000 board positions (averaging 3.8 words each on a IBM 704)</span>
<span id="cb18-962"><a href="#cb18-962" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generalization learning: Something very similar to TD-learning in reinforcement learnig, except that the reward function is not whether the board is won (1 for winning, -1 for losing, 0 otherwise), but the *piece advantage* feature.</span>
<span id="cb18-963"><a href="#cb18-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-964"><a href="#cb18-964" aria-hidden="true" tabindex="-1"></a><span class="ot">[^samuel-checkers-plies]: </span>Annoyingly I can't find any information, but considering that an IBM 704 has $5\times 10^4 \;\mathrm{MIP/sec}$, and checkers has a branching factor of 400, it would take on the order of 10 minute to search 2 plies. So my bet is 2 plies. Indeed, the paper appendix says it takes $10^{-2} \;\mathrm{sec}$ to play and evaluate one position, which means it takes about 500 instructions for one play and evaluation, and that searching 2 plies already takes 30 minutes. </span>
<span id="cb18-965"><a href="#cb18-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-966"><a href="#cb18-966" aria-hidden="true" tabindex="-1"></a>The whole program ran on an <span class="co">[</span><span class="ot">IBM 704</span><span class="co">](https://en.wikipedia.org/wiki/IBM_704)</span>, and took up about 8000 instructions.</span>
<span id="cb18-967"><a href="#cb18-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-968"><a href="#cb18-968" aria-hidden="true" tabindex="-1"></a>Just when you thought there is finally some learning, nope. Samuel got the features from interviewing the checker experts. In fact, it had a formative influence on a later pioneer of expert systems:</span>
<span id="cb18-969"><a href="#cb18-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-970"><a href="#cb18-970" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Art Samuel's work on the checker player: Art had interviewed experts to understand... the feature vector and then he did a good deal of reading about checkers... And the influential part about that was.. his machine learning component -- that once you had the expertise in, in a first-order form, it could be improved... automatically. That impressed me a great deal and I always wanted to be able to do that.</span></span>
<span id="cb18-971"><a href="#cb18-971" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-972"><a href="#cb18-972" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@brockLearningArtificialIntelligences2018</span><span class="co">]</span></span>
<span id="cb18-973"><a href="#cb18-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-974"><a href="#cb18-974" aria-hidden="true" tabindex="-1"></a>Compared to checkers, computer chess had been much more high-profile, and it has been a textbook example of logical AI. The three parts of computer chess are move generator, evaluation function, and search control, corresponding to the solution space, verifier, and heuristic search algorithm of the IPS.</span>
<span id="cb18-975"><a href="#cb18-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-976"><a href="#cb18-976" aria-hidden="true" tabindex="-1"></a>The IPS framework, with its talk of heuristic search, resembles most of all how people play board games. Indeed, <span class="co">[</span><span class="ot">@newellHumanProblemSolving1972</span><span class="co">]</span> devoted over 100 pages to chess, "the drosophila of AI". Indeed, chess seems like the perfect illustration: simply do an alpha-beta search with a heuristic evaluation function on it. This was essentially the algorithm proposed by Alan Turing in 1948 -- the <span class="co">[</span><span class="ot">Turochamp</span><span class="co">](https://en.wikipedia.org/wiki/Turochamp)</span>, and it was still the algorithm used in <span class="co">[</span><span class="ot">Deep Blue (1997)</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)). In fact, the architecture has changed so little that we can write a single "prototypical chess program":</span>
<span id="cb18-977"><a href="#cb18-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-978"><a href="#cb18-978" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-979"><a href="#cb18-979" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score(board):</span>
<span id="cb18-980"><a href="#cb18-980" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return a real number</span></span>
<span id="cb18-981"><a href="#cb18-981" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> move_generator(board):</span>
<span id="cb18-982"><a href="#cb18-982" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return a list of legal moves</span></span>
<span id="cb18-983"><a href="#cb18-983" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_move(board, move):</span>
<span id="cb18-984"><a href="#cb18-984" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the next board</span></span>
<span id="cb18-985"><a href="#cb18-985" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search(board):</span>
<span id="cb18-986"><a href="#cb18-986" aria-hidden="true" tabindex="-1"></a>    <span class="co"># do the minimax search, </span></span>
<span id="cb18-987"><a href="#cb18-987" aria-hidden="true" tabindex="-1"></a>    <span class="co"># or the alpha-beta tree search, etc</span></span>
<span id="cb18-988"><a href="#cb18-988" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> moves <span class="kw">in</span> move_generator(board):</span>
<span id="cb18-989"><a href="#cb18-989" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb18-990"><a href="#cb18-990" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_move</span>
<span id="cb18-991"><a href="#cb18-991" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-992"><a href="#cb18-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-993"><a href="#cb18-993" aria-hidden="true" tabindex="-1"></a>Progress in chess computers has come from three sources: faster computers allowing bigger search trees, better scoring functions, and better heuristic tree search algorithms (from minimax to alpha-beta to tricks like singular extensions). As an illustrative example, here is (part of) the Turochamp scoring function <span class="co">[</span><span class="ot">@newellHumanProblemSolving1972, pag 672</span><span class="co">]</span>:</span>
<span id="cb18-994"><a href="#cb18-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-995"><a href="#cb18-995" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-996"><a href="#cb18-996" aria-hidden="true" tabindex="-1"></a>material_value <span class="op">=</span> {</span>
<span id="cb18-997"><a href="#cb18-997" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pawn"</span> : <span class="dv">1</span>, <span class="st">"Knight"</span>: <span class="dv">3</span>, <span class="st">"Bishop"</span>: <span class="fl">3.5</span>,</span>
<span id="cb18-998"><a href="#cb18-998" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Rook"</span>: <span class="dv">5</span>, <span class="st">"Queen"</span>: <span class="dv">10</span>, <span class="st">"Checkmate"</span>: <span class="dv">1000</span></span>
<span id="cb18-999"><a href="#cb18-999" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-1000"><a href="#cb18-1000" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mobility(board, piece):</span>
<span id="cb18-1001"><a href="#cb18-1001" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Square root of legal moves for the piece</span></span>
<span id="cb18-1002"><a href="#cb18-1002" aria-hidden="true" tabindex="-1"></a>    legal_moves <span class="op">=</span> move_generator(board)</span>
<span id="cb18-1003"><a href="#cb18-1003" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sqrt(<span class="bu">len</span>([move <span class="cf">for</span> move <span class="kw">in</span> legal_moves <span class="cf">if</span> piece <span class="kw">in</span> move]))</span>
<span id="cb18-1004"><a href="#cb18-1004" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb18-1005"><a href="#cb18-1005" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score(board):</span>
<span id="cb18-1006"><a href="#cb18-1006" aria-hidden="true" tabindex="-1"></a>    q_value <span class="op">=</span> mobility(board, <span class="st">"Queen"</span>)</span>
<span id="cb18-1007"><a href="#cb18-1007" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb18-1008"><a href="#cb18-1008" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> q_value <span class="op">+</span> ...</span>
<span id="cb18-1009"><a href="#cb18-1009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1010"><a href="#cb18-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1011"><a href="#cb18-1011" aria-hidden="true" tabindex="-1"></a>Like its predecessors, Deep Blue used alpha-beta tree search, except it searched *a lot of positions*. To support this, it used <span class="co">[</span><span class="ot">ASIC</span><span class="co">](https://en.wikipedia.org/wiki/Application-specific_integrated_circuit)</span> <span class="co">[</span><span class="ot">VLSI</span><span class="co">](https://en.wikipedia.org/wiki/Very-large-scale_integration)</span> "chess chips",<span class="ot">[^chess-chip-mosis]</span> each with four parts: the move generator, the smart-move stack, the evaluation function, and the search control. The move generator is a 8×8 combinational logic circuit, a chess board in miniature. <span class="co">[</span><span class="ot">@hsuIBMsDeepBlue1999; @campbellDeepBlue2002</span><span class="co">]</span></span>
<span id="cb18-1012"><a href="#cb18-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1013"><a href="#cb18-1013" aria-hidden="true" tabindex="-1"></a><span class="ot">[^chess-chip-mosis]: </span>Just when you thought DARPA can't possibly be behind this, guess what, Hsu developed the earlier iterations of chess chips by taking advantage of <span class="co">[</span><span class="ot">MOSIS</span><span class="co">](https://en.wikipedia.org/wiki/MOSIS)</span>, which was part of the Strategic Computing Initiative <span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, chapter 4</span><span class="co">]</span>. More on this <span class="co">[</span><span class="ot">below</span><span class="co">](#sec-sci)</span>.</span>
<span id="cb18-1014"><a href="#cb18-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1015"><a href="#cb18-1015" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The flowchart of Deep Blue. [@hsuIBMsDeepBlue1999]</span><span class="co">](figure/chess_chip.png)</span></span>
<span id="cb18-1016"><a href="#cb18-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1017"><a href="#cb18-1017" aria-hidden="true" tabindex="-1"></a>Describing the software of Deep Blue in detail would be not particularly enlightening, so here's a pseudocode sketch:</span>
<span id="cb18-1018"><a href="#cb18-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1019"><a href="#cb18-1019" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-1020"><a href="#cb18-1020" aria-hidden="true" tabindex="-1"></a>opening_book <span class="op">=</span> ... <span class="co"># 4000 positions</span></span>
<span id="cb18-1021"><a href="#cb18-1021" aria-hidden="true" tabindex="-1"></a>extended_book <span class="op">=</span> ... <span class="co"># several million positions from 0.7M grandmaster games</span></span>
<span id="cb18-1022"><a href="#cb18-1022" aria-hidden="true" tabindex="-1"></a>endgame_table <span class="op">=</span> ... <span class="co"># all endgames with &lt;= 5 pieces, and many endgames with 6 pieces</span></span>
<span id="cb18-1023"><a href="#cb18-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1024"><a href="#cb18-1024" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_function(board):</span>
<span id="cb18-1025"><a href="#cb18-1025" aria-hidden="true" tabindex="-1"></a>    weight_vector <span class="op">=</span> ... <span class="co"># contains 8000 real numbers</span></span>
<span id="cb18-1026"><a href="#cb18-1026" aria-hidden="true" tabindex="-1"></a>    feature_vector <span class="op">=</span> features(board) <span class="co"># contains 8000 handcrafted terms</span></span>
<span id="cb18-1027"><a href="#cb18-1027" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weight_vector <span class="op">@</span> feature_vector</span>
<span id="cb18-1028"><a href="#cb18-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1029"><a href="#cb18-1029" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> play(board):</span>
<span id="cb18-1030"><a href="#cb18-1030" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> board <span class="kw">in</span> opening_book:</span>
<span id="cb18-1031"><a href="#cb18-1031" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> retrieve_opening_move(board, opening_book)</span>
<span id="cb18-1032"><a href="#cb18-1032" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> board <span class="kw">in</span> extended_book:</span>
<span id="cb18-1033"><a href="#cb18-1033" aria-hidden="true" tabindex="-1"></a>        best_score <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb18-1034"><a href="#cb18-1034" aria-hidden="true" tabindex="-1"></a>        best_move <span class="op">=</span> <span class="st">''</span></span>
<span id="cb18-1035"><a href="#cb18-1035" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> move <span class="kw">in</span> legal_moves(board):</span>
<span id="cb18-1036"><a href="#cb18-1036" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> evaluate(move, board, extended_book)</span>
<span id="cb18-1037"><a href="#cb18-1037" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> score <span class="op">&gt;</span> best_score:</span>
<span id="cb18-1038"><a href="#cb18-1038" aria-hidden="true" tabindex="-1"></a>                best_score <span class="op">=</span> score</span>
<span id="cb18-1039"><a href="#cb18-1039" aria-hidden="true" tabindex="-1"></a>                best_move <span class="op">=</span> move</span>
<span id="cb18-1040"><a href="#cb18-1040" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> size(board) <span class="op">&lt;=</span> <span class="dv">5</span> <span class="kw">or</span> (size(board) <span class="op">==</span> <span class="dv">6</span> <span class="kw">and</span> board <span class="kw">in</span> endgame_table):</span>
<span id="cb18-1041"><a href="#cb18-1041" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> retrieve_ending_move(board, endgame_table)</span>
<span id="cb18-1042"><a href="#cb18-1042" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb18-1043"><a href="#cb18-1043" aria-hidden="true" tabindex="-1"></a>        move <span class="op">=</span> alpha_beta_search(board, eval_function) <span class="co"># evaluate 200M pos/sec</span></span>
<span id="cb18-1044"><a href="#cb18-1044" aria-hidden="true" tabindex="-1"></a>    play(move)</span>
<span id="cb18-1045"><a href="#cb18-1045" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1046"><a href="#cb18-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1047"><a href="#cb18-1047" aria-hidden="true" tabindex="-1"></a>I know you are eager to hear about how Deep Blue learned. So did I. The bad news is that it barely learned anything. First, its evaluation function was just a linear sum over ~8000 hand-crafted features,<span class="ot">[^deep-blue-features]</span> with changeable linear weights. It actually had two evaluation functions, fast and slow. Only if the fast one already shows a clear advantage would the slow one be called. Further, the linear weights were mostly handcrafted too, except a small amount of automation:</span>
<span id="cb18-1048"><a href="#cb18-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1049"><a href="#cb18-1049" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The first tool had the goal of identifying features in the Deep Blue I evaluation function that were “noisy”, i.e., relatively insensitive to the particular weights chosen... A hill-climbing approach was used to explore selected features (or feature subsets), and those that did not converge were candidates for further hand examination... A second tool was developed with the goal of tuning evaluation function weights. This tool used a comparison training methodology to analyze weights related to pawn shelter. Training results showed that the hand-tuned weights were systematically too low, and they were increased prior to the 1997 match. There is some evidence that this change led to improved play.</span></span>
<span id="cb18-1050"><a href="#cb18-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1051"><a href="#cb18-1051" aria-hidden="true" tabindex="-1"></a>I didn't understand it, so I turned to a previous paper <span class="co">[</span><span class="ot">@hsuGrandmasterChessMachine1990</span><span class="co">]</span> that seems to explain it better, according to which they did two kinds of "automated" training, which were both supervised learning without backpropagation:</span>
<span id="cb18-1052"><a href="#cb18-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1053"><a href="#cb18-1053" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-1054"><a href="#cb18-1054" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hill_climbing(t, games):</span>
<span id="cb18-1055"><a href="#cb18-1055" aria-hidden="true" tabindex="-1"></a>    search_depth <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb18-1056"><a href="#cb18-1056" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> learning_rate <span class="op">*</span> random(t.shape)</span>
<span id="cb18-1057"><a href="#cb18-1057" aria-hidden="true" tabindex="-1"></a>    wins <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-1058"><a href="#cb18-1058" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (board, move) <span class="im">from</span> random_sample(grandmaster_games, N):</span>
<span id="cb18-1059"><a href="#cb18-1059" aria-hidden="true" tabindex="-1"></a>        old_move <span class="op">=</span> alpha_beta_search(board, search_depth, evaluation_function, t)</span>
<span id="cb18-1060"><a href="#cb18-1060" aria-hidden="true" tabindex="-1"></a>        new_move <span class="op">=</span> alpha_beta_search(board, search_depth, evaluation_function, t <span class="op">+</span> dt)</span>
<span id="cb18-1061"><a href="#cb18-1061" aria-hidden="true" tabindex="-1"></a>        wins <span class="op">+=</span> (new_move <span class="op">==</span> move) <span class="op">-</span> (old_move <span class="op">==</span> move)</span>
<span id="cb18-1062"><a href="#cb18-1062" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> wins <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-1063"><a href="#cb18-1063" aria-hidden="true" tabindex="-1"></a>        t <span class="op">+=</span> dt</span>
<span id="cb18-1064"><a href="#cb18-1064" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span>
<span id="cb18-1065"><a href="#cb18-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1066"><a href="#cb18-1066" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> comparison_training(t, games):</span>
<span id="cb18-1067"><a href="#cb18-1067" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> learning_rate <span class="op">*</span> random(t.shape)</span>
<span id="cb18-1068"><a href="#cb18-1068" aria-hidden="true" tabindex="-1"></a>    wins <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-1069"><a href="#cb18-1069" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (board, move) <span class="im">from</span> random_sample(grandmaster_games, N):</span>
<span id="cb18-1070"><a href="#cb18-1070" aria-hidden="true" tabindex="-1"></a>        moves <span class="op">=</span> legal_moves(board)</span>
<span id="cb18-1071"><a href="#cb18-1071" aria-hidden="true" tabindex="-1"></a>        next_board <span class="op">=</span> make_move(board, move)</span>
<span id="cb18-1072"><a href="#cb18-1072" aria-hidden="true" tabindex="-1"></a>        reference_score <span class="op">=</span> evaluation_function(t, next_board)</span>
<span id="cb18-1073"><a href="#cb18-1073" aria-hidden="true" tabindex="-1"></a>        old_scores <span class="op">=</span> []</span>
<span id="cb18-1074"><a href="#cb18-1074" aria-hidden="true" tabindex="-1"></a>        new_scores <span class="op">=</span> []</span>
<span id="cb18-1075"><a href="#cb18-1075" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> alt_move <span class="kw">in</span> moves <span class="cf">if</span> alt_move <span class="op">!=</span> move:</span>
<span id="cb18-1076"><a href="#cb18-1076" aria-hidden="true" tabindex="-1"></a>            next_board <span class="op">=</span> make_move(board, alt_move)</span>
<span id="cb18-1077"><a href="#cb18-1077" aria-hidden="true" tabindex="-1"></a>            old_scores.append(evaluation_function(t, next_board))</span>
<span id="cb18-1078"><a href="#cb18-1078" aria-hidden="true" tabindex="-1"></a>            new_scores.append(evaluation_function(t <span class="op">+</span> dt, next_board))</span>
<span id="cb18-1079"><a href="#cb18-1079" aria-hidden="true" tabindex="-1"></a>        wins <span class="op">+=</span> <span class="bu">all</span>(reference_score <span class="op">&gt;</span> new_scores) <span class="op">-</span> <span class="bu">all</span>(reference_score <span class="op">&gt;</span> old_scores)</span>
<span id="cb18-1080"><a href="#cb18-1080" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> wins <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-1081"><a href="#cb18-1081" aria-hidden="true" tabindex="-1"></a>        t <span class="op">+=</span> dt</span>
<span id="cb18-1082"><a href="#cb18-1082" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span>
<span id="cb18-1083"><a href="#cb18-1083" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1084"><a href="#cb18-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1085"><a href="#cb18-1085" aria-hidden="true" tabindex="-1"></a><span class="ot">[^deep-blue-features]</span>:</span>
<span id="cb18-1086"><a href="#cb18-1086" aria-hidden="true" tabindex="-1"></a>    And there were a lot of features, with words I barely understand:</span>
<span id="cb18-1087"><a href="#cb18-1087" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1088"><a href="#cb18-1088" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; The most significant part of the fast evaluation is the “piece placement” value, i.e., the sum of the basic piece values with square-based location adjustments. Positional features that can be computed quickly, such as “pawn can run”, are also part of the fast evaluation. The slow evaluation scans the chess board one column at a time, computing values for chess concepts such as square control, pins, X-rays, king safety, pawn structure, passed pawns, ray control, outposts, pawn majority, rook on the 7th, blockade, restraint, color complex, trapped pieces, development, and so on. The features recognized in both the slow and fast evaluation functions have programmable weights, allowing their relative importance to be easily adjusted.</span></span>
<span id="cb18-1089"><a href="#cb18-1089" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt;</span></span>
<span id="cb18-1090"><a href="#cb18-1090" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@campbellDeepBlue2002]</span></span>
<span id="cb18-1091"><a href="#cb18-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1092"><a href="#cb18-1092" aria-hidden="true" tabindex="-1"></a>Deep Blue contains 480 chess chips, each capable of $2.5 \times 10^6 \;\mathrm{position/sec}$. But the total hardware had only a sustained peak rate $2 \times 10^8 \;\mathrm{position/sec}$, meaning its utilization rate was only 16%.<span class="ot">[^deep-blue-rmax]</span> <span class="co">[</span><span class="ot">@hsuCrackingGo2007</span><span class="co">]</span> To Hsu, it was an exercise in chip design. To Kasparov, it was a dirty business. To some journalists, it was another "Man vs Machine" story. And to us, it was the last great project of logical AI in the style of Simon and Newell.</span>
<span id="cb18-1093"><a href="#cb18-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1094"><a href="#cb18-1094" aria-hidden="true" tabindex="-1"></a><span class="ot">[^deep-blue-rmax]</span>:</span>
<span id="cb18-1095"><a href="#cb18-1095" aria-hidden="true" tabindex="-1"></a>    The $R_{max}$ of Deep Blue on LINPACK was 11.38 GFLOP according to <span class="co">[</span><span class="ot">TOP500 List - June 1997</span><span class="co">](https://web.archive.org/web/20090213103245/http://www.top500.org/list/1997/06/300)</span>, meaning that each positional evaluation is worth 10 FLOP, although I have doubts about just how they managed to cram the LINPACK benchmark onto the chess chips.</span>
<span id="cb18-1096"><a href="#cb18-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1097"><a href="#cb18-1097" aria-hidden="true" tabindex="-1"></a><span class="in">    An earlier report in 1995 [@hsuDeepBlueSystem1995], published a year before Deep Blue was assembled, estimated that a general-purpose computer would take 1000 FLOP to evaluate one position. It also estimated Deep Blue would take up around 1 kW of electric power.</span></span>
<span id="cb18-1098"><a href="#cb18-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1099"><a href="#cb18-1099" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Deep Thought was not an "expert system"... Several members of the team would probably consider it an insult to call Deep Thought an expert system. In fact, at least two members of the team had used the word *bullshit* to describe "expert systems", or for that matter, Artificial Intelligence. Second, the Deep Thought research was supported in part by the VLSI project, and none of the money came from the DARPA funding for expert systems research.</span></span>
<span id="cb18-1100"><a href="#cb18-1100" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1101"><a href="#cb18-1101" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hsuDeepBlueBuilding2002, page 98</span><span class="co">]</span></span>
<span id="cb18-1102"><a href="#cb18-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1103"><a href="#cb18-1103" aria-hidden="true" tabindex="-1"></a>10 years after the historic win, Hsu wrote a brief essay describing how to make a superhuman Go machine. He estimated that it was already possible to get a *single* Go-chip to evaluate $2 \times 10^{10} \;\mathrm{position/sec}$, and so with 10 years of Moore's law giving another 100×, a machine with 480 Go-chips would be able to evaluate $10^{14} \;\mathrm{position/sec}$ by 2017.</span>
<span id="cb18-1104"><a href="#cb18-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1105"><a href="#cb18-1105" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... with some optimization a machine that can search a trillion positions per second would be enough to play Go at the very highest level. It would then be cheaper to build the machine out of FPGAs (field-programmable gate arrays) instead of the much more expensive and highly unwieldy full-custom chips. That way, university students could easily take on the challenge. At Microsoft Research Asia we are seeding university efforts in China with the goal of solving some of the basic problems. </span></span>
<span id="cb18-1106"><a href="#cb18-1106" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1107"><a href="#cb18-1107" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hsuCrackingGo2007</span><span class="co">]</span></span>
<span id="cb18-1108"><a href="#cb18-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1109"><a href="#cb18-1109" aria-hidden="true" tabindex="-1"></a>In 2016, AlphaGo defeated the 9-dan player Lee Sedol at 4 wins and 1 loss,<span class="ot">[^alphago-move-37]</span> and it "<span class="sc">\[</span>evaluated<span class="sc">\]</span> thousands of times fewer positions than Deep Blue". <span class="co">[</span><span class="ot">@silverMasteringGameGo2016</span><span class="co">]</span> The subsequent AlphaZero reached superhuman performance with just $10^4$ evaluated positions per move. <span class="co">[</span><span class="ot">@silverGeneralReinforcementLearning2018</span><span class="co">]</span></span>
<span id="cb18-1110"><a href="#cb18-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1111"><a href="#cb18-1111" aria-hidden="true" tabindex="-1"></a><span class="ot">[^alphago-move-37]</span>:</span>
<span id="cb18-1112"><a href="#cb18-1112" aria-hidden="true" tabindex="-1"></a>    In game 2, AlphaGo played black. Media made much out of the 19th move of AlphaGo ("Move 37"), which the supervised learning policy network (which was supervise-trained to predict what a human would play, as according to a large dataset of human games) predicted a probability of $10^{-4}$. This was given much media attention. Something similar happened with Deep Blue vs Kasparov, game 2, when Deep Blue (White) played 36.axb5, with immediate effect:</span>
<span id="cb18-1113"><a href="#cb18-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1114"><a href="#cb18-1114" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; so fluid was its play that the grandmasters in attendance all understood Benjamin's contention that Blue "played real chess" that day. What really shook Garry Kasparov, though, was a move that the computer didn't make. On Move 36, Blue had an opportunity to shift its queen to a devastating position -- clearly the smart choice. Instead it took a subtler but superior tack that wound up to be near decisive in defeating Kasparov. After the champ resigned, he rushed back to his Plaza suite, cranked up his own computers and tried in vain to understand how a hunk of sand and metal could have understood chess so deeply. Apparently this puzzlement crossed into the realm of suspicion: the Kasparov camp was soon demanding to see Deep Blue's printouts. "It was a masterpiece by computer", said Kasparov second Michael Khodarkovsky. "We would like to understand why it was possible." (Eventually, a neutral arbiter examined the printout.) Later Kasparov blurted out his real complaint. "Suddenly \[Deep Blue\] played like a god for one moment," he said.</span></span>
<span id="cb18-1115"><a href="#cb18-1115" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-1116"><a href="#cb18-1116" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@levyBigBluesHand1997]</span></span>
<span id="cb18-1117"><a href="#cb18-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1118"><a href="#cb18-1118" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expert systems</span></span>
<span id="cb18-1119"><a href="#cb18-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1120"><a href="#cb18-1120" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The miracle product is knowledge, and the Japanese are planning to package and sell it the way other nations package and sell energy, food, or manufactured goods... The essence of the computer revolution is that the burden of producing the future knowledge of the world will be transferred from human heads to machine artifacts.</span>  </span>
<span id="cb18-1121"><a href="#cb18-1121" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1122"><a href="#cb18-1122" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, Chapter 4</span><span class="co">]</span></span>
<span id="cb18-1123"><a href="#cb18-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1124"><a href="#cb18-1124" aria-hidden="true" tabindex="-1"></a><span class="fu">### DENDRAL</span></span>
<span id="cb18-1125"><a href="#cb18-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1126"><a href="#cb18-1126" aria-hidden="true" tabindex="-1"></a>Spectrometry means taking an unknown chemical, then do some physics experiment on it to obtain a line-graph, then discover what that chemical is based on that line-graph. A mathematician would write something like this:</span>
<span id="cb18-1127"><a href="#cb18-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1128"><a href="#cb18-1128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1129"><a href="#cb18-1129" aria-hidden="true" tabindex="-1"></a>(\text{chemical}) \xrightarrow{\text{spectrometry}} (\R \to \R) \xrightarrow{\text{chemist}} (\text{chemical})</span>
<span id="cb18-1130"><a href="#cb18-1130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1131"><a href="#cb18-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1132"><a href="#cb18-1132" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Mass spectrometry</span><span class="co">](https://en.wikipedia.org/wiki/Mass_spectrometry)</span>, for example, breaks a chemical into fragments, and measures the mass-to-charge ratios of the fragments, in units of $\frac{\text{atomic mass unit}}{\text{electron charge}}$. Many fragments carry just +1 electron charge, so the mass-to-charge ratio can be interpreted as roughly the atomic mass of the fragment. A peak at $x$, for example, means when the chemical breaks, it often results in some fragments with mass $x$. Trained chemists would be able to study a mass spectrometry plot and figure out what it means. </span>
<span id="cb18-1133"><a href="#cb18-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1134"><a href="#cb18-1134" aria-hidden="true" tabindex="-1"></a>Given a chemical species, by standard <span class="co">[</span><span class="ot">stiochiometry</span><span class="co">](https://en.wikipedia.org/wiki/Stoichiometry)</span> one can measure the chemical formula of the species, but it remains to discover its chemical structure. This is what DENDRAL<span class="ot">[^dendral-name]</span> was designed to do: given the mass spectrometry, the chemical formula, and some additional information (a later version could incorporate the NMR spectrum), output possible molecular structures for the species.</span>
<span id="cb18-1135"><a href="#cb18-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1136"><a href="#cb18-1136" aria-hidden="true" tabindex="-1"></a><span class="ot">[^dendral-name]: </span>The full name is "heuristic dendritic algorithm". It is "dendritic" because it originally only could process chemical structures with no cycles.</span>
<span id="cb18-1137"><a href="#cb18-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1138"><a href="#cb18-1138" aria-hidden="true" tabindex="-1"></a>Like the IPS of Simon and Newell, DENDRAL started as a heuristic search program. Its problem space is enumerated by a structure generator, which, given a chemical formula, generates all chemically stable structures according to some chemical rules. For example, <span class="co">[</span><span class="ot">geminal diols</span><span class="co">](https://en.wikipedia.org/wiki/Geminal_diol)</span> are unstable, so those are not enumerated. Each generated structure is then broken into fragments, again according to some heuristic rules. For example, in a ketone (R-(C=O)-R'), it is very unlikely for the C=O double bond to be broken, while it is quite easy for the R-(C=O) and the (C=O)-R' bonds to be broken.</span>
<span id="cb18-1139"><a href="#cb18-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1140"><a href="#cb18-1140" aria-hidden="true" tabindex="-1"></a>If that is all there is, then we have something not much better than exhaustive search, and would not scale. The breakthrough of DENDRAL was that the DENDRAL team had a professional chemist, who entered a large number of heuristic rules for interpreting mass spectrometry lines. These greatly decrease the number of solutions to verify.</span>
<span id="cb18-1141"><a href="#cb18-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1142"><a href="#cb18-1142" aria-hidden="true" tabindex="-1"></a>Consider an illustrative example from <span class="co">[</span><span class="ot">@feigenbaumGeneralityProblemSolving1970, table 1</span><span class="co">]</span>. Let $m$ be the mass of the whole molecule. Then there is a <span class="co">[</span><span class="ot">ketone carbonyl group</span><span class="co">](https://en.wikipedia.org/wiki/Ketone)</span> (R-(C=O)-R', mass 28) if there are 2 peaks at mass $x_1, x_2$ such that</span>
<span id="cb18-1143"><a href="#cb18-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1144"><a href="#cb18-1144" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$x_1+x_2 = m+28$,</span>
<span id="cb18-1145"><a href="#cb18-1145" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$x_1 - 28$ is a high peak,</span>
<span id="cb18-1146"><a href="#cb18-1146" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$x_2 - 28$ is a high peak,</span>
<span id="cb18-1147"><a href="#cb18-1147" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>At least one of $x_1$ or $x_2$ is high.</span>
<span id="cb18-1148"><a href="#cb18-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1149"><a href="#cb18-1149" aria-hidden="true" tabindex="-1"></a>A molecule R-(C=O)-R' containing a ketone group often breaks at the bond next to the carbonyl group. This results in 4 possible fragments: R-(C=O)-, -(C=O)-R', R-, -R'. Since the -(C=O)- fragment has mass 28, the first 3 rules would be satisfied. The 4th rule ensures the fragments are statistically significant, not noise. (What counts as "high" is a parameter that the expert sets.)</span>
<span id="cb18-1150"><a href="#cb18-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1151"><a href="#cb18-1151" aria-hidden="true" tabindex="-1"></a>The full architecture is as follows:</span>
<span id="cb18-1152"><a href="#cb18-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1153"><a href="#cb18-1153" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-1154"><a href="#cb18-1154" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plan(chemical_formula, spectrometric_data):</span>
<span id="cb18-1155"><a href="#cb18-1155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use the rules and data to list plausible and implausible structural elements</span></span>
<span id="cb18-1156"><a href="#cb18-1156" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e.g., if the ketone carbonyl group is plausible, then put it into good_list</span></span>
<span id="cb18-1157"><a href="#cb18-1157" aria-hidden="true" tabindex="-1"></a>    <span class="co"># else, put it into the bad_list</span></span>
<span id="cb18-1158"><a href="#cb18-1158" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> good_list, bad_list</span>
<span id="cb18-1159"><a href="#cb18-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1160"><a href="#cb18-1160" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate(chemical_formula, good_list, bad_list):</span>
<span id="cb18-1161"><a href="#cb18-1161" aria-hidden="true" tabindex="-1"></a>    <span class="co"># enumerate all plausible structures </span></span>
<span id="cb18-1162"><a href="#cb18-1162" aria-hidden="true" tabindex="-1"></a>    <span class="co"># containing groups from the good_list, but not the bad_list</span></span>
<span id="cb18-1163"><a href="#cb18-1163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> plausible_structures</span>
<span id="cb18-1164"><a href="#cb18-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1165"><a href="#cb18-1165" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test(plausible_structures, spectrometric_data):</span>
<span id="cb18-1166"><a href="#cb18-1166" aria-hidden="true" tabindex="-1"></a>    structures <span class="op">=</span> []</span>
<span id="cb18-1167"><a href="#cb18-1167" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> structure <span class="kw">in</span> plausible_structures:</span>
<span id="cb18-1168"><a href="#cb18-1168" aria-hidden="true" tabindex="-1"></a>        simulated_data <span class="op">=</span> simulate_spectrometry(chemical_formula)</span>
<span id="cb18-1169"><a href="#cb18-1169" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> distance(simulated_data, spectrometric_data)</span>
<span id="cb18-1170"><a href="#cb18-1170" aria-hidden="true" tabindex="-1"></a>        structures.append((score, structure))</span>
<span id="cb18-1171"><a href="#cb18-1171" aria-hidden="true" tabindex="-1"></a>    structures.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">0</span>])</span>
<span id="cb18-1172"><a href="#cb18-1172" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> structures</span>
<span id="cb18-1173"><a href="#cb18-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1174"><a href="#cb18-1174" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(chemical_formula, spectrometric_data):</span>
<span id="cb18-1175"><a href="#cb18-1175" aria-hidden="true" tabindex="-1"></a>    good_list, bad_list <span class="op">=</span> plan(chemical_formula, spectrometric_data)</span>
<span id="cb18-1176"><a href="#cb18-1176" aria-hidden="true" tabindex="-1"></a>    plausible_structures <span class="op">=</span> generate(chemical_formula, good_list, bad_list)</span>
<span id="cb18-1177"><a href="#cb18-1177" aria-hidden="true" tabindex="-1"></a>    structures <span class="op">=</span> test(plausible_structures, spectrometric_data)</span>
<span id="cb18-1178"><a href="#cb18-1178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> structures</span>
<span id="cb18-1179"><a href="#cb18-1179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1180"><a href="#cb18-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1181"><a href="#cb18-1181" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@duffieldApplicationsArtificialIntelligence1969, figure 1</span><span class="co">]</span>](figure/DENDRAL_flowchart.png)</span>
<span id="cb18-1182"><a href="#cb18-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1183"><a href="#cb18-1183" aria-hidden="true" tabindex="-1"></a>During the period of 1965 to 1969, DENDRAL's performance increased steadily as more chemical knowledge was entered. In the discussion section, they summarized their lessons learned as a tradeoff. Whereas previous logical AI systems like GPS focused on generic heuristic search over solution spaces, they concluded that generality of the solver has a price being paid in speed and power of finding actual solutions. </span>
<span id="cb18-1184"><a href="#cb18-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1185"><a href="#cb18-1185" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In recognition of these difficulties, a vienpoint at the other extreme has ewerged, informally called "the big switch hypothesis"... generality in problem solving is achieved by arraying specialists at the terminals of a big switch. The big switch is moved from specialist toi specialist as the problem solver switches its attention from one problem area to another... The general methods do solve DENDRAL problems, sometimes well as with some amino acid spectra, but they ara relatively weak and inefficient.</span></span>
<span id="cb18-1186"><a href="#cb18-1186" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1187"><a href="#cb18-1187" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... This is remarkable. The planner, which is the specialist at "understanding" the data and inferrirg conditions on tho solution, is so powerful that the need for the general problem solving processes of the system is obviated. Another way to view this is that all the relevant theoretical knowledge to solve these </span><span class="co">[</span><span class="ot">amine</span><span class="co">](https://en.wikipedia.org/wiki/Amine)</span><span class="at"> problems has been mapped over from its general form in the predictor ("first principles") to efficient special forms in the planner ("cookbook recipes").</span></span>
<span id="cb18-1188"><a href="#cb18-1188" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1189"><a href="#cb18-1189" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumGeneralityProblemSolving1970</span><span class="co">]</span></span>
<span id="cb18-1190"><a href="#cb18-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1191"><a href="#cb18-1191" aria-hidden="true" tabindex="-1"></a>In another paper <span class="co">[</span><span class="ot">@buchananRediscoveringProblemsArtificial1970</span><span class="co">]</span>, the authors expressed their surprise that they could split the program into two parts, which would become the "inference engine" and the "knowledge base". It was as if they have discovered that, instead of manually writing in a lot of if-then statements, they could write a single <span class="in">`eval`</span> function, and then just write a lot of entries in a giant database of rules in a uniform format, and run the <span class="in">`eval`</span> function over the rules. It reminds me of von Neumann discovering the code is data, data is code idea, and thus avoid the trouble of having to physically rewire ENIAC every time the program changes.</span>
<span id="cb18-1192"><a href="#cb18-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1193"><a href="#cb18-1193" aria-hidden="true" tabindex="-1"></a>It was reported to have been used in "terpenoid natural products from plant and marine animal sources, marine sterols, organic acids in human urine and other body fluids..." and was found to reach expert performance. What it lacked in knowledge it made up in thoroughness, and so it outperformed the experts when the sample is a mixture of several chemicals. <span class="co">[</span><span class="ot">@buchananDendralMetaDendral1981</span><span class="co">]</span></span>
<span id="cb18-1194"><a href="#cb18-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1195"><a href="#cb18-1195" aria-hidden="true" tabindex="-1"></a><span class="fu">### Meta-DENDRAL</span></span>
<span id="cb18-1196"><a href="#cb18-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1197"><a href="#cb18-1197" aria-hidden="true" tabindex="-1"></a>The Meta-DENDRAL was an early example of a logical AI system that could learn from data. It was developed near the end of DENDRAL, when the number of rules became hard to manage. The team decided to see if they could design an expert system that is an expert at *learning* organic chemical mass spectrometric data -- not *generic* learning from *generic* data. Their hypothesis was "knowledge acquisition is itself a knowledge-based task". <span class="co">[</span><span class="ot">@buchananDENDRALMetaDENDRALTheir1981</span><span class="co">]</span></span>
<span id="cb18-1198"><a href="#cb18-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1199"><a href="#cb18-1199" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`INTSUM`</span> ("interpretation and summary") takes a list. Each list item is a molecular structure and its mass spectrum. It computes an explanation for the spetrum by molecular bond clevages and atomic transfers. It returns the cleavages, atomic transfers, and spectrum peaks as supporting evidence for each cleavage and transfer.</span>
<span id="cb18-1200"><a href="#cb18-1200" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`RULEGEN`</span> ("rule generation") takes the output from <span class="in">`INTSUM`</span> and infer cleavage rules from it. For example, <span class="in">`X*X`</span> means "any bond can be cleaved", <span class="in">`-CO*NH-`</span> means that "any peptide bond can be cleaved", etc. It always starts with the most generic rule <span class="in">`X*X`</span>, and then tree-searches for more and more specific rules by adding (never removing) more atoms or features to the rule, until reaching a rule whose child rules all perform less well than it.</span>
<span id="cb18-1201"><a href="#cb18-1201" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>Each atom, like the <span class="in">`X`</span> in <span class="in">`X*C`</span>, could be annotated with some or all features from a list of 4: atom type (<span class="in">`type`</span>, could be carbon, oxygen...), the number of other carbons connected to (<span class="in">`nbrs`</span>), numbers of hydrogens connected to (<span class="in">`nhs`</span>), or number of multiple bonds (<span class="in">`dots`</span>).</span>
<span id="cb18-1202"><a href="#cb18-1202" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>For example, <span class="in">`-CO*NH-`</span> is similar (though not exactly the same) as <span class="in">`-X[type=C, dots=1]*X[type=N, nbrs=2, nhs=1, dots=0]-`</span>.</span>
<span id="cb18-1203"><a href="#cb18-1203" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>How well a rule performs is measured by the number of positive examples (a predicted peak that is really there), negative examples (a predicted peak that is not there), and rule specificity (the more atoms or features, the better).</span>
<span id="cb18-1204"><a href="#cb18-1204" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`RULEMOD`</span> ("rule modification") takes the rules output from <span class="in">`RULEGEN`</span>, scores them according to how many positive and negative examples it has, merges near-duplicate rules by Robinson unification, and generalize them (with a penalty score if the generalized rule has more negative examples).</span>
<span id="cb18-1205"><a href="#cb18-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1206"><a href="#cb18-1206" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Architecture of Meta-DENDRAL. [@buchananDENDRALMetaDENDRALTheir1981]</span><span class="co">](figure/meta-DENDRAL.png)</span></span>
<span id="cb18-1207"><a href="#cb18-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1208"><a href="#cb18-1208" aria-hidden="true" tabindex="-1"></a>In a 1978 report, they first verified that Meta-DENDRAL reproduced 8 well-known rules for <span class="co">[</span><span class="ot">aliphatic amines</span><span class="co">](https://en.wikipedia.org/wiki/Aliphatic_amine)</span> and <span class="co">[</span><span class="ot">estrogens</span><span class="co">](https://en.wikipedia.org/wiki/Estrogen)</span>, such as the famous <span class="co">[</span><span class="ot">α-cleavage</span><span class="co">](https://en.wikipedia.org/wiki/Alpha_cleavage)</span>. Some new rules discovered by Meta-DENDRAL for classifying keto<span class="co">[</span><span class="ot">androstanes</span><span class="co">](https://en.wikipedia.org/wiki/Androstane)</span>. An androstane has 11 ways for attaching a keto group, 55 ways to attach 2 ketos, etc, and though there was a mass of mass spectrometric data for them, there were few cleavage rules due to the complexity of the molecules.</span>
<span id="cb18-1209"><a href="#cb18-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1210"><a href="#cb18-1210" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; On the three classes of ketoandrostanes for which no general class rules have been reported, the mono-, di-, and triketoandrostanes, the program found general rules describing the mass spectrometric behavior of those classes... The program has discovered consistent fragmentation behavior in sets of molecules which have not appeared by manual examination to behave homogeneously in the mass spectrometer... it comes close to capturing in a computer program all we could discern by observing human problem-solving behavior. It is intended to relieve chemists of the need to exercise their personal heuristics over and over again, and thus we believe it can aid chemists in suggesting more novel extensions to existing theory.</span></span>
<span id="cb18-1211"><a href="#cb18-1211" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1212"><a href="#cb18-1212" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@buchananDENDRALMetaDENDRALTheir1981</span><span class="co">]</span></span>
<span id="cb18-1213"><a href="#cb18-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1214"><a href="#cb18-1214" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Cleavage and transfer rules for diketoandrostanes discovered by Meta-DENDRAL. [@buchananDENDRALMetaDENDRALTheir1981, table 4]</span><span class="co">](figure/meta-DENDRAL_diketoandrostane.png)</span></span>
<span id="cb18-1215"><a href="#cb18-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1216"><a href="#cb18-1216" aria-hidden="true" tabindex="-1"></a>They concluded that it was already possible to create AI assistants to perform tedious tasks for organic chemists.</span>
<span id="cb18-1217"><a href="#cb18-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1218"><a href="#cb18-1218" aria-hidden="true" tabindex="-1"></a><span class="fu">### MYCIN</span></span>
<span id="cb18-1219"><a href="#cb18-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1220"><a href="#cb18-1220" aria-hidden="true" tabindex="-1"></a>After the success of DENDRAL, another team developed MYCIN, an expert system for diagnosing bacterial infections like a doctor. Compared to DENDRAL, MYCIN's main breakthrough was in allowing reasoning with uncertainty. Instead of using probability, it uses "Certainty Factors" (CF), which ranges from $<span class="co">[</span><span class="ot">-1, +1</span><span class="co">]</span>$, with $-1$ meaning "certainly false", $+1$ "certainly true", and $0$ "complete uncertainty". Given two statements $p, q$ with CF $x, y$, the CF for $p \;\mathrm{AND} q$ is combined according to</span>
<span id="cb18-1221"><a href="#cb18-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1222"><a href="#cb18-1222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1223"><a href="#cb18-1223" aria-hidden="true" tabindex="-1"></a>CF(x, y)=\begin{cases} X+Y -XY   &amp; \text{if } X,Y&gt;0 <span class="sc">\\</span> </span>
<span id="cb18-1224"><a href="#cb18-1224" aria-hidden="true" tabindex="-1"></a> X+Y+XY &amp; \text{if } X,Y&lt;0 <span class="sc">\\</span></span>
<span id="cb18-1225"><a href="#cb18-1225" aria-hidden="true" tabindex="-1"></a> \frac{X+Y}{1-\min(|X|,|Y|)} &amp; \text{otherwise} </span>
<span id="cb18-1226"><a href="#cb18-1226" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb18-1227"><a href="#cb18-1227" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1228"><a href="#cb18-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1229"><a href="#cb18-1229" aria-hidden="true" tabindex="-1"></a>This combination has these desirable properties:</span>
<span id="cb18-1230"><a href="#cb18-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1231"><a href="#cb18-1231" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining unknown with anything leaves it unchanged.</span>
<span id="cb18-1232"><a href="#cb18-1232" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining true with anything (except false) gives true. Similarly for false.</span>
<span id="cb18-1233"><a href="#cb18-1233" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining true and false is a division-by-zero error.</span>
<span id="cb18-1234"><a href="#cb18-1234" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining +x and -x gives unknown.</span>
<span id="cb18-1235"><a href="#cb18-1235" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining two positives (except true) gives a larger positive. Similarly for negatives.</span>
<span id="cb18-1236"><a href="#cb18-1236" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Combining a positive and a negative gives something in between.</span>
<span id="cb18-1237"><a href="#cb18-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1238"><a href="#cb18-1238" aria-hidden="true" tabindex="-1"></a>At this point, we strongly recommend that you try out MYCIN for yourself. Unfortunately, unlike the famous ELIZA, it is quite hard to get a working copy of DENDRAL or MYCIN. However, you can experience the fun of MYCIN by asking a modern LLM to roleplay as one. If you still want to do it the old-school way, follow the <span class="co">[</span><span class="ot">tutorial here</span><span class="co">](code/run_mycin.md)</span>.</span>
<span id="cb18-1239"><a href="#cb18-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1240"><a href="#cb18-1240" aria-hidden="true" tabindex="-1"></a>Done? Good. MYCIN is very cleanly implemented in Common Lisp for Chapter 16 of *Paradigms of artificial intelligence programming*, which is available on <span class="co">[</span><span class="ot">GitHub</span><span class="co">](https://github.com/norvig/paip-lisp/tree/main)</span>. Like all expert systems, it has a logical inference engine (shell) and a knowledge base. The shell performs logical inference under uncertainty according to the rules of certainty factors, while the knowledge base consists of statemets of this kind:</span>
<span id="cb18-1241"><a href="#cb18-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1242"><a href="#cb18-1242" aria-hidden="true" tabindex="-1"></a><span class="in">```lisp</span></span>
<span id="cb18-1243"><a href="#cb18-1243" aria-hidden="true" tabindex="-1"></a><span class="in">;;;; File mycin-r.lisp: Sample parameter list and rulebase for mycin.</span></span>
<span id="cb18-1244"><a href="#cb18-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1245"><a href="#cb18-1245" aria-hidden="true" tabindex="-1"></a><span class="in">(requires "mycin")</span></span>
<span id="cb18-1246"><a href="#cb18-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1247"><a href="#cb18-1247" aria-hidden="true" tabindex="-1"></a><span class="in">;;; Parameters for patient:</span></span>
<span id="cb18-1248"><a href="#cb18-1248" aria-hidden="true" tabindex="-1"></a><span class="in">(defparm name patient t "Patient's name: " t read-line)</span></span>
<span id="cb18-1249"><a href="#cb18-1249" aria-hidden="true" tabindex="-1"></a><span class="in">(defparm sex patient (member male female) "Sex:" t)</span></span>
<span id="cb18-1250"><a href="#cb18-1250" aria-hidden="true" tabindex="-1"></a><span class="in">(defparm age patient number "Age:" t)</span></span>
<span id="cb18-1251"><a href="#cb18-1251" aria-hidden="true" tabindex="-1"></a><span class="in">(defparm burn patient (member no mild serious)</span></span>
<span id="cb18-1252"><a href="#cb18-1252" aria-hidden="true" tabindex="-1"></a><span class="in">  "Is ~a a burn patient?  If so, mild or serious?" t)</span></span>
<span id="cb18-1253"><a href="#cb18-1253" aria-hidden="true" tabindex="-1"></a><span class="in">(defparm compromised-host patient yes/no</span></span>
<span id="cb18-1254"><a href="#cb18-1254" aria-hidden="true" tabindex="-1"></a><span class="in">  "Is ~a a compromised host?")</span></span>
<span id="cb18-1255"><a href="#cb18-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1256"><a href="#cb18-1256" aria-hidden="true" tabindex="-1"></a><span class="in">;;;; ...</span></span>
<span id="cb18-1257"><a href="#cb18-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1258"><a href="#cb18-1258" aria-hidden="true" tabindex="-1"></a><span class="in">(defrule 165</span></span>
<span id="cb18-1259"><a href="#cb18-1259" aria-hidden="true" tabindex="-1"></a><span class="in">  if (gram organism is pos)</span></span>
<span id="cb18-1260"><a href="#cb18-1260" aria-hidden="true" tabindex="-1"></a><span class="in">     (morphology organism is coccus)</span></span>
<span id="cb18-1261"><a href="#cb18-1261" aria-hidden="true" tabindex="-1"></a><span class="in">     (growth-conformation organism is chains)</span></span>
<span id="cb18-1262"><a href="#cb18-1262" aria-hidden="true" tabindex="-1"></a><span class="in">  then .7</span></span>
<span id="cb18-1263"><a href="#cb18-1263" aria-hidden="true" tabindex="-1"></a><span class="in">     (identity organism is streptococcus))</span></span>
<span id="cb18-1264"><a href="#cb18-1264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1265"><a href="#cb18-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1266"><a href="#cb18-1266" aria-hidden="true" tabindex="-1"></a>The full MYCIN system reached impressive results:</span>
<span id="cb18-1267"><a href="#cb18-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1268"><a href="#cb18-1268" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 70% of MYCIN’s therapies were rated as acceptable by a majority of the evaluators.... 75% is in fact better than the degree of agreement that could generally be achieved by Stanford faculty being assessed under the same criteria.</span></span>
<span id="cb18-1269"><a href="#cb18-1269" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1270"><a href="#cb18-1270" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@buchananRuleBasedExpert1984, chapter 30</span><span class="co">]</span></span>
<span id="cb18-1271"><a href="#cb18-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1272"><a href="#cb18-1272" aria-hidden="true" tabindex="-1"></a>Impressive enough to catch the eye of people outside of AI community. Here seemed like a system that might actually be commercialized and do the work of doctors. And not just doctors -- what else might it do?</span>
<span id="cb18-1273"><a href="#cb18-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1274"><a href="#cb18-1274" aria-hidden="true" tabindex="-1"></a>To explore this, EMYCIN ("empty MYCIN" or "extensible MYCIN") was created, which was essentially MYCIN with its knowledge base removed, and some functions added so that one can enter new rules interactively. The experience of an EMYCIN session is that of being interviewed by some programmer who is trying to write down a precise program of how you do your job.</span>
<span id="cb18-1275"><a href="#cb18-1275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1276"><a href="#cb18-1276" aria-hidden="true" tabindex="-1"></a>It is more fun, again, to try EMYCIN for yourself by creating a new knowledge base for whatever interests you, and it is easy to get an LLM to roleplay as an EMYCIN. If you prefer reading, then the following example comes from <span class="co">[</span><span class="ot">@buchananRuleBasedExpert1984, page 325</span><span class="co">]</span> (<span class="in">`&gt;`</span> in front of user input), showing a user creating a new rule for diagnosing hemophilia:</span>
<span id="cb18-1277"><a href="#cb18-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1278"><a href="#cb18-1278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1279"><a href="#cb18-1279" aria-hidden="true" tabindex="-1"></a><span class="in">Enter Parms, Rules, Save changes, or Go?</span></span>
<span id="cb18-1280"><a href="#cb18-1280" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; Rules</span></span>
<span id="cb18-1281"><a href="#cb18-1281" aria-hidden="true" tabindex="-1"></a><span class="in">Rule number of NEW: </span></span>
<span id="cb18-1282"><a href="#cb18-1282" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; NEW</span></span>
<span id="cb18-1283"><a href="#cb18-1283" aria-hidden="true" tabindex="-1"></a><span class="in">RULE025</span></span>
<span id="cb18-1284"><a href="#cb18-1284" aria-hidden="true" tabindex="-1"></a><span class="in">PREMISE: </span></span>
<span id="cb18-1285"><a href="#cb18-1285" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; (REASON = BLEEDING, SIGBLD, FINALDEF = COAGULATION,</span></span>
<span id="cb18-1286"><a href="#cb18-1286" aria-hidden="true" tabindex="-1"></a><span class="in">&gt;  DEFPATH = INTRINSIC ~ INTERFERENCE)</span></span>
<span id="cb18-1287"><a href="#cb18-1287" aria-hidden="true" tabindex="-1"></a><span class="in">RULE025</span></span>
<span id="cb18-1288"><a href="#cb18-1288" aria-hidden="true" tabindex="-1"></a><span class="in">ACTION: </span></span>
<span id="cb18-1289"><a href="#cb18-1289" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; (DX = DXHEMOPHILIA)</span></span>
<span id="cb18-1290"><a href="#cb18-1290" aria-hidden="true" tabindex="-1"></a><span class="in">BLEEDING → BLEEDING-HISTORY? </span></span>
<span id="cb18-1291"><a href="#cb18-1291" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; Yes</span></span>
<span id="cb18-1292"><a href="#cb18-1292" aria-hidden="true" tabindex="-1"></a><span class="in">COAGULATION → COAGULATION-DEFECT?</span></span>
<span id="cb18-1293"><a href="#cb18-1293" aria-hidden="true" tabindex="-1"></a><span class="in">&gt; Yes</span></span>
<span id="cb18-1294"><a href="#cb18-1294" aria-hidden="true" tabindex="-1"></a><span class="in">Translate, No further changes, or prop name:</span></span>
<span id="cb18-1295"><a href="#cb18-1295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1296"><a href="#cb18-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1297"><a href="#cb18-1297" aria-hidden="true" tabindex="-1"></a>After this rule is entered, it can be displayed as follows:</span>
<span id="cb18-1298"><a href="#cb18-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1299"><a href="#cb18-1299" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1300"><a href="#cb18-1300" aria-hidden="true" tabindex="-1"></a><span class="in">RULE025</span></span>
<span id="cb18-1301"><a href="#cb18-1301" aria-hidden="true" tabindex="-1"></a><span class="in">IF: 1) Bleeding-history is one of the reasons for this consultation,</span></span>
<span id="cb18-1302"><a href="#cb18-1302" aria-hidden="true" tabindex="-1"></a><span class="in">    2) There is an episode of significant bleeding in the patient,</span></span>
<span id="cb18-1303"><a href="#cb18-1303" aria-hidden="true" tabindex="-1"></a><span class="in">    3) Coagulation-defect is one of the bleeding disorders in the patient,</span></span>
<span id="cb18-1304"><a href="#cb18-1304" aria-hidden="true" tabindex="-1"></a><span class="in">    4) The defective coagulation pathway of the patient is intrinsic, and</span></span>
<span id="cb18-1305"><a href="#cb18-1305" aria-hidden="true" tabindex="-1"></a><span class="in">    5) There are not factors which interfere with the patient's normal bleeding</span></span>
<span id="cb18-1306"><a href="#cb18-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1307"><a href="#cb18-1307" aria-hidden="true" tabindex="-1"></a><span class="in">THEN: It is definite (1.0) that the following is one of the bleeding diagnoses of </span></span>
<span id="cb18-1308"><a href="#cb18-1308" aria-hidden="true" tabindex="-1"></a><span class="in">      the patient: The patient has one or more of the following conditions: Hemophilia A,</span></span>
<span id="cb18-1309"><a href="#cb18-1309" aria-hidden="true" tabindex="-1"></a><span class="in">      von Willebrand's syndrome, an IX, XI, or XII deficiency, or a high molecular weight</span></span>
<span id="cb18-1310"><a href="#cb18-1310" aria-hidden="true" tabindex="-1"></a><span class="in">      Kallikrein defect.</span></span>
<span id="cb18-1311"><a href="#cb18-1311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1312"><a href="#cb18-1312" aria-hidden="true" tabindex="-1"></a><span class="in">PREMISE: (AND (SAME CNTXT REASON BLEEDING-HISTORY)</span></span>
<span id="cb18-1313"><a href="#cb18-1313" aria-hidden="true" tabindex="-1"></a><span class="in">              (SAME CNTXT SIGBLD)</span></span>
<span id="cb18-1314"><a href="#cb18-1314" aria-hidden="true" tabindex="-1"></a><span class="in">              (SAME CNTXT FINALDEF COAGULATION-DEFECT)</span></span>
<span id="cb18-1315"><a href="#cb18-1315" aria-hidden="true" tabindex="-1"></a><span class="in">              (SAME CNTXT DEFPATH INTRINSIC)</span></span>
<span id="cb18-1316"><a href="#cb18-1316" aria-hidden="true" tabindex="-1"></a><span class="in">              (NOTSAME CNTXT INTERFERENCE))</span></span>
<span id="cb18-1317"><a href="#cb18-1317" aria-hidden="true" tabindex="-1"></a><span class="in">ACTION: (CONCLUDETEXT CNTXT DX (TEXT DXHEMOPHILIA) TALLY 1000)</span></span>
<span id="cb18-1318"><a href="#cb18-1318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1319"><a href="#cb18-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1320"><a href="#cb18-1320" aria-hidden="true" tabindex="-1"></a>The "MYCIN gang" summarized their lessons learned in <span class="co">[</span><span class="ot">@buchananRuleBasedExpert1984</span><span class="co">]</span>. With certainty factors, shell, and knowledge base, the main pieces of the expert system boom have fallen into place.</span>
<span id="cb18-1321"><a href="#cb18-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1322"><a href="#cb18-1322" aria-hidden="true" tabindex="-1"></a><span class="fu">### What is knowledge?</span></span>
<span id="cb18-1323"><a href="#cb18-1323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1324"><a href="#cb18-1324" aria-hidden="true" tabindex="-1"></a>Knowledge, in the context of expert systems, is basically object-oriented programming + relational database + first-order logic.</span>
<span id="cb18-1325"><a href="#cb18-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1326"><a href="#cb18-1326" aria-hidden="true" tabindex="-1"></a>There, now I've said it. It explains why expert systems is so boring. The useful parts of it ended up being Java + SQL. </span>
<span id="cb18-1327"><a href="#cb18-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1328"><a href="#cb18-1328" aria-hidden="true" tabindex="-1"></a>To see this, consider a few examples of what is "knowledge" in expert systems.</span>
<span id="cb18-1329"><a href="#cb18-1329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1330"><a href="#cb18-1330" aria-hidden="true" tabindex="-1"></a>First-order predicate logic: it looks like</span>
<span id="cb18-1331"><a href="#cb18-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1332"><a href="#cb18-1332" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1333"><a href="#cb18-1333" aria-hidden="true" tabindex="-1"></a>\frac{\forall x, IsHuman(x)\to IsMortal(x) \quad IsHuman(Socrates)}{IsMortal(Socrates)}</span>
<span id="cb18-1334"><a href="#cb18-1334" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1335"><a href="#cb18-1335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1336"><a href="#cb18-1336" aria-hidden="true" tabindex="-1"></a>Robinson unification is an operation in first-order logic, where we have two formulas with variables in them, and unification finds a way to substitute the variables, so that the two formulas become equal. For example:</span>
<span id="cb18-1337"><a href="#cb18-1337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1338"><a href="#cb18-1338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1339"><a href="#cb18-1339" aria-hidden="true" tabindex="-1"></a>\frac{\forall x, IsHuman(x)\to Hates(x, Java) \quad IsHuman(Socrates)}{Hates(Socrates, Java)}{(x \leftarrow Socrates)}</span>
<span id="cb18-1340"><a href="#cb18-1340" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-1341"><a href="#cb18-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1342"><a href="#cb18-1342" aria-hidden="true" tabindex="-1"></a>The frame: Looks exactly like data types in Java. </span>
<span id="cb18-1343"><a href="#cb18-1343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1344"><a href="#cb18-1344" aria-hidden="true" tabindex="-1"></a>A semantic graph: a network of frames. Looks exactly like a <span class="co">[</span><span class="ot">UMD diagrams</span><span class="co">](https://en.wikipedia.org/wiki/Unified_Modeling_Language)</span>.</span>
<span id="cb18-1345"><a href="#cb18-1345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1346"><a href="#cb18-1346" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A frame system. It looks exactly the same as those UMD diagram I hated back when I learned Java programming. [@russellArtificialIntelligenceModern1995, figure 10.7]</span><span class="co">](figure/frame_system.png)</span></span>
<span id="cb18-1347"><a href="#cb18-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1348"><a href="#cb18-1348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Knowledge Principle</span></span>
<span id="cb18-1349"><a href="#cb18-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1350"><a href="#cb18-1350" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Edward Feigenbaum:</span><span class="sc">\]</span><span class="at"> In 1968, I was writing a paper with Bruce </span><span class="sc">\[</span><span class="at">Buchanan</span><span class="sc">\]</span><span class="at"> and Josh Lederberg in which we chose to summarize the evidence from the many DENDRAL experiments from mid-1965 to mid-1968. It was evident that the improvement in DENDRAL's performance as a mass spectrum analyst was almost totally a function of the amount and quality of the knowledge that we had obtained from Djerassi's experts, and that it was only weakly related to any improvements that the AI scientists like me and Bruce had made to the reasoning processes used in DENDRAL's hypothesis formation. So in 1968, I called this observation the “Knowledge is Power Hypothesis.” One data point. Later, as the evidence accumulated from dozens of -- or hundreds of -- expert systems, I changed the word “hypothesis” to “principle.”</span></span>
<span id="cb18-1351"><a href="#cb18-1351" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1352"><a href="#cb18-1352" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">Bruce Buchanan:</span><span class="sc">\]</span><span class="at"> Art Samuel's work on the checker player: Art had interviewed experts to understand ... the feature vector and then he did a good deal of reading about checkers... That impressed me a great deal and I always wanted to be able to do that. </span><span class="sc">\[</span><span class="at">Meta-DENDRAL</span><span class="sc">\]</span><span class="at"> did learn the rules of mass spectrometry from empirical data. A footnote on that. The data were very sparse. It took about one graduate student one year to obtain and interpret one mass spectrum, so we couldn't ask for very much data. This was not a big data problem.</span></span>
<span id="cb18-1353"><a href="#cb18-1353" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1354"><a href="#cb18-1354" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; quoted in </span><span class="co">[</span><span class="ot">@brockLearningArtificialIntelligences2018</span><span class="co">]</span></span>
<span id="cb18-1355"><a href="#cb18-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1356"><a href="#cb18-1356" aria-hidden="true" tabindex="-1"></a>What was new about expert systems? The previous approach to logical AI focused on general algorithms (usually search) and problem representation, guided by a small amount of heuristics. On the general algorithms side, examples included <span class="co">[</span><span class="ot">A* search</span><span class="co">](https://en.wikipedia.org/wiki/A*_search_algorithm)</span> developed for Shakey the robot, <span class="co">[</span><span class="ot">dynamic time warping</span><span class="co">](https://en.wikipedia.org/wiki/Dynamic_time_warping)</span> developed for speech recognition, <span class="co">[</span><span class="ot">KMP algorithm</span><span class="co">](https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm)</span> for string matching, etc. </span>
<span id="cb18-1357"><a href="#cb18-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1358"><a href="#cb18-1358" aria-hidden="true" tabindex="-1"></a>While it is anachronistic, a good example of non-trivial data representation for effective search is the <span class="co">[</span><span class="ot">bitboard</span><span class="co">](https://www.chessprogramming.org/Bitboards)</span> used for computer chess. It represents the entire chess board with a bit array in a clever way, so that many operations, like finding which pieces are attacking a square, becomes bitwise operations, allowing fast game tree search.</span>
<span id="cb18-1359"><a href="#cb18-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1360"><a href="#cb18-1360" aria-hidden="true" tabindex="-1"></a>Expert systems inverts this focus. Heuristics (in the form of expert knowledge) is placed front and center, while algorithm and representation was almost beside the point -- they were all basically flavors of first-order predicate logic inference, and they distinguish themselves by how easy it is for the end user, and how fast it runs (often measured by "number of logical inferences per second").</span>
<span id="cb18-1361"><a href="#cb18-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1362"><a href="#cb18-1362" aria-hidden="true" tabindex="-1"></a>We can think of this as an early appearance of *dataset* in AI. From our scaling-hypothesis point of view, this was a step in the right direction, but it was yet incomplete, since the data was heavily distilled by human experts into rules. Many of the AI researchers recognized the problem, and worked on automatic rule-generation, but none succeeded in general.</span>
<span id="cb18-1363"><a href="#cb18-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1364"><a href="#cb18-1364" aria-hidden="true" tabindex="-1"></a>Philosophically, expert systems has more in common with inductive, scientific reasoning, while the previous logical AI with deductive, mathematical reasoning  <span class="co">[</span><span class="ot">@lindsayDENDRALCaseStudy1993</span><span class="co">]</span>. In a position paper coauthored by Feigenbaum and Douglas Lenat, we have a clear statement of the assumptions behind expert systems AI.</span>
<span id="cb18-1365"><a href="#cb18-1365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1366"><a href="#cb18-1366" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Knowledge is Power" or, more cynically "Intelligence is in the eye of the (uninformed) beholder."... The Knowledge Principle (KP): A system exhibits intelligent understanding and action at a high level of competence primarily because of the specific knowledge that it can bring to bear: the concepts, facts, representations, methods, models, metaphors, and heuristics about its domain of endeavor... Knowledge is often considered Compiled Search; despite that, the KP claims that only a small portion of the knowledge can be generalized so it applies across domains, without sacrificing most of its power.</span></span>
<span id="cb18-1367"><a href="#cb18-1367" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1368"><a href="#cb18-1368" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Explicit Knowledge Principle: Much of the knowledge in an intelligent system needs to be represented explicitly.</span></span>
<span id="cb18-1369"><a href="#cb18-1369" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1370"><a href="#cb18-1370" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The Competence Threshold: Difficult tasks succumb nonlinearly to knowledge. There is an ever greater "payoff" to adding each piece of knowledge, up to some level of competence (e.g., where an NP complete problem becomes Polynomial). Beyond that, additional knowledge is useful but not frequently needed (e.g., handling rare cases.). Crossing the Competence Threshold, one enters the realm of experts. There, the knowledge-search tradeoff is fairly evenly balanced.</span></span>
<span id="cb18-1371"><a href="#cb18-1371" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1372"><a href="#cb18-1372" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@lenatThresholdsKnowledge2000</span><span class="co">]</span></span>
<span id="cb18-1373"><a href="#cb18-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1374"><a href="#cb18-1374" aria-hidden="true" tabindex="-1"></a>From the hindsight of deep learning, the first hypothesis has been amply justified, the second refuted, and the third appears to be differ case-by-case.<span class="ot">[^competence-threshold]</span> Lenat, however, bet everything on the three assumptions, in a heroic 30-year-long journey to build <span class="co">[</span><span class="ot">Cyc, an expert system AGI</span><span class="co">](#sec-cyc)</span>.</span>
<span id="cb18-1375"><a href="#cb18-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1376"><a href="#cb18-1376" aria-hidden="true" tabindex="-1"></a><span class="ot">[^competence-threshold]: </span>In self-driving cars, it is the long tail of rare events that take the longest to learn, yet they were what is required to get the car to drive at expert level. Further, the improvement is smooth: there is no "threshold" at which the value of one additional rare event drops suddenly. Similarly, <span class="co">[</span><span class="ot">Gwern argued that "the last bits are the deepest"</span><span class="co">](https://gwern.net/scaling-hypothesis#:~:text=The%20last%20bits%20are%20deepest)</span>.</span>
<span id="cb18-1377"><a href="#cb18-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1378"><a href="#cb18-1378" aria-hidden="true" tabindex="-1"></a><span class="fu">### AI boom</span></span>
<span id="cb18-1379"><a href="#cb18-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1380"><a href="#cb18-1380" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A typical expert system architecture during the 1980s. [@harmonExpertSystemsBusiness2022, figure 2]</span><span class="co">](figure/expert_system_architecture.png)</span></span>
<span id="cb18-1381"><a href="#cb18-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1382"><a href="#cb18-1382" aria-hidden="true" tabindex="-1"></a>During the late 1970s, expert systems got noticed outside the small scholarly community, and as the 1980s went on, knowledge became money. The first wave of commercial AI arrived, and it lasted for about 10 years.</span>
<span id="cb18-1383"><a href="#cb18-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1384"><a href="#cb18-1384" aria-hidden="true" tabindex="-1"></a>Instead of describing in detail these systems, we can just admire tha sudden explosion of commercial expert systems:</span>
<span id="cb18-1385"><a href="#cb18-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1386"><a href="#cb18-1386" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; analysis of physical objects (like buildings or bridges), SACON; determining the structure of proteins from X-ray crystallographic data, in collaboration with experts at UC San Diego, CRYSALIS; interpreting data about a person's lung functioning coming from an instrument called a spirometer, in collaboration with a doctor at California Pacific Medical Center, PUFF; managing ventilator machines in intensive care units, another collaboration with a CPMC ICU lead physician, VM... Feigenbaum's lab was funded by IBM to help them develop their first expert system—final diagnosis of errors in disk drives before they were shipped to the customer... GEO, to analyze and form hypotheses about the geology of the bore hole as drilling proceeded down inch by inch... </span><span class="sc">\[</span><span class="at">DARPA</span><span class="sc">\]</span><span class="at">, which funded half of the research in Feigenbaum's lab, wanted an expert system to hypothesize about the behavior of enemy submarines hiding in U.S. coastal waters, interpreting data from ocean noises, and reconnaissance aircraft sightings, and using a large compendium of mostly secret intelligence knowledge about those enemy submarines and their behaviors... the classified expert system HASP for enemy submarine surveillance. Importantly, it included explanations in English for all of its inferred hypotheses, thereby gaining the trust of the Navy personnel at the coastal stations.</span></span>
<span id="cb18-1387"><a href="#cb18-1387" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1388"><a href="#cb18-1388" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ...</span></span>
<span id="cb18-1389"><a href="#cb18-1389" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1390"><a href="#cb18-1390" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By 1988, Paul Harmon, an expert systems newsletter editor, counted several thousand expert systems operating in fields as varied as construction, finance, heavy manufacturing, and computer configuration and sales.</span></span>
<span id="cb18-1391"><a href="#cb18-1391" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1392"><a href="#cb18-1392" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mccorduckScientificLifeEdward2022</span><span class="co">]</span></span>
<span id="cb18-1393"><a href="#cb18-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1394"><a href="#cb18-1394" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In 1980 John McDermott of Carnegie Mellon delivered to Digital Equipment Corporation the first version of XCON, an expert system designed to help the computer manufacturer configure its machines to suit customer demand; by the middle of the decade the company estimated it was sav- ing $40 million annually by use of XCON. The CBS Evening News re- ported in September 1983 that the expert system PROSPECTOR, instantiating the knowledge of nine geologists, had helped a company discover molybdenum deposits in Washington State’s Mount Tolman. Comparable stories proliferated. Companies scrambled to buy expert systems. New companies sprang up to service them. Bright students were lured away from graduate school with salary offers of \$30,000.</span></span>
<span id="cb18-1395"><a href="#cb18-1395" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1396"><a href="#cb18-1396" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 191</span><span class="co">]</span></span>
<span id="cb18-1397"><a href="#cb18-1397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1398"><a href="#cb18-1398" aria-hidden="true" tabindex="-1"></a>The AI boom caught even the imagination of the experts themselves:</span>
<span id="cb18-1399"><a href="#cb18-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1400"><a href="#cb18-1400" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; at the moment the expert system takes hold of the expert's own imagination. For weeks, perhaps longer, he has watched what is most charitably described as a burlesque of his thinking processes dancing across a display. All of a sudden (or so it seems) the burlesque sharpens into adroit imitation: there before him are the very reasoning processes he has originated, nourished, and cherished over a professional lifetime. His excitement mounts, and he becomes an enthusiastic partner in the last few steps of perfecting the electronic image of his mind. He becomes infected by the "immortality syndrome" as one researcher calls it—elation at the thought that what he knows, has so painstakingly acquired over a lifetime of experience, will live on beyond him.</span></span>
<span id="cb18-1401"><a href="#cb18-1401" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1402"><a href="#cb18-1402" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, page 93</span><span class="co">]</span></span>
<span id="cb18-1403"><a href="#cb18-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1404"><a href="#cb18-1404" aria-hidden="true" tabindex="-1"></a>A best-selling book was full of miraculous stories of growth and business profits:</span>
<span id="cb18-1405"><a href="#cb18-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1406"><a href="#cb18-1406" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Mike-in-the-Box, "God in the works" (the captured expertise of an aging, irreplaceable blast furnace expert at Nippon-Kokan), ‘‘Geoff’s Book” (thousands of expert rules from the head of the senior, top estimator at building contractor Lend Lease of Australia), and J. A. Gilreath (Schlumberger’s ace oilfield data interpreter, whose expertise is now enshrined in that company’s Dipmeter Advisor system) are among the stars we meet. Much of the priceless skill of these experts has been captured by "knowledge engineer": translators.</span></span>
<span id="cb18-1407"><a href="#cb18-1407" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1408"><a href="#cb18-1408" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; At IBM Burlington (the chip operation), a 10 to 20 percent increase in throughput has been realized; this adds up to tens of millions of dollars’ annual savings from just the one system. At the British National Health Service, a demanding and critical evaluation task that took six experts two hours is now done (better) in nine minutes. At American Express, the "decline rate" (decisions not to grant credit) has been reduced by fully one-third, and the value of the single, new AI system is already estimated at \$27 million a year. A Westinghouse system (a new service which that firm sells to utilities), aimed at enhancing the utilization of giant electric power generation turbines, contributes a whopping $2 to $3 million per year per customer machine. Then there’s a sales support system at Digital, called XSEL, which has reduced a three-hour system configuration/alternative generation task to fifteen minutes; moreover, less than 1 percent of the systems so specified turn out not to be manufacturable, down from 30 percent before the system was installed—all of which is worth $70 million a year, says DEC, not including immeasurable added customer satisfaction that accrues from providing the customer with more options. And an AI system that aids product design at Canon has made scarce, highly skilled lens designers fully twelve times more productive!</span></span>
<span id="cb18-1409"><a href="#cb18-1409" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1410"><a href="#cb18-1410" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ...</span></span>
<span id="cb18-1411"><a href="#cb18-1411" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1412"><a href="#cb18-1412" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For a customer, NKK Steel, IBM built a system that schedules the movement of materials and products and does the assignment of workers to tasks. The expert system was put into operation in September, 1987. It produces in half an hour a schedule that previously took ten hours to prepare and overall saves the company 100 million yen per year (about $700 thousand).</span></span>
<span id="cb18-1413"><a href="#cb18-1413" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1414"><a href="#cb18-1414" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ...</span></span>
<span id="cb18-1415"><a href="#cb18-1415" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1416"><a href="#cb18-1416" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Force Requirements Expert System, an expert system to advise on the deployment of ships in the U.S. Pacific Fleet. According to TI, a typical deployment problem would take an experienced operations officer and his staff as much as a week to solve, but with the help of Fresh, the officer can produce a solution by himself in six to eight hours.</span></span>
<span id="cb18-1417"><a href="#cb18-1417" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1418"><a href="#cb18-1418" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumRiseExpertCompany1988</span><span class="co">]</span></span>
<span id="cb18-1419"><a href="#cb18-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1420"><a href="#cb18-1420" aria-hidden="true" tabindex="-1"></a>Wait, the US Pacific Fleet? Yes! The military took on many expert systems. More on this <span class="co">[</span><span class="ot">below</span><span class="co">](#sec-sci)</span>.</span>
<span id="cb18-1421"><a href="#cb18-1421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1422"><a href="#cb18-1422" aria-hidden="true" tabindex="-1"></a>The market segmented into the following parts:</span>
<span id="cb18-1423"><a href="#cb18-1423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1424"><a href="#cb18-1424" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Language: Some companies marketed basic language development and consulting, mainly in Lisp and Prolog.</span>
<span id="cb18-1425"><a href="#cb18-1425" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Expert system building tools: Some companies marketed software for building expert systems. They might be expert system "shells" like the EMYCIN, with some extras to make it easier for non-researchers like engineers to enter their knowledge into the computer.</span>
<span id="cb18-1426"><a href="#cb18-1426" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Application builders: Some companies would build expert systems on demand. They would send in knowledge engineers into the field and elicit knowledge from experts, by interview, observing, asking questions, etc. At the end of the process, they would deliver the finished expert system.</span>
<span id="cb18-1427"><a href="#cb18-1427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1428"><a href="#cb18-1428" aria-hidden="true" tabindex="-1"></a>However, there was a persistent confusion as to the point of expert systems, since even deep into the AI boom period, people still often thought the expert system shell was "the AI" that the AI companies were selling, even when it's the knowledge engineering that they sold. It was kind of a <span class="co">[</span><span class="ot">shell game</span><span class="co">](https://en.wikipedia.org/wiki/Shell_game)</span>.</span>
<span id="cb18-1429"><a href="#cb18-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1430"><a href="#cb18-1430" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;  The idea was that there was a piece of magic that was the AI and that this magic, plus a software development environment that made it easy to build these things, was salable... Where was the AI? It wasn’t in the inference engine at all. These inference engines were, after all, pretty simple pieces of software that tested to see if the logic of the rules that the knowledge engineers wrote came up with any conclusions. The AI in complex expert systems was in the organization and representation of knowledge, the attempt to understand the domain under study, and the crystallization of what was important in the domain and how experts in the domain reasoned.</span></span>
<span id="cb18-1431"><a href="#cb18-1431" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1432"><a href="#cb18-1432" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@schankWheresAI1991</span><span class="co">]</span></span>
<span id="cb18-1433"><a href="#cb18-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1434"><a href="#cb18-1434" aria-hidden="true" tabindex="-1"></a><span class="fu">### The knowledge bottleneck</span></span>
<span id="cb18-1435"><a href="#cb18-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1436"><a href="#cb18-1436" aria-hidden="true" tabindex="-1"></a>If knowledge is power, then how does one acquire more power? The "knowledge bottleneck" already appeared in the earliest papers on DENDRAL:</span>
<span id="cb18-1437"><a href="#cb18-1437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1438"><a href="#cb18-1438" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; we could get rid of the "middle man" in the information transfer by educating a programmer in mass spectrometry or by educating a chemist in Lisp. Or we could replace the middle man with a program designed to perform the same function as B (the layman/programmer) in the dialog above. In effect, we have been moving slowly in all three of these directions at once. But what we would most like to pursue is the design of a program to elicit information from an expert who is not also a programmer.</span></span>
<span id="cb18-1439"><a href="#cb18-1439" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1440"><a href="#cb18-1440" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One obvious reason for the encouragingly high level of performance of the computer is the large amount of mass spectrometry knowledge which chemists have imparted to the program. Yet this has been one of the biggest bottlenecks in developing the program... The preponderance of time was now spent by the chemist deciding how to change the rules in the table to bring the program’s behaviour more in line with real data.</span></span>
<span id="cb18-1441"><a href="#cb18-1441" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span>  </span>
<span id="cb18-1442"><a href="#cb18-1442" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@buchananRediscoveringProblemsArtificial1970</span><span class="co">]</span></span>
<span id="cb18-1443"><a href="#cb18-1443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1444"><a href="#cb18-1444" aria-hidden="true" tabindex="-1"></a>There were mainly two kinds of "knowledge acquisition". Most of it was slow and painful, with knowledge engineers "eliciting" knowledge from experts by interviews and observations. It was a cottage industry for spinning out knowledge, and many recognized this as the great problem for scaling expert systems up. Much of the tooling came into making the cottage industry faster. MYCIN had taken 20 person-years to produce just 475 rules! In contrast, GASOIL in 1986 would take one person-year to produce 2,500 rules, a speed up of 100x. <span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 194, page 370</span><span class="co">]</span></span>
<span id="cb18-1445"><a href="#cb18-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1446"><a href="#cb18-1446" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Feigenbaum: I said, "Sato-san </span><span class="sc">\[</span><span class="at">CEO of Fujitsu Laboratories in Japan</span><span class="sc">\]</span><span class="at">, what message would you like me to take back to the people in the US about your experience in expert systems?" He said, "Tell them it's too hard to get the knowledge."</span></span>
<span id="cb18-1447"><a href="#cb18-1447" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1448"><a href="#cb18-1448" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-1449"><a href="#cb18-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1450"><a href="#cb18-1450" aria-hidden="true" tabindex="-1"></a>From various reading, it seems to me that the largest possible expert systems assembled by such a cottage industry contained around 10,000 rules. For example, the XCON system had around 16,000 rules. <span class="co">[</span><span class="ot">@barkerExpertSystemsConfiguration1989</span><span class="co">]</span> Anything bigger than that basically was too complicated for its own good. Except the Cyc.</span>
<span id="cb18-1451"><a href="#cb18-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1452"><a href="#cb18-1452" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Feigenbaum: In 1973 there was a guy named Harold Cohen who made an intelligent painter. You guys should actually do some research on that... It was probably the longest-lived expert system in the history of expert systems. Harold died </span><span class="sc">\[</span><span class="at">in 2016</span><span class="sc">\]</span><span class="at">. It was a 15,000-rule system representing the rules that he got out of his own head.</span></span>
<span id="cb18-1453"><a href="#cb18-1453" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1454"><a href="#cb18-1454" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018a</span><span class="co">]</span></span>
<span id="cb18-1455"><a href="#cb18-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1456"><a href="#cb18-1456" aria-hidden="true" tabindex="-1"></a>There were many attempts at automatic knowledge acquisition, starting with Meta-DENDRAL, and culminating with Cyc. They all failed to scale up. We will do a detailed case-study of Cyc and its scalability problems.</span>
<span id="cb18-1457"><a href="#cb18-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1458"><a href="#cb18-1458" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; This is the stuff of excellent AI science. But did Meta-DENDRAL find any application in any industrial setting? No. Nor have any of the other complex machine learning procedures (however, machine induction based on algorithms of </span><span class="co">[</span><span class="ot">Quinlan</span><span class="co">](https://en.wikipedia.org/wiki/Ross_Quinlan)</span><span class="at"> have had a marginal success). The industry of AI applications is still awaiting the dawn of an era of knowledge engineering significantly aided by machine learning.</span></span>
<span id="cb18-1459"><a href="#cb18-1459" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1460"><a href="#cb18-1460" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@lindsayDENDRALCaseStudy1993</span><span class="co">]</span></span>
<span id="cb18-1461"><a href="#cb18-1461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1462"><a href="#cb18-1462" aria-hidden="true" tabindex="-1"></a><span class="fu">### Where did it go?</span></span>
<span id="cb18-1463"><a href="#cb18-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1464"><a href="#cb18-1464" aria-hidden="true" tabindex="-1"></a>Around mid-1990s, it was pretty much official: the Expert System hype died. According to the AI mythos, after this came the second AI winter. Where did it go?</span>
<span id="cb18-1465"><a href="#cb18-1465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1466"><a href="#cb18-1466" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The new darling of the media -- virtual reality -- has supplanted AI as having the potential to merge science fiction with real-world applications... Patrick Albert... pointed out the main problem afflicting the AI industry: "companies have been marketing AI technologies, and not solutions." ... the more invisible AI becomes, the more palatable it becomes to the end-user. The day of generic expert system tools is probably over, Arjimand said, to be replaced by off-the-shelf applications. </span></span>
<span id="cb18-1467"><a href="#cb18-1467" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1468"><a href="#cb18-1468" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Both Monte Zweben, President of Red Pepper Software (San Mateo, CA), and Tom Laffey, Chief Technology Officer of Talarian (Mountain View, CA), had similar stories to tell regarding the successful launch of companies selling real-time expert system tools: never, ever call the products "AI". "Don’t mention AI if you want any venture capital money," Laffey warned. "Call it something else, such as advanced decision systems. These days, people come to AI almost as a last resort." Zweben’s company shared the same fate as Talarian: he had to remove or restate every mention of AI from the Red Pepper prospectus before investors would take him seriously. Despite the literally thousands of successfully deployed intelligent ap- plications, AI’s reputation continues to suffer because nobody is giving credit to the AI component. Zweben suggested wish- fully that AI companies insist on being recognized for their contribution to applications, perhaps even demanding an ‘AI inside’ label, it la Intel’s ‘Intel inside’ label on PCs.</span></span>
<span id="cb18-1469"><a href="#cb18-1469" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1470"><a href="#cb18-1470" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@blanchardAAAI94StateAI1994</span><span class="co">]</span></span>
<span id="cb18-1471"><a href="#cb18-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1472"><a href="#cb18-1472" aria-hidden="true" tabindex="-1"></a>Schank, writing near the end of the expert systems hype, argued that AI researchers missed the point about scaling. They thought AI is about designing an algorithm, when it is really quite tedious -- real AI is 1% inspiration and 99% perspiration. He used the experience of getting ATRANS to work in practice, a program that read international bank money transfer messages:</span>
<span id="cb18-1473"><a href="#cb18-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1474"><a href="#cb18-1474" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Any of Cognitive Systems' programmers would have been justified in complaining that they had come to work there to do AI, and all they were doing was working on endless details about determining various abbreviations for bank names. They also asked, Where’s the AI? The lesson to be learned from ATRANS is simple enough... AI entails massive software engineering. To paraphrase Thomas Edison, “AI is 1-percent inspiration and 99-percent perspiration.” AI people will never build any real AI unless they are willing to make the tremendously complex effort that is involved in making sophisticated software work.</span></span>
<span id="cb18-1475"><a href="#cb18-1475" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1476"><a href="#cb18-1476" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One serious problem in AI these days is that we keep producing researchers instead of builders. Every new Ph.D. recipient, it seems, wants to continue to work on some obscure small problem whose solution will benefit some mythical program that no one will ever write. We are in danger of creating a generation of computationally sophisticated philosophers.</span></span>
<span id="cb18-1477"><a href="#cb18-1477" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1478"><a href="#cb18-1478" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@schankWheresAI1991</span><span class="co">]</span></span>
<span id="cb18-1479"><a href="#cb18-1479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1480"><a href="#cb18-1480" aria-hidden="true" tabindex="-1"></a>Winograd argued that expert systems are structured like human bureaucracies, with formalized explicit rules, and so they have same strengths and weaknesses. This explains why they work only in stable and precise technical areas, where exceptions are not the rule. He gave an example expert system that was stuck in development hell for 15 years, presumably as it was in an era (internal medicine) that has too many exceptions to the rules:</span>
<span id="cb18-1481"><a href="#cb18-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1482"><a href="#cb18-1482" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; One system for medical diagnosis, called </span><span class="co">[</span><span class="ot">CADUCEUS</span><span class="co">]</span><span class="at">(https://en.wikipedia.org/wiki/CADUCEUS_(expert_system)) (originally INTERNIST), has 500 disease profiles, 350 disease variations, several thousand symptoms, and 6,500 rules describing relations among symptoms. After 15 years of development, the system is still not on the market. According to one report, it gave a correct diagnosis in only 75 percent of its carefully selected test cases. Nevertheless, Myers, the medical expert who developed it, "believes that the addition of another 50 </span><span class="sc">\[</span><span class="at">diseases</span><span class="sc">\]</span><span class="at"> will make the system workable and, more importantly, practical."</span></span>
<span id="cb18-1483"><a href="#cb18-1483" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1484"><a href="#cb18-1484" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@winograd10ThinkingMachines1991</span><span class="co">]</span></span>
<span id="cb18-1485"><a href="#cb18-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1486"><a href="#cb18-1486" aria-hidden="true" tabindex="-1"></a>In 1992, Feigenbaum admitted that the hope of generally intelligent expert systems failed. They turned out to be like mesas: narrow, brittle, and isolated. They work well within the knowledge base, but immediately fail when even slightly outside of it. Every expert system was unique and custom-made. They couldn't be mass-produced, and their knowledge bases are incompatible, so they couldn't talk to each other or share each other's knowledge. Although, he dreamed of a "Library of Congress of knowledge codified and represented for expert system use", which he saw in the <span class="co">[</span><span class="ot">Cyc</span><span class="co">](#sec-cyc)</span>. <span class="co">[</span><span class="ot">@feigenbaumPersonalViewExpert1992</span><span class="co">]</span></span>
<span id="cb18-1487"><a href="#cb18-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1488"><a href="#cb18-1488" aria-hidden="true" tabindex="-1"></a>Many years later, in 2018 and 2022, some of the expert systems people reviewed to their younger days to find out what went wrong.</span>
<span id="cb18-1489"><a href="#cb18-1489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1490"><a href="#cb18-1490" aria-hidden="true" tabindex="-1"></a>Harmon argued that expert systems failed to <span class="co">[</span><span class="ot">"cross the chasm"</span><span class="co">](https://en.wikipedia.org/wiki/Crossing_the_Chasm)</span>. A new technology is adopted in two waves, with the first wave driven by small companies ("innovators" and "early adopters") who were optimistic about its future, and the second wave driven by large companies that sell to the "majority" who have been convinced that it grows the bottom-line. The first wave typically appears at technology fairs, while the second wave typically appears at <span class="co">[</span><span class="ot">trade fairs</span><span class="co">](https://en.wikipedia.org/wiki/Trade_show)</span>. The "chasm" between the two waves happen because some technologies never get past the "a good idea" stage, and end up being "a good idea that didn't work out for most", and it may remain in use only in niche places.</span>
<span id="cb18-1491"><a href="#cb18-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1492"><a href="#cb18-1492" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Moore's technology adoption life cycle curve. [@harmonExpertSystemsBusiness2022, figure 3]</span><span class="co">](figure/Moore_chasm.png)</span></span>
<span id="cb18-1493"><a href="#cb18-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1494"><a href="#cb18-1494" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By the late 1990s, most expert systems vendors had disappeared. Some expert systems tool companies survived until later, and large companies like IBM simply shifted their emphasis to other product lines as demand changed. In essence, the expert systems market never really achieved take-off.</span></span>
<span id="cb18-1495"><a href="#cb18-1495" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1496"><a href="#cb18-1496" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@harmonExpertSystemsBusiness2022</span><span class="co">]</span></span>
<span id="cb18-1497"><a href="#cb18-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1498"><a href="#cb18-1498" aria-hidden="true" tabindex="-1"></a>Though expert systems don't cost salary like human experts, they still have a high maintanence cost, because knowledge updates:</span>
<span id="cb18-1499"><a href="#cb18-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1500"><a href="#cb18-1500" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Harmon: When you start to see attendance and vendors dropping off, you know that the market is closing down for some reason. That certainly happened in that expert systems array. The second thing is that expert systems knowledge isn't a constant... If a company had a knowledge base and passed it to somebody else, it would be certainly at the cutting edge. But it would be out of date within a year or two anyway. The ability of these systems to be maintained, to have people bring them up to date is critical, too.</span></span>
<span id="cb18-1501"><a href="#cb18-1501" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1502"><a href="#cb18-1502" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Feigenbaum: In 1987 dollars, to maintain the famous </span><span class="co">[</span><span class="ot">DEC configuration system</span><span class="co">](https://en.wikipedia.org/wiki/Xcon)</span><span class="at"> cost DEC $2.7 million a year because the products kept changing.</span></span>
<span id="cb18-1503"><a href="#cb18-1503" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1504"><a href="#cb18-1504" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-1505"><a href="#cb18-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1506"><a href="#cb18-1506" aria-hidden="true" tabindex="-1"></a>The more powerful features of expert systems were too difficult to use for people untrained in computer science, and the features that outsiders could use were pretty simple and boring.</span>
<span id="cb18-1507"><a href="#cb18-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1508"><a href="#cb18-1508" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Lenat: it was closer to what Ed and others were saying: the tools were too hard to use; the education and knowledge transfer to the people who would have to build the systems wasn't there. I was on the </span><span class="co">[</span><span class="ot">Inference</span><span class="co">](https://en.wikipedia.org/wiki/Inference_Corporation)</span><span class="at"> advisory board. and I loved ART </span><span class="sc">\[</span><span class="at">Automated Reasoning Tool, produced by Inference</span><span class="sc">\]</span><span class="at">. It had context and all sorts of wonderful features and truth maintenance. In general, the first thing that the customers would do is turn all that off because it was very complicated... They just used this narrow little tiny iris that wasn't quite enough for them to get enough traction to make it cost-effective.</span></span>
<span id="cb18-1509"><a href="#cb18-1509" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1510"><a href="#cb18-1510" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Friedland: People bought zillions of copies of ART probably about 1985 and right around the tradeshow in Los Angeles. The same thing, with IntelliCorp, people bought KEE </span><span class="sc">\[</span><span class="at">[Knowledge Engineering Environment</span><span class="sc">\]</span><span class="at">(https://en.wikipedia.org/wiki/Knowledge_Engineering_Environment)</span><span class="sc">\]</span><span class="at"> like chocolate candy bars, but it took really skilled people to use those tools effectively just as it takes really skilled people to use these things. NASA spent \$1 billion on an SAP system and spent almost no money on consulting advice to use it. It took teams of people, and I was on one of the teams, five years to fix the mess that caused at NASA by buying SAP. It ending up with a system that totally ruined its financial management for years.</span></span>
<span id="cb18-1511"><a href="#cb18-1511" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1512"><a href="#cb18-1512" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Haigh: If you're Peter Hart or Ed Feigenbaum, you can do amazing things, but there aren't that many Ed Feigenbaum’s and Peter Hart’s around... How do you scale that up if you sell the tool? You’re saying they turn off all the smart stuff. There isn’t a huge base of people out there who are smart enough and have the right background to do the things that the really smart people can.</span></span>
<span id="cb18-1513"><a href="#cb18-1513" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1514"><a href="#cb18-1514" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-1515"><a href="#cb18-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1516"><a href="#cb18-1516" aria-hidden="true" tabindex="-1"></a>From a purely business perspective, the profit margins were too thin. Those selling programming language support and generic shells died, because those quickly became commodities with thin profit margin, and could not compete with large incumbents (like IBM) who could run a loss leader.</span>
<span id="cb18-1517"><a href="#cb18-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1518"><a href="#cb18-1518" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Allen: the first generation of expert system companies had an extremely skewed image of what the market was because the federal government was coming in and throwing tons of money into the thing... we shipped and the next month we were doing a million a month in revenue... Once that initial fact-finding effort had gone on within those organizations, they said, "Well, it's either too expensive or we’re going to do it in-house."</span></span>
<span id="cb18-1519"><a href="#cb18-1519" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1520"><a href="#cb18-1520" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-1521"><a href="#cb18-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1522"><a href="#cb18-1522" aria-hidden="true" tabindex="-1"></a>Those that survived, survived by pivoting:</span>
<span id="cb18-1523"><a href="#cb18-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1524"><a href="#cb18-1524" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>to object-oriented programming tools or databases, which are similar to knowledge bases;</span>
<span id="cb18-1525"><a href="#cb18-1525" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>to relational databases, which are similar to knowledge bases;</span>
<span id="cb18-1526"><a href="#cb18-1526" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>to <span class="co">[</span><span class="ot">business rules</span><span class="co">](https://en.wikipedia.org/wiki/Business_rule)</span>, which are particularly cheap to construct, because instead of living inside expert heads, they are already written down as business policies and top-down procedural guidelines;</span>
<span id="cb18-1527"><a href="#cb18-1527" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>to consulting, building expert systems for their customers and keep maintaining it with new knowledge.</span>
<span id="cb18-1528"><a href="#cb18-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1529"><a href="#cb18-1529" aria-hidden="true" tabindex="-1"></a>And knowledge acquisition, the dream of machine learning breaking through the bottleneck? Some of it failed, and some of it was taken over by statistical machine learning and "data mining", as discovering logical rules and decision trees over a large database. Data science for the 2000s.</span>
<span id="cb18-1530"><a href="#cb18-1530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1531"><a href="#cb18-1531" aria-hidden="true" tabindex="-1"></a><span class="fu">### Did it succeed after all?</span></span>
<span id="cb18-1532"><a href="#cb18-1532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1533"><a href="#cb18-1533" aria-hidden="true" tabindex="-1"></a>True, the higher dreams of expert system AGI did not pan out, but small parts of AI had successfully broken out from the academia and become infrastructure: practical, invisible, even boring.</span>
<span id="cb18-1534"><a href="#cb18-1534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1535"><a href="#cb18-1535" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Harmon: several of these old expert system tool vendors who then became business rule vendors became part of the business process tool market, and it exists there today... It's a very easy kind of knowledge to capture. As opposed to interviewing an expert and trying to get them to give you heuristic information, these guys were dealing almost entirely with procedures that had already been stated in a rulebook. In any case, it's just one variation of what people with this technology went out and found out a niche and did. There was a market for parts of the technology. It just didn't happen to fit the big model.</span></span>
<span id="cb18-1536"><a href="#cb18-1536" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1537"><a href="#cb18-1537" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Feigenbaum: rules-based systems lives on today, very strongly absorbed into the infrastructure of IT. Somebody mentioned yesterday that if you take off the back cover of some system and you look in there there's a rule-based system in there... It's not the full base. It's not the full inference engine. It's not the full expert system, but the business rules exist.</span></span>
<span id="cb18-1538"><a href="#cb18-1538" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1539"><a href="#cb18-1539" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-1540"><a href="#cb18-1540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1541"><a href="#cb18-1541" aria-hidden="true" tabindex="-1"></a>I imagine the world of knowledge in rings around a mineshaft. Directly inside the mineshaft are researchers, who send out cartloads of barely refined ore. These are then refined into shape by the technologists. Finally those ingots are hammered into shape, to be used by those in the business who just want to get a well-packaged modular piece of tech to do something reliably and cheaply.</span>
<span id="cb18-1542"><a href="#cb18-1542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1543"><a href="#cb18-1543" aria-hidden="true" tabindex="-1"></a>Numerical computing started as research projects on the early giant mainframes, which are then turned into numerical programs written in C, which then gets turned into packaged systems like Matlab and Macsyma, usable by people outside the numerical computing community, who just need to calculate the pressure of an oil well or the tension in a building beam.</span>
<span id="cb18-1544"><a href="#cb18-1544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1545"><a href="#cb18-1545" aria-hidden="true" tabindex="-1"></a>My guess is that the expert system boom took place because there was something genuinely new: it was the brith of non-numerical software engineering.</span>
<span id="cb18-1546"><a href="#cb18-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1547"><a href="#cb18-1547" aria-hidden="true" tabindex="-1"></a>Mechanical calculators were present since the 19th century, and numerical methods such as finite elements, weather prediction, linear programming, cybernetics, etc, simply migrated wholesale to electronic computers in the 1940s, and the mathematics and engineering department could simply churn out numerical programmers by giving them a course in ALGOL -- a name that means "<span class="sc">\[</span>numerical<span class="sc">\]</span> algorithm language".</span>
<span id="cb18-1548"><a href="#cb18-1548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1549"><a href="#cb18-1549" aria-hidden="true" tabindex="-1"></a>In contrast, there was very little *symbolic* algorithms before computers came around, and it was born essentially around the 1950s as "symbolic AI" or "computer science". Entire university departments for computer science had to be invented. MIT's CS department was established in 1963, MIT 1965, and Berkeley 1967. The story makes too much if we assume progress marches <span class="co">[</span><span class="ot">one generation at a time</span><span class="co">](https://en.wikipedia.org/wiki/Planck's_principle)</span>: </span>
<span id="cb18-1550"><a href="#cb18-1550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1551"><a href="#cb18-1551" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The heroic age: Preliminary theoretical AI studies by Turing, McCulloch, Pitts, etc, in the 1940s.</span>
<span id="cb18-1552"><a href="#cb18-1552" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The classical age: Universities create a department of AI and CS and start teaching graduate students the subject with canonical textbooks, creating a reliable stream of professors and lecturers of the subject, in the 1960s.</span>
<span id="cb18-1553"><a href="#cb18-1553" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The civilized age: The technology spills out into the commercial world, and universities create undergraduate degrees in computer science dedicated to churning out software engineers, as SWE becomes a professional class with stock options and a retirement plan, in the 1980s.</span>
<span id="cb18-1554"><a href="#cb18-1554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1555"><a href="#cb18-1555" aria-hidden="true" tabindex="-1"></a>In 1980, laypeople outside the computer community knew very well that computers can crunch statistical datasets and numerical simulations, and that they can perform if-then-else logical control flows, but they thought that's *all* they could do. In the 1970s, expert systems with uncertainty quantification was something new in the research level, as barely refined ore. Around 1980, it had been roughly packaged up as EMYCIN by researchers and technologists, who had used EMYCIN to solve real problems. So, during 1980s, expert systems reached the last stage: to be hammered into a tool for business.</span>
<span id="cb18-1556"><a href="#cb18-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1557"><a href="#cb18-1557" aria-hidden="true" tabindex="-1"></a>Indeed, at the start of the boom, there was a serious lack of computer science graduates who could write the expert systems. This seemed rather silly, now that we've seen that much of what expert systems did are now done by object-oriented programming and relational databases. But remember that back in 1980s, computer science was a purer science, unlike electric engineering. Software engineering was just getting started.</span>
<span id="cb18-1558"><a href="#cb18-1558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1559"><a href="#cb18-1559" aria-hidden="true" tabindex="-1"></a>Similarly, there was also the promise of logic programming over imperative programming, of <span class="co">[</span><span class="ot">formal program synthesis</span><span class="co">](https://en.wikipedia.org/wiki/Program_synthesis)</span>: the user specifies the results, and a logical inference engine would synthesize a way to get there. This was a development from robot planning (especially <span class="co">[</span><span class="ot">Shakey</span><span class="co">](#sec-shakey)</span>), where the user would input a goal state of the world, and the planner would compute a motion plan to reach that state. This was also a revelation. Compared to the previous method of programming directly the motion plan like writing assembly code, this was like compiling a source code into assembly. This was a major promise of Prolog-based logic programming. I am less certain about where this has ended up, but my hypothesis is the same: When it is *possible* to specify a task domain by formal logic, then it works, and this lives today in logistical planning software, robotic path-finding, automated compiler design, etc. However, this does not work in domains not logically specified.</span>
<span id="cb18-1560"><a href="#cb18-1560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1561"><a href="#cb18-1561" aria-hidden="true" tabindex="-1"></a>So what happened to expert systems? The working parts (knowledge representation, retrieval, logical inference, logistical planning, data dashboards, automatic industrial process control) got rolled into standard software engineering and became too boring to be considered AI. The not working parts (automatic knowledge acquisition, machine learning, vision, speech, translation) got abandoned, only to be resurrected again by statistical machine learning, and then deep learning.</span>
<span id="cb18-1562"><a href="#cb18-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1563"><a href="#cb18-1563" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; As soon as it works, no one calls it AI anymore.</span></span>
<span id="cb18-1564"><a href="#cb18-1564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1565"><a href="#cb18-1565" aria-hidden="true" tabindex="-1"></a>The working parts of expert systems live behind boring acronyms like Systems Applications and Products (SAP), Automated Reasoning Tool (ART), and Knowledge Management Systems (KMS).<span class="ot">[^expert-system-acronym]</span> As a pattern, the areas where expert systems succeeded include logistics planning, business rules, tax code, bureaucratic rules, while they failed basically at any kind of general intelligence in even slightly unstructured environments. The common intuition that they are fragile is largely correct, and they work precisely in standardized environments with minimal change, much like bureaucracies. Indeed, a good intuition is that expert systems are digitized bureaucracies, with the same strengths and weaknesses.</span>
<span id="cb18-1566"><a href="#cb18-1566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1567"><a href="#cb18-1567" aria-hidden="true" tabindex="-1"></a><span class="ot">[^expert-system-acronym]: </span>Are you bored yet? Here are more! Knowledge base management system (KBMS), enterprise resource planning (ERP), business process management (BPM), process-oriented knowledge management (PKM), business process management system (BPMS), online transactional processing (OLTP), recency, frequency, monetary value analysis (RFM), earnings before interest, taxes, depreciation and amortization (EBITDA)... The last one was not about expert systems, but it might as well be, haha.</span>
<span id="cb18-1568"><a href="#cb18-1568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1569"><a href="#cb18-1569" aria-hidden="true" tabindex="-1"></a>We also have another hint of what mattered in the old days. In the 1978 report on Meta-DENDRAL, the authors claimed that a serious problem was simply that software on one machine doesn't run on another machine. "Just copy it" did not work, because the machines had incompatible, bespoke operating systems. The "write once, compile it everywhere" that we take for granted in software engineering only came around circa 1990.</span>
<span id="cb18-1570"><a href="#cb18-1570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1571"><a href="#cb18-1571" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; While the software is almost too complex to export, our research-oriented computer facility has too little capacity for import. Support of an extensive body of outside users means that resources (people as well as computers) must be diverted from the research goals of the project. At considerable cost in money and talent, it has been possible to export the programs to Edinburgh. But such extensive and expensive collaborations for technology transfer are almost never done in AI.</span></span>
<span id="cb18-1572"><a href="#cb18-1572" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1573"><a href="#cb18-1573" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@buchananDENDRALMetaDENDRALTheir1981</span><span class="co">]</span></span>
<span id="cb18-1574"><a href="#cb18-1574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1575"><a href="#cb18-1575" aria-hidden="true" tabindex="-1"></a>Meanwhile, Feigenbaum left the MYCIN-gang life and became the Chief Scientist of <span class="co">[</span><span class="ot">US Air Force</span><span class="co">](https://en.wikipedia.org/wiki/United_States_Air_Force)</span>, and tried to teach them about software engineering. With regard to technology, the military was still doing it the same way as they did in the 1950s. They prioritized hardware before software, and what software they developed was by the waterfall model they used for <span class="co">[</span><span class="ot">SAGE</span><span class="co">](https://en.wikipedia.org/wiki/Semi_Automatic_Ground_Environment)</span> <span class="co">[</span><span class="ot">@boehmView20th21st2006</span><span class="co">]</span>. Needless to say, his attempts to teach them about post-1950s software engineering went nowhere. I feel like his story is somehow a reflection of this larger story of how expert system AI became boring software engineering.</span>
<span id="cb18-1576"><a href="#cb18-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1577"><a href="#cb18-1577" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; He recalls visiting the offices of a defense contractor working on a half-billion-dollar missile defense system under construction. While the innovative physics in the hardware seemed to be on track, the crucial and difficult software controlling the remarkable aiming system was being handled by only two software engineers, who admitted they hadn't yet made much progress.</span></span>
<span id="cb18-1578"><a href="#cb18-1578" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1579"><a href="#cb18-1579" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mccorduckScientificLifeEdward2022</span><span class="co">]</span></span>
<span id="cb18-1580"><a href="#cb18-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1581"><a href="#cb18-1581" aria-hidden="true" tabindex="-1"></a>The non-working parts of expert systems were all about massive learning. It is fine to encode a few thousand rules by hand, but one does not simply write "a little grammar" for English text or speech. I have a mental picture of three rule-based regimes:</span>
<span id="cb18-1582"><a href="#cb18-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1583"><a href="#cb18-1583" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A few large rules in the center, strongly held. These create the appearance of a rule-based system, and allows one to feel like "a little grammar" is all it takes. This is the Chomskyan and logical AI regime.</span>
<span id="cb18-1584"><a href="#cb18-1584" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A network of many medium rules, weakly held. They are strongly interacting with each other, clobbering over each other, so that it is hard to make sure the network behaves correctly unless the priority weights are set correctly. If the interaction weights are too low, the system is not "contextual" enough. If the weights are too high, it would become "chaotic". Expert systems are typcially stuck in this regime. Trying to extend beyond this regime leads to fragile systems and development hell.</span>
<span id="cb18-1585"><a href="#cb18-1585" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Innumerable little rules and one-off corner cases, piercing through the network like so many porcupine spikes. This is the "unreasonable effectiveness of data" regime. Essentially all unstructured environments like speech, language, and vision are here.</span>
<span id="cb18-1586"><a href="#cb18-1586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1587"><a href="#cb18-1587" aria-hidden="true" tabindex="-1"></a><span class="fu">### But why the hype?</span></span>
<span id="cb18-1588"><a href="#cb18-1588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1589"><a href="#cb18-1589" aria-hidden="true" tabindex="-1"></a>In our perspective, expert systems seem like boring database and Java programming, and it is hard to imagine people getting hyped about databases or Java, so we tend to imagine the computer scientists promising some miracle technology they could not deliver. But it seems to me that, while they did overestimate what their technologies could deliver, the technologies themselves worked exactly as specified -- databases, logical inference, and object-oriented programming!</span>
<span id="cb18-1590"><a href="#cb18-1590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1591"><a href="#cb18-1591" aria-hidden="true" tabindex="-1"></a>So the problem now becomes: How could people have been hyped about such boring things?</span>
<span id="cb18-1592"><a href="#cb18-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1593"><a href="#cb18-1593" aria-hidden="true" tabindex="-1"></a>Although computer scientists had long known that computers could perform symbolic and logical reasoning, in the 1980s, it was a genuine revelation to people outside.</span>
<span id="cb18-1594"><a href="#cb18-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1595"><a href="#cb18-1595" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There is a certain inevitability to knowledge engineering and its applications. The cost of the computers will fall drastically during the coming two decades. As it does, many more of the practitioners of the world's professions will be persuaded to turn to economical automatic information processing for assistance in managing the increasing complexity of their daily tasks. They will find, in most of computer science, help only for those of their problems that have a mathematical or statistical core, or are of a routine data-processing nature. But such problems will be rare, except in engineering and physical science. In medicine, biology, management -- indeed in most of the world's work -- the daily tasks are those requiring symbolic reasoning with detailed professional knowledge. The computers that will act as "intelligent assistants" for these professionals must be-endowed with such reasoning capabilities and knowledge.</span></span>
<span id="cb18-1596"><a href="#cb18-1596" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1597"><a href="#cb18-1597" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumKnowledgeEngineeringApplied1984</span><span class="co">]</span></span>
<span id="cb18-1598"><a href="#cb18-1598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1599"><a href="#cb18-1599" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; even high-ranking computing executives. Many did not believe that computers could be programmed to reason and to reach uncertain conclusions. They were so familiar with lock-step algorithms that always reached the correct answer that anything less than certainty simply did not seem like real computing. In a similar way, AI languages like LISP and Prolog were nearly incomprehensible to those who had always imagined that Fortran and COBOL pretty much-defined software development. The excitement about AI and expert systems was almost as if experienced computer professionals were being asked to go back to college and learn computer science all over again.</span></span>
<span id="cb18-1600"><a href="#cb18-1600" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1601"><a href="#cb18-1601" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@harmonExpertSystemsBusiness2022</span><span class="co">]</span></span>
<span id="cb18-1602"><a href="#cb18-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1603"><a href="#cb18-1603" aria-hidden="true" tabindex="-1"></a>And while the grandest dreams of expert system AI did not pan out, it still offered incremental profit of a few million dollars at a time. The pieces that worked quickly became too boring to mention, and the pieces that didn't work got forgotten, or returned to academia, where ideas hope for their eventual justification.</span>
<span id="cb18-1604"><a href="#cb18-1604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1605"><a href="#cb18-1605" aria-hidden="true" tabindex="-1"></a>Except the thing called "Cyc".</span>
<span id="cb18-1606"><a href="#cb18-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1607"><a href="#cb18-1607" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cyc {#sec-cyc}</span></span>
<span id="cb18-1608"><a href="#cb18-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1609"><a href="#cb18-1609" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; He divided the universe in forty categories or classes, these being further subdivided into differences, which was then subdivided into species. He assigned to each class a monosyllable of two letters; to each difference, a consonant; to each species, a vowel. For example: </span><span class="in">`de`</span><span class="at">, which means an element; </span><span class="in">`deb`</span><span class="at">, the first of the elements, fire; </span><span class="in">`deba`</span><span class="at">, a part of the element fire, a flame. In a similar language invented by Letellier (1850) </span><span class="in">`a`</span><span class="at"> means animal; </span><span class="in">`ab`</span><span class="at">, mammal; </span><span class="in">`abo`</span><span class="at">, carnivore; </span><span class="in">`aboj`</span><span class="at">, feline; </span><span class="in">`aboje`</span><span class="at">, cat; </span><span class="in">`abi`</span><span class="at">, herbivore; </span><span class="in">`abiv`</span><span class="at">, horse; etc... children would be able to learn this language without knowing it be artificial; afterwards, at school, they would discover it being an universal code and a secret encyclopaedia.</span></span>
<span id="cb18-1610"><a href="#cb18-1610" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1611"><a href="#cb18-1611" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Once we have defined Wilkins' procedure, it is time to examine a problem which could be impossible or at least difficult to postpone: the value of this four-level table which is the base of the language. Let us consider the eighth category, the category of stones. Wilkins divides them into common (silica, gravel, schist), modics (marble, amber, coral), precious (pearl, opal), transparent (amethyst, sapphire) and insolubles (chalk, arsenic). Almost as surprising as the eighth, is the ninth category. This one reveals to us that metals can be imperfect (cinnabar, mercury), artificial (bronze, brass), recremental (filings, rust) and natural (gold, tin, copper). Beauty belongs to the sixteenth category; it is a living brood fish, an oblong one.</span></span>
<span id="cb18-1612"><a href="#cb18-1612" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1613"><a href="#cb18-1613" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Borges, *The analytical language of John Wilkins*</span></span>
<span id="cb18-1614"><a href="#cb18-1614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1615"><a href="#cb18-1615" aria-hidden="true" tabindex="-1"></a>Many years later, surrounded by the humming servers of the Cyc database, Douglas Lenat was to remember that distant afternoon when he first conceived of encoding all of common sense.</span>
<span id="cb18-1616"><a href="#cb18-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1617"><a href="#cb18-1617" aria-hidden="true" tabindex="-1"></a><span class="fu">### AM</span></span>
<span id="cb18-1618"><a href="#cb18-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1619"><a href="#cb18-1619" aria-hidden="true" tabindex="-1"></a>Why AM and Eurisko Appear to Work</span>
<span id="cb18-1620"><a href="#cb18-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1621"><a href="#cb18-1621" aria-hidden="true" tabindex="-1"></a>The Nature of Heuristics</span>
<span id="cb18-1622"><a href="#cb18-1622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1623"><a href="#cb18-1623" aria-hidden="true" tabindex="-1"></a><span class="fu">### EURISKO</span></span>
<span id="cb18-1624"><a href="#cb18-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1625"><a href="#cb18-1625" aria-hidden="true" tabindex="-1"></a>AI alignment people often tell the legend of EURISKO, a program that discovered loopholes in a sci-fi ship-building tournament, allowing its creator to win two years in a row.</span>
<span id="cb18-1626"><a href="#cb18-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1627"><a href="#cb18-1627" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; AI has for many years understood enough about representation and inference to tackle this project, but no one has sat down and done it... only by pulling together the latest human interface tools, Lisp machines, ideas of enforced semantics, and funding for a decade-long effort could we attempt a project of this scale. </span><span class="co">[</span><span class="ot">@lenatCycUsingCommon1985</span><span class="co">]</span></span>
<span id="cb18-1628"><a href="#cb18-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1629"><a href="#cb18-1629" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cyc</span></span>
<span id="cb18-1630"><a href="#cb18-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1631"><a href="#cb18-1631" aria-hidden="true" tabindex="-1"></a>In 1984, <span class="co">[</span><span class="ot">Douglas Lenat</span><span class="co">](https://en.wikipedia.org/wiki/Douglas_Lenat)</span> began the Cyc project, an ambitious attempt to scale symbolic AI up to the real world. Like most expert systems, the Cyc project consists of a giant knowledge base encoded in a LISP-like symbolic logic language, upon which inference engines can be run to produce logical reasoning. Unlike most expert systems, the ambition of Cyc was universal: Its knowledge base would not be restricted to expert knowledge in a particular domain, but *all* commonsense knowledge in *all* domains that humans have commonsense about.</span>
<span id="cb18-1632"><a href="#cb18-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1633"><a href="#cb18-1633" aria-hidden="true" tabindex="-1"></a>Even from the vantage point of 1985, it was clear to all that there was a lot of commonsense to code in, although few could have predicted that Lenat would persevere at it for over 30 years.</span>
<span id="cb18-1634"><a href="#cb18-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1635"><a href="#cb18-1635" aria-hidden="true" tabindex="-1"></a>They themselves underestimated the difficulty. In 1990, they confidently titled a paper "Cyc: A midterm report" <span class="co">[</span><span class="ot">@lenatCycMidtermReport1990</span><span class="co">]</span>, suggesting that they expected to be done around 1995.</span>
<span id="cb18-1636"><a href="#cb18-1636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1637"><a href="#cb18-1637" aria-hidden="true" tabindex="-1"></a>The progress report in 1995 stated that, while the system is far from done, they have at least manually entered $10^5$ "general concepts" and $10^6$ "commonsense axioms" into Cyc, at the price of 100 person-years. <span class="co">[</span><span class="ot">@lenatCycLargescaleInvestment1995</span><span class="co">]</span></span>
<span id="cb18-1638"><a href="#cb18-1638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1639"><a href="#cb18-1639" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Moreover, statistics, colocation, and frequency do not resolve such questions. But the task goes from impossible to trivial if one already knows a few things about boxes and pens, police and demonstrators, and water and teakettles. The same sort of chicken-and-egg relationship characterizes CYC and ML because learning occurs at the fringe of what one already knows. Therefore, in the early 1980s, when the rest of the world was so enthusiastic about Natural Language Understanding, Machine Learning, and AI in general, we were pessimistic. We concluded the only way out of this codependency would be to prime the pump by manually crafting a million axioms covering an appreciable fraction of the required knowledge. That knowledge would serve as a critical mass, enabling further knowledge collection through NLU and ML, beginning in the mid-1990s. Mary Shepherd and I embarked on that task in 1984, knowing we had little chance of success, but seeing no alternative but to try... we are now moving toward the transition point where NLU and ML are supported. The rest of the world is disillusioned and pessimistic about symbolic AI, but ironically, as CYC reaches closure, our hopes for NLU and ML in the next 10 years are very high.</span></span>
<span id="cb18-1640"><a href="#cb18-1640" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1641"><a href="#cb18-1641" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@lenatCycLargescaleInvestment1995</span><span class="co">]</span></span>
<span id="cb18-1642"><a href="#cb18-1642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1643"><a href="#cb18-1643" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... give CYC enough knowledge by the late 1990s to enable it to learn more by means of natural language conversations and reading. Soon thereafter, say by 2001, we planned to have it learning on its own, by automated-discovery methods guided by models or minitheories of the real world. To a large extent, that's just what we did. At the end of 1994, the CYC program was mature enough to spin off from MCC as a new company -- Cycorp -- to commercialize the technology and begin its widespread deployment.</span></span>
<span id="cb18-1644"><a href="#cb18-1644" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1645"><a href="#cb18-1645" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@lenat20012001Common2001</span><span class="co">]</span></span>
<span id="cb18-1646"><a href="#cb18-1646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1647"><a href="#cb18-1647" aria-hidden="true" tabindex="-1"></a>In 2016, Lenat finally declared the Cyc project "done" and set about commercializing it.</span>
<span id="cb18-1648"><a href="#cb18-1648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1649"><a href="#cb18-1649" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Having spent the past 31 years memorizing an astonishing collection of general knowledge, the artificial-intelligence engine created by Doug Lenat is finally ready to go to work... most of what is left to be added is relevant to a specific area of expertise, such as finance or oncology.</span></span>
<span id="cb18-1650"><a href="#cb18-1650" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1651"><a href="#cb18-1651" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Among other projects, the company is developing a personal assistant equipped with Cyc's general knowledge. This could perhaps lead to something similar to Siri... the CEO of Lucid says the new company is in talks with various others interested in using the Cyc knowledge base. Lucid has been working with the Cleveland Clinic, for example, to help automate the process of finding patients for clinical studies.</span></span>
<span id="cb18-1652"><a href="#cb18-1652" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1653"><a href="#cb18-1653" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@knightAI30Years2016</span><span class="co">]</span></span>
<span id="cb18-1654"><a href="#cb18-1654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1655"><a href="#cb18-1655" aria-hidden="true" tabindex="-1"></a>That was essentially the last we heard from Cyc.</span>
<span id="cb18-1656"><a href="#cb18-1656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1657"><a href="#cb18-1657" aria-hidden="true" tabindex="-1"></a>When looking at this figure from 1985, one is simultaneously filled with respect and sadness, for they were facing impossible odds, and yet they charged right into it.</span>
<span id="cb18-1658"><a href="#cb18-1658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1659"><a href="#cb18-1659" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@lenatCycUsingCommon1985, Figure 1</span><span class="co">]</span>](figure/cyc_project_ontology.png)</span>
<span id="cb18-1660"><a href="#cb18-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1661"><a href="#cb18-1661" aria-hidden="true" tabindex="-1"></a>Their "midterm report" only accentuates this sense of tragedy, of seeing them fighting impossible odds, and losing. They saw with clarity that there is no shortcut to intelligence, no "Maxwell's equations of thought".</span>
<span id="cb18-1662"><a href="#cb18-1662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1663"><a href="#cb18-1663" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The majority of work in knowledge representation has dealt with the technicalities of relating predicate calculus to other formalisms and with the details of various schemes for default reasoning. There has almost been an aversion to addressing the problems that arise in actually representing large bodies of knowledge with content. However, deep, important issues must be addressed if we are to ever have a large intelligent knowledge-based program: What ontological categories would make up an adequate set for carving up the universe? How are they related? What are the important facts and heuristics most humans today know about solid objects? And so on. In short, we must bite the bullet.</span></span>
<span id="cb18-1664"><a href="#cb18-1664" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1665"><a href="#cb18-1665" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We don't believe there is any shortcut to being intelligent, any yet-to-be-discovered Maxwell's equations of thought, any AI Risc architecture that will yield vast amounts of problem-solving power. Although issues such as architecture are important, no powerful formalism can obviate the need for a lot of knowledge.</span></span>
<span id="cb18-1666"><a href="#cb18-1666" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1667"><a href="#cb18-1667" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By knowledge, we don't just mean dry, almanac-like or highly domain-specific facts. Rather, most of what we need to know to get by in the real world is prescientific (knowledge that is too commonsensical to be included in reference books; for example, animals live for a single solid interval of time, nothing can be in two places at once, animals don't like pain), dynamic (scripts and rules of thumb for solving problems) and metaknowledge (how to fill in gaps in the knowledge base, how to keep it organized, how to monitor and switch among problem-solving methods, and so on). Perhaps the hardest truth to face, one that AI has been trying to wriggle out of for 34 years, is that there is probably no elegant, effortless way to obtain this immense knowledge base. Rather, the bulk of the effort must (at least initially) be manual entry of assertion after assertion. </span><span class="co">[</span><span class="ot">@lenatCycMidtermReport1990</span><span class="co">]</span></span>
<span id="cb18-1668"><a href="#cb18-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1669"><a href="#cb18-1669" aria-hidden="true" tabindex="-1"></a><span class="fu">## Robots</span></span>
<span id="cb18-1670"><a href="#cb18-1670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1671"><a href="#cb18-1671" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELIZA</span></span>
<span id="cb18-1672"><a href="#cb18-1672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1673"><a href="#cb18-1673" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Science promised man power. But as so often happens when people are seduced by promises of power ... the price actually paid is servitude and impotence.</span></span>
<span id="cb18-1674"><a href="#cb18-1674" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1675"><a href="#cb18-1675" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- the book jacket to </span><span class="co">[</span><span class="ot">@weizenbaumComputerPowerHuman1976</span><span class="co">]</span></span>
<span id="cb18-1676"><a href="#cb18-1676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1677"><a href="#cb18-1677" aria-hidden="true" tabindex="-1"></a>ELIZA is well-known as the first popular chatbot. Fortunately, unlike the others like EPAM or SHRDLU, ELIZA is so famous that it is available everywhere. We will simply describe how ELIZA works. The detailed code and further information is online at <span class="co">[</span><span class="ot">ELIZAGEN</span><span class="co">](https://sites.google.com/view/elizagen-org/)</span>.</span>
<span id="cb18-1678"><a href="#cb18-1678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1679"><a href="#cb18-1679" aria-hidden="true" tabindex="-1"></a>According to the original paper <span class="co">[</span><span class="ot">@weizenbaumELIZAComputerProgram1966</span><span class="co">]</span>, ELIZA is essentially a word substitution program of minimal content, roleplaying as a Rogerian therapist. This role was chosen because a psychotherapist is one of the few roles that can pretend to know nothing about the world.</span>
<span id="cb18-1680"><a href="#cb18-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1681"><a href="#cb18-1681" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; If, for example, one were to tell a psychiatrist "I went for a long boat ride" and he responded "Tell me about boats", one would not assume that he knew nothing about boats, but that he had some purpose in so directing the subsequent conversation.</span></span>
<span id="cb18-1682"><a href="#cb18-1682" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1683"><a href="#cb18-1683" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@weizenbaumELIZAComputerProgram1966</span><span class="co">]</span></span>
<span id="cb18-1684"><a href="#cb18-1684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1685"><a href="#cb18-1685" aria-hidden="true" tabindex="-1"></a>ELIZA is programmable: It reads in an "ELIZA script" (a dialect of LISP) that looks like </span>
<span id="cb18-1686"><a href="#cb18-1686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1687"><a href="#cb18-1687" aria-hidden="true" tabindex="-1"></a><span class="in">```lisp</span></span>
<span id="cb18-1688"><a href="#cb18-1688" aria-hidden="true" tabindex="-1"></a><span class="in">(SORRY ((0) (PLEASE DON'T APOLOGIZE)</span></span>
<span id="cb18-1689"><a href="#cb18-1689" aria-hidden="true" tabindex="-1"></a><span class="in">            (APOLOGIES ARE NOT NECESSARY)</span></span>
<span id="cb18-1690"><a href="#cb18-1690" aria-hidden="true" tabindex="-1"></a><span class="in">            (WHAT FEELINGS DO YOU HAVE WHEN YOU APOLOGIZE)))</span></span>
<span id="cb18-1691"><a href="#cb18-1691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1692"><a href="#cb18-1692" aria-hidden="true" tabindex="-1"></a><span class="in">(EVERYONE 2 ((0 (* EVERYONE EVERYBOOY NOBODY NOONE) 0)</span></span>
<span id="cb18-1693"><a href="#cb18-1693" aria-hidden="true" tabindex="-1"></a><span class="in">             (REALLY, 2) (SURELY NOT 2) </span></span>
<span id="cb18-1694"><a href="#cb18-1694" aria-hidden="true" tabindex="-1"></a><span class="in">             (CAN YOU THINK OF ANYONE IN PARTICULAR) (WHO, FOR EXAMPLE)))</span></span>
<span id="cb18-1695"><a href="#cb18-1695" aria-hidden="true" tabindex="-1"></a><span class="in">(EVERYBODY 2 (= EVERYONE))</span></span>
<span id="cb18-1696"><a href="#cb18-1696" aria-hidden="true" tabindex="-1"></a><span class="in">(NOBOOY 2 (= EVERYONE))</span></span>
<span id="cb18-1697"><a href="#cb18-1697" aria-hidden="true" tabindex="-1"></a><span class="in">(NOONE 2 (= EVERYONE))</span></span>
<span id="cb18-1698"><a href="#cb18-1698" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1699"><a href="#cb18-1699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1700"><a href="#cb18-1700" aria-hidden="true" tabindex="-1"></a>This snippet shows several features of the ELIZA script. A script is a list of rules. Each rule begins with a keyword like <span class="in">`SORRY`</span>, followed by an optional rank, which determines how early the rule applies. A higher-ranked rule would beat out a lower-ranked rule. If there is no rank, then whatever appears first in the script applies. After that, there is a list of rewrite rules, which were essentially the same as regex expressions. For example, <span class="in">`(0 (* EVERYONE EVERYBOOY NOBODY NOONE) 0)`</span> would, in regex expression, be <span class="in">`(.*) (EVERYONE|EVERYBODY|NOBODY|NOONE) (.*)`</span>, and the rewrite rule <span class="in">`(REALLY, 2)`</span> then corresponds to <span class="in">`REALLY $2`</span>.</span>
<span id="cb18-1701"><a href="#cb18-1701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1702"><a href="#cb18-1702" aria-hidden="true" tabindex="-1"></a>Indeed, once we see this, we can write a short ELIZA in python:</span>
<span id="cb18-1703"><a href="#cb18-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1704"><a href="#cb18-1704" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-1705"><a href="#cb18-1705" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb18-1706"><a href="#cb18-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1707"><a href="#cb18-1707" aria-hidden="true" tabindex="-1"></a>rules <span class="op">=</span> {</span>
<span id="cb18-1708"><a href="#cb18-1708" aria-hidden="true" tabindex="-1"></a>    <span class="st">"everyone"</span>: {</span>
<span id="cb18-1709"><a href="#cb18-1709" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rank"</span>: <span class="dv">2</span>,</span>
<span id="cb18-1710"><a href="#cb18-1710" aria-hidden="true" tabindex="-1"></a>        <span class="st">"decomposition"</span>: <span class="vs">r"(.*) (everyone|everybody|nobody|noone) (.*)"</span>,</span>
<span id="cb18-1711"><a href="#cb18-1711" aria-hidden="true" tabindex="-1"></a>        <span class="st">"reassembly"</span>: [<span class="st">"Really $2?"</span>, <span class="st">"Surely not $2?"</span>, <span class="st">"Can you think of anyone in particular?"</span>]</span>
<span id="cb18-1712"><a href="#cb18-1712" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-1713"><a href="#cb18-1713" aria-hidden="true" tabindex="-1"></a>    <span class="st">"i am"</span>: {</span>
<span id="cb18-1714"><a href="#cb18-1714" aria-hidden="true" tabindex="-1"></a>         <span class="st">"rank"</span> : <span class="dv">1</span>,</span>
<span id="cb18-1715"><a href="#cb18-1715" aria-hidden="true" tabindex="-1"></a>         <span class="st">"decomposition"</span>: <span class="vs">r"(.*) i am (.*)"</span>,</span>
<span id="cb18-1716"><a href="#cb18-1716" aria-hidden="true" tabindex="-1"></a>         <span class="st">"reassembly"</span>: [<span class="st">"How long have you been $2?"</span>, <span class="st">"Do you believe you are $2?"</span>]</span>
<span id="cb18-1717"><a href="#cb18-1717" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-1718"><a href="#cb18-1718" aria-hidden="true" tabindex="-1"></a>    <span class="st">"sorry"</span>: {</span>
<span id="cb18-1719"><a href="#cb18-1719" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rank"</span>: <span class="dv">0</span>,</span>
<span id="cb18-1720"><a href="#cb18-1720" aria-hidden="true" tabindex="-1"></a>        <span class="st">"decomposition"</span>: <span class="vs">r"(.*) sorry (.*)"</span>,</span>
<span id="cb18-1721"><a href="#cb18-1721" aria-hidden="true" tabindex="-1"></a>        <span class="st">"reassembly"</span>: [<span class="st">"Please don't apologize."</span>, <span class="st">"Apologies are not necessary."</span>]</span>
<span id="cb18-1722"><a href="#cb18-1722" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-1723"><a href="#cb18-1723" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-1724"><a href="#cb18-1724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1725"><a href="#cb18-1725" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eliza_response(user_input):</span>
<span id="cb18-1726"><a href="#cb18-1726" aria-hidden="true" tabindex="-1"></a>    user_input <span class="op">=</span> user_input.lower()</span>
<span id="cb18-1727"><a href="#cb18-1727" aria-hidden="true" tabindex="-1"></a>    matched_rules <span class="op">=</span> []</span>
<span id="cb18-1728"><a href="#cb18-1728" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> keyword, rule <span class="kw">in</span> rules.items():</span>
<span id="cb18-1729"><a href="#cb18-1729" aria-hidden="true" tabindex="-1"></a>        match <span class="op">=</span> re.match(rule[<span class="st">"decomposition"</span>], user_input)</span>
<span id="cb18-1730"><a href="#cb18-1730" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> match:</span>
<span id="cb18-1731"><a href="#cb18-1731" aria-hidden="true" tabindex="-1"></a>            matched_rules.append(</span>
<span id="cb18-1732"><a href="#cb18-1732" aria-hidden="true" tabindex="-1"></a>               (rule[<span class="st">"rank"</span>], match, rule[<span class="st">"reassembly"</span>])</span>
<span id="cb18-1733"><a href="#cb18-1733" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb18-1734"><a href="#cb18-1734" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> matched_rules:</span>
<span id="cb18-1735"><a href="#cb18-1735" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply precedence, fallback to first match if ranks are equal</span></span>
<span id="cb18-1736"><a href="#cb18-1736" aria-hidden="true" tabindex="-1"></a>        matched_rules.sort(reverse<span class="op">=</span><span class="va">True</span>, key <span class="op">=</span> <span class="kw">lambda</span> x : x[<span class="dv">0</span>])</span>
<span id="cb18-1737"><a href="#cb18-1737" aria-hidden="true" tabindex="-1"></a>        _, match, reassembly_options <span class="op">=</span> matched_rules[<span class="dv">0</span>]</span>
<span id="cb18-1738"><a href="#cb18-1738" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> reassembly_options[<span class="dv">0</span>]</span>
<span id="cb18-1739"><a href="#cb18-1739" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> response</span>
<span id="cb18-1740"><a href="#cb18-1740" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"I am not sure I understand you fully."</span></span>
<span id="cb18-1741"><a href="#cb18-1741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1742"><a href="#cb18-1742" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb18-1743"><a href="#cb18-1743" aria-hidden="true" tabindex="-1"></a>    user_input <span class="op">=</span> <span class="bu">input</span>(<span class="st">"You: "</span>)</span>
<span id="cb18-1744"><a href="#cb18-1744" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> user_input.lower() <span class="op">==</span> <span class="st">"quit"</span>:</span>
<span id="cb18-1745"><a href="#cb18-1745" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb18-1746"><a href="#cb18-1746" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> eliza_response(user_input)</span>
<span id="cb18-1747"><a href="#cb18-1747" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"&gt; "</span> <span class="op">+</span> response)</span>
<span id="cb18-1748"><a href="#cb18-1748" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1749"><a href="#cb18-1749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1750"><a href="#cb18-1750" aria-hidden="true" tabindex="-1"></a>The full ELIZA also has a single MEMORY keyword which allows it to refer to what the user has said previously, though the core idea is there: it is regex parsing and rewriting.</span>
<span id="cb18-1751"><a href="#cb18-1751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1752"><a href="#cb18-1752" aria-hidden="true" tabindex="-1"></a>ELIZA was designed to be extensible, and extensions had been used by writing other ELIZA scripts. In the language of expert systems, ELIZA is a shell which can use the scripts as knowledge bases. See <span class="co">[</span><span class="ot">ELIZAGEN</span><span class="co">](https://sites.google.com/view/elizagen-org/resources)</span> for some references to using ELIZA in education, such as for teaching poetry and the 4-vector. <span class="co">[</span><span class="ot">@taylorAutomatedTutoringIts1968</span><span class="co">]</span></span>
<span id="cb18-1753"><a href="#cb18-1753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1754"><a href="#cb18-1754" aria-hidden="true" tabindex="-1"></a>Weizenbaum was dismayed to find that people treated ELIZA as if it understood what they said, and became increasly concerned with AI and started arguing against it in various ways. To us, the most interesting critique is that he rejected the philosophical position behind the Turing test, that to simulate understanding is to understand. After all, ELIZA knew nothing at all, yet people treated it as if it understood a lot. He pointed to Chomsky's work as a good example of theory-guided AI science, contrasted with the "it seems to work" AI performance. In Chomsky's terms, it is the contrast between *competence* and *performance*.</span>
<span id="cb18-1755"><a href="#cb18-1755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1756"><a href="#cb18-1756" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; After all, a plain typowriter in some sense mirrors the behavior of tic child (one types a question and gets no response whatever), but it does not help us to understand autism. A model must be made to stand or fall on the basis of its theory... The failure to make distinctions between descriptions, even those that "work," and theories accounts in large part for the fact that those who refuse to accept the view of man as machine have been put on the defensive.</span></span>
<span id="cb18-1757"><a href="#cb18-1757" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1758"><a href="#cb18-1758" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Recent advances in computer understanding of natural language offer an excellent case in point. Halle and Chomsky, to mention only the two with whom I am most familiar, have long labored on a theory of language which any model of language behavior must satisfy. Their aim is like that of the physicist who writes a set of differential equations that anyone riding a bicycle must satisfy. No physicist claims that a person need know, let alone be able to solve, such differential equations in order to become a competent cyclist. Neither do Halle and Chomsky claim that humans know or knowingly obey the rules they believe to govern language behavior. Halle and Chomsky also strive, as do physical theorists, to identify the constants and parameters of their theories with components of reality. Workers in computer comprehension of natural language operate in what is usually called performance mode. It is as if they are building machines that can ride bicycles by following heuristics like "if you feel a displacement to the left, move your weight to the left."</span></span>
<span id="cb18-1759"><a href="#cb18-1759" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1760"><a href="#cb18-1760" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@weizenbaumImpactComputerSociety1972</span><span class="co">]</span></span>
<span id="cb18-1761"><a href="#cb18-1761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1762"><a href="#cb18-1762" aria-hidden="true" tabindex="-1"></a>So far, this is fairly standard critique of a performance-over-competence culture in AI. However, Weizenbaum was driven by a moral urgency as he looked into the deeper source for this mistake, and finding a moral-philosophical error:</span>
<span id="cb18-1763"><a href="#cb18-1763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1764"><a href="#cb18-1764" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>There are multiple categories of things.</span>
<span id="cb18-1765"><a href="#cb18-1765" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Humans (and perhaps sufficiently human-like objects, like chimpanzees) are the only category where morality makes sense.</span>
<span id="cb18-1766"><a href="#cb18-1766" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>If $x$ is an object in the human-like category, then asking "Is $x$ a meat machine?" is a category error, of treating objects in the human category as if they are objects in the technological category. The right answer is to reject this "technological question" and ask a "human question" instead, like "What is wrong with you to ask such a question?".</span>
<span id="cb18-1767"><a href="#cb18-1767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1768"><a href="#cb18-1768" aria-hidden="true" tabindex="-1"></a>He was particularly incensed by Kenneth Colby's DOCTOR program, which was similar to ELIZA, except intended for production. Colby was a psychiatrist who saw the plight of patients who saw therapists maybe once a month -- if lucky. He argued that if an artificial DOCTOR could provide some help, it is better than nothing, and some people agreed.</span>
<span id="cb18-1769"><a href="#cb18-1769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1770"><a href="#cb18-1770" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; How is Al bad? Are we hurting people by doing it? I don't know anyone who has suffered from it yet. (In fact, despite Weizenbaum's arguments about Colby and automated psychotherapy, I remember a non-speaking adult and several autistic children who began to talk because they were talking to Colby's non-threatening machine.)</span></span>
<span id="cb18-1771"><a href="#cb18-1771" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1772"><a href="#cb18-1772" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@schankWeizenbaumControversy1976</span><span class="co">]</span></span>
<span id="cb18-1773"><a href="#cb18-1773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1774"><a href="#cb18-1774" aria-hidden="true" tabindex="-1"></a>To Weizenbaum, this is dehumanizing and disrespectful, a moral error, and whether it actually helps patients improve -- as measured by quantitative evidence like whether non-verbal people started speaking again -- is irrelevant. Thinking that it is a relevant question just shows confusion of the performance of therapy with the competence of therapy, and a deeply technological mentality:</span>
<span id="cb18-1775"><a href="#cb18-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1776"><a href="#cb18-1776" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The question "Is the brain merely a meat machine?", which Simon puts in a so much more sophisticated form, is typical of the kind of question formulated by, indeed formulatable only by, a technological mentality. Once it is accepted as legitimate, arguments as to what a computer can or cannot do "in principle" begin to rage and themselves become legitimate. But the legitimacy of the technological question -- for example, is human behavior to be understood either in terms of the organization or of the physical properties of "components" - -need not be admitted in the first instance. A human question can be asked instead. Indeed, we might begin by asking what has already become of "the whole man" when he can conceive of computers organized in his own image... Whoever dictates the questions in large part determines the answers. In that sense, technology, and especially computer technology, has become a self-fulfilling nightmare... We must come to see that technology is our dream and that we must ultimately decide how it is to end.</span></span>
<span id="cb18-1777"><a href="#cb18-1777" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1778"><a href="#cb18-1778" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@weizenbaumImpactComputerSociety1972</span><span class="co">]</span></span>
<span id="cb18-1779"><a href="#cb18-1779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1780"><a href="#cb18-1780" aria-hidden="true" tabindex="-1"></a>He presented his full thesis in a book *Computer Power and Human Reason: From Judgment to Calculation* (1976), with the following theses:</span>
<span id="cb18-1781"><a href="#cb18-1781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1782"><a href="#cb18-1782" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Computers might be intelligent, but they will never be wise (or to feel emotions, to love, etc). To "calculate" requires just intelligence, but to "judge" requires wisdom.</span>
<span id="cb18-1783"><a href="#cb18-1783" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The development of AI threatens to replace judgment with calculation, which will destroy human dignity. This replacement of judgment with calculation is an absurd political ideology, and must be resisted politically.</span>
<span id="cb18-1784"><a href="#cb18-1784" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>If, however, we do not resist, but keep following this political ideology, we would end up with the obviously absurd conclusion that "the brain is merely a meat machine". *Reductio ad absurdum*.</span>
<span id="cb18-1785"><a href="#cb18-1785" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>This dangerous development of AI did not come from a wise scientific project of understanding how human intelligence works, but from a megalomaniac, obsessive-compulsive desire to make machine parodies of human behavior. The method of AI development was heuristic, empirical, a kind of "I wonder what the machine would do if I write this program...", without a scientific theory.</span>
<span id="cb18-1786"><a href="#cb18-1786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1787"><a href="#cb18-1787" aria-hidden="true" tabindex="-1"></a>When the book came out, it received many reviews and counter-reviews, resulting in a "Weizenbaum controversy". I found this reply by Weizenbaum the funniest:</span>
<span id="cb18-1788"><a href="#cb18-1788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1789"><a href="#cb18-1789" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I have in mind also the teaching urged on us by some leaders of the AI community that there is nothing unique about the human species, that in fact, the embrace of the illusion of human uniqueness amounts to a kind of species prejudice and is unworthy of enlightened intellectuals. If we find nothing abhorrent in the use of artificially sustained, disembodied animal brains as computer components, and if there is nothing that uniquely distinguishes the human species from animal species, then -- need I spell out where that idea leads?</span></span>
<span id="cb18-1790"><a href="#cb18-1790" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1791"><a href="#cb18-1791" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; quoted in </span><span class="co">[</span><span class="ot">@mccorduckMachinesWhoThink2004, page 370</span><span class="co">]</span></span>
<span id="cb18-1792"><a href="#cb18-1792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1793"><a href="#cb18-1793" aria-hidden="true" tabindex="-1"></a>Apparently Weizenbaum, in his human-centered wisdom, rejected Darwinism as well. In any case, his critiques seem perennial,<span class="ot">[^weizenbaum-nightmare]</span> though irrelevant for the further evolution of technology, which is exactly the techno-drenched nightmare he was trying to warn us away from, to no effect. We sleepwalk yet deeper into this nightmare.</span>
<span id="cb18-1794"><a href="#cb18-1794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1795"><a href="#cb18-1795" aria-hidden="true" tabindex="-1"></a><span class="ot">[^weizenbaum-nightmare]</span>:</span>
<span id="cb18-1796"><a href="#cb18-1796" aria-hidden="true" tabindex="-1"></a>    Witness some modern critiques of AI, especially from the Critical Humanities. Though a few critical humanists really were critical *of* humanity, which brings the amusing prospect of *another* nightmare of Weizenbaum, this time from the opposite direcion of "We must come to see that humanity is our dream and that we must ultimately decide how it is to end."</span>
<span id="cb18-1797"><a href="#cb18-1797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1798"><a href="#cb18-1798" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; As the archaeology of our thought easily shows, man is an invention of recent date. And one perhaps nearing its end. If those arrangements were to disappear as they appeared, if some event of which we can at the moment do no more than sense the possibility – without knowing either what its form will be or what it promises – were to cause them to crumble, as the ground of Classical thought did, at the end of the eighteenth century, then one can certainly wager that man would be erased, like a face drawn in sand at the edge of the sea.</span></span>
<span id="cb18-1799"><a href="#cb18-1799" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-1800"><a href="#cb18-1800" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@foucaultOrderThings2012, page 422]</span></span>
<span id="cb18-1801"><a href="#cb18-1801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1802"><a href="#cb18-1802" aria-hidden="true" tabindex="-1"></a><span class="fu">### SHRDLU {#sec-shrdlu}</span></span>
<span id="cb18-1803"><a href="#cb18-1803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1804"><a href="#cb18-1804" aria-hidden="true" tabindex="-1"></a>During the early days, the only robots were "<span class="co">[</span><span class="ot">Unimates</span><span class="co">](https://en.wikipedia.org/wiki/Unimate)</span>", arms blindly performing preprogrammed motions, but there had always been the dream and hope of a robot that can see and act, wih proper hand-eye coordination. Perhaps even to speak.</span>
<span id="cb18-1805"><a href="#cb18-1805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1806"><a href="#cb18-1806" aria-hidden="true" tabindex="-1"></a>By writing the famous SHRDLU, Terry Winograd took a small step towards this dream for his PhD in mathematics during 1968--1970, and published it in a long journal article <span class="co">[</span><span class="ot">@winogradUnderstandingNaturalLanguage1972</span><span class="co">]</span>. Again like ELIZA, it is better played than explained, so please play with it now. In the program, the user carries on a conversation with the computer, moving objects, naming collections and querying the state of a simplified "blocks world", essentially a virtual box filled with different blocks. It totaled ~500 KB of LISP code. I have saved the <span class="co">[</span><span class="ot">original code</span><span class="co">](code/SHRDLU.zip)</span> for safe-keeping.<span class="ot">[^shrdlu-original-code]</span></span>
<span id="cb18-1807"><a href="#cb18-1807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1808"><a href="#cb18-1808" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shrdlu-original-code]</span>: </span>
<span id="cb18-1809"><a href="#cb18-1809" aria-hidden="true" tabindex="-1"></a>    I really don't recommend reading it. Though it was in a dialect of LISP, it was written in the impenetrable style of assembly code. I will just write some amusing discoveries in the code base:</span>
<span id="cb18-1810"><a href="#cb18-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1811"><a href="#cb18-1811" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; it occupies around 200k of core (caution: indiscriminately running a job that big in the middle of the day is a good way to make enemies!!!!! Alway check the level of system usage before loading...)</span></span>
<span id="cb18-1812"><a href="#cb18-1812" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt;</span></span>
<span id="cb18-1813"><a href="#cb18-1813" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; -- `mannew` from the SHRDLU archive</span></span>
<span id="cb18-1814"><a href="#cb18-1814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1815"><a href="#cb18-1815" aria-hidden="true" tabindex="-1"></a><span class="in">    The original SHRDLU had some manual fixes in the compiled assembly code (!). Terry Winograd's first research student rewrote much of SHRDLU so that it is portable. Some people sent letters (physical letters!) to request the code, and they would duly mail it out (by magnetic tape?). As one can imagine, only a few dozen source codes were mailed out, according to [SHRDLU resurrection](https://web.archive.org/web/20171117063022/http://www.semaphorecorp.com/misc/shrdlu.html) (created in 2002, and last updated on 2013-08-22).</span></span>
<span id="cb18-1816"><a href="#cb18-1816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1817"><a href="#cb18-1817" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The result of typing "Will you please stack up both of the red blocks and either a green cube or a pyramid?" [@winogradUnderstandingNaturalLanguage1972, figure 5]</span><span class="co">](figure/SHRDLU.png)</span></span>
<span id="cb18-1818"><a href="#cb18-1818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1819"><a href="#cb18-1819" aria-hidden="true" tabindex="-1"></a>The main part of SHRDLU has the following parts:</span>
<span id="cb18-1820"><a href="#cb18-1820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1821"><a href="#cb18-1821" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A natural language understanding (NLU) module, which uses <span class="in">`DICTIONARY`</span>, <span class="in">`GRAMMAR`</span>, <span class="in">`SEMANTICS`</span>, and so on, to parse user input into a logical expression.</span>
<span id="cb18-1822"><a href="#cb18-1822" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`PLANNER`</span>, which takes the state of the world (as a logical expression) and the user input (as another logical expression), and compute a motion plan for the simulated arm.</span>
<span id="cb18-1823"><a href="#cb18-1823" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`MOVER`</span>, which simulates a robot arm. It has only three kinds of commands: <span class="in">`MOVETO`</span>, <span class="in">`GRASP`</span>, <span class="in">`UNGRASP`</span>.</span>
<span id="cb18-1824"><a href="#cb18-1824" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Blocks world simulator.</span>
<span id="cb18-1825"><a href="#cb18-1825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1826"><a href="#cb18-1826" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Architecture of SHRDLU. The NLU module takes up most of the region on the right.[@winogradUnderstandingNaturalLanguage1972, figure 1]</span><span class="co">](figure/SHRDLU_architecture.png)</span></span>
<span id="cb18-1827"><a href="#cb18-1827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1828"><a href="#cb18-1828" aria-hidden="true" tabindex="-1"></a>The key parts of the system are the NLU and the <span class="in">`PLANNER`</span>.</span>
<span id="cb18-1829"><a href="#cb18-1829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1830"><a href="#cb18-1830" aria-hidden="true" tabindex="-1"></a>The <span class="in">`PLANNER`</span>, just like the GPS of Simon and Newell, starts with the goal as the root node, and searches for a chain of logical operations that would eventually lead to a leaf node equal to the current state of the world.<span class="ot">[^shrdlu-logic]</span> This was called "backward chaining", though it was the same as the means-end analysis of GPS. It then stores this chain of logical operations, and converts it into a sequence of <span class="in">`MOVER`</span> commands and sends them to <span class="in">`MOVER`</span>. When asked "Why did you do it?", it would convert this plan into an explanation in English.</span>
<span id="cb18-1831"><a href="#cb18-1831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1832"><a href="#cb18-1832" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shrdlu-logic]: </span>For a detailed exposition of how SHRDLU-like AI systems perform planning by symbolic logic, see <span class="co">[</span><span class="ot">@russellArtificialIntelligenceModern2021, chapter 11.2</span><span class="co">]</span>.</span>
<span id="cb18-1833"><a href="#cb18-1833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1834"><a href="#cb18-1834" aria-hidden="true" tabindex="-1"></a>The NLU module parses the sentence into a tree by "systemic grammar" which while different from Chomskyan generative grammar in details, is the same in spirit.</span>
<span id="cb18-1835"><a href="#cb18-1835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1836"><a href="#cb18-1836" aria-hidden="true" tabindex="-1"></a>For example, "Harry slept on the porch after he gave Alice the jewels." is parsed to:</span>
<span id="cb18-1837"><a href="#cb18-1837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1838"><a href="#cb18-1838" aria-hidden="true" tabindex="-1"></a><span class="in">```lisp</span></span>
<span id="cb18-1839"><a href="#cb18-1839" aria-hidden="true" tabindex="-1"></a><span class="in">(#SLEEP :HARRY :RELl)</span></span>
<span id="cb18-1840"><a href="#cb18-1840" aria-hidden="true" tabindex="-1"></a><span class="in">(#LOCATION :REL1 :PORCH)</span></span>
<span id="cb18-1841"><a href="#cb18-1841" aria-hidden="true" tabindex="-1"></a><span class="in">(#GIVE :HARRY :ALICE :JEWELS :REL2)</span></span>
<span id="cb18-1842"><a href="#cb18-1842" aria-hidden="true" tabindex="-1"></a><span class="in">(#AFTER :REL1 :REL2)</span></span>
<span id="cb18-1843"><a href="#cb18-1843" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1844"><a href="#cb18-1844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1845"><a href="#cb18-1845" aria-hidden="true" tabindex="-1"></a>Instead of analyzing syntax and semantics independently, SHRDLU combines them closely to determine the correct parse of a sentence. For example, a user input "Pick up the red cube." would only be parsed correctly if SHRDLU actually checks the state of the world that there really is exactly one <span class="in">`(#SHAPE :CUBE :REL1) (#COLOR :RED :REL1)`</span>. If there are two, it would then reply "I don't know which one you meant." and if there are none, it would reply "I can't pick up a nonexistent object.".</span>
<span id="cb18-1846"><a href="#cb18-1846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1847"><a href="#cb18-1847" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A blocks world much simpler than the one used by SHRDLU, along with its logical representation. Combination of [@russellArtificialIntelligenceModern2021, figure 11.3] and [@russellArtificialIntelligenceModern2021, figure 11.4].</span><span class="co">](figure/blocks_world_logic.png)</span></span>
<span id="cb18-1848"><a href="#cb18-1848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1849"><a href="#cb18-1849" aria-hidden="true" tabindex="-1"></a>SHRDLU was a milestone, and perhaps it was too good to be true. Like the Georgetown--IBM demo, it attracted and impressed, but led to inevitable disappointment when the success failed to scale up. Why was there a hype in the first place, though?</span>
<span id="cb18-1850"><a href="#cb18-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1851"><a href="#cb18-1851" aria-hidden="true" tabindex="-1"></a>In 1991, as the expert systems hype was dying down, Schank wrote an essay trying to diagnose the source of the hype. One source, he argued, was the focus on designing a good theoretical framework that is verified on small scale demos and "microworlds", and expect it to simply scale up.</span>
<span id="cb18-1852"><a href="#cb18-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1853"><a href="#cb18-1853" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Nevertheless, there were otherwise intelligent people claiming that Winograd's (1972) SHRDLU program that worked on 31 examples had solved the natural language problem or that MYCIN (Shortliffe 1976) had solved the problem of getting expertise into a computer. Prior to 1982, it is safe to say that no one had really tried to build an AI program that was more than simply suggestive of what could be built. AI had a real definition then, and it was the gee whiz definition given earlier.</span></span>
<span id="cb18-1854"><a href="#cb18-1854" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1855"><a href="#cb18-1855" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@schankWheresAI1991</span><span class="co">]</span></span>
<span id="cb18-1856"><a href="#cb18-1856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1857"><a href="#cb18-1857" aria-hidden="true" tabindex="-1"></a>Winograd in an interview shortly afterwards concurred:</span>
<span id="cb18-1858"><a href="#cb18-1858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1859"><a href="#cb18-1859" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; WINOGRAD: Well, implementation and product are two stages. That is, implementation was always there as the coin of the realm. Implementation meant something you could show off. It didn't mean something that somebody else could use... there was no attempt to get it to the point where you could actually hand it to somebody and they could use it to move blocks around... Pressure was for something you could demo... I think AI suffered from that a lot, because it led to "Potemkin villages", things which -- for the things they actually did in the demo looked good, but when you looked behind that there wasn't enough structure to make it really work more generally.</span></span>
<span id="cb18-1860"><a href="#cb18-1860" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1861"><a href="#cb18-1861" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; NORBERG: Is that a question of size, or is it a question of the idea itself - the idea's too small?</span></span>
<span id="cb18-1862"><a href="#cb18-1862" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1863"><a href="#cb18-1863" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; WINOGRAD: The idea of --?</span></span>
<span id="cb18-1864"><a href="#cb18-1864" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1865"><a href="#cb18-1865" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; NORBERG: Well, let's say the ideas behind the blocks world, SHRDLU.</span></span>
<span id="cb18-1866"><a href="#cb18-1866" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1867"><a href="#cb18-1867" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; WINOGRAD: Well, I think it was based on a presupposition -- at least an attitude -- that making things work in the large, really working, was just like getting a demo except more details to be filled in. That is, if you had a basic idea and you could show it worked on something then it was just a sort of grubby, detail work to fill in all, you know, the hundreds of entries you would need to make it work for real. But that -- an idea -- and this is tied to the top-down, rationalistic way of approaching it, right. An idea which said, "here's a nice logical way this should work -- would work in practice if you just went far enough with the details." And I think that's been a problem with AI all along. It's true in problem-solving, right? Problem-solving, as conceived by Newell and Simon and developed, and so on, has a certain realm of applicability but it's very different from, you know, you coming to me and saying, "I have a problem. Would you help me solve it?", in terms of -- to take the most obvious things - the hard part is figuring out what the problem space is, not searching it.</span></span>
<span id="cb18-1868"><a href="#cb18-1868" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1869"><a href="#cb18-1869" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">An Interview with Terry Allen Winograd (1991-12-11)</span><span class="co">](https://conservancy.umn.edu/server/api/core/bitstreams/a0a8ffa6-0149-4606-88e8-4eec0690d794/content#page=7)</span></span>
<span id="cb18-1870"><a href="#cb18-1870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1871"><a href="#cb18-1871" aria-hidden="true" tabindex="-1"></a>Philosophically, it seems like the rational methodology of theoretical physics: One has a good theory, which can be checked in a precise experiment in a vacuum. If the observation is as predicted, then one assumes it would simply scale up. Similarly, if a theory, such as neural networks, cannot perform something as simple as testing for connectivity (as <span class="co">[</span><span class="ot">Minsky and Papert argued</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/reading-perceptron-book/index.html#chapter-13)</span>), then that theory is disproven. In this case, systemic grammar was the linguistic theory to be tested, and the blocks world of SHRDLU constituted a laboratory proof. That it never scaled up was a shame, but not something people expected back then.</span>
<span id="cb18-1872"><a href="#cb18-1872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1873"><a href="#cb18-1873" aria-hidden="true" tabindex="-1"></a>This focus on toy models, "microworlds", and proofs of concepts, was prevalent, and indeed the best way to obtain knowledge, if one accepts the rational methodology.</span>
<span id="cb18-1874"><a href="#cb18-1874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1875"><a href="#cb18-1875" aria-hidden="true" tabindex="-1"></a><span class="al">![Marvin Minsky and Builder the robot in a physical blocks world, which could use a camera to detect the shape of blocks in one pile, and replicate it with blocks in another pile. It was a microworld for studying hand-eye coordination. It's hard to tell who is having more fun here.](figure/minsky_robot_arm_blocks.jpg)</span></span>
<span id="cb18-1876"><a href="#cb18-1876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1877"><a href="#cb18-1877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1878"><a href="#cb18-1878" aria-hidden="true" tabindex="-1"></a>We know better now. The actual trajectory of AI has destroyed faith this methodology, but why? It is still mysterious, and many still argue that we should not accept this.</span>
<span id="cb18-1879"><a href="#cb18-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1880"><a href="#cb18-1880" aria-hidden="true" tabindex="-1"></a><span class="fu">### Shakey {#sec-shakey}</span></span>
<span id="cb18-1881"><a href="#cb18-1881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1882"><a href="#cb18-1882" aria-hidden="true" tabindex="-1"></a>In 1964-04, the Stanford Research Institute (SRI) submitted a proposal to ARPA to build a robot that could move through a cluttered room using its own cameras, with the unassuming name "Intelligent Automata" so that it did not appear to be a sci-fi project. It was later renamed to "Intelligent Automata to Reconnaissance".<span class="ot">[^shakey-reconnaissance]</span> This resulted in Shakey the robot, developed during 1966--1972. Despite the deliberately unassuming name, it had the ambition of integrating all the subfields of AI as then understood into a single package.</span>
<span id="cb18-1883"><a href="#cb18-1883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1884"><a href="#cb18-1884" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; to develop an experimental test bed for integrating all the subfields of artificial intelligence as then understood. SRI wanted to integrate in one system representation and reasoning, planning, machine learning, computer vision, natural language understanding, even speech understanding, for the first time.</span></span>
<span id="cb18-1885"><a href="#cb18-1885" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1886"><a href="#cb18-1886" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@kuipersShakeyConceptionHistory2017</span><span class="co">]</span></span>
<span id="cb18-1887"><a href="#cb18-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1888"><a href="#cb18-1888" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shakey-reconnaissance]: </span>Annoyingly, I have checked all the official reports -- the interim reports <span class="co">[</span><span class="ot">1</span><span class="co">](https://web.archive.org/web/20060316080944/http://www.ai.sri.com/pubs/files/rosen66-p5953-interim1.pdf)</span>, <span class="co">[</span><span class="ot">2</span><span class="co">](https://web.archive.org/web/20060316081210/http://www.ai.sri.com/pubs/files/rosen67-p5953-interim2.pdf)</span>, <span class="co">[</span><span class="ot">3</span><span class="co">](https://web.archive.org/web/20060316081226/http://www.ai.sri.com/pubs/files/rosen67-p5953-interim3.pdf)</span>, <span class="co">[</span><span class="ot">4</span><span class="co">](https://web.archive.org/web/20060316081638/http://www.ai.sri.com/pubs/files/nilsson68-p5953-interim4.pdf)</span>, and the <span class="co">[</span><span class="ot">final report</span><span class="co">](https://web.archive.org/web/20060316081339/http://www.ai.sri.com/pubs/files/nilsson68-p5953-final.pdf)</span>, and *none* of them told me what it is supposed to reconnoiter for!</span>
<span id="cb18-1889"><a href="#cb18-1889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1890"><a href="#cb18-1890" aria-hidden="true" tabindex="-1"></a>Even before it was finished, it became a celebrity. The *Life* magazine called Shakey the "first electronic person" <span class="co">[</span><span class="ot">in 1970</span><span class="co">](https://gwern.net/doc/reinforcement-learning/robot/1970-darrach.pdf)</span>.<span class="ot">[^shakey-life-magazine]</span> A <span class="co">[</span><span class="ot">1972 documentary</span><span class="co">](https://www.youtube.com/watch?v=GmU7SimFkpU)</span> shows its operations, in which one can see its shaking motion, and how it stops after each straight-line motion. <span class="co">[</span><span class="ot">@stanfordresearchinstituteShakeyExperimentRobot1972</span><span class="co">]</span> The shaking is due to the springs in two wheels, and the stopping is to wait for computer vision and planning to finish, and for the shaking to stop. Early during development, it was tethered. A bit later, the tether was removed, and the researchers found it to mysteriously rotate once in a while. It turned out to be a vestigial subroutine meant to untwist the tether. (Peter Hart, at 05:55)</span>
<span id="cb18-1891"><a href="#cb18-1891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1892"><a href="#cb18-1892" aria-hidden="true" tabindex="-1"></a><span class="ot">[^shakey-life-magazine]</span>:</span>
<span id="cb18-1893"><a href="#cb18-1893" aria-hidden="true" tabindex="-1"></a>    This article was considered sensational and misleading by most of the people who worked on Shakey.</span>
<span id="cb18-1894"><a href="#cb18-1894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1895"><a href="#cb18-1895" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; an article that was more than science fiction: the AI community feels it was victimized in this instance by outright lies. Said Rosen, *He came here and all of us spent a great deal of time being very honest and candid with him. Then he didn’t present the whole story. He picked the sensational things and left out the others...* Bert Raphael, who had spent a lot of time with Darrach, goes further: *...He wrote it as if he’d seen many things he never saw, and wrote about seeing Shakey going down the hall and hurrying from office to office, when in fact all the time he’d been here we were in the process of changing one computer system to another and never demonstrated anything for him. There were many direct quotes that were imaginary or completely out of context.*</span></span>
<span id="cb18-1896"><a href="#cb18-1896" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-1897"><a href="#cb18-1897" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@mccorduckMachinesWhoThink2004, page 273]</span></span>
<span id="cb18-1898"><a href="#cb18-1898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1899"><a href="#cb18-1899" aria-hidden="true" tabindex="-1"></a>::: {#fig-shakey layout-ncol=2}</span>
<span id="cb18-1900"><a href="#cb18-1900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1901"><a href="#cb18-1901" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The original design of Shakey. It had two arms that got cancelled. Dimensions: `56''L; 35'' W; 57'' H`. [Source](https://www.computerhistory.org/revolution/artificial-intelligence-robotics/13/289/1239).</span><span class="co">](figure/Shakey_original.png)</span></span>
<span id="cb18-1902"><a href="#cb18-1902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1903"><a href="#cb18-1903" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Shakey the robot in 1972. Standing *square*ly away from the uncanny valley, it is almost cute in its boxy appearance. Just watching it makes me want to make "beep-boop" sound. [Source](https://en.wikipedia.org/wiki/File:SRI_Shakey_with_callouts.jpg)</span><span class="co">](figure/SRI_Shakey_with_callouts.jpg)</span></span>
<span id="cb18-1904"><a href="#cb18-1904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1905"><a href="#cb18-1905" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Schematic cleaned diagram of Shakey. [@slocumRobotExcessMachine2024, figure 9]</span><span class="co">](figure/Shakey_overview_1.png)</span></span>
<span id="cb18-1906"><a href="#cb18-1906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1907"><a href="#cb18-1907" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Why Shakey shakes: Shakey is moved by two diagonal drive wheels, and the other two diagonal wheels have springs on them to allow Shakey to go up slopes. Whenever it starts and stops, it shakes back and forth across the diagonal. [@slocumRobotExcessMachine2024, figure 10]</span><span class="co">](figure/Shakey_overview_2.png)</span></span>
<span id="cb18-1908"><a href="#cb18-1908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1909"><a href="#cb18-1909" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@kuipersShakeyConceptionHistory2017, figure 4</span><span class="co">]</span>](figure/Shakey_predicate_calculus.png)</span>
<span id="cb18-1910"><a href="#cb18-1910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1911"><a href="#cb18-1911" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@kuipersShakeyConceptionHistory2017, figure 6</span><span class="co">]</span>](figure/Shakey_hierarchical_planning.png)</span>
<span id="cb18-1912"><a href="#cb18-1912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1913"><a href="#cb18-1913" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Ideally smoothed path (A), planned path (B), and actual shakey path (illustrative only) (C). [@slocumRobotExcessMachine2024, figure 11]</span><span class="co">](figure/Shakey_path_planning.png)</span></span>
<span id="cb18-1914"><a href="#cb18-1914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1915"><a href="#cb18-1915" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1916"><a href="#cb18-1916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1917"><a href="#cb18-1917" aria-hidden="true" tabindex="-1"></a>It was a fine example of logical AI, and several classical algorithms were developed specifically for it, including the A* search for pathfinding on a graph, the Hough transform for its vision; and the visibility graph method specifically for pathfinding in a Euclidean plane with obstacles. Like SHRDLU, it represented the state of the world and the goal state using first-order predicate logic, and planned by logic programming (mostly backward chaining and <span class="co">[</span><span class="ot">Robinson resolution</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Resolution_(logic))). It also understood natural English commands. It had a primitive level of rote learning, in the sense that it memorized previous plans ("macros"), which could then be used as single components in later plans. These all worked and still continue to work.</span>
<span id="cb18-1918"><a href="#cb18-1918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1919"><a href="#cb18-1919" aria-hidden="true" tabindex="-1"></a>Shakey also demonstrated the same lesson of expert systems against the generic logical AI approach:</span>
<span id="cb18-1920"><a href="#cb18-1920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1921"><a href="#cb18-1921" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Shakey showed that you could not, for example, take a graph-searching algorithm from a chess program and hand-printed-character-recognizing algorithm from a vision program and, having attached them together, expect the robot to understand the world. As Raphael put it, there are serious questions about the interaction between knowledge in different domains... the overwhelming message--not always recognized by those doing the robotics work themselves--was that general principles of intelligence were insufficient... there was considerable resistance to that idea. Edward Feigenbaum and his </span><span class="sc">\[</span><span class="at">DENDRAL group</span><span class="sc">\]</span><span class="at"> were coming to the same conclusion, but they felt very lonely in that discovery. Joel Moses, whose thesis had relied on expertise instead of general principles, remembers the frustration of trying to expound that point of view. "Papert almost cried once," Moses remembers. "He said, 'How can you get those guys to listen?' That was 1966, maybe 1968." But the robots seemed to prove the view beyond a shadow of a doubt.</span></span>
<span id="cb18-1922"><a href="#cb18-1922" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1923"><a href="#cb18-1923" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mccorduckMachinesWhoThink2004, page 269--276</span><span class="co">]</span></span>
<span id="cb18-1924"><a href="#cb18-1924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1925"><a href="#cb18-1925" aria-hidden="true" tabindex="-1"></a>But since AI is whatever doesn't work yet, we will focus on what barely worked: its vision. Shakey's natural habitat was a toy model of an office space, designed specifically to be as easy to see as possible. If computer vision could not approach the real world, the real world could approach computer vision.</span>
<span id="cb18-1926"><a href="#cb18-1926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1927"><a href="#cb18-1927" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The project team was well aware of Shakey’s limited mechanical and sensory capabilities, and designed a correspondingly simple experimental environment consisting of half a dozen rooms populated with large, geometric blocks. The blocks were painted so that edges were visible to the low-resolution TV camera, while still being sufficiently reflective for our homemade laser rangefinder to work. We also used dark baseboards, again for visibility, and exploited them to update the position error that accumulated in the dead reckoning process that relied on Shakey’s stepping motors.</span></span>
<span id="cb18-1928"><a href="#cb18-1928" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1929"><a href="#cb18-1929" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@kuipersShakeyConceptionHistory2017</span><span class="co">]</span></span>
<span id="cb18-1930"><a href="#cb18-1930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1931"><a href="#cb18-1931" aria-hidden="true" tabindex="-1"></a>Shakey's vision system was "scene analysis". In short, it analyzes a picture as a geometer would expect. It starts by discovering edges, then performs some computational geometry on them to recover outlines of basic shapes, such as cubes, then fills in the faces, then fills in the bodies between the faces. The algorithm had to do something clever to deal with occlusions. In the end, a complete 3D scene populated with 3D objects is recovered.</span>
<span id="cb18-1932"><a href="#cb18-1932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1933"><a href="#cb18-1933" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Scene analysis. Figure from [@guzmanDecompositionVisualScene1968]</span><span class="co">](figure/guzman_1968.png)</span></span>
<span id="cb18-1934"><a href="#cb18-1934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1935"><a href="#cb18-1935" aria-hidden="true" tabindex="-1"></a>After converting a grayscale image to a line drawing, the system uses a "formal grammar" of line drawings (look up "Huffman--Clowes scene labeling") to identify 4 kinds of objects: wedge, cube, wall, floor. For example, <span class="in">`Wedge = TRIANGLE OR TRIANGLE + QUAD`</span>, while <span class="in">`Cube = QUAD + QUAD + QUAD`</span>. The more grammatical rules, the more object classes the system could identify.</span>
<span id="cb18-1936"><a href="#cb18-1936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1937"><a href="#cb18-1937" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The same 4 scenes in: digitized grayscale image, divided into sets of equal grayscale level, merged into regions, converted to line drawings. [@briceSceneAnalysisUsing1970, figure 7, figure 8, figure 12, figure 14]</span><span class="co">](figure/Shakey_vision.png)</span></span>
<span id="cb18-1938"><a href="#cb18-1938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1939"><a href="#cb18-1939" aria-hidden="true" tabindex="-1"></a>One might question why they decided to identy only 4 kinds of objects. The reality is that it is simply very difficult to perform scene analysis on anything more complicated. Indeed, in a 1972 PhD thesis, David Waltz extended scene analysis to shadows, and had to catalog "thousands of junctions, in order to deal with cracks and shadows". <span class="co">[</span><span class="ot">@waltzSheddingLightShadows1972, page 48; nilssonQuestArtificialIntelligence2009, page 185</span><span class="co">]</span></span>
<span id="cb18-1940"><a href="#cb18-1940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1941"><a href="#cb18-1941" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The junction rules used in analyzing a cube with a shadow. [@waltzSheddingLightShadows1972, page 54]</span><span class="co">](figure/Waltz_1972_scene_analysis.png)</span></span>
<span id="cb18-1942"><a href="#cb18-1942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1943"><a href="#cb18-1943" aria-hidden="true" tabindex="-1"></a>Still, since Shakey's computer ran at just 0.3 MIPS, it was doing its best. As compute improves, the best paradigm changes from the logical approach, to the statistical, to the neural. This was another early instance of the bitter lesson.</span>
<span id="cb18-1944"><a href="#cb18-1944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1945"><a href="#cb18-1945" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A particular example computer vision system `ISUPPOSEW` (1971) that processes the scene as a list of line segments. I picked this mainly for its aesthetic quality. [@raphaelResearchApplicationsArtificial1971, page 197]</span><span class="co">](figure/ISUPPOSEW.png)</span></span>
<span id="cb18-1946"><a href="#cb18-1946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1947"><a href="#cb18-1947" aria-hidden="true" tabindex="-1"></a>Other than the difficulty of programming (enumerating thousands of rules can't be fun), it was also very brittle. Moravec reports an early 1977 robot that featurizes camera images taken between two steps in the robot trajectory and compares them to triangulate the scene. It only worked on very clean and uncluttered scenes with sharp images:</span>
<span id="cb18-1948"><a href="#cb18-1948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1949"><a href="#cb18-1949" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">early 1977</span><span class="sc">\]</span><span class="at"> The program would take a picture and choose up to a hundred features. It would then drive the robot forward about a meter, stop, take another picture, and search for the same features in the second image. Then it would invoke the camera solver to find the robot movement and the three-dimensional locations of the features that explained their apparent motion from one image to the other. Despite much fine-tuning, the program's error rate never dropped below about one wrong motion solution in four, meaning the robot could move about four meters before becoming confused about its position--discouraging. The camera solver repeatedly tweaked an estimate of the robot's motion to make the features line up as well as possible, and threw away those that seemed too far off... 10--20% of the feature matches were wrong, often because an area chosen in a first image had, in a second image, been eclipsed or changed in appearance by point-of-view or lighting effects or camera noise... It was necessary to track about one hundred features to succeed even three steps in four, consuming several minutes of computer time. Months of fiddling with the program's mathematics and assumptions made little difference.</span></span>
<span id="cb18-1950"><a href="#cb18-1950" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1951"><a href="#cb18-1951" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@moravecRobotMereMachine1999, page 30</span><span class="co">]</span></span>
<span id="cb18-1952"><a href="#cb18-1952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1953"><a href="#cb18-1953" aria-hidden="true" tabindex="-1"></a>In fact, there was a little bit of faking in the demo movie:</span>
<span id="cb18-1954"><a href="#cb18-1954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1955"><a href="#cb18-1955" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; its most impressive feat -- moving a wedge to a block, ascending it, and pushing off a smaller block -- was recorded on film piecemeal, requiring multiple takes -- and several hours -- for each error-prone stage... Shakey's vision programs, as most others of the time, reduced images to a short list of geometric edges before doing anything else. The approach was quite inappropriate for outdoor scenes containing few simple edges, but many complicated shapes and color patterns.</span></span>
<span id="cb18-1956"><a href="#cb18-1956" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1957"><a href="#cb18-1957" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@moravecRobotMereMachine1999, page 26 -- 28</span><span class="co">]</span></span>
<span id="cb18-1958"><a href="#cb18-1958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1959"><a href="#cb18-1959" aria-hidden="true" tabindex="-1"></a>In 1973, Duda and Hart from the Shakey team published the famous "Duda and Hart" book on pattern classification <span class="co">[</span><span class="ot">@dudaPatternClassificationScene1973</span><span class="co">]</span>. The book contained two halves. The first half was statistical: Bayes, nearest neighbors, perceptron, clustering, etc. The second half was on scene analysis. It is instructive to compare the first edition with the second, published in 2001 <span class="co">[</span><span class="ot">@dudaPatternClassification2001</span><span class="co">]</span>, almost completely statistical. There were new chapters on neural networks, Boltzmann machines, decision trees, and so on. In contrast, scene analysis was completely removed. It says something about the obsolescence of scene analysis even in 2001, as Duda and Hart deleted half of their most famous book just to avoid talking about it. In fact, the only mention is a condemnation:</span>
<span id="cb18-1960"><a href="#cb18-1960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1961"><a href="#cb18-1961" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Some of the earliest work on three-dimensional object recognition relied on complex grammars which described the relationships of corners and edges, in block structures such arches and towers. It was found that such systems were very brittle; they failed whenever there were errors in feature extraction, due to occlusion and even minor misspecifications of the model. For the most part, then, grammatical methods have been abandoned for object recognition and scene analysis.</span></span>
<span id="cb18-1962"><a href="#cb18-1962" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1963"><a href="#cb18-1963" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@dudaPatternClassification2001, section 8.8</span><span class="co">]</span></span>
<span id="cb18-1964"><a href="#cb18-1964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1965"><a href="#cb18-1965" aria-hidden="true" tabindex="-1"></a>Concurrent to Shakey, in 1966, some undergraduate students were assigned to constructing "a significant part of a visual system" in a single summer. Of course, it failed at this task, as vision turned out to be the part of AI least amenable to logical approaches.</span>
<span id="cb18-1966"><a href="#cb18-1966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1967"><a href="#cb18-1967" aria-hidden="true" tabindex="-1"></a>As of 2007, such logical AI programs for vision had been completely obsoleted by statistical methods:</span>
<span id="cb18-1968"><a href="#cb18-1968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1969"><a href="#cb18-1969" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; one prominent vision researcher told me that the "residue of model-based vision is close to zero", and another told me that "most current robotic systems use vision hacks" instead of general-purpose, science-based scene-analysis methods.</span></span>
<span id="cb18-1970"><a href="#cb18-1970" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1971"><a href="#cb18-1971" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- </span><span class="co">[</span><span class="ot">@nilssonQuestArtificialIntelligence2009, page 20</span><span class="co">]</span></span>
<span id="cb18-1972"><a href="#cb18-1972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1973"><a href="#cb18-1973" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Fifth Generation</span></span>
<span id="cb18-1974"><a href="#cb18-1974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1975"><a href="#cb18-1975" aria-hidden="true" tabindex="-1"></a><span class="fu">### Japan Was Number One</span></span>
<span id="cb18-1976"><a href="#cb18-1976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1977"><a href="#cb18-1977" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Tactically, the attack on Pearl Harbor was one of the most brilliantly executed strokes of the war.  But politically, it was most unwise, for America fought back. Today, 40 years after the end of World War II, the Japanese are on the move again in one of history’s most brilliant commercial offensives, as they go about dismantling American industry. Whether they are still only smart, or have finally learned to be wiser than we, will be tested in the next 10 years. Only then will we know who finally won the war 50 years before.</span></span>
<span id="cb18-1978"><a href="#cb18-1978" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1979"><a href="#cb18-1979" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@whiteDangerJapan1985</span><span class="co">]</span></span>
<span id="cb18-1980"><a href="#cb18-1980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1981"><a href="#cb18-1981" aria-hidden="true" tabindex="-1"></a>In 1980, the Japanese was ready to take on the world. Despite the devastation of war, Japan quickly emerged as a peer competitor to America, leading to the Japan-panic symbolized by <span class="co">[</span><span class="ot">*Japan as Number One* (1979)</span><span class="co">](https://en.wikipedia.org/wiki/Japan_as_Number_One%3A_Lessons_for_America)</span>. Cyberpunk stories tell of a neon future with equal mindshare in English and Japanese, where massive zaibatsus battle with conglomerates over the emergent planetary commercium. By GDP, Japan became Number 2 in 1968, and by 1990 it was just 30% smaller than America's, and it had been growing about 1%/yr more. At this rate, it would have become Number 1 in 2020.</span>
<span id="cb18-1982"><a href="#cb18-1982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1983"><a href="#cb18-1983" aria-hidden="true" tabindex="-1"></a>The future is now, and we were robbed of this cyberpunk future. Its GDP reached a high point in 1995, and . Many people gave many reasons, such as the liquidity trap, the demographic crisis, the Plaza Accords, and so on. For our purposes, we just need to know that Japan had been knocked out of the AI game after this.</span>
<span id="cb18-1984"><a href="#cb18-1984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1985"><a href="#cb18-1985" aria-hidden="true" tabindex="-1"></a>Like how the American ARPA pushed behind the development of AI and computing, the Japanese <span class="co">[</span><span class="ot">MITI</span><span class="co">](https://en.wikipedia.org/wiki/Ministry_of_International_Trade_and_Industry)</span> had coordinated the development of many industries in Japan, and seeing the rise of expert systems, the time seemed ripe for a coordinated attack on AI. On the back of great optimism, the Fifth Generation Computer System (FGCS) project launched in 1982, led by Kazuhiro Fuchi. Its goals was ambitious to the point of revolutionary, and so was its schedule.</span>
<span id="cb18-1986"><a href="#cb18-1986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1987"><a href="#cb18-1987" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Even those who adore--the word is not too strong--their unusual director are often dismayed by him. A month after the center formally opened, the hardware committee met with Fuchi and showed him the fast-track two-year plan they'd devised for producing the prototype hardware scheduled for the first three-year phase. Instead of being pleased, Fuchi flew into a rage. That alone is unusual enough among Japanese managers, but what Fuchi wants is even more upsetting: cut that schedule down to a year and a half, he demands. The hardware committee is in shock. They already think themselves reckless in their two-year schedule. Fuchi will have none of it. "We have to manage to do this!" he says angrily. After a little while he calms down. "Go and think it over," he says more reasonably. "If you absolutely have them. But see if it can't be done in a year and a half. Loosen up on the quality assurance and give me a real machine in a year and a half."</span></span>
<span id="cb18-1988"><a href="#cb18-1988" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-1989"><a href="#cb18-1989" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ...</span></span>
<span id="cb18-1990"><a href="#cb18-1990" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1991"><a href="#cb18-1991" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Everybody knows that Fuchi has irrevocably resigned from his former post at the Electrotechnical Laboratory, a startling step for any Japanese employee, all the more one with such seniority. A high roller, he's placing all his bets on the Fifth Generation project. The legends add that Fuchi would have been eligible for a comfortable government pension if he'd only waited two or three months to resign his position at ETL, but he spurned anything so trivial as personal financial security to delay his project even by months. This is sensational to the young researchers who have grown up in the lifetime employment system of Japan.</span></span>
<span id="cb18-1992"><a href="#cb18-1992" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-1993"><a href="#cb18-1993" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, pages 110--112</span><span class="co">]</span></span>
<span id="cb18-1994"><a href="#cb18-1994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1995"><a href="#cb18-1995" aria-hidden="true" tabindex="-1"></a>::: {#fig-fgcp-orgchart layout-ncol=2}</span>
<span id="cb18-1996"><a href="#cb18-1996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1997"><a href="#cb18-1997" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@aisoFifthGenerationComputer1988, figure 6</span><span class="co">]</span>](figure/FGCS_orgchart_1.png)</span>
<span id="cb18-1998"><a href="#cb18-1998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1999"><a href="#cb18-1999" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, page 123</span><span class="co">]</span>](figure/FGCS_orgchart_2.png)</span>
<span id="cb18-2000"><a href="#cb18-2000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2001"><a href="#cb18-2001" aria-hidden="true" tabindex="-1"></a>Overall plan of the FGCS.</span>
<span id="cb18-2002"><a href="#cb18-2002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2003"><a href="#cb18-2003" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-2004"><a href="#cb18-2004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2005"><a href="#cb18-2005" aria-hidden="true" tabindex="-1"></a>The name "fifth generation" came from the idea of 4 generations of hardware: vacuum tube, transistor, integrated circuits, VLSI. The generation following these would be the fifth, consisting of massively parallel computers natively running logical programs, including logical AI systems. The project had the following parts: parallel logic programming, hardware, and AI.</span>
<span id="cb18-2006"><a href="#cb18-2006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2007"><a href="#cb18-2007" aria-hidden="true" tabindex="-1"></a>The project saw the future, and it would be parallel logic programming, for which they decided on a variant of <span class="co">[</span><span class="ot">Prolog</span><span class="co">](https://en.wikipedia.org/wiki/Prolog)</span> that uses "flat guarded Horn clauses". <span class="co">[</span><span class="ot">@feigenbaumJapaneseNationalFifth1993</span><span class="co">]</span> But why did they pick an obscure language, not the famed Lisp?</span>
<span id="cb18-2008"><a href="#cb18-2008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2009"><a href="#cb18-2009" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Prolog can be seen as an extension of Lisp." He says Prolog provides the extra functionality of “pattern matching and non-determinism,” and is "capable of integrating interesting features of other languages such as Smalltalk, PS, and APL."</span></span>
<span id="cb18-2010"><a href="#cb18-2010" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2011"><a href="#cb18-2011" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@warrenViewFifthGeneration1982</span><span class="co">]</span></span>
<span id="cb18-2012"><a href="#cb18-2012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2013"><a href="#cb18-2013" aria-hidden="true" tabindex="-1"></a>Vague, but that is as good an explanation as I could find.</span>
<span id="cb18-2014"><a href="#cb18-2014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2015"><a href="#cb18-2015" aria-hidden="true" tabindex="-1"></a>In terms of hardware, they planned for parallel computers that runs Prolog operations natively, aiming to eventually reach a target of $10^9 \;\mathrm{LIPS}$ -- 1 giga logical inferences per second.<span class="ot">[^lips-definition]</span> They also aimed for VLSI chips of $10^7$ transistors per chip. Since in 1982, a standard computer could perform Prolog operations at $10^5 \;\mathrm{LIPS}$, this implied they planned for a doubling time of 9 months. <span class="co">[</span><span class="ot">@bramerFifthGenerationAnnotated1984, page 6</span><span class="co">]</span></span>
<span id="cb18-2016"><a href="#cb18-2016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2017"><a href="#cb18-2017" aria-hidden="true" tabindex="-1"></a><span class="ot">[^lips-definition]: </span>A "logical inference" is technically defined as any Prolog procedure call, but can be thought of as any atomic logical operation, such as performing one *modus ponens*, one variable substitution, etc.</span>
<span id="cb18-2018"><a href="#cb18-2018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2019"><a href="#cb18-2019" aria-hidden="true" tabindex="-1"></a>They aimed to develop multiple AI systems, each of which would be an expert system written in their version of Prolog. The inference engine would be a standard logic programming system, similar to the planner used in Shakey. The knowledge base was the key. It would be written in a "knowledge-base management software using relational algebra", which probably meant a <span class="co">[</span><span class="ot">relational database</span><span class="co">](https://en.wikipedia.org/wiki/Relational_database)</span>. They planned that, at the end of the project, they would have the software and the hardware to handle expert systems with $10^4$ rules and $10^4$ objects, with "semi-automated" knowledge acquisition. <span class="co">[</span><span class="ot">@warrenViewFifthGeneration1982; @feigenbaumJapaneseNationalFifth1993</span><span class="co">]</span></span>
<span id="cb18-2020"><a href="#cb18-2020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2021"><a href="#cb18-2021" aria-hidden="true" tabindex="-1"></a>Specific plans they had for AI systems <span class="co">[</span><span class="ot">@feigenbaumJapaneseNationalFifth1993; @moto-okaFifthGenerationComputers1984; @feigenbaumFifthGenerationArtificial1984, pages 121--131; @bramerFifthGenerationAnnotated1984, page 6; @feigenbaumRiseExpertCompany1988, pages 202--203</span><span class="co">]</span>:</span>
<span id="cb18-2022"><a href="#cb18-2022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2023"><a href="#cb18-2023" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Computer-readable dictionaries with around 2 million entries in total. These would include a word dictionary with 800K words, a "concept classification dictionary" of 400K concepts, including a general thesaurus, and a "concept description dictionary" of another 400K concepts. These would serve as a general-purpose knowledge base that any expert system could utilize.</span>
<span id="cb18-2024"><a href="#cb18-2024" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>English-Japanese translator with vocabulary size ≥100,000, at ≥90% accuracy (with the last 10% fixed up by humans).</span>
<span id="cb18-2025"><a href="#cb18-2025" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Continuous ASR with vocabulary size ≥50,000 words and 95% per-word accuracy from at least "a few hundred" speakers, in both English and Japanese, at ≤3× real time.</span>
<span id="cb18-2026"><a href="#cb18-2026" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A question-answering system built on top of the ASR system. It would converse with the user with synthesized speech in Japanese or English. The first planned system would handle document queries in the computing literature. It would have vocabulary size ≥5,000 and ≥10,000 inference rules. After its success, more systems would be built for other professional fields.</span>
<span id="cb18-2027"><a href="#cb18-2027" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Natural language processing with vocabulary size ≤100,000, and ≤2000 grammatical rules, achieving ≥99% accuracy in syntactic analysis.</span>
<span id="cb18-2028"><a href="#cb18-2028" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>An image processing system with hardware featurizers, that can store ≥10,000 pieces of graphic and image information in its knowledge base. It would be applied to computer-aided design and manufacture and analysis of aerial and satellite images, medical images, etc.</span>
<span id="cb18-2029"><a href="#cb18-2029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2030"><a href="#cb18-2030" aria-hidden="true" tabindex="-1"></a><span class="fu">### Autopsy</span></span>
<span id="cb18-2031"><a href="#cb18-2031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2032"><a href="#cb18-2032" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ICOT set out to build a machine that could provide upwards of a 100 MLIPs of 'symbol crunching' power. However, there was no application whose clear need for such horsepower drove the development and whose success (or failure) would serve as the tangible evaluation of the effort. From our current perspective it is clear that there could not have been such an application, since any such application would necessarily have had to contain very large stores of knowledge; but in 1982 when the project began, there were no techniques available for capturing and managing such a large knowledge base. Even today, after more than a decade of research into knowledge representation, we have only a small base of experience and very few tested techniques for this task.</span></span>
<span id="cb18-2033"><a href="#cb18-2033" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2034"><a href="#cb18-2034" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumJapaneseNationalFifth1993</span><span class="co">]</span></span>
<span id="cb18-2035"><a href="#cb18-2035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2036"><a href="#cb18-2036" aria-hidden="true" tabindex="-1"></a>After 10 years and \$400M, the FGCS wrapped up in 1992. The MITI announced that it would give away the developed software for free.</span>
<span id="cb18-2037"><a href="#cb18-2037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2038"><a href="#cb18-2038" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The problem for Japan is that the computer industry shifted so rapidly that the technological path the Fifth Generation took -- which seemed a wise choice in 1982 -- turned out to be at odds with the computer industry's direction by 1992. In a sense, Japan's ability to stay the course in pursuit of a long-term payoff -- usually considered one of the country's strongest assets -- turned into a liability. A similar challenge for Japan may now be arising in high-definition television. Japan's HDTV system, which has been in development for two decades, is now coming to market just as some engineers believe that a major shift to digital television technology will make the Japanese analog approach obsolete.</span></span>
<span id="cb18-2039"><a href="#cb18-2039" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2040"><a href="#cb18-2040" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... "If it had really caught on, the Japanese companies would not have let it go," said Edward Feigenbaum... While the project developed some interesting computer designs and software, he said, even in Japan "no one is using the technology."</span></span>
<span id="cb18-2041"><a href="#cb18-2041" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2042"><a href="#cb18-2042" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@pollackFifthGenerationBecame1992</span><span class="co">]</span></span>
<span id="cb18-2043"><a href="#cb18-2043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2044"><a href="#cb18-2044" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; On the research side, it made little progress in AI, NLP, natural interface, knowledge acquisition, construction of large knowledge bases. On the commercial side, its architectures were a commercial failure as they require the user to use an unfamiliar paradigm (parallel logical programming) on hardware that is not better than standard hardware. The promised applied expert systems were not developed because the research did not progress as planned.</span></span>
<span id="cb18-2045"><a href="#cb18-2045" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2046"><a href="#cb18-2046" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumJapaneseNationalFifth1993, table 2</span><span class="co">]</span></span>
<span id="cb18-2047"><a href="#cb18-2047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2048"><a href="#cb18-2048" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The PIM hardware seems destined for the same fate. The processing elements in the PIMs have cycle times no better than 60 ns; even assuming that the features which provide direct support for XLI offer a speedup factor of 3, this leaves the uniprocessor performance lagging behind the best of today's conventional microprocessors. Both HP and DEC have announced the imminent introduction of uniprocessors of between 100 and 200 MIPS. The interconnection networks in the PIMs do not seem to constitute an advance over those explored in other parallel systems. Finally, the PIMs are essentially 'integer machines'; they do not have floating point hardware. While the interconnection networks of the PIMs have reasonable performance, this performance is comparable to that of commercial parallel machines in the US such as the CM-5.</span></span>
<span id="cb18-2049"><a href="#cb18-2049" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2050"><a href="#cb18-2050" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; But these days, few people want specialized computers for artificial intelligence, preferring powerful general-purpose machines like those made by Sun Microsystems Inc., a fast-growing Silicon Valley company that did not exist when the Fifth Generation Project was conceived. And a host of scrappy American companies have sprung up to sell massively parallel computers with tens of thousands of processors, far more than the Fifth Generation machines.</span></span>
<span id="cb18-2051"><a href="#cb18-2051" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2052"><a href="#cb18-2052" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@pollackFifthGenerationBecame1992</span><span class="co">]</span></span>
<span id="cb18-2053"><a href="#cb18-2053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2054"><a href="#cb18-2054" aria-hidden="true" tabindex="-1"></a>THe fastest systems they built were the PIM/p with 512 processors at peak performance 156 MLIPS, and PIM/m with 256 processors at 153 MLIPS. Both had clock frequency 16 MHz. They sticked to the original estimate, made at the start of the project, that their logic-specific chips could run logical inferences at approximately 100 times faster than a general computer. <span class="ot">[^pim-p-citation]</span></span>
<span id="cb18-2055"><a href="#cb18-2055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2056"><a href="#cb18-2056" aria-hidden="true" tabindex="-1"></a><span class="ot">[^pim-p-citation]</span>: </span>
<span id="cb18-2057"><a href="#cb18-2057" aria-hidden="true" tabindex="-1"></a>    <span class="at">&gt; たとえば、512 台のプロセッサを持つ PIM モデル p ではピーク性能で156 MLIPS (1秒間に1億5600万回の推論処理を行なう速度)、256 台のプロセッサを持 つモデル m では153 MLIPSという、汎用大型機の約100倍に当たる世界最高の 推論処理速度を達成している。実際の応用システムでの利用でも、アルゴリズ ムの工夫とあいまって、512 台にいたるまでほぼプロセッサの台数に比例する並 列処理効果を得ている。</span></span>
<span id="cb18-2058"><a href="#cb18-2058" aria-hidden="true" tabindex="-1"></a><span class="at">    &gt; </span></span>
<span id="cb18-2059"><a href="#cb18-2059" aria-hidden="true" tabindex="-1"></a><span class="at">    &gt; </span><span class="co">[</span><span class="ot">第五世代コンピュータ・プロジェクト 最終評価報告書: 並列記号処理ハードウェア技術</span><span class="co">](https://www.ueda.info.waseda.ac.jp/AITEC_ICOT_ARCHIVES/ICOT/Museum/FinalReport/node17.html#SECTION03022300000000000000)</span></span>
<span id="cb18-2060"><a href="#cb18-2060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2061"><a href="#cb18-2061" aria-hidden="true" tabindex="-1"></a>    <span class="co">[</span><span class="ot">Top Page for FGCS Museum: ５つのＰＩＭの概要</span><span class="co">](https://www.ueda.info.waseda.ac.jp/AITEC_ICOT_ARCHIVES/ICOT/Museum/MACHINE/pim-spec-J.html)</span></span>
<span id="cb18-2062"><a href="#cb18-2062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2063"><a href="#cb18-2063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2064"><a href="#cb18-2064" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The LIPS of computers produced by the FGCS at its ending in 1992, with forecasts up to 2000. [@FGCS_scaling_plot.png, page 27, figure 2]</span><span class="co">](figure/FGCS_scaling_plot.png)</span></span>
<span id="cb18-2065"><a href="#cb18-2065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2066"><a href="#cb18-2066" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="1 LIPS = 100 OPS?" collapse="true" }</span>
<span id="cb18-2067"><a href="#cb18-2067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2068"><a href="#cb18-2068" aria-hidden="true" tabindex="-1"></a>From the start of the project, they assumed that 1 LIP takes about 100 operations on a conventional computer. They also planned that, at the end of the project, there should be a machine with 1000 processors achieving 1 GLIPS, implying at least 1 MLIPS per processor. <span class="co">[</span><span class="ot">@feigenbaumJapaneseNationalFifth1993</span><span class="co">]</span></span>
<span id="cb18-2069"><a href="#cb18-2069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2070"><a href="#cb18-2070" aria-hidden="true" tabindex="-1"></a>According to <span class="co">[</span><span class="ot">@bramerFifthGenerationAnnotated1984, page 6</span><span class="co">]</span>, as of 1984, a conventional computer cound run Prolog at 10--100 KLIPS, and that 1 LIPS = 100--1000 OPS. Now, they did not state what counts as "conventional", but probably they meant something between Sun-1 (0.5 MIPS) and Cray-1 (150 MIPS). Unfortunately, this gives us a ridiculously wide range of 1 LIPS = 5--1500 OPS.</span>
<span id="cb18-2071"><a href="#cb18-2071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2072"><a href="#cb18-2072" aria-hidden="true" tabindex="-1"></a>As far as I see, they probably just got that number by running some Prolog programs on the computers they have available in 1982. Fortunately, someone did exactly this experiment and found that 1 LIPS = 53 OPS as of 1990 <span class="co">[</span><span class="ot">@kellerGigaLIPFastEnough1990</span><span class="co">]</span>, so the 1 LIPS = 100 OPS rule is good enough.</span>
<span id="cb18-2073"><a href="#cb18-2073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2074"><a href="#cb18-2074" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-2075"><a href="#cb18-2075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2076"><a href="#cb18-2076" aria-hidden="true" tabindex="-1"></a>Now, assuming that 1 LIPS = 100 OPS, then to reach 1 GLIPS on a conventional computer would require 100 GFLOPS. Now, according to <span class="co">[</span><span class="ot">TOP500 list of 1993-11</span><span class="co">](https://www.top500.org/lists/top500/1993/11/)</span>, the second-fastest computer in the world was a 1024-core <span class="co">[</span><span class="ot">Connection Machine</span><span class="co">](https://en.wikipedia.org/wiki/Connection_Machine)</span>-5 (developed by the <span class="co">[</span><span class="ot">Strategic Computing Initiative</span><span class="co">](#sec-sci)</span>), which ran at 60 GFLOPS. So just by making a parallel computer with 1000 standard floating-point processors, they made something that reached the Japanese target of 1 GLIP/sec, without ever dealing with specialized hardware! Yet another example of specialized hardware overtaken by general computers, like Rosenblatt's <span class="co">[</span><span class="ot">Tobermory</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/perceptron-controversy/index.html#the-perceptron-controversy-1960s)</span>, and the <span class="co">[</span><span class="ot">Lisp machines</span><span class="co">](https://en.wikipedia.org/wiki/Lisp_machine)</span>.</span>
<span id="cb18-2077"><a href="#cb18-2077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2078"><a href="#cb18-2078" aria-hidden="true" tabindex="-1"></a>Though the FGCS project was a failure, and Japan no longered mattered in AI since its end, it had an indirect effect. Feigenbaum and the long-time AI journalist <span class="co">[</span><span class="ot">Pamela McCorduck</span><span class="co">](https://en.wikipedia.org/wiki/Pamela_McCorduck)</span> coauthored a book <span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984</span><span class="co">]</span> that became the hottest book inside the Beltway. Ominously, they warned of imminent Japanese domination:</span>
<span id="cb18-2079"><a href="#cb18-2079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2080"><a href="#cb18-2080" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We calculate that in 1982, the aggregate spent in the United States on artificial intelligence research from all sources -- governmental and private -- was about 50 million. This is just about equal to the amount the Japanese government expects to spend on an average per year over the next ten years for its Fifth Generation (and does not count Japanese internal industrial AI support that may double or triple the amount). If we continue as we have, we two nations will act as guinea pigs for an interesting experiment in planned, as opposed to unplanned, research... The Japanese have announced that in ten years they will produce knowledge information processors. Several options are open to Americans, but few of them offer truly palatable alternatives to undertaking our own version... The United States should form a national center for knowledge technology... The center we propose would be an expression and institutional embodiment of national will </span><span class="sc">\[</span><span class="at">like NASA</span><span class="sc">\]</span><span class="at">.</span></span>
<span id="cb18-2081"><a href="#cb18-2081" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2082"><a href="#cb18-2082" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, pages 261--269</span><span class="co">]</span></span>
<span id="cb18-2083"><a href="#cb18-2083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2084"><a href="#cb18-2084" aria-hidden="true" tabindex="-1"></a>The hardware developed, but there was no use for it. Parallel logic programming was difficult for the outside programmers, used to serial imperative programming. </span>
<span id="cb18-2085"><a href="#cb18-2085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2086"><a href="#cb18-2086" aria-hidden="true" tabindex="-1"></a>And they were not the first to raise the alarm:</span>
<span id="cb18-2087"><a href="#cb18-2087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2088"><a href="#cb18-2088" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In January 1981, Professor </span><span class="co">[</span><span class="ot">Arvind</span><span class="co">]</span><span class="at">(https://en.wikipedia.org/wiki/Arvind_(computer_scientist)) of MIT returned from Tokyo with an early report on the Fifth Generation Project, the same report Feigenbaum had put in his "to read sometime" pile at Stanford a few months earlier. Arvind showed it to </span><span class="co">[</span><span class="ot">Michael Dertouzos</span><span class="co">](https://en.wikipedia.org/wiki/Michael_Dertouzos)</span><span class="at">, a professor and director of the MIT Laboratory for Computer Science. Dertouzos recollected in notes: "I panic. My colleagues are (way too) relaxed about it and tell me that I am over-reacting." One of the things that troubled Dertouzos was the similarities between the Japanese plan and long-range plans at MIT.</span></span>
<span id="cb18-2089"><a href="#cb18-2089" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2090"><a href="#cb18-2090" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, pages 199</span><span class="co">]</span></span>
<span id="cb18-2091"><a href="#cb18-2091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2092"><a href="#cb18-2092" aria-hidden="true" tabindex="-1"></a>Partly as a result of this, multiple countries launched their own national AI projects,<span class="ot">[^fgcs-list]</span> the most notable of which was the <span class="co">[</span><span class="ot">Strategic Computing Initiative</span><span class="co">](#sec-sci)</span>, funded by the ARPA -- I mean, DARPA at this point -- which would be much more successful.</span>
<span id="cb18-2093"><a href="#cb18-2093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2094"><a href="#cb18-2094" aria-hidden="true" tabindex="-1"></a><span class="ot">[^fgcs-list]: </span>FGCS (Japan, 1982--1992), Alvey Programme (UK, 1984--1990), ESPRIT programs (Europe, 1983--1998), and the Strategic Computing Initiative (America, 1984--1993).</span>
<span id="cb18-2095"><a href="#cb18-2095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2096"><a href="#cb18-2096" aria-hidden="true" tabindex="-1"></a><span class="fu">## Intelligence in the age of war machines</span></span>
<span id="cb18-2097"><a href="#cb18-2097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2098"><a href="#cb18-2098" aria-hidden="true" tabindex="-1"></a><span class="fu">### Early war machines</span></span>
<span id="cb18-2099"><a href="#cb18-2099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2100"><a href="#cb18-2100" aria-hidden="true" tabindex="-1"></a>The dream of peace produces war machines. Ancient Athenians dreamed of <span class="co">[</span><span class="ot">Talos</span><span class="co">](https://en.wikipedia.org/wiki/Talos)</span>, a bronze giant who defended Crete, while the Jews of Prague dreamed of <span class="co">[</span><span class="ot">Golem</span><span class="co">](https://en.wikipedia.org/wiki/Golem#Etymology)</span>. The ages has been too kind to Zhuge Liang, and his wheelbarrow, invented for carrying war supplies, became the legend of <span class="co">[</span><span class="ot">wooden robot oxen</span><span class="co">](https://en.wikipedia.org/wiki/Wooden_ox)</span>.</span>
<span id="cb18-2101"><a href="#cb18-2101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2102"><a href="#cb18-2102" aria-hidden="true" tabindex="-1"></a>The industrial revolution produced early ideas of feedback mechanism, such as the <span class="co">[</span><span class="ot">centrifugal governor</span><span class="co">](https://en.wikipedia.org/wiki/Centrifugal_governor)</span> and the <span class="co">[</span><span class="ot">gyro autopilot</span><span class="co">](https://en.wikipedia.org/wiki/Gyroscopic_autopilot)</span>. It took until WWII for someone to put together high explosives, slow burning fuel, and the feedback mechanism, to create the cruise missile. The first of its kind was the V-1 rocket, which already incorporates the basic features of all cruise missiles.</span>
<span id="cb18-2103"><a href="#cb18-2103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2104"><a href="#cb18-2104" aria-hidden="true" tabindex="-1"></a>The V-1 looks like a small unmanned jet airplane. It has the following senses: roll (gyro), pitch (gyro), yaw (magnetic compass), altitude (barometer), distance traveled (vane anemometer). The roll, pitch, yaw, and altitude are maintained by negative feedback. So for example, if the missile is heading east to the set-point of yaw, a valve would open, and compressed gas would force the rudder to turn, which yaws the missile west. As soon as the vane anemometer has turned a designated number, the missile considers itself to have reached the target. It turns off the engine and sharply dives to the ground, and explodes upon impact.</span>
<span id="cb18-2105"><a href="#cb18-2105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2106"><a href="#cb18-2106" aria-hidden="true" tabindex="-1"></a>Other than V-1 and V-2, there were no autonomous war machines during WWII, though there were several radio-controlled weapons such as <span class="co">[</span><span class="ot">explosive little tanks</span><span class="co">](https://en.wikipedia.org/wiki/Goliath_tracked_mine)</span> and <span class="co">[</span><span class="ot">little planes for target practice</span><span class="co">](https://en.wikipedia.org/wiki/Radioplane_OQ-2)</span>. Skinner, thinking outside (inside?) the box, worked on <span class="co">[</span><span class="ot">Project Pigeon</span><span class="co">](https://en.wikipedia.org/wiki/Project_Pigeon)</span>. He trained pigeons in skinner boxes to peck at the ship appearing on a screen. If the pigeon is pecking on the top-left, then the missile would turn to the bottom-right. In effect, the pigeon becomes the negative feedback controller. Though it was cancelled, it would have been considerably cheaper than <span class="co">[</span><span class="ot">the Japanese version</span><span class="co">](https://en.wikipedia.org/wiki/Kamikaze)</span> should it have ever reached production.</span>
<span id="cb18-2107"><a href="#cb18-2107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2108"><a href="#cb18-2108" aria-hidden="true" tabindex="-1"></a>&lt;video controls width=100%&gt;</span>
<span id="cb18-2109"><a href="#cb18-2109" aria-hidden="true" tabindex="-1"></a>  &lt;source src="figure/Project%20Pigeon.webm" type="video/webm" /&gt;</span>
<span id="cb18-2110"><a href="#cb18-2110" aria-hidden="true" tabindex="-1"></a>&lt;/video&gt;</span>
<span id="cb18-2111"><a href="#cb18-2111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2112"><a href="#cb18-2112" aria-hidden="true" tabindex="-1"></a>After WWII, some autonomous defense systems were developed and deployed, such as <span class="co">[</span><span class="ot">close-in weapon systems</span><span class="co">](https://en.wikipedia.org/wiki/Close-in_weapon_system)</span> on ships. These detect incoming incoming missiles and enemy aircraft by radar, computes their trajectories, and shoots them down. Since they must operate on the time-scale of seconds, they are fully automatic with no human in the loop. Despite this, these are quite uncontroversial and do not typically earn the title of "killer robots", presumably because compared to autonomous *offense*, defense is inherently more controllable and predictable in effect.</span>
<span id="cb18-2113"><a href="#cb18-2113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2114"><a href="#cb18-2114" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nuclear war machines</span></span>
<span id="cb18-2115"><a href="#cb18-2115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2116"><a href="#cb18-2116" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Deterrence is the art of producing in the mind of the enemy the fear to attack. And so, because of the automated and irrevocable decision making process which rules out human meddling, the doomsday machine is terrifying. It's simple to understand. And completely credible, and convincing... When you merely wish to bury bombs, there is no limit to the size. After that they are connected to a gigantic complex of computers. Now then, a specific and clearly defined set of circumstances, under which the bombs are to be exploded, is programmed into a tape memory bank.</span></span>
<span id="cb18-2117"><a href="#cb18-2117" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2118"><a href="#cb18-2118" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- </span><span class="co">[</span><span class="ot">Dr. Strangelove</span><span class="co">](https://en.wikipedia.org/wiki/Dr._Strangelove)</span><span class="at"> (1964)</span></span>
<span id="cb18-2119"><a href="#cb18-2119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2120"><a href="#cb18-2120" aria-hidden="true" tabindex="-1"></a>During the Cold War, the following technological factors of nuclear weapons determined the grand nuclear strategy.</span>
<span id="cb18-2121"><a href="#cb18-2121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2122"><a href="#cb18-2122" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>First-strike nuclear offense is impossible to defend against. Some bombs will get through all defense.</span>
<span id="cb18-2123"><a href="#cb18-2123" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Nuclear weapon is so much more powerful than non-nuclear weapons, that the only proportionate deterrence to a nuclear attack is another nuclear attack.</span>
<span id="cb18-2124"><a href="#cb18-2124" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>First-strike capability is indistinguishable from second-strike capability.</span>
<span id="cb18-2125"><a href="#cb18-2125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2126"><a href="#cb18-2126" aria-hidden="true" tabindex="-1"></a>Because of (1) and (2), the only way to deter a nuclear first-strike was to threaten a nuclear second-strike. This is the <span class="co">[</span><span class="ot">MAD</span><span class="co">](https://en.wikipedia.org/wiki/Mutual_assured_destruction)</span> nuclear deterrence doctrine. Because deterrence requires enough bombs to survive a first-strike, both sides would rather build up more second-strike bombs than the other side's first-strike bombs. Because of (3), there aren't "second-strike bombs" vs "first-strike bombs", only bombs. Therefore, we have a positive feedback loop where both sides aim to have more bombs than the other -- the <span class="co">[</span><span class="ot">nuclear arms race</span><span class="co">](https://en.wikipedia.org/wiki/Nuclear_arms_race)</span>. Because having too many bombs increases the chance of accidents, both sides are motivated to slow down the race. Thus the <span class="co">[</span><span class="ot">ABM Treaty</span><span class="co">](https://en.wikipedia.org/wiki/Anti-Ballistic_Missile_Treaty)</span>, where both sides agree to *not* build many missile defense systems! This paradoxical treaty was designed to make both sides *more* vulnerable to second-strike, meaning that less bombs are needed to ensure second-strike capability, thus complementing the <span class="co">[</span><span class="ot">SALT treaties</span><span class="co">](https://en.wikipedia.org/wiki/Strategic_Arms_Limitation_Talks)</span> that limited the number of bombs.</span>
<span id="cb18-2127"><a href="#cb18-2127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2128"><a href="#cb18-2128" aria-hidden="true" tabindex="-1"></a>Both sides' nuclear technology went through several iterations, with increasing second-strike capability, and ended up with the "nuclear triad" of bombers that stay in the air 24/7, submarines hidden under the sea, and ICBMs hardened inside silos. Each of the three has different tradeoffs, necessitating all three to be maintained.</span>
<span id="cb18-2129"><a href="#cb18-2129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2130"><a href="#cb18-2130" aria-hidden="true" tabindex="-1"></a>Of course, even if the triad survives the first-strike, it is no good if they won't activate. The command center might be destroyed. The communication lines might be cut. The soldiers might refuse to launch based on their own conscience. All these dangers lead to the pressure to automate second-strike. The pinnacle of this logic was the <span class="co">[</span><span class="ot">Supersonic Low Altitude Missile (SLAM)</span><span class="co">](https://en.wikipedia.org/wiki/Supersonic_Low_Altitude_Missile)</span>, a cruise missile powered by a nuclear engine. The nuclear engine is like a fission nuclear reactor in nuclear power plants, except that the fission power does not boil water, but heat up air, which expands and shoots out from the tail of the missile, allowing it to fly at Mach 3.</span>
<span id="cb18-2131"><a href="#cb18-2131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2132"><a href="#cb18-2132" aria-hidden="true" tabindex="-1"></a>Despite having no GPS (it was the 1960s!), because the SLAM would fly $\sim 200 \;\mathrm{m}$ above ground, it could navigate itself by <span class="co">[</span><span class="ot">terrain contour matching</span><span class="co">](https://en.wikipedia.org/wiki/TERCOM)</span>: It compares a height-scan of the local terrain against a stored copy of the terrain. Even after dropping all its nuclear warheads, it can remain airborne for weeks, destroying the ground with sonic booms as overkill. The project was shelved in 1964, apparently considered too destabilizing, and they settled for just drilling the nuclear launch routines into the missileers until they work like robots that would not hesitate to execute the launch command.</span>
<span id="cb18-2133"><a href="#cb18-2133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2134"><a href="#cb18-2134" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The terrain contour matching algorithm. By a curious coincidence, the algorithm typically attempts to find a line segment within the stored terrain map that minimizes the [Mean Absolute Deviation](https://en.wikipedia.org/wiki/Average_absolute_deviation) with the local terrain of the missile... also with the "MAD" acronym. [@goldenTerrainContourMatching1980, figure 2]</span><span class="co">](figure/TERCOM.png)</span></span>
<span id="cb18-2135"><a href="#cb18-2135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2136"><a href="#cb18-2136" aria-hidden="true" tabindex="-1"></a>In the movie *Dr. Strangelove* (1964), nuclear deterrence was taken to its logical end point. In the movie, the Soviet Union built a "doomsday machine", which is a Cobalt bomb that when exploded, makes enough fallout to render the entire earth uninhabitable for a century. This was then connected to sensors around the Soviet Union, so that any nuclear attack automatically triggers it. Finally, the machine triggers if it detects attempts to un-trigger it, thus closing the logic loop and making it a fully automatic deterrence machine.<span class="ot">[^dead-hand]</span></span>
<span id="cb18-2137"><a href="#cb18-2137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2138"><a href="#cb18-2138" aria-hidden="true" tabindex="-1"></a><span class="ot">[^dead-hand]: </span>I was going to write something about the <span class="co">[</span><span class="ot">Dead Hand</span><span class="co">](https://en.wikipedia.org/wiki/Dead_Hand)</span> system, but after a brief search, the available information looks too much like conspiracy theory and rumors, so I will not.</span>
<span id="cb18-2139"><a href="#cb18-2139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2140"><a href="#cb18-2140" aria-hidden="true" tabindex="-1"></a><span class="fu">### Intelligence</span></span>
<span id="cb18-2141"><a href="#cb18-2141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2142"><a href="#cb18-2142" aria-hidden="true" tabindex="-1"></a>The previous sections has made it clear that ARPA has been inevitable behind every AI development since the 1960s. Indeed, ARPA funded 75--95% of all AI projects during the 1960s <span class="co">[</span><span class="ot">@guiceControversyStateLord1998</span><span class="co">]</span>. Though this essay is on logical AI, a brief detour about neural network is in order.</span>
<span id="cb18-2143"><a href="#cb18-2143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2144"><a href="#cb18-2144" aria-hidden="true" tabindex="-1"></a>During the Cold War, intelligence, in the sense of intelligence-gathering and reconnaissance was a vital area of artificial intelligence. Some of the early neural networks, such as MINOS II, was explicitly built with an objective of scanning aerial photographs for interesting military targets like tanks. <span class="co">[</span><span class="ot">@nilssonQuestArtificialIntelligence2009, pages 98--109</span><span class="co">]</span> The CIA even <span class="co">[</span><span class="ot">experimented with Rosenblatt's Mark I Perceptron machine</span><span class="co">](https://www.cia.gov/readingroom/document/cia-rdp78b04770a002300030027-6)</span> for the same purpose <span class="co">[</span><span class="ot">@irwinArtificialWorldsPerceptronic2024</span><span class="co">]</span>. As an example, <span class="co">[</span><span class="ot">@kanalRecognitionSystemDesign1964</span><span class="co">]</span> describes a two-layered perceptron network, of type $\R^{N \times N} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>$. It works as follows:</span>
<span id="cb18-2145"><a href="#cb18-2145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2146"><a href="#cb18-2146" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The grayscale photo is down-scaled and binarized by convolution with a <span class="co">[</span><span class="ot">discrete Laplace filter</span><span class="co">](https://en.wikipedia.org/wiki/Discrete_Laplace_operator)</span>: $\R^{N \times N} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32}$.</span>
<span id="cb18-2147"><a href="#cb18-2147" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The weights for the 24 hidden perceptrons are constructed by <span class="co">[</span><span class="ot">linear discriminant analysis</span><span class="co">](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)</span>: $<span class="sc">\{</span>0, 1<span class="sc">\}</span>^{32\times 32} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24}$</span>
<span id="cb18-2148"><a href="#cb18-2148" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The output perceptron is learned by the <span class="co">[</span><span class="ot">perceptron learning rule</span><span class="co">](https://en.wikipedia.org/wiki/Perceptron#Learning_algorithm_for_a_single-layer_perceptron)</span>: $<span class="sc">\{</span>0, 1<span class="sc">\}</span>^{24} \to <span class="sc">\{</span>0, 1<span class="sc">\}</span>$.</span>
<span id="cb18-2149"><a href="#cb18-2149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2150"><a href="#cb18-2150" aria-hidden="true" tabindex="-1"></a>::: {#fig-kanal-1964-neural-tanks layout-ncol=2}</span>
<span id="cb18-2151"><a href="#cb18-2151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2152"><a href="#cb18-2152" aria-hidden="true" tabindex="-1"></a><span class="al">![Grayscale photos, some containing tanks, and some not.](figure/kanal_1964_fig_tank_nontank_mosaic.png)</span>{#fig-kanal-1964-neural-tanks-tank-nontank-mosaic}</span>
<span id="cb18-2153"><a href="#cb18-2153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2154"><a href="#cb18-2154" aria-hidden="true" tabindex="-1"></a><span class="al">![A picture of a tank after convolution with a discrete Laplace filter.](figure/kanal_1964_fig_binary_image_tank.png)</span>{#fig-kanal-1964-neural-tanks-binary-image-tank}</span>
<span id="cb18-2155"><a href="#cb18-2155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2156"><a href="#cb18-2156" aria-hidden="true" tabindex="-1"></a><span class="al">![The architecture of the network.](figure/kanal_1964_fig_architecture.png)</span>{#fig-kanal-1964-neural-tanks-architecture}</span>
<span id="cb18-2157"><a href="#cb18-2157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2158"><a href="#cb18-2158" aria-hidden="true" tabindex="-1"></a>Images from <span class="co">[</span><span class="ot">@kanalRecognitionSystemDesign1964</span><span class="co">]</span>.</span>
<span id="cb18-2159"><a href="#cb18-2159" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-2160"><a href="#cb18-2160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2161"><a href="#cb18-2161" aria-hidden="true" tabindex="-1"></a>Neural networks (such as Minsky's <span class="co">[</span><span class="ot">SNARC</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_Neural_Analog_Reinforcement_Calculator)</span> and Rosenblatt's perceptrons) were funded by the Office of Naval Research (ONR) on the order of \$50K, while logical AI was funded by ARPA, whose contracts were on the order of \$500K. This made a real difference in the days of mainframes. <span class="co">[</span><span class="ot">@guiceControversyStateLord1998</span><span class="co">]</span> See my essay on the <span class="co">[</span><span class="ot">*Perceptron Controversy*</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/perceptron-controversy/)</span> for details.</span>
<span id="cb18-2162"><a href="#cb18-2162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2163"><a href="#cb18-2163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Strategic Computing Project {#sec-sci}</span></span>
<span id="cb18-2164"><a href="#cb18-2164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2165"><a href="#cb18-2165" aria-hidden="true" tabindex="-1"></a>The <span class="co">[</span><span class="ot">Strategic Defense Initiative</span><span class="co">](https://en.wikipedia.org/wiki/Strategic_Defense_Initiative)</span> (SDI), better known as "Star Wars", was announced by President Reagan in 1983. It aimed to shoot down Soviet ICBMs during their spaceflight with tools including lasers, particle-beam weapons, and ground and space-based missile systems. If this was successful, it would cripple Soviet second-strike capability. Although President Reagan claimed the project aimed to make nuclear weapons "impotent and obsolete", it would be incredible, even <span class="co">[</span><span class="ot">idealists</span><span class="co">](https://en.wikipedia.org/wiki/Idealism_in_international_relations)</span>, to suppose that other countries would believe it. Indeed, the Soviet Premier Andropov immediately condemned this, suspecting it was in fact a plan to make America the only nuclear power immune to a second-strike and become the global hegemon.</span>
<span id="cb18-2166"><a href="#cb18-2166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2167"><a href="#cb18-2167" aria-hidden="true" tabindex="-1"></a>Though the SDI did not bring the Star Wars, or make plans for AI, it had an indirect effect on intelligence in the age of war machines. In the same year, the Strategic Computing Project (SCI) began, and its funding was facilitated by the SDI, as well as the Japan scare from the Fifth Generation, which was the hottest topic in the Beltway.</span>
<span id="cb18-2168"><a href="#cb18-2168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2169"><a href="#cb18-2169" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It is tempting to regard all this as just another skirmish in the trade wars, where engagements have already taken place in steel, automobiles, and consumer electronics... our national self-interest, not to mention our economic security, does not allow us this luxury. Information processing is an \$88-billion-per-year industry in the United States, and its loss would be disastrous. The default of this American industry, which has led the world for decades, would be a mortal economic wound... The superior technology usually wins the war – whether that war is martial, entrepreneurial, or cultural.</span></span>
<span id="cb18-2170"><a href="#cb18-2170" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2171"><a href="#cb18-2171" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@feigenbaumFifthGenerationArtificial1984, pages 17--18</span><span class="co">]</span></span>
<span id="cb18-2172"><a href="#cb18-2172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2173"><a href="#cb18-2173" aria-hidden="true" tabindex="-1"></a>It's war. America could not lose the AI race. The congress approved the SCI, a 10-year project that would end up costing \$1 billion funded by DARPA. The final plan was published in 1983-10 as <span class="co">[</span><span class="ot">@darpaStrategicComputingNew1983</span><span class="co">]</span>.</span>
<span id="cb18-2174"><a href="#cb18-2174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2175"><a href="#cb18-2175" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The SCI plan according to the bureaucrats. Yawn. [@rolandStrategicComputingDARPA2002, pages 77--78], which were cleaned up from [@darpaStrategicComputingNew1983, figure 4.1, figure 4.2]</span><span class="co">](figure/SCI_plan.png)</span></span>
<span id="cb18-2176"><a href="#cb18-2176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2177"><a href="#cb18-2177" aria-hidden="true" tabindex="-1"></a>The project has 3 application areas: the "Battlem Management System" for the Navy, "Pilot's Associate" for the Air Force, and "Autonomous Land Vehicle" (ALV) for the Army. To develop these areas, it would develop 4 technologies: speech (for Pilot's Associate and Battle Management), language (for Battle Management), vision (for ALV), and general expert systems (for all). It would also develop massively parallel (≥1000 processors) teraFLOPS computers as its own bet on the fifth generation of computing.</span>
<span id="cb18-2178"><a href="#cb18-2178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2179"><a href="#cb18-2179" aria-hidden="true" tabindex="-1"></a>How did it go? Spoiler: massively parallel computers at the teraOPS level succeeded, language abandoned, vision failed, self-driving cars improved but failed to reach the promise, generic expert systems failed, a few specific expert systems worked.</span>
<span id="cb18-2180"><a href="#cb18-2180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2181"><a href="#cb18-2181" aria-hidden="true" tabindex="-1"></a><span class="fu">### Computing</span></span>
<span id="cb18-2182"><a href="#cb18-2182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2183"><a href="#cb18-2183" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Many veterans and supporters of the program believe that it was created in response to a compelling technological opportunity. In the early 1980s, advances in microelectronics design and manufacturing held out the promise of greatly improved computer chips. New concepts of computer architecture could conceivably exploit these chips in machines of unprecedented speed and power. Such computers might finally have the muscle necessary to achieve artificial intelligence -- machine capabilities comparable to those of human thought.</span></span>
<span id="cb18-2184"><a href="#cb18-2184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2185"><a href="#cb18-2185" aria-hidden="true" tabindex="-1"></a>Near the end of SCI, computers were within 10x of the teraFLOPS goal. Congress approved the <span class="co">[</span><span class="ot">High Performance Computing Act of 1991</span><span class="co">](https://en.wikipedia.org/wiki/High_Performance_Computing_Act_of_1991)</span> to fund the development of Internet infrastructure and more massively parallel computers -- rebranded as "high performance computing".</span>
<span id="cb18-2186"><a href="#cb18-2186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2187"><a href="#cb18-2187" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; By mid-1992 a completely new generation of computers have been introduced. Understanding this generation should make it possible to build the next-generation supercomputer class machine, that would reach a teraflop of peak power for a few, large-scale applications by the end of 1995.</span></span>
<span id="cb18-2188"><a href="#cb18-2188" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2189"><a href="#cb18-2189" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@bellUltracomputersTeraflopIts1992</span><span class="co">]</span></span>
<span id="cb18-2190"><a href="#cb18-2190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2191"><a href="#cb18-2191" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Progress towards the teraFLOPS computer. [@bellUltracomputersTeraflopIts1992, figure 1]</span><span class="co">](figure/Bell_1992_teraOPS.png)</span></span>
<span id="cb18-2192"><a href="#cb18-2192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2193"><a href="#cb18-2193" aria-hidden="true" tabindex="-1"></a>The desired "1000 core computer" did come in 1991 as CM-5 at about 60 GFLOP/sec, 4300 FLOPS/\$ <span class="co">[</span><span class="ot">@bellUltracomputersTeraflopIts1992</span><span class="co">]</span>, and a little late on schedule. The first teraFLOPS computer, <span class="co">[</span><span class="ot">ASCI Red</span><span class="co">](https://en.wikipedia.org/wiki/ASCI_Red)</span>, arrived in 1996, with 9298 CPUs.<span class="ot">[^asci-red]</span> It was designed for simulating nuclear bomb tests.</span>
<span id="cb18-2194"><a href="#cb18-2194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2195"><a href="#cb18-2195" aria-hidden="true" tabindex="-1"></a><span class="ot">[^asci-red]: </span>I couldn't find its price, but its successor ASCI White cost \$110 million, so if we assume ASCI Red cost \$100 million, then Gordon Bell's prediction that a teraFLOPS computer would sell for about \$40 million at 25 KFLOPS/\$, in 1995 was nearly right. <span class="co">[</span><span class="ot">@bellUltracomputersTeraflopIts1992</span><span class="co">]</span></span>
<span id="cb18-2196"><a href="#cb18-2196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2197"><a href="#cb18-2197" aria-hidden="true" tabindex="-1"></a>The previous paradigm of supercomputers were hitting the limits of what you can do with just ~10 cores and shared memory architectures. For example, the Cray-2, an exemplar of 1980s supercomputers, had only 8 processors. Experts saw that future supercomputers needed to be "massively parallel", i.e. over 1000 cores. Indeed, the Japanese FGCS project produced parallel computers of up to 512 cores for the same rationale.</span>
<span id="cb18-2198"><a href="#cb18-2198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2199"><a href="#cb18-2199" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; During the 1980s, as the demand for computing power increased, the trend to a much larger number of processors began, ushering in the age of massively parallel systems, with distributed memory and distributed file systems, given that shared memory architectures could not scale to a large number of processors.</span></span>
<span id="cb18-2200"><a href="#cb18-2200" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2201"><a href="#cb18-2201" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Greg Astfalk (1996). Applications on Advanced Architecture Computers. SIAM. pp. 62.</span></span>
<span id="cb18-2202"><a href="#cb18-2202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2203"><a href="#cb18-2203" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Compared to existing expert systems running 2,000 rules at 50--100 rules per second, SCI promised" multiple cooperating expert systems with planning capability" running 30,000 rules firing at 12,000 rules per second and six times real time.</span></span>
<span id="cb18-2204"><a href="#cb18-2204" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2205"><a href="#cb18-2205" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 195</span><span class="co">]</span></span>
<span id="cb18-2206"><a href="#cb18-2206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2207"><a href="#cb18-2207" aria-hidden="true" tabindex="-1"></a>Other than massively parallel computers, there were also a few odds and ends. At the start of the program, there were brief efforts to get <span class="co">[</span><span class="ot">gallium arsenide (GaAs)</span><span class="co">](https://en.wikipedia.org/wiki/Gallium_arsenide)</span> chips working. Compared to silicon, GaAs has a wider bandgap, thus it tolarates higher temperatures and generally more extreme conditions. It started a running joke that GaAs would be the big silicon-chip killer in the next 10 years. 40 years later, it has yet to happen.</span>
<span id="cb18-2208"><a href="#cb18-2208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2209"><a href="#cb18-2209" aria-hidden="true" tabindex="-1"></a>More relevant was <span class="co">[</span><span class="ot">MOSIS</span><span class="co">](https://en.wikipedia.org/wiki/MOSIS)</span>, an on-demand chip fabrication service that was affordable enough even for university projects, especially university courses that taught the new <span class="co">[</span><span class="ot">VLSI</span><span class="co">](https://en.wikipedia.org/wiki/Very-large-scale_integration)</span> method -- just send in the design and get your final project back! Indeed, Feng-hsiung Hsu fabbed earlier iterations of chess chips by MOSIS.</span>
<span id="cb18-2210"><a href="#cb18-2210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2211"><a href="#cb18-2211" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pilot's associate</span></span>
<span id="cb18-2212"><a href="#cb18-2212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2213"><a href="#cb18-2213" aria-hidden="true" tabindex="-1"></a>There is little known about the Pilot's Associate project. The original plan called for 10,000-rule, real-time expert systems, animated displays with $10^8$ polygons per second, 200-word speaker-independent speech input system that works in high-noise environments, and a 1,000-word speech output system. Though the systems were demonstrated three times, there was no applications or follow-up. <span class="co">[</span><span class="ot">@nilssonQuestArtificialIntelligence2009, pages 362--363</span><span class="co">]</span> </span>
<span id="cb18-2214"><a href="#cb18-2214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2215"><a href="#cb18-2215" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Concept art for Pilot's Associate. [@rolandStrategicComputingDARPA2002, figure 7.1]</span><span class="co">](figure/Pilot_s_associate.png)</span></span>
<span id="cb18-2216"><a href="#cb18-2216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2217"><a href="#cb18-2217" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The dataflow of Pilot's Associate in 1991, at its third and final demo. [@banksPilotsAssociateCooperative1991, figure 1]</span><span class="co">](figure/pilot_s_assoctiate_1991.png)</span></span>
<span id="cb18-2218"><a href="#cb18-2218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2219"><a href="#cb18-2219" aria-hidden="true" tabindex="-1"></a><span class="fu">### Battle management</span></span>
<span id="cb18-2220"><a href="#cb18-2220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2221"><a href="#cb18-2221" aria-hidden="true" tabindex="-1"></a>In the long-gone past, an army was like a clockwork toy. It can march, hold ground, or turn slowly. Frontlines were on the order of 1 km, since it would be hard to see the commander from farther away. The progress of warfare made the battlespace more complex.</span>
<span id="cb18-2222"><a href="#cb18-2222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2223"><a href="#cb18-2223" aria-hidden="true" tabindex="-1"></a>Unsurprisingly, it was a secret thing. It was not described in detail anywhere. An expert system pioneer recalls:</span>
<span id="cb18-2224"><a href="#cb18-2224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2225"><a href="#cb18-2225" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; McCune: I built a system that I can't say very much about. It was a signal analysis system. I built it for $1 million. Five years later the boss of the boss of the boss of my client said, "Thank you, Brian. You saved me $500 million." That's what I'm talking about ROI. He said, "What other systems can you build for me?" I built him two more systems. So, it did pay off for the military.</span></span>
<span id="cb18-2226"><a href="#cb18-2226" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2227"><a href="#cb18-2227" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@allenExpertSystemsPioneer2018</span><span class="co">]</span></span>
<span id="cb18-2228"><a href="#cb18-2228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2229"><a href="#cb18-2229" aria-hidden="true" tabindex="-1"></a>However, we know that the Navy did get what they wanted, and they did work.</span>
<span id="cb18-2230"><a href="#cb18-2230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2231"><a href="#cb18-2231" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; “Battle Management Ashore” was officially the Fleet Command Center Battle Management Program (FCCBMP). Like PA, FCCBMP was to consist of five expert systems. Each would perform a particular task for the headquarters of the Pacific Fleet at Pearl Harbor (Commander-In-Chief, Pacific Fleet, or CINCPACFLT ). First, the Force Requirements Expert System (FRESH) would monitor the readiness of the fleet and assist in allocating its forces according to the capabilities and status of the individual ships. The Capabilities Assessment Expert System (CASES), would compare the relative strength of United States and hostile forces. The Campaign Simulation Expert System (CAMPSIM) would simulate the outcome of different courses of action. The Operations Plan Generation Expert System (OPGEN) would develop operational plans according to specified strategies. Finally, the Strategy Generation and Evaluation Expert System (STRATUS) would assist in developing plans for theater-level strategy. </span></span>
<span id="cb18-2232"><a href="#cb18-2232" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2233"><a href="#cb18-2233" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, pages 218--219</span><span class="co">]</span></span>
<span id="cb18-2234"><a href="#cb18-2234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2235"><a href="#cb18-2235" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In June 1986, FRESH Prototype One was installed in the test bed, and two months later it was demonstrated successfully to DARPA and the navy using the IRUS natural language generator developed by BBN, SAIC, and the Naval Ocean Systems Center (NOSC). At that time the IRUS vocabulary recognized 5,000 words, including proper names and naval terms; it successfully comprehended and responded to queries in terms usually used by the operations staff. By 1987 the enhanced system was performing in ninety minutes tasks that would usually take the CINCPACFLT staff fifteen hours. By then the navy employed the system routinely to monitor the readiness of its ships in the Pacific. </span></span>
<span id="cb18-2236"><a href="#cb18-2236" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2237"><a href="#cb18-2237" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, pages 265--266</span><span class="co">]</span></span>
<span id="cb18-2238"><a href="#cb18-2238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2239"><a href="#cb18-2239" aria-hidden="true" tabindex="-1"></a>Lest some, out of moral integrity, claim that mixing military and AI only hurts everyone, there was one definite success story in practice: DART.</span>
<span id="cb18-2240"><a href="#cb18-2240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2241"><a href="#cb18-2241" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Desert Shield/Storm</span><span class="co">](https://en.wikipedia.org/wiki/Gulf_War)</span><span class="at"> in 1990--91 </span><span class="sc">\[</span><span class="at">... had</span><span class="sc">\]</span><span class="at"> no prior buildup of troops or supplies. The US Department of Defense sealifted 2.4 million tons of cargo during the first six months of Desert Shield -- more than four times the cargo carried across the English Channel to Normandy during the D-Day invasion... About halfway through the six months of Desert Shield, Kral installed the system at the </span><span class="co">[</span><span class="ot">USTRANSCOM</span><span class="co">](https://en.wikipedia.org/wiki/United_States_Transportation_Command)</span><span class="at"> transportation command and the </span><span class="co">[</span><span class="ot">US European command</span><span class="co">](https://en.wikipedia.org/wiki/United_States_European_Command)</span><span class="at">, where it was used for the duration.</span></span>
<span id="cb18-2242"><a href="#cb18-2242" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2243"><a href="#cb18-2243" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hedbergDARTRevolutionizingLogistics2002</span><span class="co">]</span></span>
<span id="cb18-2244"><a href="#cb18-2244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2245"><a href="#cb18-2245" aria-hidden="true" tabindex="-1"></a>We don't have any pictures of this, or even source code, as it is probably a state secret. Still, it is described as</span>
<span id="cb18-2246"><a href="#cb18-2246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2247"><a href="#cb18-2247" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; a GUI-based scheduler that took a mainframe flat file of the details of all items to be moved--dates to move, places to move to and from, and so forth--and loaded the data into an Oracle database. The scheduling was done on a front-end Sun-4 workstation.</span></span>
<span id="cb18-2248"><a href="#cb18-2248" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2249"><a href="#cb18-2249" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hedbergDARTRevolutionizingLogistics2002</span><span class="co">]</span></span>
<span id="cb18-2250"><a href="#cb18-2250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2251"><a href="#cb18-2251" aria-hidden="true" tabindex="-1"></a>And did it work?</span>
<span id="cb18-2252"><a href="#cb18-2252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2253"><a href="#cb18-2253" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It enabled users to examine schedules at a higher level of abstraction, because it could readily aggregate modules. Planners could run strategic transportation models using DART in a matter of minutes rather than in hours or days. This enabled them to consider more alternatives and develop a more realistic action plan in far less time... The DART scheduling application paid back all of DARPA's 30 years of investment in AI in a matter of a few months, according to Victor Reis, Director of DARPA at the time.</span></span>
<span id="cb18-2254"><a href="#cb18-2254" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2255"><a href="#cb18-2255" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hedbergDARTRevolutionizingLogistics2002</span><span class="co">]</span></span>
<span id="cb18-2256"><a href="#cb18-2256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2257"><a href="#cb18-2257" aria-hidden="true" tabindex="-1"></a>I guess one can interpret it as either "wars are really expensive" or "DARPA had invested too little in AI".</span>
<span id="cb18-2258"><a href="#cb18-2258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2259"><a href="#cb18-2259" aria-hidden="true" tabindex="-1"></a><span class="fu">### Autonomous Land Vehicle</span></span>
<span id="cb18-2260"><a href="#cb18-2260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2261"><a href="#cb18-2261" aria-hidden="true" tabindex="-1"></a>If the other parts of SCI was shrouded in mystery, the Autonomous Land Vehicle (ALV) part made up for this. The ALV project was designed for the army, with a budget of \$10 million contracted to multiple organizations, each taking care of part of the system. The project had yearly goals, starting with 10 km/h in 1985 and ending with 50 km/h in 1990.</span>
<span id="cb18-2262"><a href="#cb18-2262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2263"><a href="#cb18-2263" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="The exact yearly goals" collapse="true" }</span>
<span id="cb18-2264"><a href="#cb18-2264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2265"><a href="#cb18-2265" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1985 - Road Following Demonstration: Vehicle traverses a 2 km preset route on a paved road at speeds up to 10 km/h. Forward motion only and no obstacle avoidance required.</span>
<span id="cb18-2266"><a href="#cb18-2266" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1986 - Obstacle Avoidance Demonstration: Vehicle traverses 5 km road course at speeds up to 20 km/h; must recognize and maneuver to avoid fixed objects that are small with respect to road width.</span>
<span id="cb18-2267"><a href="#cb18-2267" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1987 - Cross-country Route Planning Demonstration: Vehicle plans and executes a 5 km traverse of open desert terrain at speeds up to 5 km/h. Demonstrates soil and ground cover typing.</span>
<span id="cb18-2268"><a href="#cb18-2268" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1988 - Road Network Route Planning and Obstacle Avoidance Demonstration: Vehicle plans and executes a 20 km point-to-point traverse through a road network at speeds up to 20 km/h using landmarks as navigation aids. Demonstration includes map updating and off-road maneuvering to avoid obstacles.</span>
<span id="cb18-2269"><a href="#cb18-2269" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1989 - Cross-country Traverse with Landmark Recognition Demonstration: Vehicle plans and executes a 20 km traverse through desert terraín with obstacles at speeds up to 10 km/h. Demonstration includes replanning when confronted with impassable obstacles.</span>
<span id="cb18-2270"><a href="#cb18-2270" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>1990 - Mixed road and Open Terrain Demonstration: Vehicle plans and executes a 20 km traverse in wooded terrain with isolated obstacles and a 50 km traverse on paved and unpaved roads at speeds up to 50 km/h. Route planning includes multiple goals.</span>
<span id="cb18-2271"><a href="#cb18-2271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2272"><a href="#cb18-2272" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-2273"><a href="#cb18-2273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2274"><a href="#cb18-2274" aria-hidden="true" tabindex="-1"></a>What did the army expect to gain from this? Reconnaissance, "offensive and defensive missions" with a platoon of vehicles, and robotic variants of the <span class="co">[</span><span class="ot">Armored Family of Vehicles</span><span class="co">](https://en.wikipedia.org/wiki/Armored_Systems_Modernization)</span> that could execute missions "singularly, in packs, or in concert with manned vehicles", sometime after 1991. <span class="co">[</span><span class="ot">@leightyDevelopingTechnologiesArmy1986</span><span class="co">]</span></span>
<span id="cb18-2275"><a href="#cb18-2275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2276"><a href="#cb18-2276" aria-hidden="true" tabindex="-1"></a>Out of these, we focus on the Navigation Lab (Navlab) at Carnegie Mellon University, since that one had the greatest impact.</span>
<span id="cb18-2277"><a href="#cb18-2277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2278"><a href="#cb18-2278" aria-hidden="true" tabindex="-1"></a>Navlab started work on ALV in 1984. The first vehicle they produced was Navlab 1 (1986). Its sensors included cameras, a sonar, a lidar, and an inertial guidance system (this was before GPS). Its only actuator was a stepped motor for steering. In the middle was a <span class="co">[</span><span class="ot">Sun 3</span><span class="co">](https://en.wikipedia.org/wiki/Sun-3)</span>, a standard workstation of the time, and optionally a <span class="co">[</span><span class="ot">Warp</span><span class="co">]</span>(https://en.wikipedia.org/wiki/WARP_(systolic_array)#Applications) computer, a <span class="co">[</span><span class="ot">systolic array</span><span class="co">](https://en.wikipedia.org/wiki/Systolic_array)</span> developed as part of SCI.</span>
<span id="cb18-2279"><a href="#cb18-2279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2280"><a href="#cb18-2280" aria-hidden="true" tabindex="-1"></a>A Warp computer is made of a chain of processors. Each processor is programmable, and data "pulses through" the processors like blood flowing through vessels. This allowed it to perform data parallel computations, like 2D convolutions and other computer vision tasks. You can think of it as a GPU for the 1980s. In a 10-core Warp computer, each core ran at 10 MIPS, and the whole thing could run a neural network at 17 million "connections per second", meaning that it takes about $\frac{1.7 \times 10^7}{N}$ seconds to run one forward and backward pass over a neural network with $N$ weights. Impressively, this was 30\% faster than even the 65K-core Connection Machine-1. <span class="co">[</span><span class="ot">@blellochNetworkLearningConnection1987; @pomerleauNeuralNetworkSimulation1988</span><span class="co">]</span></span>
<span id="cb18-2281"><a href="#cb18-2281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2282"><a href="#cb18-2282" aria-hidden="true" tabindex="-1"></a>FIDO (Find Instead of Destroy Objects) was a <span class="co">[</span><span class="ot">stereovision</span><span class="co">](https://en.wikipedia.org/wiki/Computer_stereo_vision)</span> algorithm. It takes as input two cameras' images, and for each, uses a hand-designed "interest operator" to find landmark points, then use that to compute the 3D locations of the landmarks. These are sent to a path-planner. It ran at 4.8 sec/pass. No wonder the car could only drive 0.5 m/s. Work on FIDO stopped in 1987, since it was outclassed by the lidar. <span class="co">[</span><span class="ot">@thorpeVisionNavigationCarnegie1990, chapter 14</span><span class="co">]</span></span>
<span id="cb18-2283"><a href="#cb18-2283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2284"><a href="#cb18-2284" aria-hidden="true" tabindex="-1"></a>SCARF (Supervised Classification Applied to Road-Following) was developed since 1986. Schematically, the first version runs as follows. At each step, it compares each image pixel against a road color and an off-road color. It partitions an image's pixels into connected blobs of "probably road" and "probably off-road" by a simple Bayes classifier. It then converts the blobs into polygons, and compare each polygonal edge with an idealized road model (a projective transform of a circular arc), minimizing change compared to the previous frame's road model. It uses the best-fit road model to compute the new average on- and off-road pixel colors. It returns the fitted ideal road model, which is used to decide the turning angle.</span>
<span id="cb18-2285"><a href="#cb18-2285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2286"><a href="#cb18-2286" aria-hidden="true" tabindex="-1"></a>In pseudocode:</span>
<span id="cb18-2287"><a href="#cb18-2287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2288"><a href="#cb18-2288" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-2289"><a href="#cb18-2289" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SCARF:</span>
<span id="cb18-2290"><a href="#cb18-2290" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, ...):</span>
<span id="cb18-2291"><a href="#cb18-2291" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_dist <span class="op">=</span> (road_color_mean, road_color_variance)</span>
<span id="cb18-2292"><a href="#cb18-2292" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.off_road_dist <span class="op">=</span> (off_road_color_mean, off_road_color_variance)</span>
<span id="cb18-2293"><a href="#cb18-2293" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_model <span class="op">=</span> initial_road_model</span>
<span id="cb18-2294"><a href="#cb18-2294" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_location <span class="op">=</span> <span class="va">None</span></span>
<span id="cb18-2295"><a href="#cb18-2295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2296"><a href="#cb18-2296" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> process_image(<span class="va">self</span>, image):</span>
<span id="cb18-2297"><a href="#cb18-2297" aria-hidden="true" tabindex="-1"></a>        pixels <span class="op">=</span> label_pixels(image, <span class="va">self</span>.road_color, <span class="va">self</span>.off_road_color)</span>
<span id="cb18-2298"><a href="#cb18-2298" aria-hidden="true" tabindex="-1"></a>        blobs <span class="op">=</span> connected_components(pixels)</span>
<span id="cb18-2299"><a href="#cb18-2299" aria-hidden="true" tabindex="-1"></a>        polygons <span class="op">=</span> fit_polygons(blobs)</span>
<span id="cb18-2300"><a href="#cb18-2300" aria-hidden="true" tabindex="-1"></a>        candidate_edges <span class="op">=</span> select_road_edges(polygons)</span>
<span id="cb18-2301"><a href="#cb18-2301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2302"><a href="#cb18-2302" aria-hidden="true" tabindex="-1"></a>        <span class="co"># update states</span></span>
<span id="cb18-2303"><a href="#cb18-2303" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_model, <span class="va">self</span>.road_location <span class="op">=</span> fit_road_model(candidate_edges, <span class="va">self</span>.road_model)</span>
<span id="cb18-2304"><a href="#cb18-2304" aria-hidden="true" tabindex="-1"></a>        road_pixels, off_road_pixels <span class="op">=</span> divide_image(image, <span class="va">self</span>.road_location)</span>
<span id="cb18-2305"><a href="#cb18-2305" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.road_dist <span class="op">=</span> (mean(road_pixels), variance(road_pixels))</span>
<span id="cb18-2306"><a href="#cb18-2306" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.off_road_dist <span class="op">=</span> (mean(off_road_pixels), variance(off_road_pixels))</span>
<span id="cb18-2307"><a href="#cb18-2307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2308"><a href="#cb18-2308" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.road_model, <span class="va">self</span>.road_location</span>
<span id="cb18-2309"><a href="#cb18-2309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-2310"><a href="#cb18-2310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2311"><a href="#cb18-2311" aria-hidden="true" tabindex="-1"></a>SCARF ran at about 3 sec/pass. Later versions allowed multiple on- and off-road colors, and used <span class="co">[</span><span class="ot">Hough transform</span><span class="co">](https://en.wikipedia.org/wiki/Hough_transform)</span> to directly fit the edges of the idealized road model to image.</span>
<span id="cb18-2312"><a href="#cb18-2312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2313"><a href="#cb18-2313" aria-hidden="true" tabindex="-1"></a>ALVINN, the first neural network driver, began in February 1989. It was trained off-line on a Warp, using purely generated images and driving instructions, presumably because they could not afford to store real images on disk. A training run took 8 hours on the Warp, but inference just took 0.75 s/image on a Sun 3, so they would train it on a Warp in the lab, and run it on a Sun 3 in the car. Soon, it set the Navlab speed record $1.3 \;\mathrm{m/s}$ on 1989-03-16.</span>
<span id="cb18-2314"><a href="#cb18-2314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2315"><a href="#cb18-2315" aria-hidden="true" tabindex="-1"></a>In 1989-06, they were greatly surprised to find that ALVINN could be trained rapidly online, so they started doing runs where for the first 10 minutes a human would drive while the ALVINN is trained online in the Warp computer in the back of the car (often carrying around a graduate student watching it train), then ALVINN would take over control. This was possibly the first successful imitation learning application. They also found that, because a human driver would never go off the lanes, ALVINN would not know what to do if it starts going off the lane, so they programmed a data augmentation method by shearing the image left and right by 5 angles each, and the real human steering angle is shifted accordingly. In this way, each example is augmented to 11 examples. </span>
<span id="cb18-2316"><a href="#cb18-2316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2317"><a href="#cb18-2317" aria-hidden="true" tabindex="-1"></a>In 1989, Navlab 1 burned when conditioning system leaked liquid onto the computers. Navlab 2 was built in 1990 based on a <span class="co">[</span><span class="ot">Humvee</span><span class="co">](https://en.wikipedia.org/wiki/Humvee)</span>, which could drive both on-road (110 km/h) and off-road (10 km/h). Information about the subsequent Navlab cars is scarce, but from what I gathered, they were generally statistical methods on handcrafted features, without neural networks, learned features, and with only a minimum amount of online learning.</span>
<span id="cb18-2318"><a href="#cb18-2318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2319"><a href="#cb18-2319" aria-hidden="true" tabindex="-1"></a>In 1995, Navlab 5 drove across continental America "No Hands Across America" autonomously for 98% of the time at average speed 100 km/h. However, little happened subsequent this -- until 2004, when DARPA issued a <span class="co">[</span><span class="ot">Grand Challenge</span><span class="co">](https://en.wikipedia.org/wiki/DARPA_Grand_Challenge)</span> for self-driving again. The Stanford Team that won in 2005 later became <span class="co">[</span><span class="ot">Google Waymo</span><span class="co">](https://en.wikipedia.org/wiki/Waymo)</span>.</span>
<span id="cb18-2320"><a href="#cb18-2320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2321"><a href="#cb18-2321" aria-hidden="true" tabindex="-1"></a><span class="fu">### Demo or die</span></span>
<span id="cb18-2322"><a href="#cb18-2322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2323"><a href="#cb18-2323" aria-hidden="true" tabindex="-1"></a>Well, remember that the planners wanted a demo of ALV every year. So how did the demos go?</span>
<span id="cb18-2324"><a href="#cb18-2324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2325"><a href="#cb18-2325" aria-hidden="true" tabindex="-1"></a>A team at Martin Marietta Denver Aerospace was responsible for putting together the demos, and they called their vehicle "Alvin" (no relation to ALVINN). Like Navlab 1, the system essentially has two parts: the vision part, which extracts the shape of the road from the camera video, and the planner. Unlike Navlab 1, the planner was a sophisticated expert system that uses the road model output by the vision and its knowledge base (location, map, known objects, goal location, etc) to compute a driving plan.</span>
<span id="cb18-2326"><a href="#cb18-2326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2327"><a href="#cb18-2327" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The knowledge base consists of a priori map data, and a set of routines for accessing the data. Currently, the map data contains information describing the road network being used as the ALV test track. The map data contains coordinates which specify the location of the roadway, as well as various significant features along the road, such as intersections, sharp curves, and several local road features.</span></span>
<span id="cb18-2328"><a href="#cb18-2328" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2329"><a href="#cb18-2329" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@turkVITSaVisionSystem1988</span><span class="co">]</span></span>
<span id="cb18-2330"><a href="#cb18-2330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2331"><a href="#cb18-2331" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The architecture of Alvin. It has a low-level vision model and a high-level expert system planner. [@turkVITSaVisionSystem1988, figure 1, figure 3]</span><span class="co">](figure/Alvin_architecture.png)</span></span>
<span id="cb18-2332"><a href="#cb18-2332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2333"><a href="#cb18-2333" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">How Alvin represents the road. [@turkVITSaVisionSystem1988, figure 4, figure 5]</span><span class="co">](figure/Alvin_scene_representation.png)</span></span>
<span id="cb18-2334"><a href="#cb18-2334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2335"><a href="#cb18-2335" aria-hidden="true" tabindex="-1"></a>Alvin's vision system was plagued by the same problem of logical AI: fragility. Every time a part upgrades, something breaks. Much of the high-level planning was written to deal with the fragility of the vision system. If the high-level planner detects that the scene model output by the vision system is probably nonsense, it simply discard it. The endless trouble encountered by Alvin deserves quotation in full:</span>
<span id="cb18-2336"><a href="#cb18-2336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2337"><a href="#cb18-2337" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The vision system proved highly sensitive to environmental conditions--the quality of light, the location of the sun, shadows, and so on. The system worked differently from month to month, day to day, and even test to test. Sometimes it could accurately locate the edge of the road, sometimes not. The system reliably distinguished the pavement of the road from the dirt on the shoulders, but it was fooled by dirt that was tracked onto the roadway by heavy vehicles maneuvering around the ALV. In the fall, the sun, now lower in the sky, reflected brilliantly off the myriads of polished pebbles in the tarmac itself, producing glittering reflections that confused the vehicle. Shadows from trees presented problems, as did asphalt patches from the frequent road repairs made necessary by the harsh Colorado weather and the constant pounding of the eight-ton vehicle.</span></span>
<span id="cb18-2338"><a href="#cb18-2338" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2339"><a href="#cb18-2339" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Perhaps more alarming to the Martin engineers was the early realization that there would not be one all-purpose, road-following algorithm. Different situations required different programs. The first road-following algorithm that Maryland installed on the vehicle, the “vanishing point” algorithm, had functioned satisfactorily in the lab but not on the road. Under certain conditions the vehicle thought the road had folded back under itself. This algorithm had to be replaced by the “flat-earth” algorithm, so-called because it worked by using a two-dimensional representation of the road and assuming that the road was perfectly flat. The algorithm was quick to run, but it was relatively inaccurate, and, not surprisingly, it worked only on flat ground. The third program, the “hill-and-dale” algorithm, used a three-dimensional representation of the road. It functioned better on uneven ground, but it did not work on curves. Maryland came up with a fourth algorithm, the “zero-bank” algorithm, which solved this problem; but it ran too slowly on the vehicle’s computers and had to be put off until phase II of the program...</span></span>
<span id="cb18-2340"><a href="#cb18-2340" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2341"><a href="#cb18-2341" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Other problems were caused just by the sheer complexity of the system. By the November 1985 demonstration, 25,000–30,000 lines of code were running in real time on ten different processors... Each new feature and capability brought with it a host of unanticipated problems. A new panning system, installed in early 1986 to permit the camera to turn as the road curved, unexpectedly caused the vehicle to veer back and forth until it ran off the road altogether. The software glitch was soon fixed, but the panning system had to be scrapped anyway; the heavy, 40-pound camera stripped the device’s gears whenever the vehicle made a sudden stop.</span></span>
<span id="cb18-2342"><a href="#cb18-2342" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2343"><a href="#cb18-2343" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, pages 234--235</span><span class="co">]</span></span>
<span id="cb18-2344"><a href="#cb18-2344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2345"><a href="#cb18-2345" aria-hidden="true" tabindex="-1"></a>Given such serious problem, the team opted to just "study for the test". Like the many demos before and since then, it promises to do much more than it could, using techniques much less general than it should.</span>
<span id="cb18-2346"><a href="#cb18-2346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2347"><a href="#cb18-2347" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Given such unanticipated difficulties and delays, Martin increasingly directed its efforts toward achieving just the specific capabilities required by the milestones, at the expense of developing more general capabilities... Martin’s selection of technology was conservative. It had to be, as the ALV program could afford neither the lost time nor the bad publicity that a major failure would bring... ADS’s obstacle-avoidance algorithm was so narrowly focused that the company was unable to test it in a parking lot; it worked only on roads.</span></span>
<span id="cb18-2348"><a href="#cb18-2348" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2349"><a href="#cb18-2349" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 235</span><span class="co">]</span></span>
<span id="cb18-2350"><a href="#cb18-2350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2351"><a href="#cb18-2351" aria-hidden="true" tabindex="-1"></a>Though Alvin passed one demo after another, the "demo or die" approach resulted in a series of demos made by "ad-hoc, off-the-shelf solutions" that did not generalize, or integrate the other technologies developed in the SCI.</span>
<span id="cb18-2352"><a href="#cb18-2352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2353"><a href="#cb18-2353" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The experience with ALV mirrored what was going on elsewhere in the SC program. The applications failed to connect with the technology base. Instead, applications extemporized ad-hoc, off-the-shelf solutions to meet demonstration deadlines. Meanwhile, the many research projects in the technology base rose and fell on their own merits. Mutually incompatible, they seldom achieved integration, let alone transition... Takeo Kanade... criticized the program as “too much demo-driven... Instead of integrating the technologies developed in the SC tech base... effort is spent ‘shopping’ for existing techniques which can be put together just for the sake of a demonstration.” Based on the recommendations of the panel, DARPA quietly abandoned the milestones and ended the ALV’s development program.</span></span>
<span id="cb18-2354"><a href="#cb18-2354" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2355"><a href="#cb18-2355" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, pages 243--245</span><span class="co">]</span></span>
<span id="cb18-2356"><a href="#cb18-2356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2357"><a href="#cb18-2357" aria-hidden="true" tabindex="-1"></a><span class="fu">### General AI technologies</span></span>
<span id="cb18-2358"><a href="#cb18-2358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2359"><a href="#cb18-2359" aria-hidden="true" tabindex="-1"></a>SCI called for three fields of basic AI in support of the above applications: speech recognition, computer vision, and general integration of logical AI techniques. Only speech recognition was a success.</span>
<span id="cb18-2360"><a href="#cb18-2360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2361"><a href="#cb18-2361" aria-hidden="true" tabindex="-1"></a>The aspiration of the speech recognition task was to allow pilots to speak to the computer, so it eventually had to recognize continuous speech with noise. DARPA released a benchmark of 21000 sentences from 160 speakers reading out sentences "appropriate to a naval resource management task built around existing interactive database and graphics programs" <span class="co">[</span><span class="ot">@priceDARPA1000wordResource1988</span><span class="co">]</span>. This was one of the first public benchmarks, instilling a benchmark-centric culture around ASR early on. The HMM-based models, similar to those developed by Jelinek *et al* at IBM, reached the goal.</span>
<span id="cb18-2362"><a href="#cb18-2362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2363"><a href="#cb18-2363" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Throughout the program, speech recognition held to its original goal of 10,000-word continuous speech recognition, using speaker-independent natural grammar, moderate noise, and low stress... Such systems were up and running by the end of SC, being integrated into military applications and undergoing development for commercial applications.</span></span>
<span id="cb18-2364"><a href="#cb18-2364" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2365"><a href="#cb18-2365" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 211</span><span class="co">]</span></span>
<span id="cb18-2366"><a href="#cb18-2366" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2367"><a href="#cb18-2367" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In January 1986 Carnegie Mellon had demonstrated a speech system that could recognize 250 words spoken continuously regardless of the speaker. By 1987 this system could cope with a 1,000-word vocabulary with 95 percent accuracy, operating at 10 times real time on a parallel system. Texas Instruments produced a robust 200-word connected-speech-recognition system that was installed on F-16 fighters for operational testing by pilots.</span></span>
<span id="cb18-2368"><a href="#cb18-2368" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2369"><a href="#cb18-2369" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 224</span><span class="co">]</span></span>
<span id="cb18-2370"><a href="#cb18-2370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2371"><a href="#cb18-2371" aria-hidden="true" tabindex="-1"></a>The aspiration of the vision task was to allow armored vehicles to drive through hostile environments autonomously. Among </span>
<span id="cb18-2372"><a href="#cb18-2372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2373"><a href="#cb18-2373" aria-hidden="true" tabindex="-1"></a>TODO David Marr's theory</span>
<span id="cb18-2374"><a href="#cb18-2374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2375"><a href="#cb18-2375" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Developments in vision were far more disappointing. Part of the reason is that expectations at the beginning of SC were so high. Prior research on computer vision may be grouped in three eras. In the 1950s and 1960s techniques from signal processing and statistical decision theory produced important developments in areas such as Synthetic Aperture Radar, image-enhancement, and terrain-matching, cruise-missile guidance. These were essentially ad hoc inventions, innocent of a conceptual paradigm. </span></span>
<span id="cb18-2376"><a href="#cb18-2376" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2377"><a href="#cb18-2377" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In the late 1970s, when DARPA was funding an image-understanding program aimed at photo interpretation, a “signals-to-symbols” paradigm gained currency. It was, however, a theory of low-level, general-purpose vision, limited essentially to two-dimensional analysis. Optimism that this limitation might be breached grew in the late 1970s, culminating in the 1982 publication of David Marr’s pathbreaking study, *Vision*, just as the SC plan was taking shape.</span></span>
<span id="cb18-2378"><a href="#cb18-2378" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2379"><a href="#cb18-2379" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; As Noam Chomsky had done for speech in the 1950s, Marr refined a new paradigm based on modeling visual cues such as shading, stereopsis, texture, edges, and color to arrive at what he called a “2-D sketch.” His theoretical models, combined with the magnified computing power of SC’s new architectures, suggested to many researchers that high-level vision was within reach, that a computer would soon employ standard algorithms to distill visual and other signals into machine understanding of what it was “seeing.”</span></span>
<span id="cb18-2380"><a href="#cb18-2380" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2381"><a href="#cb18-2381" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 212</span><span class="co">]</span></span>
<span id="cb18-2382"><a href="#cb18-2382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2383"><a href="#cb18-2383" aria-hidden="true" tabindex="-1"></a>As for the general AI integration, the idea was similar to Shakey. Just like Shakey integrated the main logical AI techniques up to 1970, SCI called for integrating the main logical AI techniques up to 1980s. The SCI planners thought that the success of expert systems had shown that the time was ripe for a concerted push for a general expert system that combines the best ideas so far: blackboards (developed during the ARPA-funded speech understanding project), forward and reverse chaining, default reasoning, etc. This integration proved a failure, like the dream of a generally intelligent expert system. <span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, page 243</span><span class="co">]</span></span>
<span id="cb18-2384"><a href="#cb18-2384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2385"><a href="#cb18-2385" aria-hidden="true" tabindex="-1"></a>In 1990, funding for AI was killed, because the new director of SCI believed there is no unified AI principle, only particular AI systems demonstrating particular intelligences.</span>
<span id="cb18-2386"><a href="#cb18-2386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2387"><a href="#cb18-2387" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In a cold and devastating review of “The Limits of Artificial Intelligence” prepared for the 1987 edition of The Encyclopedia of Artificial Intelligence, </span><span class="co">[</span><span class="ot">\[Jacob\] Schwartz</span><span class="co">](https://en.wikipedia.org/wiki/Jacob_T._Schwartz)</span><span class="at"> had argued that AI had yet to demonstrate “any unifying principles of self organization,” meaning that its “applications must still be seen as adaptations of diverse ideas rather than as systematic accomplishments of a still mythical AI technology.” ... he believed that expert systems were achieving what success they had by clever programming, not by the application of any general principles. His analysis bode ill for the prospects of achieving a generic expert system of the kind envisioned by the SC program and the contracts with Teknowledge and IntelliCorp. Indeed, Schwartz believed that the same critique applied to AI in general; he concluded that “it may be necessary to develop a relatively large number of artificial systems that mimic particular types of reasoning and mental functions in cases specialized enough to have particularly efficient treatment.”</span></span>
<span id="cb18-2388"><a href="#cb18-2388" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2389"><a href="#cb18-2389" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@rolandStrategicComputingDARPA2002, pages 204--208</span><span class="co">]</span></span>
<span id="cb18-2390"><a href="#cb18-2390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2391"><a href="#cb18-2391" aria-hidden="true" tabindex="-1"></a><span class="fu">## Philosophy</span></span>
<span id="cb18-2392"><a href="#cb18-2392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2393"><a href="#cb18-2393" aria-hidden="true" tabindex="-1"></a>Astrophysicists, measuring the motion of galaxies, notice that the stars are rotating too fast. There is not enough matter to tether them, and they ought to fly out into the intergalactic emptiness. To solve this problem, they proposed "dark matter", unknown matter that provides the missing gravitational force, and physicists ever since had been searching them.</span>
<span id="cb18-2394"><a href="#cb18-2394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2395"><a href="#cb18-2395" aria-hidden="true" tabindex="-1"></a>Similarly, sometimes when you read through a field of study, you notice that the arguments seem to rotate around some kind of unspoken assumption that you might see if you just take all the books and throw them to the ground, so that they are all opened at random places. Then you turn your head and squint at the words refracted through the eyelids, the pupils, and the cornea, which you have repurposed as a primitive kind of optical computer. And you see the dark matter, the intellectual centers of gravity.</span>
<span id="cb18-2396"><a href="#cb18-2396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2397"><a href="#cb18-2397" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Under an invisible spell, they will each start out anew, only to end up revolving in the same orbit once again... their thinking is not nearly as much a discovery as it is a recognition, remembrance, a returning and homecoming into a distant, primordial, total economy of the soul, from which each concept once grew: -- to this extent, philosophizing is a type of atavism of the highest order.</span></span>
<span id="cb18-2398"><a href="#cb18-2398" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2399"><a href="#cb18-2399" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@nietzscheGoodEvilPrelude2002, Section 1.20</span><span class="co">]</span></span>
<span id="cb18-2400"><a href="#cb18-2400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2401"><a href="#cb18-2401" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Symbolic Hypothesis</span></span>
<span id="cb18-2402"><a href="#cb18-2402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2403"><a href="#cb18-2403" aria-hidden="true" tabindex="-1"></a>In <span class="co">[</span><span class="ot">their Turing award lecture of 1975</span><span class="co">](https://yuxi-liu-wired.github.io/docs/posts/1975-herbert-simon-allen-newell/)</span>, Allen Newell and Herbert Simon gave a definitive statement of the Physical Symbol System Hypothesis for AI, which they had labored under, first unconsciously but then consciously, since the early 1950s.</span>
<span id="cb18-2404"><a href="#cb18-2404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2405"><a href="#cb18-2405" aria-hidden="true" tabindex="-1"></a>They began by some examples of "qualitative structure" in science, which do not deal with numbers, but with symbols. For example, a basic statement of cell theory -- "organisms are made of little cells that are mostly alike" -- doesn't contain a single number, yet it has great significance. Such non-numerical discrete statements are made of "symbols", and they stated their **Physical Symbol System Hypothesis** (PSSH):</span>
<span id="cb18-2406"><a href="#cb18-2406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2407"><a href="#cb18-2407" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A physical symbol system has the necessary and sufficient means for general intelligent action.</span></span>
<span id="cb18-2408"><a href="#cb18-2408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2409"><a href="#cb18-2409" aria-hidden="true" tabindex="-1"></a>where a physical symbol system is essentially a machine that can be built in our physical world, and that manipulates with symbols. As an example, a digital computer running a LISP interpreter is a physical symbol system. We can attach cameras and wheels to the computer, so that the camera sends into the interpreter a symbolic representation of what it sees, and the wheels receives symbolic commands for motion. This is basically a robot according to the PSSH.</span>
<span id="cb18-2410"><a href="#cb18-2410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2411"><a href="#cb18-2411" aria-hidden="true" tabindex="-1"></a>They also gave a **Heuristic Search Hypothesis**:</span>
<span id="cb18-2412"><a href="#cb18-2412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2413"><a href="#cb18-2413" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A physical symbol system exercises its intelligence in problem solving by search-that is, by generating and progressively modifying symbol structures until it produces a solution structure.</span></span>
<span id="cb18-2414"><a href="#cb18-2414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2415"><a href="#cb18-2415" aria-hidden="true" tabindex="-1"></a>What is not said is equally revealing. In the lecture, there were over 100 mentions of the word "search", but the only statement about learning is... a mention of Plato's theory of <span class="co">[</span><span class="ot">anamnesis</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Anamnesis_(philosophy))! For them, a symbolic system starts out already with a solution generator and a solution tester, and problem-solving is nothing but heuristically searching over the generated solutions until one passes the tester. Indeed, in their telling, AI research is just search, not learning.</span>
<span id="cb18-2416"><a href="#cb18-2416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2417"><a href="#cb18-2417" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... During the first decade or so of artificial intelligence research, the study of problem solving was almost synonymous with the study of search processes. From our characterization of problems and problem solving, it is easy to see why this was so. In fact, it might be asked whether it could be otherwise. ...  There is no mystery where the information that guided the search came from. We need not follow Plato in endowing the symbol system with a previous existence in which it already knew the solution. A moderately sophisticated generator-test system did the trick without invoking reincarnation.</span></span>
<span id="cb18-2418"><a href="#cb18-2418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2419"><a href="#cb18-2419" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cognitivism</span></span>
<span id="cb18-2420"><a href="#cb18-2420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2421"><a href="#cb18-2421" aria-hidden="true" tabindex="-1"></a>There was a persistent legend about a certain psychologist, that he educated his own children with <span class="co">[</span><span class="ot">skinner boxes</span><span class="co">](https://en.wikipedia.org/wiki/Operant_conditioning_chamber)</span>. While just a legend, the real B. F. Skinner did have a philosophy as radical as the legend suggests.</span>
<span id="cb18-2422"><a href="#cb18-2422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2423"><a href="#cb18-2423" aria-hidden="true" tabindex="-1"></a>In the 1950s, Skinner dominated behaviorism, which dominated American psychology. In short, behaviorism models animal behavior as stimulus-response reflexes, which can be understood as parameterized functions $a_\theta(o)$, where $o$ stands for the observational stimulus, $\theta$ the internal parameters of the animal, and $a_\theta(o)$ the response action. The parameters $\theta$ is a function of the previous history of stimuli and reward/punishments: $(o_0, a_0, r_0, o_1, a_1, r_1, \dots)$. The set up is the same as modern reinforcement learning (RL).</span>
<span id="cb18-2424"><a href="#cb18-2424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2425"><a href="#cb18-2425" aria-hidden="true" tabindex="-1"></a><span class="ot">[^skinner-box]</span>:</span>
<span id="cb18-2426"><a href="#cb18-2426" aria-hidden="true" tabindex="-1"></a>    <span class="co">[</span><span class="ot">Feynman told of the following maze-running rat legend</span><span class="co">](https://gwern.net/maze)</span>:</span>
<span id="cb18-2427"><a href="#cb18-2427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2428"><a href="#cb18-2428" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; He had a long corridor with doors all along one side where the rats came in, and doors along the other side where the food was. He wanted to see if he could train the rats to go in at the third door down from wherever he started them off. No. The rats went immediately to the door where the food had been the time before. The question was, how did the rats know, because the corridor was so beautifully built and so uniform, that this was the same door as before? Obviously there was something about the door that was different from the other doors. So he painted the doors very carefully, arranging the textures on the faces of the doors exactly the same. Still the rats could tell. Then he thought maybe the rats were smelling the food, so he used chemicals to change the smell after each run. Still the rats could tell. Then he realized the rats might be able to tell by seeing the lights and the arrangement in the laboratory like any commonsense person. So he covered the corridor, and, still the rats could tell. He finally found that they could tell by the way the floor sounded when they ran over it. And he could only fix that by putting his corridor in sand. So he covered one after another of all possible clues and finally was able to fool the rats so that they had to learn to go in the third door. If he relaxed any of his conditions, the rats could tell.</span></span>
<span id="cb18-2429"><a href="#cb18-2429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2430"><a href="#cb18-2430" aria-hidden="true" tabindex="-1"></a>The great thing about skinner boxes is that they are standardized to be lightproof, soundproof, and whatever-proof, thus controlling for all confounding variables. Before skinner boxes, mouse experiments were full of confounding variables, and had a kind of replication crisis in the 1930s. With the skinner box, the degrees of rat freedom are minimized, turning rats into standardized systems. This finally allowed measurable progress, allowing the breakout success of behaviorism in the 1950s.<span class="ot">[^skinner-box]</span></span>
<span id="cb18-2431"><a href="#cb18-2431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2432"><a href="#cb18-2432" aria-hidden="true" tabindex="-1"></a>Skinner's ambitions went far beyond rats. In 1957, he published <span class="co">[</span><span class="ot">*Verbal Behavior*</span><span class="co">](https://en.wikipedia.org/wiki/Verbal_Behavior)</span>, in which he explained human language as stimulus-response networks, built up piece by piece during child development. To give an example, when one searches for a book with a title "Verbal Behavior", one would say "Verbal Behavior, Verbal Behavior, Verbal Behavior..." (a "self-echoic") while the eye scans the shelf. When the visual stimulus matches the verbal stimulus, the "grab book" action is triggered (a "tact"). The touch of the hand with the book then stops self-echoic behavior. In Skinner's terms, this verbal behavior is a "<span class="co">[</span><span class="ot">descriptive autoclitic</span><span class="co">](https://en.wikipedia.org/wiki/Autoclitic)</span>".</span>
<span id="cb18-2433"><a href="#cb18-2433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2434"><a href="#cb18-2434" aria-hidden="true" tabindex="-1"></a>He was at his most radical in <span class="co">[</span><span class="ot">*Beyond Freedom and Dignity* (1971)</span><span class="co">](https://en.wikipedia.org/wiki/Beyond_Freedom_and_Dignity)</span>, which essentially argued that human society will be reorganized according to behaviorist principles. Instead of the indirect and unreliable behavior control using verbal moral judgment, a society would use more direct operant conditioning methods that are experimentally proven by behaviorist psychologists.</span>
<span id="cb18-2435"><a href="#cb18-2435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2436"><a href="#cb18-2436" aria-hidden="true" tabindex="-1"></a>Though behaviorism has remained alive and well to this day, linguistics took a sudden turn around 1960 thanks to Noam Chomsky. According to legend, Chomsky wrote a review of *Verbal Behavior* in 1959, in which he soundly routed behaviorist linguistics [@chomskyReviewSkinnersVerbal1959]. The truth is more complicated, since Chomsky also wrote several other famous works like [*Syntactic Structures* (1957)](https://en.wikipedia.org/wiki/Syntactic_Structures), [*Aspects of the Theory of Syntax* (1967)](https://en.wikipedia.org/wiki/Aspects_of_the_Theory_of_Syntax), and the foundational papers on formal grammar like the <span class="co">[</span><span class="ot">Chomsky hierarchy</span><span class="co">](https://en.wikipedia.org/wiki/Chomsky_hierarchy)</span>.</span>
<span id="cb18-2437"><a href="#cb18-2437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2438"><a href="#cb18-2438" aria-hidden="true" tabindex="-1"></a>Chomsky argued that there are two ways of doing research in psychology and linguistics: "empiricism" and "rationalism". Skinner's book was the best example of empiricism, and since Skinner's book is wrong, the book becomes a *reductio ad absurdum* of empiricism. Instead, one must turn back to rationalist psychology and linguistics.</span>
<span id="cb18-2439"><a href="#cb18-2439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2440"><a href="#cb18-2440" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I had intended this review not specifically as a criticism of Skinner's speculations regarding language, but rather as a more general critique of behaviorist (I would now prefer to say "empiricist") speculation as to the nature of higher mental processes... I do not, in other words, see any way in which his proposals can be substantially improved within the general framework of behaviorist or neobehaviorist, or, more generally, empiricist ideas that has dominated much of modern linguistics, psychology, and philosophy. The conclusion that I hoped to establish in the review, by discussing these speculations in their most explicit and detailed form, was that the general point of view was largely mythology, and that its widespread acceptance is not the result of empirical support, persuasive reasoning, or the absence of a plausible alternative.</span></span>
<span id="cb18-2441"><a href="#cb18-2441" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2442"><a href="#cb18-2442" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; -- Preface to the 1967 reprint. </span><span class="co">[</span><span class="ot">@chomskyReviewBFSkinners1967</span><span class="co">]</span></span>
<span id="cb18-2443"><a href="#cb18-2443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2444"><a href="#cb18-2444" aria-hidden="true" tabindex="-1"></a>What is wrong with empiricism? Fundamentally, Chomsky's argument is based on two properties that every human language has:</span>
<span id="cb18-2445"><a href="#cb18-2445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2446"><a href="#cb18-2446" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Infinity: There exists infinitely many grammatical sentences, and infinitely many ungrammatical sentences.</span>
<span id="cb18-2447"><a href="#cb18-2447" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generativity: Humans can agree with each other whether a never-before-seen sentence is grammatical or ungrammatical.</span>
<span id="cb18-2448"><a href="#cb18-2448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2449"><a href="#cb18-2449" aria-hidden="true" tabindex="-1"></a>Plato observed that, though we have only seen imperfect geometric shapes, we have a concept of perfect circles, triangles and so on. He inferred from this that we are born with the ideal concepts within us, to be matched against imperfect shapes out there. Similarly, Chomsky argued that we are born with the ideal Universal Grammar within us, to be matched against the language observations in the world.</span>
<span id="cb18-2450"><a href="#cb18-2450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2451"><a href="#cb18-2451" aria-hidden="true" tabindex="-1"></a>For example, in the Universal Grammar, there is a setting called "subject-verb-object order", with 6 possible values: SVO, SOV, ..., OVS. An infant need only observe a few dozen sentences to fix this setting. Chomsky extended this project to all of natural language grammar.</span>
<span id="cb18-2452"><a href="#cb18-2452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2453"><a href="#cb18-2453" aria-hidden="true" tabindex="-1"></a>Chomsky made a multi-pronged rejection of empiricism:</span>
<span id="cb18-2454"><a href="#cb18-2454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2455"><a href="#cb18-2455" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Poverty of stimulus: Humans learn language with just a few years of language instruction. This is impossible if they "start from scratch". Thus, they have a lot of inborn grammar.</span>
<span id="cb18-2456"><a href="#cb18-2456" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Colorless green ideas sleep furiously: Because there are many meaningless but grammatical sentences, grammar is independent of meaning. Thus, grammar, unlike meaning, can be a small closed system that fits inside a brain at birth.</span>
<span id="cb18-2457"><a href="#cb18-2457" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Probability is meaningless: A sentence is either grammatical or not. THere is no in-between. Therefore it is meaningless to talk about the "probability of a sentence" like the empiricists.</span>
<span id="cb18-2458"><a href="#cb18-2458" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Impersonal abstraction: Real humans can make mistakes, but language itself makes no mistake. A tired human might say "Ideas sleep furiously." is ungrammatical 10\% of the times, but the English language *itself* would always say it is grammatical. Thus, the probabilities measured from real human behavior is meaningless for theoretical linguistics.</span>
<span id="cb18-2459"><a href="#cb18-2459" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Competence, not performance: Even if an empirical model of language, like the HMM, works 99% of the times, a single counterexample disproves it. To work "most of the times" is performance. To work all the time is competence. Linguistic science is about competence, and performance is sufficient only for engineering. Competence either/or, while performance is usually/rarely. Linguistics is about competence, and performance is left for the psychologists and engineers.</span>
<span id="cb18-2460"><a href="#cb18-2460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2461"><a href="#cb18-2461" aria-hidden="true" tabindex="-1"></a>The 60 years afterwards have been one long struggle against empiricism along these lines. For example, he had repeatedly simplified the Universal Grammar down to the minimalist core, so that it could possibly fit inside a single gene that appeared once in the evolution of humans, "switching on" language for humans and no other species. And by "60 years", I meant it. He was nothing if not consistent:</span>
<span id="cb18-2462"><a href="#cb18-2462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2463"><a href="#cb18-2463" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Evidently, one's ability to produce and recognize grammatical utterances is not based on notions of statistical approximation and the like... a structural analysis cannot be understood as a schematic summary developed by sharpening the blurred edges in the full statistical picture... that grammar is autonomous and independent of meaning, and that probabilistic models give no particular insight into some of the basic problems of syntactic structure.</span></span>
<span id="cb18-2464"><a href="#cb18-2464" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2465"><a href="#cb18-2465" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@chomskySyntacticStructures1957, pages 16--17</span><span class="co">]</span></span>
<span id="cb18-2466"><a href="#cb18-2466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2467"><a href="#cb18-2467" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; But it must be recognized that the notion of "probability of a sentence" is an entirely useless one, under any known interpretation of this term.</span></span>
<span id="cb18-2468"><a href="#cb18-2468" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2469"><a href="#cb18-2469" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@chomskyEmpiricalAssumptionsModern1969</span><span class="co">]</span></span>
<span id="cb18-2470"><a href="#cb18-2470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2471"><a href="#cb18-2471" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It's true there's been a lot of work on trying to apply statistical models to various linguistic problems. I think there have been some successes, but a lot of failures. There is a notion of success ... which I think is novel in the history of science. It interprets success as approximating unanalyzed data. </span></span>
<span id="cb18-2472"><a href="#cb18-2472" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2473"><a href="#cb18-2473" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Chomsky at the MIT150: Brains, Minds and Machines Symposium (2011), quoted in </span><span class="co">[</span><span class="ot">@norvigChomskyTwoCultures2017</span><span class="co">]</span></span>
<span id="cb18-2474"><a href="#cb18-2474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2475"><a href="#cb18-2475" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Well, first we should ask the question whether large language models have achieved anything, anything, in this domain? Answer: No! They've achieved zero... GPT-4 is coming along, which is supposed to going to have a trillion parameters. It will be exactly the same. It'll use even more energy and achieve exactly nothing, for the same reasons. So there's nothing to discuss.</span></span>
<span id="cb18-2476"><a href="#cb18-2476" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2477"><a href="#cb18-2477" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Machine Learning Street Talk: The Ghost in the Machine and the Limits of Human Understanding (2022)</span><span class="co">](https://whimsical.com/question-1-large-language-models-such-as-gpt-3-DJmQ8R5kD8tqvsXxgCN9vK)</span></span>
<span id="cb18-2478"><a href="#cb18-2478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2479"><a href="#cb18-2479" aria-hidden="true" tabindex="-1"></a>Knowing his framework, we understand why he rejected both statistical models like n-grams or neural models like GPT-3 as "zero" in terms of advancing theoretical linguistics. They are empirically constructed: thousands of researchers were just trying things out, and eventually they started to work. Worse, both kinds of models assign *nothing but* probabilities to sentences!</span>
<span id="cb18-2480"><a href="#cb18-2480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2481"><a href="#cb18-2481" aria-hidden="true" tabindex="-1"></a>When engaging with the modern Chomskyans (they still exist!), one notices a strategic ambiguity on the edge of competence vs performance. On one hand, Chomsky has simply defined scientific linguistics to be the study of language and competence. That is, he made the following kind of definition:</span>
<span id="cb18-2482"><a href="#cb18-2482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2483"><a href="#cb18-2483" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Language is a kind of mathematical object with associated transformations of it (such as the transformation that converts a verb to a past tense).</span>
<span id="cb18-2484"><a href="#cb18-2484" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A person or a computer, has competence for a language iff it can perform the correct transformations on a language object.</span>
<span id="cb18-2485"><a href="#cb18-2485" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Scientific linguistics is the study of languages, and how competence is implemented in various algorithms.</span>
<span id="cb18-2486"><a href="#cb18-2486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2487"><a href="#cb18-2487" aria-hidden="true" tabindex="-1"></a>Chomsky's definition deliberately draws a line between competence and performance. However, this line immediately gets crossed, because even immortals cannot subsist on only aether. Chomskyan scientific linguistics, to be scientific, still needs to gather empirical data and predict outcomes of empirical experiments, and thus was Chomsky able to influence AI developments, by an implicit empirical claim: "Building an AI like a generative grammar is how you get good empirical performance."</span>
<span id="cb18-2488"><a href="#cb18-2488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2489"><a href="#cb18-2489" aria-hidden="true" tabindex="-1"></a>Chomskyans have long engaged with AI. There have been Chomskyan language models, but the idea is very different. When Chomskyans do a language model, it is a scientific experiment to test a linguistic theory. If a program written according to a <span class="co">[</span><span class="ot">merge-grammar</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Merge_(linguistics)) of verbs can convert verbs to the past tense correctly (on a small example of 200 verbs), then that shows merge-grammar theory of verbs is a good theory. The n-gram language model is *trivially* disproven,<span class="ot">[^n-gram-proof]</span> so even if an n-gram model achieves better performance according to the entropy, all a Chomskyan needs to do is point at that theorem, and say, "That's not science, that's engineering.".</span>
<span id="cb18-2490"><a href="#cb18-2490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2491"><a href="#cb18-2491" aria-hidden="true" tabindex="-1"></a><span class="ot">[^n-gram-proof]</span>:</span>
<span id="cb18-2492"><a href="#cb18-2492" aria-hidden="true" tabindex="-1"></a>    The short explanation: English is not a regular language, so it can't be modeled by a Markov chain.</span>
<span id="cb18-2493"><a href="#cb18-2493" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-2494"><a href="#cb18-2494" aria-hidden="true" tabindex="-1"></a><span class="in">    The slightly longer explanation: English has [center embedding](https://en.wikipedia.org/wiki/Center_embedding), so English cannot be parsed by any finite state machine, while n-gram models are probabilistic finite state machines (aka Markov chains). Now prove the following theorem: If a language is not parsable by a finite state machine, then for any Markov model for the language, there exists sentences $s_1, s_2, \dots$ in the language, such that $\lim_{n \to \infty} Pr(s_n) = 0$. To show this, prove that there exists arbitrarily long sentences that are so long that the Markov chain "forgets where it was". The argument is similar to the [pumping lemma for regular languages](https://en.wikipedia.org/wiki/Pumping_lemma_for_regular_languages).</span></span>
<span id="cb18-2495"><a href="#cb18-2495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2496"><a href="#cb18-2496" aria-hidden="true" tabindex="-1"></a>Now, when Chomsky took a look at GPT-4, all he saw was another "success as approximating unanalyzed data", a *reductio ad absurdum* of empiricism at the price of \$100 million. So there's nothing to discuss.<span class="ot">[^blurry-jpeg]</span></span>
<span id="cb18-2497"><a href="#cb18-2497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2498"><a href="#cb18-2498" aria-hidden="true" tabindex="-1"></a><span class="ot">[^blurry-jpeg]: </span>Some critics of recent large models, like Ted Chiang's "blurry jpeg of the Internet", and Emily Bender's "stochastic parrot", are analogous to the Chomskyan critique of "success as approximating unanalyzed data". And Gary Marcus has been a committed Chomskyan since the 1990s, so analyzing his criticisms of AI in the Chomskyan framework is left as an exercise for the reader. Indeed, they had been much less circumspect compared to Chomsky, since they had been predicting the imminent *empirical* failure of large models at performance because of their lack of *rational* competence.</span>
<span id="cb18-2499"><a href="#cb18-2499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2500"><a href="#cb18-2500" aria-hidden="true" tabindex="-1"></a>The influence of Chomsky had been immense, both in linguistics and psychology. Chomskyan linguistics is the theoretical foundation to early MT systems like Vanquois' (TODO). In psychology, his approach became "cognitivism" TODO</span>
<span id="cb18-2501"><a href="#cb18-2501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2502"><a href="#cb18-2502" aria-hidden="true" tabindex="-1"></a>|                           | Rationalism                      | Empiricism                      |</span>
<span id="cb18-2503"><a href="#cb18-2503" aria-hidden="true" tabindex="-1"></a>| ------------------------- | -------------------------------- | -------------------------------- |</span>
<span id="cb18-2504"><a href="#cb18-2504" aria-hidden="true" tabindex="-1"></a>| Well-known Advocates:     | Noam Chomsky, Marvin Minsky                 | Claude Shannon, B. F. Skinner, J. R. Firth, Zellig Harris |</span>
<span id="cb18-2505"><a href="#cb18-2505" aria-hidden="true" tabindex="-1"></a>| Model:                    | Competence Model                 | Noisy Channel Model             |</span>
<span id="cb18-2506"><a href="#cb18-2506" aria-hidden="true" tabindex="-1"></a>| Contexts of Interest:     | Phrase Structure                | N-grams                         |</span>
<span id="cb18-2507"><a href="#cb18-2507" aria-hidden="true" tabindex="-1"></a>| Goals:                    | All and Only                     | Minimize Prediction Error (Entropy) |</span>
<span id="cb18-2508"><a href="#cb18-2508" aria-hidden="true" tabindex="-1"></a>|                           | Explanatory                     | Descriptive                     |</span>
<span id="cb18-2509"><a href="#cb18-2509" aria-hidden="true" tabindex="-1"></a>|                           | Theoretical                     | Applied                         |</span>
<span id="cb18-2510"><a href="#cb18-2510" aria-hidden="true" tabindex="-1"></a>| Linguistic Generalizations: | Agreement and                   | Collocations and Word Associations |</span>
<span id="cb18-2511"><a href="#cb18-2511" aria-hidden="true" tabindex="-1"></a>|                           | Wh-movement                      |                                 |</span>
<span id="cb18-2512"><a href="#cb18-2512" aria-hidden="true" tabindex="-1"></a>| Parsing Strategies:       | Principle-Based                 | Preference-Based                |</span>
<span id="cb18-2513"><a href="#cb18-2513" aria-hidden="true" tabindex="-1"></a>|                           | CKY (Chart), ATNs,               | Forward-Backward, Inside-Outside |</span>
<span id="cb18-2514"><a href="#cb18-2514" aria-hidden="true" tabindex="-1"></a>|                           | Unification                     |                                 |</span>
<span id="cb18-2515"><a href="#cb18-2515" aria-hidden="true" tabindex="-1"></a>| Applications:             | Understanding                   | Recognition                     |</span>
<span id="cb18-2516"><a href="#cb18-2516" aria-hidden="true" tabindex="-1"></a>|                           | Who did what to whom             | Noisy Channel Applications       |</span>
<span id="cb18-2517"><a href="#cb18-2517" aria-hidden="true" tabindex="-1"></a>: <span class="co">[</span><span class="ot">@churchIntroductionSpecialIssue1993, Table 5</span><span class="co">]</span></span>
<span id="cb18-2518"><a href="#cb18-2518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2519"><a href="#cb18-2519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2520"><a href="#cb18-2520" aria-hidden="true" tabindex="-1"></a>Outside of linguistics and abstract science, Chomskyan ideas appeared as "<span class="co">[</span><span class="ot">structuralism</span><span class="co">](https://en.wikipedia.org/wiki/Structuralism)</span>" of <span class="co">[</span><span class="ot">Claude Lévi-Strauss</span><span class="co">](https://en.wikipedia.org/wiki/Claude_L%C3%A9vi-Strauss)</span>. As an example, the Kareira society was divided into 4 sections: Banaka (0), Karimera (1), Burung (2), Palyeri (3). A Banaka man can only marry a Palyeri woman, and their children will be Karimera. In total, we have a table:</span>
<span id="cb18-2521"><a href="#cb18-2521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2522"><a href="#cb18-2522" aria-hidden="true" tabindex="-1"></a>| father | mother | child |</span>
<span id="cb18-2523"><a href="#cb18-2523" aria-hidden="true" tabindex="-1"></a>|---|---|---|</span>
<span id="cb18-2524"><a href="#cb18-2524" aria-hidden="true" tabindex="-1"></a>| 0 | 3 | 1 |</span>
<span id="cb18-2525"><a href="#cb18-2525" aria-hidden="true" tabindex="-1"></a>| 1 | 2 | 0 |</span>
<span id="cb18-2526"><a href="#cb18-2526" aria-hidden="true" tabindex="-1"></a>| 2 | 1 | 3 |</span>
<span id="cb18-2527"><a href="#cb18-2527" aria-hidden="true" tabindex="-1"></a>| 3 | 0 | 2 |</span>
<span id="cb18-2528"><a href="#cb18-2528" aria-hidden="true" tabindex="-1"></a>: Kareira kinship system</span>
<span id="cb18-2529"><a href="#cb18-2529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2530"><a href="#cb18-2530" aria-hidden="true" tabindex="-1"></a>This structure has the following good properties:</span>
<span id="cb18-2531"><a href="#cb18-2531" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Exogamy.</span>
<span id="cb18-2532"><a href="#cb18-2532" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Equal women exchange. Sections 0 and 3 exchange women. Sections 1 and 2 exchange women.</span>
<span id="cb18-2533"><a href="#cb18-2533" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Equal child exchange. Sections 1 and 0 exchange children in the sense that a man in section 1 would have children in section 0, and vice versa. The same for 2 and 3.</span>
<span id="cb18-2534"><a href="#cb18-2534" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Stable over time.</span>
<span id="cb18-2535"><a href="#cb18-2535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2536"><a href="#cb18-2536" aria-hidden="true" tabindex="-1"></a>Lévi-Strauss found many such recurring structures across human societies, and proposed to analyze human mythologies with the same method as well (a pinnacle example was <span class="co">[</span><span class="ot">*The Hero with a Thousand Faces*</span><span class="co">](https://en.wikipedia.org/wiki/The_Hero_with_a_Thousand_Faces)</span> which literally proposed a single structure for all human mythologies). This then got picked up by sociologists and commentators, followed by the "post-structuralists" who had even less to contribute to AI than Dreyfus.</span>
<span id="cb18-2537"><a href="#cb18-2537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2538"><a href="#cb18-2538" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Sub-symbolic Hypothesis</span></span>
<span id="cb18-2539"><a href="#cb18-2539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2540"><a href="#cb18-2540" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... we had two major misconceptions: first, that learning is a *problem* rather than a *solution*. If back at the beginning you asked an AI researcher what the major problem areas in the field were, they would have listed computer vision, inference, knowledge representation, understanding language, ... and learning. You would no more set out to translate between languages by writing a program to learn how to do so than you would create a rocket that learned to go to the moon. When put that way, it seems like common sense, but it is wrong. Our second big mistake was our allegiance to the physical symbol hypothesis... Newell and Simon were the first to state this explicitly, but ... virtually everyone believed it at that time--certainly your author.</span></span>
<span id="cb18-2541"><a href="#cb18-2541" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2542"><a href="#cb18-2542" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@charniakAIIntellectualHistory2024</span><span class="co">]</span></span>
<span id="cb18-2543"><a href="#cb18-2543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2544"><a href="#cb18-2544" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; AI research has foundered in a sea of incrementalism. No one is quite sure where to go save improving on earlier demonstrations of techniques in symbolic manipulation of ungrounded representations. At the same time, small AI companies are folding, and attendance is well down at national and international AI conferences... the *it symbol system hypothesis* upon which *it classical AI* is based is fundamentally flawed... Traditional AI has tried to demonstrate sophisticated reasoning in rather impoverished domains. The hope is that the ideas used will generalize to robust behavior in more complex domains. Nouvelle AI tries to demonstrate less sophisticated tasks operating robustly in noisy complex domains. The hope is that the ideas used will generalize to more sophisticated tasks.</span></span>
<span id="cb18-2545"><a href="#cb18-2545" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2546"><a href="#cb18-2546" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@brooksElephantsDonPlay1990</span><span class="co">]</span></span>
<span id="cb18-2547"><a href="#cb18-2547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2548"><a href="#cb18-2548" aria-hidden="true" tabindex="-1"></a>The dominance of the Symbolic Hypothesis was never complete. There were often objections to it.</span>
<span id="cb18-2549"><a href="#cb18-2549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2550"><a href="#cb18-2550" aria-hidden="true" tabindex="-1"></a>In 1972, Hubert Dreyfus raised a fuss with a book *What Computers Can't Do: The Limits of Artificial Intelligence*. Unfortunately, his work was based on the phenomenology of Merleau-Ponty and Heidegger, who wrote like *real and genuine* philosophers,<span class="ot">[^feigenbaum-cotton-candy]</span> so I just resorted to checking <span class="co">[</span><span class="ot">his Wikipedia article</span><span class="co">](https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence)</span>. From what I gathered, his argument was that the Symbolic Hypothesis is flawed in the sense that it is too "closed".</span>
<span id="cb18-2551"><a href="#cb18-2551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2552"><a href="#cb18-2552" aria-hidden="true" tabindex="-1"></a><span class="ot">[^feigenbaum-cotton-candy]</span>: </span>
<span id="cb18-2553"><a href="#cb18-2553" aria-hidden="true" tabindex="-1"></a>    Edward Feigenbaum's reaction is representative of most AI scientists:</span>
<span id="cb18-2554"><a href="#cb18-2554" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-2555"><a href="#cb18-2555" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; What artificial intelligence needs is a good Dreyfus. The conceptual problems in AI are really rough, and a guy like that could be an enormous help... But Dreyfus bludgeons us over the head with stuff he's misunderstood and is obsolete anyway -- and every time you confront him with one more intelligent program, he says, "I never said a computer couldn't do that." And what does he offer us instead? Phenomenology! That ball of fluff! That cotton candy! [@mccorduckMachinesWhoThink2004, pages 229--230]</span></span>
<span id="cb18-2556"><a href="#cb18-2556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2557"><a href="#cb18-2557" aria-hidden="true" tabindex="-1"></a>Fortunately, before I gave up, someone pointed me to a better, previous report <span class="co">[</span><span class="ot">@dreyfusAlchemyArtificialIntelligence1965</span><span class="co">]</span>:</span>
<span id="cb18-2558"><a href="#cb18-2558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2559"><a href="#cb18-2559" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; having read "Alchemy and Artificial Intelligence" for this investigation... It seems to me that Dreyfus' 1965 critiques of 1960s AI approaches were largely correct, for roughly the right reasons, in a way that seems quite impressive in hindsight... Dreyfus' arguments are inspired by his background in phenomenological philosophy, but he expresses his arguments in clear and straightforward language... the AI community hardly responded to Dreyfus' critique at all -- and when they did, they often misrepresented his claims and arguments in ways that are easy to detect if one merely checks Dreyfus' original report.</span></span>
<span id="cb18-2560"><a href="#cb18-2560" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2561"><a href="#cb18-2561" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@muehlhauserWhatShouldWe2016</span><span class="co">]</span></span>
<span id="cb18-2562"><a href="#cb18-2562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2563"><a href="#cb18-2563" aria-hidden="true" tabindex="-1"></a>With that, I managed to understand Dreyfus' argument clearly. His main point is that logical AI, exemplified by Simon and Newell's GPS,  cannot reach human-level reasoning, because logical AI cannot perform 3 fundamental human forms of information processing: fringe consciousness, essence/accident discrimination, and ambiguity tolerance. These require brain-like computers to perform.</span>
<span id="cb18-2564"><a href="#cb18-2564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2565"><a href="#cb18-2565" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Fringe consciousness: Chess players do not analyze positions like the GPS. Whereas the GPS performs a unified heuristic search, chess players seem to unconsciously scan a large number of positions, making some variations seem salient, which they then consciously "count out". The unconscious scanning is *not* search, since otherwise why not perform unconscious search all the way to the finish line? The conscious "counting out" is captured by the GPS, but the unconscious "zeroing in" is not.</span>
<span id="cb18-2566"><a href="#cb18-2566" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Essence/accident discrimination: Even on simple, well-defined problems like cryptogram puzzles, the GPS and humans reason very differently. Humans can simplify problems with symmetry like "for basically the same reason...", and backtrack based on an understanding of the overall problem structure. Even Simon and Newell have labelled their human subjects' reasoning steps as either "essential" or "inessential". GPS solves a problem like humans do only if the programmers have so helpfully pre-structured the problem with the essential features. These all show that human reasoning distinguishes some as essential while others as accidental, and focuses their conscious problem solving over the essential features, something GPS cannot do.</span>
<span id="cb18-2567"><a href="#cb18-2567" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Ambiguity tolerance: So far, machine translation and language understanding research had only worked on highly artificial and restricted domains, since none of them could handle the ambiguity in natural language. Humans can handle this massive ambiguity because humans process language not according to precise rules, but by unconscious processing that statistically combines context, goals, and background knowledge, and produces *precise enough* outputs.</span>
<span id="cb18-2568"><a href="#cb18-2568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2569"><a href="#cb18-2569" aria-hidden="true" tabindex="-1"></a>From our vantage point, chess ended up falling to the heuristic search of DeepBlue, but Go did require combining "fringe consciousness" with heuristic search in the CNN+MCTS architecture of AlphaGo. The three forms of information processing he singled out as requiring brain-like computing turned out to be precisely where neural networks achieved breakout success. Of course, the logical AI camp would not go down without a fight, and with "Parallel Distributed Processing" -- the revival of neural networks in 1980s -- there would be a bitter dispute, centered around, of all things, how to form the past tense of English verbs.<span class="ot">[^dreyfus-2012]</span></span>
<span id="cb18-2570"><a href="#cb18-2570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2571"><a href="#cb18-2571" aria-hidden="true" tabindex="-1"></a><span class="ot">[^dreyfus-2012]</span>:</span>
<span id="cb18-2572"><a href="#cb18-2572" aria-hidden="true" tabindex="-1"></a>    Having checked out his latest writing, we regret to inform thee that he was a blind cat that caught a mice by an accidental swipe of the paw, but then starved to death by doing it again and again. He simply did not believe AI was possible at all, that human intelligence requires human existence (really showing off his existentialist colors there), and *all* apparent progress in AI are like climbing a tree and claiming progress on landing on the moon.</span>
<span id="cb18-2573"><a href="#cb18-2573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2574"><a href="#cb18-2574" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; The commonsense knowledge problem, which as Minsky says, stopped AI in the early 70ies, has never been solved; except for Lenat it has just been ignored. Yet Chalmers assumes incremental progress and confidently asserts that "Given the way that computer technology always advances, it is natural enough to think that once there is AI, AI? will be just around the corner." But that just is the first step fallacy. AI is always just round the corner but, as Chalmers himself admits, never succeeds in turning that corner. There is, in fact, *no reason to think that we are making progress towards AI or, indeed, that AI is even possible, in which case claiming incremental progress towards it would make no sense.*</span></span>
<span id="cb18-2575"><a href="#cb18-2575" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; </span></span>
<span id="cb18-2576"><a href="#cb18-2576" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; [@dreyfusHistoryFirstStep2012]</span></span>
<span id="cb18-2577"><a href="#cb18-2577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2578"><a href="#cb18-2578" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Douglas Hofstadter</span><span class="co">](https://en.wikipedia.org/wiki/Douglas_Hofstadter)</span> raised a similar objection, but from within the logical AI tradition. His essential point was that logical AI, as conceived by Simon and Newell, is a closed system. For example, a chess computer might play a perfect chess even when the room is on fire. The concept of fire, or indeed anything that is beyond the mathematical strucure of chess, does not feature in the computer's symbolic universe, and so it does not exist for the computer.<span class="ot">[^holt-chess-fire]</span> Whereas Dreyfus argued that intelligence is open by the "cotton candy" of phenomenology, sieging the head from the outside in, Hofstadter used the Gödel incompleteness theorems to break the head open, from the inside out.</span>
<span id="cb18-2579"><a href="#cb18-2579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2580"><a href="#cb18-2580" aria-hidden="true" tabindex="-1"></a><span class="ot">[^holt-chess-fire]</span>:</span>
<span id="cb18-2581"><a href="#cb18-2581" aria-hidden="true" tabindex="-1"></a>    This example was given by Anatol Holt at ARPA Principal Investigators' Conference in 1974, and quoted in <span class="co">[</span><span class="ot">@winograd10ThinkingMachines1991</span><span class="co">]</span>:</span>
<span id="cb18-2582"><a href="#cb18-2582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2583"><a href="#cb18-2583" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; A brilliant chess move while the room is filling with smoke because the house is burning down does not show intelligence. If the capacity for brilliant chess moves without regard to life circumstances deserves a name, I would naturally call it "artificial intelligence."</span></span>
<span id="cb18-2584"><a href="#cb18-2584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2585"><a href="#cb18-2585" aria-hidden="true" tabindex="-1"></a>The rough idea is that any symbolic system that is powerful enough would be incomplete, and furthermore, would "reflect" its own incompleteness. The incompleteness theorems state that in any sufficiently powerful formal system, there are statements that are true about the system that cannot be proven within the system. For example, let $\Sigma$ be the logical system of Peano arithmetics, then by the incompleteness theorems, there are sentences like <span class="co">[</span><span class="ot">Rosser's sentence</span><span class="co">](https://en.wikipedia.org/wiki/Rosser%27s_trick)</span>, or "PA is consistent", which are *provably unprovable* assuming PA is consistent.</span>
<span id="cb18-2586"><a href="#cb18-2586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2587"><a href="#cb18-2587" aria-hidden="true" tabindex="-1"></a>Stated in another way, arithmetical truth cannot be defined in arithmetic -- <span class="co">[</span><span class="ot">Tarski's undefinability</span><span class="co">](https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem)</span>.</span>
<span id="cb18-2588"><a href="#cb18-2588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2589"><a href="#cb18-2589" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; O God, I could be bounded in a nut shell and count</span></span>
<span id="cb18-2590"><a href="#cb18-2590" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; myself a king of infinite space, were it not that I</span></span>
<span id="cb18-2591"><a href="#cb18-2591" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; have bad dreams.</span></span>
<span id="cb18-2592"><a href="#cb18-2592" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2593"><a href="#cb18-2593" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; --- Hamlet, Act 2, Scene 2</span></span>
<span id="cb18-2594"><a href="#cb18-2594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2595"><a href="#cb18-2595" aria-hidden="true" tabindex="-1"></a>In the context of AI, this means that a symbolic system, no matter how complex, will always have limitations in representing and reasoning about the world, even if the world is but itself. We need not assume there is an "outside". The symbolic system, even when floating in a mathematical vacuum, creates its own outside.</span>
<span id="cb18-2596"><a href="#cb18-2596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2597"><a href="#cb18-2597" aria-hidden="true" tabindex="-1"></a>His solution was to add in some "strange loops", which would both create general intelligence and create consciousness in one fell swoop. These strange loops are hierarchical structures where crossing levels leads back to the starting point. In the context of AI, Hofstadter proposed that implementing strange loops within a symbolic system would allow the system to refer to itself and its own structure, potentially leading to self-awareness and general intelligence. This self-referential capability would enable the system to overcome the limitations imposed by the incompleteness theorems and exhibit more flexible and human-like intelligence.</span>
<span id="cb18-2598"><a href="#cb18-2598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2599"><a href="#cb18-2599" aria-hidden="true" tabindex="-1"></a>Hofstadter was a far better writer than Dreyfus, and his 1979 book *Gödel, Escher, Bach* was a popular hit among both the common people and the computer scientists. Despite this, the trajectory of AI did not go as he expected.</span>
<span id="cb18-2600"><a href="#cb18-2600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2601"><a href="#cb18-2601" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There may be programs which can beat anyone at chess, but they will not be exclusively chess players. They will be programs of general intelligence, and they will be just as temperamental as people. "Do you want to play chess?" "No, I'm bored with chess. Let's talk about poetry." </span><span class="co">[</span><span class="ot">@hofstadterGodelEscherBach1999, page 678</span><span class="co">]</span></span>
<span id="cb18-2602"><a href="#cb18-2602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2603"><a href="#cb18-2603" aria-hidden="true" tabindex="-1"></a>In the preface to the second edition (1999), Hofstadter admitted that this prediction went way off, but still committed to the philosophical belief behind these. Unfortunately, the disappointments did not stop coming. In </span>
<span id="cb18-2604"><a href="#cb18-2604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2605"><a href="#cb18-2605" aria-hidden="true" tabindex="-1"></a>With the rise of Transformer-based language models, . He expressed his confusion and traumatic response in a 2023 interview:</span>
<span id="cb18-2606"><a href="#cb18-2606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2607"><a href="#cb18-2607" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="sc">\[</span><span class="at">In 1960,</span><span class="sc">\]</span><span class="at"> I knew how computers worked, and I knew how extraordinarily rigid they were. You made the slightest typing error and it completely ruined your program... It felt as if artificial intelligence was the art of trying to make very rigid systems behave as if they were fluid... I felt it would be hundreds of years before anything even remotely like a human mind would be asymptotically approaching the level of the human mind, but from beneath... But when certain systems started appearing maybe 20 years ago, they gave me pause. And then this started happening at an accelerating pace where unreachable goals and things that computers shouldn't be able to do started toppling. The defeat of Gary Kasparov by Deep Blue, and then going on to Go systems, systems that could defeat some of the best Go players in the world. And then systems got better and better at translation between languages and then at producing intelligible responses to difficult questions in natural language, and even writing poetry.</span></span>
<span id="cb18-2608"><a href="#cb18-2608" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2609"><a href="#cb18-2609" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; My whole intellectual edifice, my system of beliefs--it's a very traumatic experience when some of your most core beliefs about the world start collapsing... I think about it practically all the time, every single day... and it overwhelms me and depresses me in a way that I haven't been depressed for a very long time.</span></span>
<span id="cb18-2610"><a href="#cb18-2610" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2611"><a href="#cb18-2611" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Reflections on AI</span><span class="co">](https://www.buzzsprout.com/222312/episodes/13125914)</span><span class="at">, interview with Douglas Hofstadter by Amy Jo Kim (2023-06-29)</span></span>
<span id="cb18-2612"><a href="#cb18-2612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2613"><a href="#cb18-2613" aria-hidden="true" tabindex="-1"></a><span class="fu">### Statistical learning theory</span></span>
<span id="cb18-2614"><a href="#cb18-2614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2615"><a href="#cb18-2615" aria-hidden="true" tabindex="-1"></a>In the 1960s, Vladimir Vapnik was working on a Ph.D. in statistics, but due to multiple political problems, he was forced to withdraw the thesis and republish it as a book, in which he laid out his vision of statistical learning theory.</span>
<span id="cb18-2616"><a href="#cb18-2616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2617"><a href="#cb18-2617" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; From the KGB's point of view I was a wrong person to obtain the doctoral level: I was not a member of the Communist Party, I was Jewish, my PhD adviser, Alexander Lerner, had applied for immigration to Israel and became a "refusenik," some of my friends were dissidents, and so on... The main message that I tried to deliver in the book was that classical statistics could not overcome the curse of dimensionality but the new approach could. I devoted three chapters of the book to different classical approaches and demonstrated that none of them could overcome the curse of dimensionality. Only after that did I describe the new theory.</span></span>
<span id="cb18-2618"><a href="#cb18-2618" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2619"><a href="#cb18-2619" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@vapnikEstimationDependencesBased2006</span><span class="co">]</span></span>
<span id="cb18-2620"><a href="#cb18-2620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2621"><a href="#cb18-2621" aria-hidden="true" tabindex="-1"></a>In short, Vapnik's theory is to on the one hand, minimize the training loss ("empirical risk minimization") by any statistical model, but on the other hand, avoid overfitting by controlling capacity ("VC dimension") of the model. This was a radical departure from the previous kind of "classical statistics", which, while not Chomskyan, was very close in spirit.</span>
<span id="cb18-2622"><a href="#cb18-2622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2623"><a href="#cb18-2623" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (1) There is a group of philosophers who believe that the results of scientific discovery are the real laws that exist in nature. These philosophers are called the realists.</span></span>
<span id="cb18-2624"><a href="#cb18-2624" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2625"><a href="#cb18-2625" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (2) There is another group of philosophers who believe the laws that are discovered by scientists are just an instrument to make a good prediction. The discovered laws can be very different from the ones that exist in Nature. These philosophers are called the instrumentalists.</span></span>
<span id="cb18-2626"><a href="#cb18-2626" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-2627"><a href="#cb18-2627" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The two types of approximations defined by classical discriminant analysis (using the generative model of data) and by statistical learning theory (using the function that explains the data best) reflect the positions of realists and instrumentalists in our simple model of the philosophy of generalization, the pattern recognition model. Later we will see that the position of philosophical instrumentalism played a crucial role in the success that pattern recognition technology has achieved.</span></span>
<span id="cb18-2628"><a href="#cb18-2628" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb18-2629"><a href="#cb18-2629" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">vapnikEstimationDependencesBased2006, page 415</span><span class="co">]</span></span>
<span id="cb18-2630"><a href="#cb18-2630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2631"><a href="#cb18-2631" aria-hidden="true" tabindex="-1"></a>Vapnik's books were chock-full of philosophical musings, now rarely read. Leo Breiman's philosophical musings, however, has remained famous. As a reference to <span class="co">[</span><span class="ot">C. P. Snow's "Two Cultures" lecture of 1959</span><span class="co">](https://en.wikipedia.org/wiki/The_Two_Cultures)</span>, Breiman wrote <span class="co">[</span><span class="ot">@breimanStatisticalModelingTwo2001</span><span class="co">]</span> to contrast the "data modeling culture" with the "algorithmic modeling culture".</span>
<span id="cb18-2632"><a href="#cb18-2632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2633"><a href="#cb18-2633" aria-hidden="true" tabindex="-1"></a>The data modeling culture first constructs a <span class="co">[</span><span class="ot">generative model</span><span class="co">](https://en.wikipedia.org/wiki/Generative_model)</span> of the data with a few parameters $\theta$, then construct <span class="co">[</span><span class="ot">ways to estimate</span><span class="co">](https://en.wikipedia.org/wiki/Estimator)</span> $\theta$ from data, with provable guarantees. This culture includes both the frequestists and the Bayesians.</span>
<span id="cb18-2634"><a href="#cb18-2634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2635"><a href="#cb18-2635" aria-hidden="true" tabindex="-1"></a>On the plus side, a generative model with a few parameters is easy to interpret. On the minus side, if the statistician were to interpret parameters subsequently,<span class="ot">[^easily-check-statistical-interpretation]</span> then the parameters had better mean something real, which requires the model to be close to reality. That is, the price for interpretability is eternal vigilance (against model misspecification).</span>
<span id="cb18-2636"><a href="#cb18-2636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2637"><a href="#cb18-2637" aria-hidden="true" tabindex="-1"></a><span class="ot">[^easily-check-statistical-interpretation]: </span>One can easily check this by opening a journal in economics or medicine and look at the "results" section of some papers. There one would find parameters decorated with error bars, followed by policy recommendations, such as "Since $\theta_{6} &gt; 0$ with statistical significance, we conclude that elevating melatonin has a positive impact...". If $\theta$ in this imaginary example is used in a data model like $y = \sum_i \theta_i x_i + \epsilon$, where $\epsilon$ is noise, then for the sake of this imaginary author, the real biological response of the human had better be sufficiently linear to $x_1, x_2, \dots$, at least for those $x$ within the therapeutic range.</span>
<span id="cb18-2638"><a href="#cb18-2638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2639"><a href="#cb18-2639" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; This enterprise has at its heart the belief that a statistician, by imagination and by looking at the data, can invent a reasonably good parametric class of models for a complex mechanism devised by nature... If the model is a poor emulation of nature, the conclusions may be wrong. These truisms have often been ignored in the enthusiasm for fitting data models. A few decades ago, the commitment to data models was such that even simple precautions such as residual analysis or goodness-of-fit tests were not used.</span></span>
<span id="cb18-2640"><a href="#cb18-2640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2641"><a href="#cb18-2641" aria-hidden="true" tabindex="-1"></a>The algorithmic modeling culture in contrast is very empirical -- if it works on the training set, and if statistical learning theory predicts that its train-test gap is low ("capacity control" again), then it works. Data modeling culture was stuck with generative models, unable to use tools that work despite not interpretable as generative models -- random forests, boosting, bagging, neural networks, all the latest algorithms popping up in the 1990s.</span>
<span id="cb18-2642"><a href="#cb18-2642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2643"><a href="#cb18-2643" aria-hidden="true" tabindex="-1"></a>Among the many replies to this bombshell of an editorial, <span class="co">[</span><span class="ot">David Cox</span><span class="co">]</span>(https://en.wikipedia.org/wiki/David_Cox_(statistician)) went directly for the philosophical:</span>
<span id="cb18-2644"><a href="#cb18-2644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2645"><a href="#cb18-2645" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Professor Breiman takes a rather defeatist attitude toward attempts to formulate underlying processes; is this not to reject the base of much scientific progress?</span></span>
<span id="cb18-2646"><a href="#cb18-2646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2647"><a href="#cb18-2647" aria-hidden="true" tabindex="-1"></a>Whereas <span class="co">[</span><span class="ot">Bradley Efron</span><span class="co">](https://en.wikipedia.org/wiki/Bradley_Efron)</span> was like "hopefully you are just playing devil's advocate":</span>
<span id="cb18-2648"><a href="#cb18-2648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2649"><a href="#cb18-2649" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A third front seems to have been opened in the long-running </span><span class="co">[</span><span class="ot">frequentist-Bayesian wars</span><span class="co">](https://en.wikipedia.org/wiki/Foundations_of_statistics#Bayesian_inference_versus_frequentist_inference)</span><span class="at"> by the advocates of algorithmic prediction, who don't really believe in any inferential school... The whole point of science is to open up black boxes, understand their insides, and build better boxes for the purposes of mankind. Leo himself is a notably successful scientist, so we can hope that the present paper was written more as an advocacy device than as the confessions of a born-again black boxist.</span></span>
<span id="cb18-2650"><a href="#cb18-2650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2651"><a href="#cb18-2651" aria-hidden="true" tabindex="-1"></a>TODO</span>
<span id="cb18-2652"><a href="#cb18-2652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2653"><a href="#cb18-2653" aria-hidden="true" tabindex="-1"></a><span class="fu">### Connectionism, the past tense debate, and whatever</span></span>
<span id="cb18-2654"><a href="#cb18-2654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2655"><a href="#cb18-2655" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@bermudezCognitiveScienceIntroduction2020, chapter 10</span><span class="co">]</span></span>
<span id="cb18-2656"><a href="#cb18-2656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2657"><a href="#cb18-2657" aria-hidden="true" tabindex="-1"></a>"Connectionism" is a word you don't see much nowadays, but it was a big word back in the 1980s. It is hard to pin down, but if I summarize it, it is the result of philosophers in the 1980s noticing how researchers were trying neural networks on problems that had defied logical AI approaches, and somehow achieved state of the art, way past expectations. They say, "Weird! How is it possible for neural networks, written by people not having a deep knowledge of the problem domain, using such simplistic features, to work better than the best logical AI? I must philosophize this at once!"</span>
<span id="cb18-2658"><a href="#cb18-2658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2659"><a href="#cb18-2659" aria-hidden="true" tabindex="-1"></a>Two clear camps immediately formed. On one side were the connectionists with <span class="co">[</span><span class="ot">Paul Churchland</span><span class="co">](https://en.wikipedia.org/wiki/Paul_Churchland)</span>, <span class="co">[</span><span class="ot">Patricia Churchland</span><span class="co">](https://en.wikipedia.org/wiki/Patricia_Churchland)</span>, <span class="co">[</span><span class="ot">Paul Smolensky</span><span class="co">](https://en.wikipedia.org/wiki/Paul_Smolensky)</span>, <span class="co">[</span><span class="ot">Jeffrey Elman</span><span class="co">](https://en.wikipedia.org/wiki/Jeffrey_Elman)</span>. On the other side were the cognitivists (or perhaps the rationalists) <span class="co">[</span><span class="ot">Jerry Fodor</span><span class="co">](https://en.wikipedia.org/wiki/Jerry_Fodor)</span>, <span class="co">[</span><span class="ot">Zenon Pylyshyn</span><span class="co">](https://en.wikipedia.org/wiki/Zenon_Pylyshyn)</span>, with the spirit of Noam Chomsky always present in the background.</span>
<span id="cb18-2660"><a href="#cb18-2660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2661"><a href="#cb18-2661" aria-hidden="true" tabindex="-1"></a>Chapter 18 of *Parallel Distributed Processing* vol. 2 bore the unassuming title "On learning the past tenses of verbs in English" <span class="co">[</span><span class="ot">@rumelhartLearningTensesEnglish1986</span><span class="co">]</span>. Nobody would have predicted that it ignited a long and bitter dispute "the past tense debate". </span>
<span id="cb18-2662"><a href="#cb18-2662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2663"><a href="#cb18-2663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2664"><a href="#cb18-2664" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@seidenbergQuasiregularityItsDiscontents2014</span><span class="co">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="faux-block"><a href="https://forms.gle/LBFx3sUqrD9LLLHb7/">Give anonymous feedback</a></span></p>
</div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>
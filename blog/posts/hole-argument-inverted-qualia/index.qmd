---
title: "Hole Argument and Inverted Qualia"
author: "Yuxi Liu"
date: "2023-11"
date-modified: "2024-01-20"
categories: [fun, philosophy, math, physics]
format:
  html:
    toc: true
description: "TODO description."

# image: "figure/banner.png"
status: "draft"
confidence: "low"
importance: 2
---

## Introduction

## The hole argument

[@nortonHoleArgument1999]

The hole argument, in Norton's formulation

* Given two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since
  * The two distributions are observationally identical.
The laws of the theory cannot pick between the two developments of the fields into the hole.
  * But by manifold substantivalism, they represent distinct physical systems.
* Therefore, manifold substantivalism has a problematic metaphysics.

### Responses to the hole argument

**Relationalism**. This is Einstein's response, and also the typical response nowadays.

This line of thought can be traced back to Leibniz's theory of relative space against Newton's theory of absolute space. In Leibniz's third paper during the [Leibniz--Clarke correspondence](https://en.wikipedia.org/wiki/Leibniz%E2%80%93Clarke_correspondence) [@clarkeCollectionPapersWhich1717], Leibniz proposed the "inverted space" thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place. Ergo, space is relational, not absolute.

While God or the principle of sufficient reason is no longer so assured, Leibniz's thought experiment remains potent.

**Gauge freedom**. If two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.

(i) verifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;

(ii) determinism—the laws of the theory are unable to fix the candidate surplus structure.

**Metric essentialism**. Maudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.

**Non-duality**. It is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with $\R^N$, then quotienting out smooth deformations.

The point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein's failed 1914 attempt at non-relativistic theory of gravity.

This is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces -

where there is literally an unchanging *substance* (a rubber sheet) with changeable *property* (the strain field).

## The geometry of color

### Smooth geometry

The human eye, abstractly speaking, is a light detector with 4 kinds of sensors: the rod cell, active in the dark, and 3 kinds of cone cells, active when it's bright. Each cell carries its own kind of light-sensitive proteins ("opsins"), which are molecular switches. If a photon hits an opsin in the "passive" shape, then the opsin *may* absorb the photon and flip into its "active" shape. An active opsin would then set off a molecular chain-reaction in the cell, that *may* result in an electric signal down the optic nerve.

Mathematically, suppose we shine a light on a patch of long-wavelength-type cone cells, we can represent the electric response as:

$$I_L = \int S_L(\lambda) R(\lambda) d\lambda$$

where

* $I_L$ is the **response intensity** of long-wavelength-type cone cells, in units of neural spike per second. Though each cell's operation is quantum-mechanically random, when averaged over many cone cells, the response is deterministic.
* $R(\lambda)$ is the spectral radiance at wavelength $\lambda$, or **spectrum** for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).
* $S_L$ is the **spectral sensitivity** function of the long-type cone cells.

We can similarly define $I_M, I_S$, for the other two cone cell types (medium and short). Each $S_L, S_M, S_S$ is approximately bell-shaped.

![Schematic diagram of human cone cell sensitivity. Each curve is "normalized", meaning that it is multiplied by a positive real number, so that its maximal value is exactly 1.](figure/cone_cell_sensitivity.svg)

If we ignore the rod cells, and assume no adaptation to darkness ("scotopic vision"), then human color vision is just a deterministic function that maps a spectrum to three real numbers:

$$C(P) := (I_S(P), I_M(P), I_L(P))$$

with type $(\R^+ \to \R^+) \to (\R^+)^3$, where $\R^+ = [0, \infty)$ is the space of non-negative real numbers. Define this as the $(I_S, I_M, I_L)$ as the **LMS color space**.[^sense-data] Furthermore, the biochemical limit on neural firing is 1000 Hz [@NeuronFiringRates2015], thus the LMS color space is bounded within a cube.

[^sense-data]: This seems as close to "sense data" [@hatfieldSenseData2021] as it gets in science.

Any smooth deformation of the LMS color space gives us another color space. In theory, it doesn't matter which one we use, because the underlying color space is still the same. In practice, some color spaces are easier to use than others.

![Different depictions of the same color space. By a smooth map, we can deform the LMS color space into any shape we want, such as a cone, a cube, a cylinder, a double cone, etc. Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Color_solid_comparison_hsl_hsv_cube_cylinder_cone.png)](figure/Color_solid_comparison_hsl_hsv_cube_cylinder_cone.png)

### Projective geometry

Because $C$ is a linear functional, and any two colors can be mixed to give a third color, LMS color space is a convex cone. On the tip of the cone is $(0, 0, 0)$, the color of pure darkness. It is an old experimental fact that the geometry of colors is invariant under scaling. So, if you have two lights with spectra $P, P'$, such that their colors look the same/different/very different, then we make them brighter or dimmer, to $cP, cP'$ where $c > 0$, then their colors will still look the same/different/very different.

Thus, we can factor the space of colors into two components: an [apparent lightness](https://en.wikipedia.org/wiki/Lightness), and an apparent [chromaticity](https://en.wikipedia.org/wiki/Chromaticity). So, if we take two dim red lights, and shine both of them on the same pane of [frosted glass](https://en.wikipedia.org/wiki/Frosted_glass), the frosted glass would look lighter, but have the same chromaticity. The space of chromaticities is the space of lines passing the origin, which allows us to use [projective geometry](https://en.wikipedia.org/wiki/Projective_geometry).

The space of all colors looks like a cone, and since each line in the cone can be represented as a point on the line, the space of all chromaticities looks like the intersection of the cone with a plane -- each line is represented by its intersection with the plane. What does the space of all chromaticities look like?

Because any spectrum $I$ is the convex sum of pure spectra

$$\{I_{\lambda}: \lambda \in (400 \;\mathrm{nm}, 700\;\mathrm{nm})\},$$

the space of all colors is the convex sum of all pure spectral colors 

$$\{C(I_{\lambda}): \lambda \in (400 \;\mathrm{nm}, 700\;\mathrm{nm})\}.$$

Consider a wall covered with a "pure spectral paint", in the sense that it reflects exactly light at wavelength $500 \;\mathrm{nm}$, and nothing else. Then, under any illumination, the color of the wall has the same chromaticity. Pure spectral colors are special colors, in the following diagram, on the edge of the cone are lines of pure spectral color, each produced by a spectrum that is concentrated at just one wavelength.

![The pure spectral colors in LMS color space. The rainbow curve represents the spectrum of visible light, from violet to red. Each point on this curve corresponds to a specific wavelength of light and its unique combination of stimulations to the three types of cone cells. For each point on the spectral curve, we can draw a straight line to the origin. Each point on the line has the same color, but appears increasingly bright.](figure/neural_color_space_3d.svg)

Because the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on $\R^2$, named the **gamut**. Mathematically, it is the projective transform:
$$(s, m, l) := \left(\frac{I_S}{I_S + I_M + I_L}, \frac{I_M}{I_S + I_M + I_L}, \frac{I_L}{I_S + I_M + I_L} \right)$$

The curving edge of the chromaticity space are points of pure spectral colors, from pure $700 \;\mathrm{nm}$ line on the red end, to the pure $400 \;\mathrm{nm}$ line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors. However, this is not the entirety of chromaticity space. The ray at the shortest-wavelength end (pure spectral purple) and the ray at the longest-wavelength end (pure spectral red) do not touch each other. Instead, they shoot out like two ends of a horseshoe. Chromaticity space, then, has a second, straight edge, obtained by mixing the shortest and the longest wavelength. This is the [purple boundary](https://en.wikipedia.org/wiki/Line_of_purples).

![Schrödinger's diagram of chromaticity space. *Spektralkurve*: spectral curve. *Schnitt mit einer Ebene*: intersection with an arbitrarily inclined plane. *R*: red. *G*: green. *I*: indigo. *V*: violet. *O*: origin.
[@schrodingerGrundlinienTheorieFarbenmetrik1920, figure 3]](figure/schrodinger_1920_spektralkegel.png)

Theoretically, we can imagine creating the world's best computer display by putting in a full-spectral display unit into each pixel. It will then be able to cover the entire gamut space. It will not only display true-life colors for humans, but also for dogs, bees, and mantis shrimps. Unfortunately, we don't have that luxury, and computer displays are built for human-use only, with just three spectra.

Now, if we have a pixel containing three little LED units, capable of emitting light of spectra $P_1, P_2, P_3$, then we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of $C(P_1), C(P_2), C(P_3)$, which looks like a triangular cone. Thus, the chromaticity that this pixel can display is a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.

![The triangle of displayable chromaticities for cathode-ray televisions (left) and LCDs (right). Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:CRT_and_LCD_Gamut.jpg)](figure/CRT_and_LCD_Gamut.jpg)

When you print on a page, the page does not emit color, and can only acquire color by selectively reflecting light. When under a standard white light, the more ink you lavish on a page, the more saturated the color can be, but the darker it would be, because more light is absorbed. Conversely, if all the light is reflected, then it would look white. Because of this trade-off, the gamut of printable colors is even smaller.

![The gamut of printable colors when placed under [standard white illumination](https://en.wikipedia.org/wiki/Standard_illuminant). [@macadamGeometryColorSpace1944, plate 1]](figure/cmyk_gamut_macadam_1944.png)

Evolution has created a multi-spectral display in some octopuses and chameleons. The best octopus camouflagers have 2 kinds of color organs in their skins: the chromatophores, the leucophores, and the iridocytes. Chromatophores contain pigment cells, which expand and contract by radial muscles like wheel spokes around an axis. The leucophores are roughly [ideal "matte" reflectors](https://en.wikipedia.org/wiki/Lambertian_reflectance), meaning they reflect incoming light uniformly, with little loss.

The iridocytes are the most exotic, and approximates our "world's best television screen". Specifically, they are [dielectric mirrors](https://en.wikipedia.org/wiki/Dielectric_mirror), which reflects light at a specific wavelength. They are alternating layers of guanine crystals and cytoplasms. To change color, it simply adjusts the water content of the cytoplasm, which makes them expand or contract, changing the distance between guanine layers. More pictures are found in [@cloneyChromatophoreOrgansReflector1983].

![How the iridocytes work in cephalopods. Figure from [@cossinsGroovyColor2013]](figure/iridocyte_the_scientist_2013.jpg)

![A, B. cephalopod before and after camouflage. C. structure of cephalopod skin. D. before and after chromatophore expansion. F. before and after iridocyte turning iridescent. G. the dielectric mirrors inside an iridocyte. [@chatterjeeIntersectionNaturalStructural2022, figure 4]](figure/cephalopod_biomimetics_chatterjee_2022.png)

Meanwhile, chameleons have iridocytes that operate by a different mechanism: [photonic crystals](https://en.wikipedia.org/wiki/Photonic_crystal) [@teyssierPhotonicCrystalsCause2015].

### Linear geometry

Grassmann, famous for originating linear algebra, studied color theory and applied linear algebra to it. Essentially, he discovered that the human color vision function $C$, defined previously, is a linear function. He discovered this by color-mixing experiments, in the style of 19th century psychophysics. Considering it was 50 years before the [neuron doctrine](https://en.wikipedia.org/wiki/Neuron_doctrine) became accepted, and 100 years before cone cells were observed, he did very well.

For any three spectra $P_1, P_2, P_3$, we can define their colors as $C_i := C(I_i)$. Since $C$ is a linear function, as long as $\{C_1, C_2, C_3\}$ are linearly independent, we can represent any color as $C(x_1 P_1 + x_2 P_2 + x_3 P_3)$ for some $(x_1, x_2, x_3) \in \R^3$.

For example, we can go to a scientific standard shop and buy a set of standard lamps, which when plugged into a standard plug, viewed in a standard room, at a standard distance and a standard angle, by a standard observer,[^standard-observer] will create a standard red, a standard green, and a standard blue. Then, using opaque to cover up parts of the lamp, and combining the lights, we can create any color $C(x_1 P_1 + x_2 P_2 + x_3 P_3)$, for any $(x_1, x_2, x_3) \in [0, 1]^3$. By buying more lamps, we can create all colors with $(x_1, x_2, x_3) \in (\R^+)^3$.

[^standard-observer]: Because humans are resistant to standardization, the standard observer is obtained by taking data from real observers in good health that are physiologically similar, and their average. The methodology resembles *l'homme moyen* ("the average man") of [Adolphe Quetelet](https://en.wikipedia.org/wiki/Adolphe_Quetelet), a fanatic for anthropometry. Also, the standard observer is not required to drink [standard cups of tea](https://en.wikipedia.org/wiki/ISO_3103).

Here, we notice a difficulty: we can't take a negative amount of lamp. Fortunately, we can bypass the difficulty by adding a fourth lamp, a "standard white" lamp emitting a spectrum $P_0$. Then, for any other spectrum $I$, there exists $(x_1, x_2, x_3, x_4) \in (\R^+)^4$, such that

$$
C(I) + C(x_0 P_0) = C(x_1 P_1 + x_2 P_2 + x_3 P_3)
$$

which allows us to place the color of $I$ at the unique point. Of course, the choice of $(x_1, x_2, x_3, x_4)$ is not unique. However, since color space is linear, the sum $C(x_1 P_1 + x_2 P_2 + x_3 P_3 - x_0 P_0)$ is unique. Once $C(P_0)$ is itself constructed as a linear sum of $C(\sum_{i=1}^3 x_{i, 0}P_i)$, we would have located $C(I)$ in color space, at

$$
C(I) = \sum_{i=1}^3 (x_i - x_0x_{i, 0}) C(P_i)
$$

This is essentially the state of the art of colorimetry in 1931, when CIE 1931 was constructed by color-mixing experiments. An observer is seated in a standard room, and sees two light sources. On the left, a to-be-measured light $I$ is mixed with a standard white light $P_0$, and on the right, are three standard blue, green, red lights $P_1, P_2, P_3$. The observer turns the 4 knobs until two sides look indistinguishable. This was repeated for many observers, over many days, for many light sources. The result is a table with three columns, and many rows. Each row is an industrially important light source, and the three columns are the standard red, standard green, standard blue. It schematically looks like this (I made up the data):

| color | standard red | standard green | standard blue |
|---|---|---|---|
| standard red | 1.000 | 0.000 | 0.000 |
| standard green | 0.000 | 1.000 | 0.000 |
| standard blue | 0.000 | 0.000 | 1.000 |
| standard white | 0.334 | 0.334 | 0.332 |
| ... | ... | ... | ... |

::: {.callout-note title="Technically"}

Technically, the CIE 1931 color of a spectrum $I$ is a point in $\R^3$ defined by

$$
C_{\text{CIE 1931}}(I) := \left(\int I(\lambda) \bar r(\lambda) d\lambda , \int I(\lambda) \bar g(\lambda) d\lambda , \int I(\lambda) \bar b(\lambda) d\lambda \right)
$$

where $\bar r, \bar g, \bar b$ are "standard observer color matching functions". They are not any real observer's sensitivities, because they have negative values. Instead, they are *roughly* a linear transform of the real sensitivities $S_S, S_M, S_L$, meaning CIE 1931 color space is roughly a linear transform of LMS color space.

Why did they go for a *roughly* linear transform? I know it's confusing (it confused me), but it's simply a temporary hack. Back then, they had no way to measure the neural spikes, so they had to infer the real sensitivities by indirect psychophysics data. And the negative values are for some kind of numerical stability considerations. Point being, it's really not fundamental to science, but rather a 1930s technical hack.

:::

### Opponent process

Have you ever wondered why things seem bluer just after sunset, or under a high full moon? This is where *opponent process theory* and Purkinje effect comes in. 

While the retina might be operating with the LMS color space, it is not what gets sent to the brain. Specifically, before leaving the retina, the spikes from the 3 cone cells and the rod cell (we are finally accounting for them now!) are linearly transformed by 3 paired-kinds of neurons within the retina, before sending down the optic nerve. Greatly simplified, the linear transform is:

$$
\begin{cases}
  I_{\text{Red-Green}} &= I_L - I_M \\
  I_{\text{Yellow-Blue}} &= I_L + I_M - 2 I_S \\
  I_{\text{Brightness}} &= 2I_L + I_M + 0.05 I_S + I_R
\end{cases}
$$

![[@huntMeasuringColour2011, figure 1.4]](figure/opponent_process_fig_1_4.png)

In words, the Red-Green-pair of neurons take the long-wavelength (reddish) cone cells, and subtract away the medium-wavelength (greenish) cone cells. If the result is positive, then the positive half of the pair sends down a signal at the rate of $I_L - I_M$, otherwise, the negative half of the pair sends down a signal at the rate of $-(I_L - I_M)$. This linear transform, while mathematically equivalent (as long as the rod cells don't appear) to LMS space, allows the optic nerves to carry more information in *Homo Sapiens*' natural habitat [@buchsbaumTrichromacyOpponentColours1997].

When the light level is around $0.5 \;\mathrm{lux}$, which corresponds to twilight, or a full high moon, both the rod cells and the cone cells are active [@dominyLiminalLightPrimate2020].

So, let us look at the linear transform

$$
\begin{cases}
  I_{\text{Red-Green}} &= I_L - I_M \\
  I_{\text{Yellow-Blue}} &= I_L + I_M - 2 I_S \\
  I_{\text{Brightness}} &= 2I_L + I_M + 0.05 I_S + I_R
\end{cases}
$$

Let's pretend we are the brain, interpreting the signals sent down the optic nerves. Suppose the retina secretly increases $I_R$ by a small amount of $\Delta I$, but we don't know that. How would we interpret it? We would interpret it as a color in LMS space with color 

$$(I_S + \Delta I', I_M + \Delta I', I_L + \Delta I')$$

where $2.05\Delta I' = \Delta I$. That is, it looks as if each type of cone cell has increased firing rate by the same amount. Looking at the sensitivity curve, this effect can be created by shifting the spectrum to the shorter wavelength, then increase its power slightly. Thus, things look bluer.

![Purkinje effect illustrated with a flower. As the lighting condition dims, the entire scene shifts more to the bluish shade. At low enough lighting, all cone cells deactivate, and the entire scene becomes monochromatic. Figure modified from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Purkinje_effect.png)](figure/purkinje_effect.jpg)

### Riemannian geometry

> Magnitude-notions are only possible where there is an antecedent general notion which admits of different specialisations... the only simple notions whose specialisations form a multiply extended manifoldness are the positions of perceived objects and colours. More frequent occasions for the creation and development of these notions occur first in the higher mathematic.
>
> Riemann's Habilitation dissertation, 1854 [@riemannHypothesesWhichLie2016]

Now that we have a space of colors, how do we measure distances in it? Some colors are close, while some colors are far apart. How do we quantify it? This question occupied the minds of some famous scientists, including Riemann, Grassmann, Helmholtz, and Schrödinger [@pavlidisBriefHistoryColour2021].

In 1920, Schrödinger (more famous for [his other equation](https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation)) hypothesized that color space has a Riemannian geometry, and the subjective difference between two colors is the geodesic distance between the two points in color space [@schrodingerGrundlinienTheorieFarbenmetrik1920]. This is the foundation of modern colorimetry [@niallErwinSchrodingerColor2017]. Over the years, there had been a mess of increasingly detailed theoretical models for the Riemannian metric of color space, of interest only to specialists -- see [@wyszeckiColorScienceConcepts1982, chapter 8.4] for a review. Here, we bypass most of the theory by experimental data.

Given two spectra $I, I'$, if their colors $C(I), C(I')$ are close enough, an observer would judge them as equal. This is the concept of "just noticeable difference" (JND), a foundational concept of psychophysics. In general, the JND method goes like this:

* Fix one stimulus $S$, and vary the other stimulus $S'$. The prior probability that $S = S'$ is $1/2$.
* Present both $S, S'$ to the observer.
* The observer judges whether they are the same or different.
* Repeat many times.
* If, when truly $S' = S$, the observer judges that they are the same with probability $p_0$, then the JND point is the point where the observer judges that $S' = S$ with probability $p_0/2$.

In the original experiments, MacAdam fixed one spectrum $I$, and varied the other spectrum $I'$ on a curve that passes $I$. He repeated the JND measurement along many curves across many spectra, and found that around each spectrum, the JND points make up a rough ellipsoid.

![The JND of a single observer around a single color, when approached from 14 different directions. The JND points fall roughly on an ellipse. [@wyszeckiColorScienceConcepts1982, figure 1(5.4.1)]](figure/macadam_ellipsoid_fig_1_541.png)

If the JND measurement is binary classification in color space, then what is real-valued regression in color space? Answer: color matching experiment.

Specifically, suppose we fix $I$, and let the observer turn a knob that varies $I'$ along a curve passing $I$, then we would find that $I'$ is normally distributed centered upon $I$. Perform the experiment with 3 knobs, and we would obtain an ellipsoidal cluster. The ellipsoids of $1\sigma$ are the [MacAdam ellipsoids](https://en.wikipedia.org/wiki/MacAdam_ellipse). As ellipsoids are very hard to draw, we typically only see 2D slices of them -- the MacAdam ellipses.

![The color matching experiment data of a single observer around a single color. The points are projected from 3D space to [three orthogonal views](https://en.wikipedia.org/wiki/Orthographic_projection). The ellipsoid is the ellipsoid of $3\sigma$. [@wyszeckiColorScienceConcepts1982, figure 1(5.4.3)]](figure/macadam_ellipsoid_fig_1_543.png)

::: {.callout-note title="Conjecture: perceived lightness and hues are totally geodesic foliations"}

Given two colors $C_0, C_1$, we can construct the geodesic curve between them as the shortest sequence of colors $C_a, C_b, C_c, \dots$, such that $C_0, C_a$ are JND, and $C_a, C_b$ are also JND, etc. It sounds reasonable in my head that, if $C_0, C_1$ have the same [perceived lightness](https://en.wikipedia.org/wiki/Lightness), then the geodesic connecting them should all have the same perceived lightness, because it seems like we would be wasting some precious JND on "jumping up in lightness, only to jump down again". Similarly, if $C_0, C_1$ have the same perceived hue, then I guess the geodesic through them would stay along the same perceived hue.

If this is true, then we can construct two families of foliations in color space, one for equal-lightness surfaces, and one for equal-hue surfaces. Each surface is a totally geodesic foliation [@johnsonTotallyGeodesicFoliations1980], meaning that each geodesic within a foliation is also a geodesic in the total color space.

However, this definitely isn't true for perceived saturation, as the shortest path between slightly saturated red and slightly saturated green (opposite of red) goes through perfect gray, so who knows whether this conjecture is true or not?

:::

Though JND and color matching are two different methods, they are both using people as statistical detectors, and it stands to reason that they should measure the same thing. Indeed, the ellipsoids of JND are roughly the $3\sigma$ MacAdam ellipsoids [@wyszeckiColorScienceConcepts1982, section 5.4].

![MacAdam ellipses plotted on the CIE 1931 $xy$-diagram, 10× actual size. Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:CIExy1931_MacAdam.png).](figure/CIExy1931_MacAdam.png)

Given the [Tissot's indicatrix](https://en.wikipedia.org/wiki/Tissot's_indicatrix), it is natural to try to draw a distortion-less map of earth, where all Tissot ellipses are equally-sized circles. This is impossible, and Gauss knew exactly why: earth has positive gaussian curvature, but a flat sheet of paper has zero gaussian curvature.

![Tissot's indicatrix on [Behrmann projection](https://en.wikipedia.org/wiki/Behrmann_projection). Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Tissot_behrmann.png)](figure/Tissot_behrmann.png)

Given the MacAdam ellipses, it is natural to try to draw a distortion-less map of color space. This is impossible, for the same reason: color space has nonzero curvature. It was already known to MacAdam in the 1940s that his experimental data shows color space has significant curvature.

![A paper model of a 2D subspace of the color space -- the space of colors with unit subjective brightness. The metric on the paper model faithfully matches the metric implied by MacAdam ellipse. We can see the curvature. [@macadamGeometryColorSpace1944, figure 5]](figure/paper_model_macadam_1944.png)

::: {.callout-note title="Conjecture: color space is not conformally flat"}

Is it possible to at least stretch the MacAdam ellipses into spheres, even though they aren't of the same radius? That is, is color space [conformally flat](https://en.wikipedia.org/wiki/Conformally_flat_manifold)? For example, in [Mercator's projection](https://en.wikipedia.org/wiki/Mercator_projection), the Tissot ellipses are indeed circular, though they become larger near the poles, so earth is conformally flat.

However, by [Liouville's theorem](https://en.wikipedia.org/wiki/Liouville%27s_theorem_(conformal_mappings)), conformal flatness is very stringent at 3 dimensions and above, so my conjecture is that color space is *not* conformally flat. Proof sketch: download the metric tensor from CIE, and check its [Cotton tensor](https://en.wikipedia.org/wiki/Cotton_tensor) is (statistically) nonzero.

:::

![A nonlinear map of CIE 1931 $xy$-graph designed to make MacAdam ellipses look roughly circular. [@wyszeckiColorScienceConcepts1982, figure 4(5.4.1)]](figure/macadam_ellipsoid_fig_4_541.png)

CIELAB color space is a smooth mapping from CIE 1931 color space to $\R^3$, such that the MacAdam ellipses are stretched spherical enough for practical purposes.

![All visible colors, plotted in CIELAB color space. Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png)](figure/Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png)

### Information geometry

Imagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker's ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization -- a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.

Similarly, as we move around in color space, we may distinguish colors by the photoreceptor responses, which can be inferred from the sensitivity curves $S_S, S_M, S_L$. That is, we can reduce Riemannian metric to [information geometry](https://en.wikipedia.org/wiki/Information_geometry). Working this out in detail, [@dafonsecaDerivationHumanChromatic2016] showed that the Riemannian metric in color space is roughly the same ("explains 87% variance") as the [Fisher information metric](https://en.wikipedia.org/wiki/Fisher_information_metric).

![The ellipses measured by MacAdam (green) vs ellipses predicted by information theory (red). [@dafonsecaDerivationHumanChromatic2016, Figure 8b]](figure/Fonseca_2016_fig_8b.png)

In the same vein, people have argued for centuries about why certain colors are perceived as "pure" or "primary" (white, black, red, blue, green, etc), while others are "mixed" or "derived" from the primary colors. [@macevoyGeometryColorPerception2015] argues that the primary colors are "landmarks" in the geometry of color space, much like how on a map, the peaks and troughs are local maxima of gaussian curvature, and the mountain passes are the local minima, or how on a spacetime, a black hole singularity is the point where the [Kretschmann scalar is infinite](https://en.wikipedia.org/wiki/Curvature_invariant_(general_relativity)). Intuitively, we can see this on the CIELAB color solid. The top-most point is white, the bottom-most color is violet, and you can just see yellow at another point behind the back, etc.

::: {.callout-note title="Beyond Riemannian geometry"}

While color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. [@bujackNonRiemannianNaturePerceptual2022] reported that there is "diminishing returns" in color distances.

Indeed, this non-Riemannian geometry has been known for a while. CIE in 1994 proposed a color difference, $\Delta E$, that is [not symmetric](https://en.wikipedia.org/wiki/Color_difference#CIE94). That is, if we ask a subject "How far is color 1 from color 2?" and then ask the opposite direction, we usually get a different numerical answer. This reminds me of [information-geometric divergence](https://en.wikipedia.org/wiki/Divergence_(statistics)), which is also not symmetric. I cannot find anyone who has studied this in detail, but it ought to interest the information geometers.

:::

## Inverted qualia

[@byrneInvertedQualia2004]

The inverted qualia thought experiment has been used, like the philosophical zombie, in a whole host of arguments. Let's deal with functionalism, which seems rather urgent these days, what with the advent of AI and all.

Argument against functionalism

The following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.

Thus, the mental does not supervene on functional organization.

Thus, functionalism is false.

According to functionalism, mental states are functional states: states defined by their causal role with respect to inputs, outputs, and other states. So, according to functionalism, necessarily, two creatures who are functionally alike are also mentally alike.

### Precursors

[@eastwoodAlhazenLeonardoLatemedieval1986]

Alhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.

![Leonardo da Vinci's drawings comparing the eye to a camera obscura. From *Codex Atlanticus* (1490-1495). Figure from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:1490-95_da_vinci_-_codex_atlanticus.jpg).](figure/1490-95_da_vinci_-_codex_atlanticus.jpg)

> ... certain extravagant situations are to be avoided, as they would create 'monstrosities', or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say.  

![Illustration from Descartes' *Treatise of Man*.](figure/Descartes_diagram.png)

## Problem of consciousness


[@metzingerBeingNoOne2004, chapter TODO; @rodenPosthumanLifePhilosophy2015, chapter 4]

The just noticeable difference (JND) in color perception possibly shows that we see metric, not colors themselves.


If the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.

If the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.

The meta-problem of consciousness [@chalmersMetaproblemConsciousness2018] is TODO

The inverted polarization spectrum for mantis shrimps. Why would they be confused?

[@kleinlogelSecretWorldShrimps2008]

The mantis shrimp species *Gonodactylus smithii* can detect polarization of light over the entire 3-dimensional Poincare sphere. It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.

Now, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincare sphere is inverted compared to yours? When you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, etc.

## The meta-problem

We have Type 1 and Type 2 cognitive processes for judging if something is conscious.

Type 1 processes


[@fialaPsychologicalOriginsDualism2012]

fast, domain-specific, automatic (the authors don't argue if they are also associative)

Three apparent features reliably produce AGENT categorization:

has eye-like shapes on a head-like bump;

reacts to the environment unpredictably;

moves on its own, not a slave to mere inertia.

Confirmed by judgment-speed experiments

> ... presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute... Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.  

Type 2 processes

rational deliberation, theory application, or conscious reasoning

Any brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.

The brain doesn't have eyes

The brain seems to do nothing by itself, stewing alone in a dark cave;

The brain doesn't display any motion, let alone non-inertial motion.

> Since the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.  

> Jenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick & Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious  

Alternative physicalist theory of consciousness designed to satisfy Type 1 process won't satisfy Type 2 process.

The eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.

And lock-in syndrome people don't interact and don't display noninertial motions.

Evolutionary origin of the dual process

Only very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.

Thus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.

The Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.

(Non-)Analogies

The authors thought that there is no Type 1 intuition for general relativity, so there's no explanatory gap there. But I beg to differ.

General Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent "explanatory gap", as a nagging feeling "but how do we know which one is the *real* spacetime manifold? The theory is incomplete because it doesn't tell us that.".

This is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there's a unique spacetime structure.

As another example, Bergson famously debated Einstein over the nature of time.

Intentionality explanatory gap.

Some philosophers did propose an explanatory gap.

Although most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.

This would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics.

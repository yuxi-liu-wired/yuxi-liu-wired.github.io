---
title: "Thermodynamics and economics"
author: "Yuxi Liu"
date: "2024-04-17"
date-modified: "2024-04-17"
categories: [math, physics, economics]
format:
  html:
    code-fold: true
    toc: true
    resources:
        - "figure/**"
description: ""

# image: "figure/banner.png"
# image-alt: "A metaphor for real-space renormalization, where the building on the left is coarse-grained to the building on right. The facade of a wide brutalist architecture. On the left, the windows are small and the floors are close together. On the right, the windows are large and the floors are wide apart. High contrast, monochromatic, minimalistic, in the flat style of vector svg art., illustration, conceptual art."

status: "draft"
confidence: "certain"
importance: 3
---

## Introduction

## Theodicy: economic thermodynamics

Alternative title: The Gospel of Nature according to Yuxi.


In classical thermodynamics, we consider only equilibrium systems. Similarly, in classical microeconomics, we consider only general equilibrium. As we will see, this allows us to make a mathematical analogy.

I must warn you, before you enter, to forget all about molecules and atoms. Forget all about statistics and statistical mechanics. Forget about $S = k_B\ln \Omega$ or $S = -\sum_i p_i \ln p_i$ . None of these fits into the logical structure of classical thermodynamics.

| thermodynamics | microeconomics |
|---|---|
| system | company |
| compound system | conglomerate |
| subsystem | child company |
| entropy | market value (according to an accounting agency) |
| entropies are additive | value of conglomerate is the sum of its child companies |
| energy, volume, and other conserved quantities | commodities that cannot be created or destroyed |
| inverse temperature $\beta = \partial_E S$ | marginal value of energy |
| unnamed quantity $\beta p = \partial_V S$ | marginal value of volume |
| unnamed quantity $-\beta \mu_i = \partial_{N_i} S$ | marginal value of chemical $i$ |

: Table

### second law

The second law of thermodynamics is all important: maximizing entropy is all of classical thermodynamics! Everything else are just tricks for us to understand how to maximize entropy.

### first law

> As a student, I read with advantage a small book by F. Wald entitled "The Mistress of the World and her Shadow". These meant energy and entropy. In the course of advancing knowledge the two seem to me to have exchanged places. In the huge manufactory of natural processes, the principle of entropy occupies the position of manager, for it dictates the manner and method of the whole business, whilst the principle of energy merely does the book- keeping, balancing credits and debits.
>
> [@emdenWhyWeHave1938]

The first law of thermodynamics is entirely trivial. Energy is *nothing special*!

Energy is just a conserved quantity, much like volume, mass, and some other things... In particular, the conservation of energy is not nearly as important as it sounds like. It does not deserve the title of "the first law of thermodynamics". You might as well say "conservation of mass" is "the second-first law of thermodynamics" and "conservation of volume" is "the third-first law of thermodynamics", and "conservation of electrons" and "conservation of protons" and "conservation of length" (if you are studying a thermodynamic system restricted to move on a line) and "conservation of area" (if you are studying a thermodynamic system restricted on the surface of a lake) and so on...

This sounds extraordinary, but that is merely how classical thermodynamics works. The first law of thermodynamics does not deserve its title. There should not even be a first law of thermodynamics.

Properly speaking, "conservation of energy" is not a law of thermodynamics, but a law of physics. Why? Well, energy is nothing special inside classical thermodynamics, but it is extremely special if we zoom out to consider the whole of physics, because whereas in classical thermodynamics, you can consider systems that conserve energy, or volume, or length, or mass... when you move outside of thermodynamics, such as when you add in electrodynamics, special relativity, and quantum mechanics, all kinds of conservations breakdown. You don't have conservation of mass, or number of electrons, or even volume, but energy is always conserved.

Since energy is nothing special, we will demote it to "just another commodity", like volume, number of electrons, protons, and so on.

Every conserved quantity is a commodity. The company has some commodity. Commodities themselves have no intrinsic value. Instead, the company is valued by a certain accounting agency. The CEO's job is to move around the commodities so that the accounting agency gives it the highest value on the book.

A compound system is a *conglomerate*: a giant company made of little companies.

A subsystem has an inverse temperature $\beta = 1/T$ , which equals
$$\beta = \frac{d(\text{value of a sub-company})}{d(\text{energy owned by the sub-company})}$$

In other words, the marginal value of energy. Electricity price!

If a subsystem has variable volume then it has a pressure $P$ , which satisfies
$$\beta P= \frac{d(\text{value of a sub-company})}{d(\text{volume owned by the sub-company})}$$

In other words, the marginal value of space. Real estate price!

Yes, I know it sounds weird to say (Pressure/Temperature), but that's just how the math works out. It turns out that `(Pressure/Temperature)` is more fundamental than `Pressure`... Pressure, indeed, is actually `Real estate price / Electricity price`. That's why it has units of `($/m^3)/($/Joule) = Joule/m^3`!

Why, then, do we speak of pressure $P$ and temperature $T$ , instead of $\beta$ and $\beta P$ ? I blame habit and the general inability to visualize classical entropy.

### zeroth law

The zeroth law of thermodynamics, too, becomes trivial: Temperature is *nothing special*!

The zeroth law states that if A, B in energy-contact are in equilibrium, and B, C in energy-contact are in equilibrium, then A, C in energy-contact are in equilibrium.

The exact same statement works if we replace "energy" with "volume", or "chemical $i$ ", or "commodity".

They are all merely special cases of the general economic law: If several sub-companies are allowed to trade commodity $x$ , then when the total value of the conglomerate is maximized, the marginal value of $x$ is the same for each sub-company.

### third law

This is not actually important for classical thermodynamics.

## Nonequilibrium and equilibrium

> Freedom is an iron cage.  
> Constraints set it free again.  

Classical thermodynamics is a strange kind of science. It is quite subtle, subtle as general equilibrium microeconomics. The key to understanding it is to distinguish equilibrium and nonequilibrium.

I must warn you again, to forget all about molecules and atoms. Forget all about statistics and statistical mechanics. Forget about $S = k_B\ln \Omega$ or $S = -\sum_i p_i \ln p_i$ . None of these fits into the logical structure of classical thermodynamics.

| equilibrium | nonequilibrium |
|---|---|
| physical | virtual |
| defined by external constraints | defined by internal variables |

### A little story.

On the African savannah there lived a bunch of meerkats. Meerkats love to stand on the tallest place.

At first, they could stand wherever they wanted, so they all stood on one single hill. It was crowded. A blind lion who had memorized the landscape came and ate all of them.

Then humans came and added walls that divided the savannah into tiny little stripes. Now each meerkat's location is determined by which stripe it happened to fall in. The blind lion could find the meerkat if he knew the stripe location. In other words, optimizing for height, when there is one constraint, leads to one dimension of uncertainty.

This is a subtle point, so I will say it again. If you want to optimize for a quantity, and you don't have a constraint, then you would always go to the globally best solution. The whole space of possibilities is open to you, but you don't need them.

But if you have one constraint, then you have one unique solution for each possible setting of constraint. You are still not free, but at least now you have a puppet master.

In classical thermodynamics, only equilibrium states are "real". Nonequilibrium states are "virtual", much like a virtual path in Lagrangian mechanics. Sure, you could imagine that if you throw a rock upwards, it would execute a complex figure-8 motion before returning to ground again, but that's a virtual path. The only real path is the unique virtual path that stationarizes the action integral.

Similarly, in classical thermodynamics, you could imagine that a tank of gas contains all its gas on the left side, but that's a virtual state that does not satisfy the optimization constraint. Consequently, it is only a virtual state, not a real state. Only one virtual state is real -- the unique virtual state that maximizes entropy under constraint.

### Equilibrium vs nonequilibrium entropy.

For example, consider this statement, an important consequence of the second law:
> A closed system maximizes its entropy under its constraint.  

If we think of "equilibrium" states only, then the statement makes no sense. Under a fixed constraint, there is only one possible equilibrium state, so we get something sounding as ridiculous as "A customer can have a car painted in his favorite color as long as it's black."

The statement is actually saying this:
> A closed system under constraint has many satisfying nonequilibrium states, but only one equilibrium state: the one with the lowest nonequilibrium entropy. Consequently, for every constraint, there are many nonequilibrium states that satisfy the constraint, but only one equilibrium entropy, and so equilibrium entropy is a function of constraints, even though the nonequilibrium entropy is not.  

## mechanical and other forms of work

To perform work, one must perform work *upon* something. In other words, there is no such thing as "system A performed work". There is really "some energy and length is traded between A to B in compliance with a work-equation-constraint".

## the most important systems

### Baths

A heat bath, or more accurately an energy bath, is a system that you can take or dump as much energy as you want, always at constant temperature.

An atmosphere, or more accurately an energy-and-volume bath, is a system that you can take or dump as much energy or volume as you want, always at constant temperature and pressure.

In general, a bath is an infinite source of a conserved quantity at constant marginal entropy.

We can imagine other forms of baths. For example, the surface of a lake could serve as an energy-and-area bath. A large block of salt can serve as a salt-chemical bath.

* photon gas: $S =\frac 43 \beta E \propto V^{1/4}E^{3/4} $
* ideal gas: $S \propto \ln (VE^{\hat c_V})$
* ideal spring: $S = 0$ and $E = \frac 12kx^2$
* bespoke energy storage: $S=0$ and $E = f(x)$, where $f$ is whatever you want.
* ideal battery: $S=0$ and ???

## heat engine systems

A heat engine is a subsystem that is used as a component of a large system. The large system contains 4 parts: two energy baths, one heat engine, and one bespoke energy storage.

If you only want a heat engine that works, then the bespoke energy storage does not necessarily need to be so bespoke. However, if you want a heat engine that works reversibly, i.e. at maximal efficiency, then the energy storage must be designed to be exactly right. It must be designed to follow the exact parameters of the heat engine, as well as the two energy baths' inverse temperatures. If any of those is ignored, the energy storage would fail to "mesh" with the rest of the compound system, and cause waste.

This is why we insist on calling it a heat engine *system*. Every part of it depends on every other part. The energy storage unit is just as important and precisely designed as the heat engine.

## Common errors

Heat is not a noun, but a verb.

Energy is not special, but only one more conserved quantity.

Entropy is special, because it is the one quantity that is maximized.

Classical thermodynamics

| in a waterwheel | in a heat engine |
|---|---|
| water | caloric |
| height | temperature |
| mechanical work | mechanical work |

: Carnot's metaphor

## Carathéodory: geometric thermodynamics

### Frobenius theorem

Suppose we are to find the trajectory of a particle in a subset of 3D space, but we do not know its trajectory formula. Instead, we know only that its trajectory satisfies $a d x+b d y+c d z=0$, where $a, b, c$ are smooth functions of $(x, y, z)$. Thus, our only certainty is that if at some moment in time the particle is at location $\left(x_0, y_0, z_0\right)$, then its velocity at that moment is restricted within the plane with equation

$$
a\left(x_0, y_0, z_0\right)\left[x-x_0\right]+b\left(x_0, y_0, z_0\right)\left[y-y_0\right]+c\left(x_0, y_0, z_0\right)\left[z-z_0\right]=0
$$

In other words, we can draw a "local plane" at each point in 3D space, and we know that the particle's trajectory must be tangent to the local plane at all times. If we have two equations

$$
\left\{\begin{array}{l}
a d x+b d y+c d z=0 \\
a^{\prime} d x+b^{\prime} d y+c^{\prime} d z=0
\end{array}\right.
$$

then we can draw two local planes at each point, and their intersection is generically a line, allowing us to uniquely solve for the curve starting at any point. In other words, with two 1 -forms, we can foliate the domain into curves.

If we have only one equation $a d x+b d y+c d z=0$, then we might be able to foliate $\mathbb{R}^3$ into surfaces, in which case, we can be sure that a curve starting at a certain surface must be restricted to wander within that surface. If not, then a curve starting at any point might end up at any other point in $\mathbb{R}^3$.

![The 1 -form $dz - ydx$. on $\R^3$ maximally violates the assumption of Frobenius' theorem. These planes appear to twist along the $y$-axis. It is not integrable, as can be verified by drawing an infinitesimal square in the $x$-$y$ plane, and follow the path along the one-forms. The path would not return to the same z-coordinate after one circuit.](figure/Standard_contact_structure.svg)

One can imagine starting with a cloud of little planes, and quilting them together to form a full surface. The main danger is that, if we quilt the little planes two at a time, we might go on a cycle and return to where we began, but shifted by a small amount. If this happens, then we would not get a 2-dimensional surface, but a 3-dimensional blob. An example is shown in the diagram on the right.

If the one-form is integrable, then loops exactly close upon themselves, and each surface would be 2-dimensional. Frobenius' theorem states that this happens precisely when $\omega \wedge d \omega=0$ over all of the domain, where $\omega:=a d x+b d y+c d z$. The notation is defined in the article on one-forms.

During his development of axiomatic thermodynamics, Carathéodory proved that if $\omega$ is an integrable one-form on an open subset of $\mathbb{R}^n$, then $\omega=f d g$ for some scalar functions $f, g$ on the subset. This is usually called Carathéodory's theorem in axiomatic thermodynamics. ${ }^{[1][2]}$ One can prove this intuitively by first constructing the little planes according to $\omega$, quilting them together into a foliation, then assigning each surface in the foliation with a scalar label. Now for each point $p$, define $g(p)$ to be the scalar label of the surface containing point $p$.

Now, $d g$ is a one-form that has exactly the same planes as $\omega$. However, it has "even thickness" everywhere, while $\omega$ might have "uneven thickness". This can be fixed by a scalar scaling by $f$, giving $\omega=f d g$.

![For each point $p$, the one-form $\omega(p)$ is visualized as a stack of parallel planes. The planes are quilted together, but with "uneven thickness". With a scaling at each point, $\omega$ would have "even thickness", and become an exact differential.](figure/Carathéodory's_theorem_illustration.jpg)

For each point $p$, the one-form $\omega(p)$ is visualized as a stack of parallel planes. The planes are quilted together, but with "uneven thickness". With a scaling at each point, $\omega$ would have "even thickness", and become an exact differential.

### Thermodynamics

Consider a thermodynamic system (concretely one can imagine a piston of gas) that can interact with the outside world by either heat conduction (such as setting the piston on fire) or mechanical work (pushing on the piston). He then defined "adiabatic process" as any process that the system may undergo without heat conduction, and defined a relation of "adiabatic accessibility" thus: if the system can go from state $\mathrm{A}$ to state $\mathrm{B}$ after an adiabatic process, then $B$ is adiabatically accessible from $A$. Write it as $A \succeq B$.

Now assume that

- For any pair of states $A, B$, at least one of $A \succeq B$ and $B \succeq A$ holds.
- For any state $A$, and any neighborhood of $A$, there exists a state $B$ in the neighborhood, such that $B$ is adiabatically inaccessible from $A$.

Then, we can foliate the state space into subsets of states that are mutually adiabatically accessible. With mild assumptions on the smoothness of $\succeq$, each subset is a manifold of codimension 1 . Call these manifolds "adiabatic surfaces".

By the first law of thermodynamics, there exists a scalar function $U$ ("internal energy") on the state space, such that
$$
d U=\delta W+\delta Q=\sum_i X_i d x_i+\delta Q
$$
where $X_1 d x_1, \ldots, X_n d x_n$ are the possible ways to perform mechanical work on the system. For example, if the system is a tank of ideal gas, then $\delta W=-p d V$.
Now, define the one-form on the state space
$$
\omega:=d U-\sum_i X_i d x_i
$$

Now, since the adiabatic surfaces are tangent to $\omega$ at every point in state space, $\omega$ is integrable, so by Carathéodory's theorem, there exists two scalar functions $T, S$ on state space, such that $\omega=T d S$. These are the temperature and entropy functions, up to a multiplicative constant.

By plugging in the ideal gas laws, and noting that Joule expansion is an (irreversible) adiabatic process, we can fix the sign of $d S$, and find that $A \succeq B$ means $S(A) \leq S(B)$. That is, entropy is preserved in reversible adiabatic processes, and increases during irreversible adiabatic processes.

## Chemical thermodynamics

Standard chemistry textbooks are utter nonsense when it comes to the condition for equilibrium. You usually see things like $\Delta G = 0$ for chemical reactions in open atmosphere, or $\Delta H = 0$ for chemical reactions in a sealed container in a heat bath. When I took the chemistry courses, I was terribly confused because I felt they did not make sense. I passed the exams, but only by learning to speak the right kind of nonsense. During my study of classical thermodynamics, I rederived everything for myself, and in the process finally made everything come out the right way.

To set the scene, consider a few problems in typical books on chemistry that does not make sense. For concreteness, consider a typical chemical demonstration, the dimerization reaction of 

$$2 NO_2 \to N_2 O_4$$

Now seal a certain amount of the gas inside a glass tube. Since $NO_2$ is brown, but $N_2 O_4$ is transparent, if we heat it up, the pressure would rise, forcing the reaction to go towards the $N_2O_4$ side by Le Chatelier's principle, and the glass tube would turn transparent. Putting the tube inside an ice bath would turn it brown again.

The equilibrium for reaction is typically described as follows.

Define the reaction quotient for this reaction as $Q = \frac{[N_2 O_4]}{[NO_2]^2}$. According to the standard textbook, it states that the reaction reaches equilibrium when $\Delta H = 0$, where

$$
\Delta H = \Delta H^\circ + RT \ln Q
$$

and $\Delta H^\circ$ is the change in Helmholtz energy for the reaction at the standard state. This description is nonsense.

* $Q$ is always used inside a logarithm, like $RT\ln Q$. Logarithms can *never* have a unit, even though here $Q$ has units of molar density.
* The reaction quotient's unit depends on the reaction itself. How could this possibly be true? Imagine a physical quantity $X$ that has units of meters in one problem, but units of meters$^{-3}$ in another.
* Why can't I rewrite the equation as $4 NO_2 \to 2 N_2 O_4$? This would instantly change $Q$ to $Q' = Q^2$. How could the physics of the situation depend on our convention for describing it?
* The unit for $\Delta H$ is $J/mol$, but the units for $H$ is $J$, so somehow there is an extra $mol$ appearing out of nowhere.

The real answer is as follows: 

The state of a chemical reaction system in a closed container depends on not just its temperature, but also its chemical composition. Thus, the standard state of a chemical reaction system must specify its temperature, and the concentration of all its molecules.

Consider a chemical system
$$
\sum_i x_i X_i \leftrightarrow \sum_j y_i Y_j
$$

We must *arbitrarily* fix some standard concentrations $\left[X_i\right]^o,\left[Y_j\right]^o$, then the reaction quotient **with respect to these arbitrary conventions** is

$$
\ln Q:=\sum_j \ln y_j \frac{\left[Y_j\right]}{\left[Y_j\right]^o}-\sum_i x_i \ln \frac{\left[X_i\right]}{\left[X_i\right]^o}
$$

Then, if we immerse the system in an energy and volume bath (i.e. the open air, or maybe we throw it in a plastic bag and throw it under the sea), then

$$
\frac{d G}{d \xi}=\frac{d G^{\circ}}{d \xi}+R T \ln Q
$$

is independent of our choice of standard concentrations.

## Classical statistical mechanics

Let there be an amusement park that you are going, with many amusements i. You have exactly 1 day to spend there, so you need to spend p_i of a day on amusement i.
Now your total utility at the end of the day is equal to -\sum_i p_i \ln p_i. 
Suppose that's all there is to the amusement park, then the solution is clear: you should spend an equal amount of time at each amusement. This can be proved by Lagrange multiplier. But we can also do it more intuitively as follows.
Suppose your parents gave you a schedule for your amusement. You look at the schedule and notice that p_i < p_j. You can reject the plan and say, "I can always do better just by spending equal time at i, j, even holding the other times fixed."
The proof is simple ("partial equilibrium"): If we are only allowed to trade between time at i and j (that is, we have a "partial market")
The marginal utility of amusement i is ln(1/p_i) - 1
The marginal utility of amusement j is ln(1/p_j) - 1
So, if p_i \neq p_j, then the partial market is not at partial equilibrium.
At partial equilibrium, we must have p_i = p_j

Now at general equilibrium, all partial markets must be at partial equilibrium. Thus at general equilibrium, all p_i are equal. 

Parents tell you that unfortunately there is no general equilibrium, because the amusement park is actually infinite.

Then you remembered that the amusement park has a token system: when you enter the park you would buy a certain number of tokens. Then you spend tokens at the rides. The amount of tokens spent is proportional to the time you spend in the ride.
So your parents tell you that they'll buy you a certain number of tokens $E$ at the start of the day. Then you can plan your trip yourself. Free market, indeed.
Assuming that 
The prices of amusements are 0 < E_0 < E_1 < E_2 < \cdots. Here "E_0" is the "zero-point energy", or in other words, "just relax".
You must spend exactly all your tokens. Your parents hate wastefulness and would beat you up if you don't use all the tokens.
It is possible to spend exactly all your tokens: E_0 <= E <= \max_i E_i.

Thus we have reduced the problem to
$$
\begin{cases}
\max S(p) \
\sum_i p_i \cdot 1 = 1 \
\sum_i p_i \cdot E_i = E \
\end{cases}
$$

Under these assumptions, you can calculate that there is a unique schedule that maximizes your fun, or entropy.

Now there is a slight difficulty with your previous approach. Doing partial equilibrium between 2 amusements is not possible now, because you must balance between not just time, but also tokens. Suppose you spend less time at i to spend more time at j, this might cause you to under- or over-spend your tokens. So, to make a partial equilibrium calculation, you must use at least 3 amusements, not 2.
(And you are not allowed to "just relax", since relaxing is actually "the 0th amusement", and thus it also costs you tokens and time.)
That is, you must open partial markets with i, j, k at once, and then you can run the system to partial equilibrium. This is pretty annoying. There's a better way. 

Lagrange's devil makes an appearance!

"You can't solve the general equilibrium problem, you say? Why not try to use multivariable calculus?"
"Too annoying."
"Alright, how about I make you a deal --"
"Sorry but I don't sell my soul."
"Don't be stupid -- only something as stupid as God could still believe in souls these days! I am proposing that you trade happiness for time and for tokens. I will make a set price for time and another set price for tokens. Both prices are in units of your happiness. You can buy happiness with time, or time with happiness, also for tokens."
"Uhmm..."
"That's all that I offer. You should read up on microeconomics so you can make the right choice. See you when the day comes!" 

So the day came and the devil showed up. It gave the prices as follows:
1 unit of time = alpha unit of utility.
1 unit of token = beta unit of utility.
So you realized that you must solve the following problem

$$\max_p (S(p) - \alpha \sum_i p_i - \beta \sum_i p_i E_i)$$

And that's when you found out that your parents = Lagrange's devil = Boltzmann's devil.


You realized what a great luck you have that the devil is there -- it has split a whole general equilibrium problem into so many partial equilibria:
$$\forall i, \max_{p_i} p_i \ln \frac{1}{p_i} - \alpha p_i - \beta p_i E_i$$

So you solve the problem:
$$p_i = e^{-1-\alpha} e^{-\beta E_i}$$

After you solved the problem, you are about to go to the devil, but then the devil stopped you and asked you to not make individual trades, but make a bulk one-time trade. So you calculate $\sum_i p_i$ and $\sum_i p_i E_i$, and to your surprise, you found that they equal exactly 1 and E. That is, you actually would spend all your time and tokens without needing to trade with the devil.
"So you see? If the mortal is ready to make a trade, the devil appears..."
"But why must you appear at all, if you are not actually going to trade with me anyway?"
"And when the mortal is truly ready to make a trade, the devil disappears..."

And so you sat there looking at your two equations in strange amusement:
$$p_i = \frac{e^{-\beta E_i}}{e^{1+\alpha}}, \quad \alpha+1 = \ln\sum_i e^{-\beta E_i} , \quad E = \sum_i E_i \frac{e^{-\beta E_i}}{e^{1+\alpha}}$$
A physicist comes and points out that they are better known as
$$p_i =  \frac{e^{-\beta E_i}}{Z}, \quad Z = e^{-\beta F} = \sum_i e^{-\beta E_i}, \quad E = \sum_i p_i E_i$$
and said that $Z$ is called "partition function", $F$ is "Helmholtz free energy", and $\beta$ is "inverse temperature". 

There is just one question left to solve: why did the devil design the prices this way?
"Because I don't want you to actually be happier!" is the answer.
What did the devil mean?
Well, after doing the pointless trade, you realized that you didn't actually need the devil. But then suppose the devil suddenly increased the price of tokens, then what would you do? You would realize that you can profit by spending a little less time at amusement i, and sell both the time and the tokens you saved to the devil, and increase your happiness! Similarly for any other form of price change.

(With a little calculation, you can show that, if there exists E_i \neq E_j, then any change in devil's prices would strictly allow you to increase happiness just by changing p_i and p_j.)

Therefore, the devil knows that any price change would increase your happiness, so it chose the prices that would minimize your happiness.
"And when the mortal is truly ready to make a trade, the devil disappears..." 

## Annotated references {.appendix}

* [@lemonsThermodynamicWeirdnessFahrenheit2019]. A very readable introduction to classical thermodynamics, slim but deep. I finally understood the meaning of thermodynamics means after reading it.
* [@lemonsMereThermodynamics2008]. A textbook version of the author's [@lemonsThermodynamicWeirdnessFahrenheit2019], weaving in history and philosophical contemplation at every turn.
* [@carnotReflectionsMotivePower1988]. A reprint of the most important papers in thermodynamics published before 1900. Useful to have on hand if you are reading [@lemonsThermodynamicWeirdnessFahrenheit2019].
* [@pippardElementsClassicalThermodynamics1964]. Slim, elegant, both mathematical and applied. In the best British tradition of mathematics -- think James Maxwell and G. H. Hardy.
* [@fermiThermodynamics1956]. The same as above. However, it also covers chemical thermodynamics.
* [@buchdahlConceptsClassicalThermodynamics1966]. A textbook based on Carathéodory's axiomatic thermodynamics. The notation is ponderous, and the payoff is unclear. I don't know what is its intended audience -- perhaps professional pedants and differential geometers? Nevertheless, if you need to do research in Carathéodory's axiomatic thermodynamics, I think this is your best bet.

[
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "If you thought the Stroop test is hard, just wait until you have tried this.\nPlay online | Play offline"
  },
  {
    "objectID": "projects/index.html#double-stroop",
    "href": "projects/index.html#double-stroop",
    "title": "Projects",
    "section": "",
    "text": "If you thought the Stroop test is hard, just wait until you have tried this.\nPlay online | Play offline"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n  \n  \nYuxi Liu is a PhD student in Computer Science at the Berkeley Artificial Intelligence Research Lab, researching on the scaling laws of large neural networks."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThermodynamics and economics\n\n\n\n\n\n\nmath\n\n\nphysics\n\n\neconomics\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nAnalytical mechanics\n\n\n\n\n\n\nmath\n\n\nphysics\n\n\nphilosophy\n\n\n\n.\n\n\n\n\n\nApr 11, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipia Philosophica Naturalium Mathematicarum\n\n\nPhilosophical Principles of Natural Mathematics\n\n\n\nmath\n\n\nphysics\n\n\nphilosophy\n\n\ncs\n\n\n\n.\n\n\n\n\n\nApr 11, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation and GDP since 10000 BC\n\n\n\n\n\n\nAI\n\n\nscaling\n\n\n\nWhen did the singularity get cancelled?\n\n\n\n\n\nJan 18, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nMathematical Interpretations of Quantum Mechanics\n\n\n\n\n\n\nphysics\n\n\n\nQuantum mechanics: what it all means, mathematically speaking.\n\n\n\n\n\nJan 10, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nBook Reviews\n\n\n\n\n\n\nbook-review\n\n\n\nBook reviews.\n\n\n\n\n\nDec 16, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nThe Decline of Mathematical Fields\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nhistory\n\n\nmath\n\n\n\nLosing my religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nWhat does it feel like to be a mathematical object?\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nmath\n\n\n\nMy religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About",
    "section": "",
    "text": "Yuxi Liu is a PhD student in Computer Science at the Berkeley Artificial Intelligence Research Lab, researching on the scaling laws of large neural networks."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#history",
    "href": "blog/posts/mixture-of-experts/index.html#history",
    "title": "Mixture of Experts",
    "section": "History",
    "text": "History"
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#future",
    "href": "blog/posts/mixture-of-experts/index.html#future",
    "title": "Mixture of Experts",
    "section": "Future",
    "text": "Future\n\nAnd then it finally worked. And I think the biggest difference was the computing power. Definitely there were advances in data. So we could do image net because Fei-Fei Li and others gathered this large database, and that was really important. There are certainly differences in the algorithm, right? We’ve got a slightly different squashing function. Instead of shaped like this, it’s shaped like this. I mean, I don’t know how big a deal that was, but we learned how to do stochastic gradient dissent a little bit better. We figured that dropout gave you a little bit better robustness.\nSo there were small things, but I think probably the biggest was the computing power. And I mean, I certainly remember Geoff Hinton came to Berkeley when I was a grad student in 1981, I think, when he talked about these neural nets. And we fellow grad students thought that was so cool. So we said, “Let’s go back into the lab and implement it.\nAnd of course, there was absolutely nothing you could download, so we had to build it all from scratch. And we got it to do exclusive or, and then we got it to do something a little bit more complicated. And it was exciting. And then we gave it the first real problem, and it ran overnight, and it didn’t converge, and we let it run one more day, and it still didn’t converge. And then we gave up, and we went back to our sort of knowledge-based systems approach. But if we had the computing power of today, it probably would have converged after five seconds. (Norvig 2021)"
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#a-toy-model",
    "href": "blog/posts/mixture-of-experts/index.html#a-toy-model",
    "title": "Mixture of Experts",
    "section": "A toy model",
    "text": "A toy model\nTo make this concrete, I coded up system in Python in a Jupyter notebook. See\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate the dataset\ndef generate_dataset(num_samples, sharpness=5):\n    X = np.random.randn(num_samples, 2)\n    p = np.minimum(np.exp(sharpness * np.minimum(X[:, 0], X[:, 1])), 1)\n    y = np.random.binomial(1, p, size=num_samples)\n    return X, y\n\n# Generate the dataset\nnum_samples = 1000\nX, y = generate_dataset(num_samples)\n\n# Split the dataset manually\nsplit_ratio = 0.8\nsplit_index = int(split_ratio * num_samples)\n\nX_train, X_test = X[:split_index], X[split_index:]\ny_train, y_test = y[:split_index], y[split_index:]\n\n# Plot the dataset\ndef plot_dataset(X, y, ax):\n    ax.scatter(X_train[y_train == 0][:, 0], X_train[y_train == 0][:, 1], label='Class 0', marker='o', c='blue')\n    ax.scatter(X_train[y_train == 1][:, 0], X_train[y_train == 1][:, 1], label='Class 1', marker='x', c='red')\n    ax.set_title('Dataset Scatter Plot')\n    return ax\n\nfig, ax = plt.subplots(figsize=(8, 6))\nplot_dataset(X_test, y_test, ax)\nplt.show()"
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html",
    "href": "blog/posts/mixture-of-experts/index.html",
    "title": "Mixture of Experts",
    "section": "",
    "text": "The code for the post is available at moe.ipynb."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#theory",
    "href": "blog/posts/mixture-of-experts/index.html#theory",
    "title": "Mixture of Experts",
    "section": "Theory",
    "text": "Theory\nMixture of Experts is an old technique dating back to 1991, but it has become a vital component of modern deep learning to get around the memory bottleneck. There is not much theory to speak of, because this is honestly a very simple technique. Let’s say you have a few predictive models. Each model is an expert. Now you take all of them and combine their predictions in some way – that’s mixture of experts.\n\nMixing\nConsider a simple example. Suppose we are to classify points on the \\(\\mathbb{R}^2\\) plane into 2 classes. Suppose that we can only use a single linear-logistic function \\(f(x) = \\frac{1}{1 + e^{w^T x + b}}\\), then we can write down this classifier:\n\\[\n\\hat y := \\begin{cases}\n1, \\quad & \\text{if }f(x) &gt; 0 \\\\\n0 , & \\text{otherwise}\n\\end{cases}\n\\]\nIn other words, we have a logistic regression model.\n\n\n\nAn example of a logistic regression model. The curve shows the estimated probability of passing an exam versus hours studying. If we have to do a binary prediction, then we predict \\(\\hat y = 1\\) iff \\(x \\geq 2.7\\), that is, we predict the student would pass the exam iff they had studied more than 2.7 hours. Figure from Wikipedia\n\n\nLike perceptrons, logistic regression is simple, fast, and has a very elegant theory – and like perceptrons, logistic regression does not work if the underlying system is not linearly separable.\nNow, consider the simplest example that is not linearly separable: a binary classification on the plane. One class falls into the first quadrant, and the other into the other 3 quadrants. There is some noise, so the points near the edges do not always fall into their respective classes. There is no way to perform this task well with just one logistic classifier, but with two, we should be able to perform this task well enough.\n\n\n\nA scatterplot of points that fall into 2 classes that are not linearly separable.\n\n\nLet’s design the 2 experts manually, and somehow combine them. The 2 experts should each handle one of the edges:\n\\[\nf_1(x, y) = \\frac{1}{e^{10 x}+1}, \\quad f_2(x, y) = \\frac{1}{e^{10 y}+1}\n\\]\nIn words, \\(f_1\\) is a smooth approximation to the 0-1 function that sends \\((x, y)\\) to \\(1\\) iff \\(x &gt; 0\\), and similarly, \\(f_2\\) is a smooth approximation to the 0-1 function that sends \\((x, y)\\) to \\(1\\) iff \\(y &gt; 0\\). How do we combine them?\nWe can add another “manager” which is an expert at picking experts. It would pick \\(f_1\\) if the point \\((x, y)\\) falls above the diagonal line \\(x=y\\), and pick \\(f_2\\) otherwise. This would then give us\n\\[\nf(x, y) = \\begin{cases}\nf_1(x, y), \\quad &\\text{if } y-x &gt; 0 \\\\\nf_2(x, y), \\quad &\\text{if } y-x &lt; 0\n\\end{cases}\n\\]\nThis is the simplest example of sparsely-gated MoE. For each point, the manager picks the right expert to call, and call that expert. The other expert does not ever need to be activated, saving half the compute, the manager’s computation is so simple that it does not cost anything compared to the expert’s computation, which contains an exponential.\nWe can also combine the experts by a linear function, as in\n\\[\nf(x, y) = \\sum_{i = 1}^2 p_i(x, y) f_i(x, y)\n\\]\nwhere \\((p_1, p_2)\\) is a probability distribution over the experts that depends on \\((x, y)\\), such as \\(\\sm(A(x, y))\\) where \\(A\\) is a linear operator, that is, a matrix. For lack of a better word, I call this dense MoE.\n\n\nSparsifying\nGiven a MoE, there are two ways to use it. One can use it as-is, but then every expert must be consulted on every query, defeating the main purpose of MoE in the age of large models: conditional computing. Therefore, the model should be sparsified.\nIn the first MoE paper (Jacobs et al. 1991), they manually inspected the weights (the matrix \\(A\\) in our notation), and found that some experts would never be called on any input. Then they just removed those experts. This can be understood as sparsification “at compile time”.\nIn the toy model, I trained 6 logistic regression experts to classify 2-dimensional points, so the matrix \\(A\\) has 6 rows and 2 columns. To sparsify the model at compile time to only \\(k\\) experts, I took the matrix \\(A\\) and ranked them according to their L2-norm, found the top-\\(k\\) rows of them, then mask out all the other experts. The resulting heat maps at various levels of \\(k \\in 1:6\\) are as follows.\n\n\n\nHeat maps of the compile-time sparsified MoE at various levels of sparsity.\n\n\nAs expected, when \\(k=1\\), we have only one expert taking care of everything, and end up with a linear classifier. When \\(k=2\\), the sparsified MoE looks much closer to the correct classifier. When \\(k \\geq 3\\), it becomes indistinguishable.\nNow, for the sparsely-gated MoE, the sparsification is done “at runtime”. That is, for each input \\(x\\), we find the top-\\(k\\) experts for this specific \\(x\\), and use those experts:\n\\[w(x) = \\sm(\\mathrm{top}_k(Ax))\\]\nwhere \\(\\mathrm{top}_k(v)\\) preserves the top-k entries of \\(v\\), but set all other entries to \\(-\\infty\\). This means we have to keep all experts at runtime, since each expert might be needed for some specific input point, but every input point would only activate a few experts. The key is that the activated experts depend on \\(x\\), unlike the MoE sparsified at compile time, which always activates the same few experts. This means we can achieve a lower sparsity, and less compute. We trade memory for performance and compute.\nIn the same toy model, the resulting heat maps at various levels of \\(k \\in 1:6\\) are as follows.\n\n\n\nHeat maps of the sparsely-gated MoE at various levels of sparsity.\n\n\nCompared with the compile-time sparsified MoE, the sparsely-gated MoE is already usable when \\(k=1\\), and it looks like a piecewise-linear classifier. When \\(k=2\\), it already becomes indistinguishable from the correct classifier."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#before-deep-learning",
    "href": "blog/posts/mixture-of-experts/index.html#before-deep-learning",
    "title": "Mixture of Experts",
    "section": "Before deep learning",
    "text": "Before deep learning\nIn the beginning was the gaussian. The gaussian is a beautiful distribution, with linearity, the central limit theorem, fast inference, least squares regression, and so on. The problem is that it has just one peak.\nIf one wants to model a complicated distribution with several bumps, one can make one step up the staircase of complexity, and build distributions from a linear sum of several gaussians. This is the mixture of gaussians. More generally, simple statistical models like the Poisson distribution, the Bernoulli distribution, and so on, can be added together to create mixture models.\n\n\n\nA mixture of three gaussian bumps. Figure from Wikipedia.\n\n\nA mixture of experts is then a simple generalization, and training a mixture of experts, back in the old days, was mostly thought of as statistical inference. The main problem was simply modelling complex data with a larger family of statistical distribution. Their main worry was that the experts would overfit.\nThey had little data (enough to fit onto a floppy disk), and each expert was usually just a gaussian distibution or a logistic classifier (any more complex and they wouldn’t know how to calculate the integrals and derivatives). Consequently, what they ended up trying to solve was to fit a few thousand datapoints using tens of very simple experts.\nIt is a general fact of classical machine learning that they were very worried about overfitting, and it is reasonable back then to worry, since they had such small datasets (MNIST was in 1994). This, combined with their inability to hand-design learning algorithms for complex machine learning architectures and the slowness of pure gradient descent, meant that machine learning algorithms back then were simple ones fitted onto small datasets.\nThe overall effect is:\n\ngetting training data: expensive (you have to do it yourself)\ndesigning the algorithm: expensive (cheaper if you have graduate students)\ntraining compute: moderate to high (though a few pioneers have bravely pushed to the “very expensive” regime, and failed1)\ninference compute: very cheap (since that you wouldn’t be able to train anything large)\n\n1 Peter Norvig, coauthor of the most popular AI textbook, recalls:\n\nI certainly remember Geoffrey Hinton came to Berkeley when I was a grad student in 1981, I think, when he talked about these neural nets. And we fellow grad students thought that was so cool. So we said, “Let’s go back into the lab and implement it. And of course, there was absolutely nothing you could download, so we had to build it all from scratch. And we got it to do XOR, and then we got it to do something a little bit more complicated. And it was exciting. And then we gave it the first real problem, and it ran overnight, and it didn’t converge, and we let it run one more day, and it still didn’t converge. And then we gave up, and we went back to our sort of knowledge-based systems approach. But if we had the computing power of today, it probably would have converged after five seconds. (Norvig 2021)\n\nThis should be compared to the very different situation with deep learning:\n\ngetting training data: cheap (just download it online)\ndesigning the algorithm: cheap (make a standard network, add a few decorations, then use backprop with Adam optimizer)\ntraining compute: as expensive as you want\ninference compute: as expensive as you want"
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#after-deep-learning",
    "href": "blog/posts/mixture-of-experts/index.html#after-deep-learning",
    "title": "Mixture of Experts",
    "section": "After deep learning",
    "text": "After deep learning\nWhile classical statistics and machine learning was mainly constrained by how many partial derivatives and integrals the statistician can calculate confidently on paper,2 deep learning is mainly constrained by memory and compute budget.2 If you want a taste of the old days, look at the formulas inside (Jordan and Jacobs 1994). They explicitly calculated the expectation-maximization algorithms for learning a hierarchy of linear experts.\nSo when the deep learning era came circa 2012, people immediately started looking into how to perform conditional computing: save computing cost by only calling a small portion of the model. The idea is that you would have different portions of the model be specialized for different forms of input, and for each input, the model would first cheaply find out which expert should handle it, then call upon only the few specialized experts to handle this particular input.\nDeep learning came with AlexNet (2012), and the first paper on applying MoE to deep learning was “Learning Factored Representations in a Deep Mixture of Experts” (2013). Things really started heating up though with sparsely-gated MoE (2017)."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#why-moe-for-deep-learning",
    "href": "blog/posts/mixture-of-experts/index.html#why-moe-for-deep-learning",
    "title": "Mixture of Experts",
    "section": "Why MoE for deep learning?",
    "text": "Why MoE for deep learning?\nGenerally, one uses a MoE on the frontier, because:\n\nYou really need to push the metric up by a few points.\nYou can’t train a dense model larger than the frontier model, because it simply fails to converge, or the hyperparameter settings for the small models don’t work for the larger one (and you can’t just run a grid search to find it because it costs a million dollars to do a single run).\nYou can train around 10 copies of the frontier model, because while you don’t have the money to do grid search beyond the current frontier, you have the money to train 10 at the frontier.\nYou can’t infer a dense model larger than the frontier one, because one dense model \\(N\\) times as wide would cost you \\(N^2\\) amount of storage and compute, while if you just train \\(N\\) experts, each with roughly the same architecture as the dense model, it would cost you about \\(N\\) amount of storage and about \\(2\\) amount of compute (if only 2 experts are called per question).\nIndeed, if there are too many parameters, then it can’t even be fit onto a good GPU and must be split across GPUs, and then the GPU–GPU communication becomes a serious problem (the “von Neumann bottleneck”).\n\n\n\n\nThe storage hierarchy. Figure from Harvard CS 61: Systems Programming and Machine Organization (2018), Storage 2: Cache model.\n\n\nAll of which are satisfied by Microsoft, Google, etc. This explains why GPT-4 is a MoE made by multiple GPT-3–like models.\nA quick scan of the recent literature shows this, all from Google.\n\nWe present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. (Shazeer et al. 2017)\n\n\nCombining expert, model and data parallelism, we design two large Switch Transformer models, one with 395 billion and 1.6 trillion parameters, respectively. (Fedus, Zoph, and Shazeer 2022)\n\n\nwe demonstrate the potential of V-MoE to scale vision models, and train a 15B parameter model that attains 90.35% on ImageNet. (Riquelme et al. 2021)\n\n(Shazeer et al. 2017) is not the first paper on MoE in the deep learning era, but it is the most important one. It was applied to between “stacked LSTM layers”, because it was published back when neural language models were stacks of LSTM. Nowadays, of course, MoE usually means MoE layers within Transformers, because only with Transformers do people regularly train models with more than 10 billion parameters."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "",
    "text": "This is a theory of neural scaling law, proposed by (Bahri et al. 2021; Sharma and Kaplan 2022)\nAccording to this theory, a neural network, when trained to convergence, allocates its \\(N\\) parameters in two parts: * A fixed number of parameters that map the data to an intrinsic data manifold of dim \\(d\\). * All other parameters that handle pieces of this manifold. Loss \\(\\propto\\) the volume of each manifold piece.\nThey argued that the loss function should scale as \\(L \\propto N^{-4/d}\\) for cross-entropy and mean-square losses."
  },
  {
    "objectID": "blog/posts/neural-network-scrapbook/index.html",
    "href": "blog/posts/neural-network-scrapbook/index.html",
    "title": "A Scrapbook of Neural Network Lores",
    "section": "",
    "text": "Marvin Minsky, on how he gave up on neural networks after the 1950s because he could not afford a few million neurons.\n\nI had the naive idea that if one could build a big enough network, with enough memory loops, it might get lucky and acquire the ability to envision things in its head. This became a field of study later. It was called self-organizing random networks. Even today, I still get letters from young students who say, ‘Why are you people trying to program intelligence? Why don’t you try to find a way to build a nervous system that will just spontaneously create it?’ Finally, I decided that either this was a bad idea or it would take thousands or millions of neurons to make it work, and I couldn’t afford to try to build a machine like that. (Bernstein 1981)\n\nPeter Norvig, on how he quickly gave up on neural networks in the 1980s due to lack of compute.\n\nAnd then it finally worked. And I think the biggest difference was the computing power. Definitely there were advances in data. So we could do image net because Fei-Fei Li and others gathered this large database, and that was really important. There are certainly differences in the algorithm, right? We’ve got a slightly different squashing function. Instead of shaped like this, it’s shaped like this. I mean, I don’t know how big a deal that was, but we learned how to do stochastic gradient dissent a little bit better. We figured that dropout gave you a little bit better robustness.\nSo there were small things, but I think probably the biggest was the computing power. And I mean, I certainly remember Geoffrey Hinton came to Berkeley when I was a grad student in 1981, I think, when he talked about these neural nets. And we fellow grad students thought that was so cool. So we said, “Let’s go back into the lab and implement it.\nAnd of course, there was absolutely nothing you could download, so we had to build it all from scratch. And we got it to do exclusive or, and then we got it to do something a little bit more complicated. And it was exciting. And then we gave it the first real problem, and it ran overnight, and it didn’t converge, and we let it run one more day, and it still didn’t converge. And then we gave up, and we went back to our sort of knowledge-based systems approach. But if we had the computing power of today, it probably would have converged after five seconds. (Norvig 2021)"
  },
  {
    "objectID": "blog/posts/neural-network-scrapbook/index.html#the-scaling-hypothesis",
    "href": "blog/posts/neural-network-scrapbook/index.html#the-scaling-hypothesis",
    "title": "A Scrapbook of Neural Network Lores",
    "section": "",
    "text": "Marvin Minsky, on how he gave up on neural networks after the 1950s because he could not afford a few million neurons.\n\nI had the naive idea that if one could build a big enough network, with enough memory loops, it might get lucky and acquire the ability to envision things in its head. This became a field of study later. It was called self-organizing random networks. Even today, I still get letters from young students who say, ‘Why are you people trying to program intelligence? Why don’t you try to find a way to build a nervous system that will just spontaneously create it?’ Finally, I decided that either this was a bad idea or it would take thousands or millions of neurons to make it work, and I couldn’t afford to try to build a machine like that. (Bernstein 1981)\n\nPeter Norvig, on how he quickly gave up on neural networks in the 1980s due to lack of compute.\n\nAnd then it finally worked. And I think the biggest difference was the computing power. Definitely there were advances in data. So we could do image net because Fei-Fei Li and others gathered this large database, and that was really important. There are certainly differences in the algorithm, right? We’ve got a slightly different squashing function. Instead of shaped like this, it’s shaped like this. I mean, I don’t know how big a deal that was, but we learned how to do stochastic gradient dissent a little bit better. We figured that dropout gave you a little bit better robustness.\nSo there were small things, but I think probably the biggest was the computing power. And I mean, I certainly remember Geoffrey Hinton came to Berkeley when I was a grad student in 1981, I think, when he talked about these neural nets. And we fellow grad students thought that was so cool. So we said, “Let’s go back into the lab and implement it.\nAnd of course, there was absolutely nothing you could download, so we had to build it all from scratch. And we got it to do exclusive or, and then we got it to do something a little bit more complicated. And it was exciting. And then we gave it the first real problem, and it ran overnight, and it didn’t converge, and we let it run one more day, and it still didn’t converge. And then we gave up, and we went back to our sort of knowledge-based systems approach. But if we had the computing power of today, it probably would have converged after five seconds. (Norvig 2021)"
  },
  {
    "objectID": "blog/posts/neural-network-scrapbook/index.html#neural-networks-want-to-work",
    "href": "blog/posts/neural-network-scrapbook/index.html#neural-networks-want-to-work",
    "title": "A Scrapbook of Neural Network Lores",
    "section": "Neural networks want to work",
    "text": "Neural networks want to work\nMarvin Minsky’s SNARC (1951). Designed to simulate one mouse escaping a maze, it ended up simulating multiple mice due to design bugs – which were never debugged. Though the machine had only 40 neurons, and its parts failed all the time, the whole network continued to work.\n\nIt turned out that because of an electronic accident in our design we could put two or three rats in the same maze and follow them all. The rats actually interacted with one another. If one of them found a good path, the others would tend to follow it. We sort of quit science for a while to watch the machine. We were amazed that it could have several activities going on at once in its little nervous system. Because of the random wiring, it had a sort of fail-safe characteristic. If one of the neurons wasn’t working, it wouldn’t make much of a difference—and, with nearly three hundred tubes and the thousands of connections we had soldered, there would usually be something wrong somewhere. In those days, even a radio set with twenty tubes tended to fail a lot. I don’t think we ever debugged our machine completely, but that didn’t matter. By having this crazy random design, it was almost sure to work, no matter how you built it. (Bernstein 1981)\n\nBernard Widrow once built a MADALINE I (circa 1962) in a rush to present at a technical meeting. Despite that only 1/4 of its circuits were defective, it still worked at reduced capacity.\n\nWe discovered the inherent ability of adaptive computers to ignore their own defects while we were rushing through construction of a system called Madaline I for presentation at a technical meeting. The machine was finished late the night before the meeting and the next day we showed some very complex pattern discriminations. Later we discovered that about a fourth of the circuitry was defective. Things were connected backward, there were short circuits, and poor solder joints. We were pretty unhappy until it dawned on us that this system has the ability to adapt around its own internal flaws. The capacity of the system is diminished but it does not fail. (Widrow 1963)\n\nAndrej Karpathy, on how neural network program bugs are very hard to find, because bugged neural networks do not fail, merely degrade.\n\n… perhaps you forgot to flip your labels when you left-right flipped the image during data augmentation. Your net can still (shockingly) work pretty well because your network can internally learn to detect flipped images and then it left-right flips its predictions. Or maybe your autoregressive model accidentally takes the thing it’s trying to predict as an input due to an off-by-one bug. Or you tried to clip your gradients but instead clipped the loss, causing the outlier examples to be ignored during training. Or you initialized your weights from a pretrained checkpoint but didn’t use the original mean. Or you just screwed up the settings for regularization strengths, learning rate, its decay rate, model size, etc. Therefore, your misconfigured neural net will throw exceptions only if you’re lucky; Most of the time it will train but silently work a bit worse. (Karpathy 2019)\n\nResearchers at OpenAI (2018) reported that fixing RL bugs is as important as better algorithms.\n\nBig-picture considerations like susceptibility to the noisy-TV problem are important for the choice of a good exploration algorithm. However, we found that getting seemingly-small details right in our simple algorithm made the difference between an agent that never leaves the first room and an agent that can pass the first level. To add stability to the training, we avoided saturation of the features and brought the intrinsic rewards to a predictable range. We also noticed significant improvements in performance of RND every time we discovered and fixed a bug (our favorite one involved accidentally zeroing an array which resulted in extrinsic returns being treated as non-episodic; we realized this was the case only after being puzzled by the extrinsic value function looking suspiciously periodic). Getting such details right was a significant part of achieving high performance even with algorithms conceptually similar to prior work. This is one reason to prefer simpler algorithms where possible. (Burda and Edwards 2018)\n\nAround 2019, Gwern, Shawn Presser, and others, trained \\(512\\times 512\\) image generation models using the BigGAN architecture. However, they used compare_gan, which had a multiply-by-zero bug. Somehow it still worked, but not well enough compared to the original BigGAN.\n\nOur primary goal was to train & release 512px BigGAN models on not just ImageNet but all the other datasets we had like anime datasets. The compare_gan BigGAN implementation turned out to have a subtle +1 gamma bug which stopped us from reaching results comparable to the model; while we beat our heads against the wall trying to figure out why it was working but not well enough (figuring it out far too late, after we had disbanded) … “Neural nets want to work” – even if they start out being effectively multiplied by zero. (Branwen 2022)\n\nPersonal story at the Berkeley CS 285, Deep Reinforcement Learning, 2022 Fall.\nFor Homework 3, we were asked to implement the soft actor-critic algorithm. We would implement the agent, run the agent on the Half Cheetah environment, and submit the trajectories to Gradescope, where an autograder would check the trajectories and see if the agent achieved a final score above 300. For the Half Cheetah, score means the distance it travels per episode, averaged over several episodes.\nI noticed that the algorithm I implemented did learn, but the learning curve looked like a rollercoaster, jumping up and down around the range of 250 – 300. After many fruitless and paranoid programming sessions I managed to pass the autograder by trying enough random seeds and just submitting the best seeds. The professor, Sergey Levine, offered little help, admitting that RL agents are extremely hard to debug.\nOne day after the assignment deadline, the professor announced that there was a critical one-line bug in the starter code: The correct algorithm should train the model with past game frames in a random order, but the given code always give them in the FIFO order. With the fix, the learning curve would smoothly sigmoid to 350.\n\nThe Neural Net Tank Urban Legend\nA large list of examples in The Neural Net Tank Urban Legend · Gwern.net. I have a few more.\nAccording to Sejnowski, Takeo Kanade did work on detecting tanks in images. This is unconfirmed. I have looked for “Artificial Intelligence Vision: Progress and Non-Progress”, but it is not available online. I looked for your doctoral dissertation of 1974, but it contains only facial recognition. I also cannot find anything about detecting tanks in his publication list.\n\nIn his talk “Artificial Intelligence Vision: Progress and Non-Progress,” Takeo Kanade (from Carnegie Mellon) noted that computer memories back in the 1960s were tiny by today’s standards and could hold only one image at a time. For his doctoral dissertation in 1974, Takeo had shown that, though his program could find a tank in one image, it was too difficult for it to do so in other images where the tank was in a different position and the lighting was different. But, by the time his early students graduated, the programs they designed could recognize tanks under more general conditions because computers were more powerful. Today his students’ programs can recognize tanks in any image. The difference is that today we have access to millions of images that sample a wide range of poses and lighting conditions, and computers are millions of times more powerful. (Sejnowski 2018, 256)\n\nThere was not a lot of actual research on tank recognition. (Kanal and Randall 1964) contains some good pictures. The network was a two-layered perceptron network, of type \\(\\mathbb{R}^{N \\times N} \\to \\{0, 1\\}^{32\\times 32} \\to \\{0, 1\\}^{24} \\to \\{0, 1\\}\\). It works as follows:\n\nThe grayscale photo is down-scaled and binarized by convolution with a discrete Laplace filter: \\(\\mathbb{R}^{N \\times N} \\to \\{0, 1\\}^{32\\times 32}\\).\nThe weights for the 24 hidden perceptrons are constructed by linear discriminant analysis: \\(\\{0, 1\\}^{32\\times 32} \\to \\{0, 1\\}^{24}\\)\nThe output perceptron is learned by the perceptron learning rule: \\(\\{0, 1\\}^{24} \\to \\{0, 1\\}\\).\n\n\nFigure 1: Images from (Kanal and Randall 1964).\n\n\n\n\n\n\n(a) Grayscale photos, some containing tanks, and some not.\n\n\n\n\n\n\n\n(b) A picture of a tank after convolution with a discrete Laplace filter.\n\n\n\n\n\n\n\n\n\n(c) The architecture of the network."
  },
  {
    "objectID": "blog/posts/neural-network-scrapbook/index.html#the-second-neural-network-winter",
    "href": "blog/posts/neural-network-scrapbook/index.html#the-second-neural-network-winter",
    "title": "A Scrapbook of Neural Network Lores",
    "section": "The second neural network winter",
    "text": "The second neural network winter\nThe first neural network winter started around 1965, when the main research centers pivoted away from neural networks: the Stanford Research Institute group turned to symbolic AI; the Bernard Widrow group turned to using single neurons as adaptive filters; the Frank Rosenblatt group died from lack of funds and then the literal death of Rosenblatt in 1971. It rose again around 1985, when backpropagation and improved compute allowed researchers to train neural networks on the order of \\(10^4\\) parameters and \\(4\\) layers.\nSomething strange happened during the 1990 – 2010 period: the neural network research community silently disappeared again for another 20 years. Unlike the previous case, there was no great mythology or drama about this winter, no Perceptron controversy.\nI would like to find out why.\n\nLukas: So I remember Daphne Koller telling me, maybe 2003, that the kind of state-of-the-art handwriting systems were neural nets, but that it was such an ad hoc kind of system that we shouldn’t focus on it. And I wonder if maybe I should have paid more attention to that and tried harder to make neural nets work for the applications I was doing.\nPeter: Yeah, me too. And certainly Yann LeCun had success with the digit database, and I think that was over-engineered in that they looked at exactly the features they needed for that set of digitizations of those digits. And in fact, I remember researchers talking about, “Well, what change are we going to do for sample number 347?” Right?\nLukas: Oh, really? Okay.\nPeter: There were individual data points that they would perform theories on, so that was definitely over-tuning to the data. And it should have been an indication that was a good approach. It was better than other approaches at the time.\nLukas: I guess so. Although that does sound like damming level of over-fitting the data, I suppose.\nPeter: Right. There was only a couple thousand data points. I forget exactly how many. Maybe it was 10,000. Maybe it was even 100,000, but it wasn’t many. (Norvig 2021)"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html",
    "href": "blog/posts/ai-creativity/index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#introduction",
    "href": "blog/posts/ai-creativity/index.html#introduction",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "href": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "title": "Yuxi on the Wired",
    "section": "The self-interest theory",
    "text": "The self-interest theory\nThe self-interest theory is as follows: “It is hard to get someone to understand something if something they care about depends on their not understanding it.”"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "href": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "title": "Yuxi on the Wired",
    "section": "The non-truth theory",
    "text": "The non-truth theory\nThe non-truth theory states that some arguments are forever mired in the same controversies, always rehashing the same arguments, because there is no truth to be found underneath the arguments.\nThere are certain social functions that are best served by saying something in language that looks like they talk about objective things. You can think of this as a hack in the programming language of humans. For example,\nThere are some social functions that"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems terrible that machines might create",
    "text": "Why it seems terrible that machines might create\nAt the “immortal dinner party” held by Benjamin Haydon on 28 December 1817, the Romantic poet John Keats agreed with Charles Lamb that Newton “had destroyed all the poetry of the rainbow, by reducing it to the prismatic colors”. Later, Keats wrote “Lamia” that included these famous lines:\nDo not all charms fly\nAt the mere touch of cold philosophy?\nThere was an awful rainbow once in heaven:\nWe know her woof, her texture; she is given\nIn the dull catalogue of common things.\nPhilosophy will clip an Angel's wings,\nConquer all mysteries by rule and line,\nEmpty the haunted air, and gnomed mine—\nUnweave a rainbow, as it erewhile made\nThe tender-person'd Lamia melt into a shade\nGPT4: Keats came up with the concept of “negative capability.” This is the ability to dwell in uncertainties, mysteries, doubts, without any compulsive reaching after fact and reason. Keats valued this ability, arguing that it was central to a poet’s creative process."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems incredible that machines might create",
    "text": "Why it seems incredible that machines might create\nHere, the arguments are easier to classify. It seems that there are several common mental models that people use when they think about machines that create. Using any of these would make it seem obvious that machines cannot be creative. So, I just need to classify the mental models!\n\nMachines as monkeys typing randomly\nIn Gulliver’s Travels (1726) by Jonathan Swift, there was a writing machine. It is a 16x16 matrix of little square blocks, with a character on each side. To use it, you turn the 32 handles randomly, then read out the few words that appeared by chance. This allowed:\n\nthe most ignorant person, at a reasonable charge, and with a little bodily labour, might write books in philosophy, poetry, politics, laws, mathematics, and theology, without the least assistance from genius or study.\n\nIt is a clear satire, possibly of Ramon Llull’ s Thinking Machine (3 concentric rotating disks that generate all possible theological arguments):\n\nThe first of these features means that all of these attributes are inherent; the second, that they are systematically interrelated in such a way as to affirm, with impeccable orthodoxy, that glory is eternal or that eternity is glorious; that power is true, glorious, good, great, eternal, powerful, wise, free, and virtuous, or benevolently great, greatly eternal, eternally powerful, powerfully wise, wisely free, freely virtuous, virtuously truthful, etc., etc.\n\n\n\nMachines as pipes for the water of creativity\n\nIt appears to me that if one wants to make progress in mathematics one should study the masters and not the pupils.\n\n— N.H. Abel (1802–1829), quoted from an unpublished source by O. Ore in Niels Henrik Abel, Mathematician Extraordinary, p. 138.\nThere is a common attitude that I can summarize as this: Like drawing water from the unsullied source at the mountain’s peak, so is the experience of returning to the writings of the masters: clear, refreshing, and devoid of later impurities.\n\nAncient Greek theory of creativity\nIn ancient Greece, the Muses were considered the source of the knowledge embodied in the poetry, lyric songs, and myths that were related orally for centuries in ancient Greek culture. Homer began his Iliad with:\n\nSing, Muse, the fatal wrath of Peleus’ son,\nWhich to the Greeks unnumb’red evils brought,\n\nNote that the Muses was doing the real singing, and Homer was a channel for their singing (back then, poetry was sang – the Iliad was written down only after a few centuries). In Plato’s dialog Ion, Socrates (perhaps a sockpuppet of Plato) argued that “it is not by art that poets compose… but by divine apportionment”:\n\nFor the poets tell us that they carry honey to us from every quarter like bees, and they fly as bees do, sipping from honey-flowing fountains in glens and gardens of the Muses. And they tell the truth. For a poet is a delicate thing, winged and sacred, and unable to create until he becomes inspired and frenzied, his mind no longer in him; as long as he keeps his hold on that, no man can compose or chant prophecy. Since, then, it is not by art that poets compose and say many beautiful things about their subjects, as you do about Homer, but by divine apportionment, they each can do well only that to which the Muse directs them-this one dithyrambs, that one odes, or encomia, or dances, or epics, or iambics-each of them worthless in respect to the others.\n\nThe same point was made repeatedly in Plato’s corpus.\n\nJust as the rhapsode says what he says about Homer not by art but by divine apportionment, without intelligence (Ion 534b-c, 536c, 542a), so in the Meno (gge-looa) politicians get their virtue by divine apportionment, without intelligence; they have no more wisdom than seers and soothsayers, who say many fine things but know nothing of what they say; politicians are divine and inspired like poets, and possessed by the god (Meno 9gb-e). The irrational effects of poetry and rhapsody are directly comparable to the irrational effect of vulgar politics, whose servant is vulgar rhetoric (cf. Gorgias 502C).\n\nBoth quotes came from The Dialogues of Plato, Volume 3: Ion, Hippias Minor, Laches, Protagoras, translated by R. Allen. (I decided not to use one of the freely available versions since they tended to mistranslate “gods” as “God”.)\nFor example, in Phaedrus 245a, Socrates claimed that “the poetry of the sane man vanishes into nothingness before that of the inspired madmen”:\n\nAnd a third kind of possession and madness comes from the Muses. This takes hold upon a gentle and pure soul, arouses it and inspires it to songs and other poetry, and thus by adorning countless deeds of the ancients educates later generations. But he who without the divine madness comes to the doors of the Muses, confident that he will be a good poet by art, meets with no success, and the poetry of the sane man vanishes into nothingness before that of the inspired madmen.\n\n\n\nLater manifestations\nIsaac Newton thought he was merely recovering what the ancients have known all along. His friend William Stukeley described Newton as “the Great Restorer of True Philosophy”.\n\n\nApplication to machine creativity\n\n\n\nMachines as flowers for the DNA of creativity\nFrom Lovelace’s “Notes by the Translator”:\n\nThe Analytical Engine has no pretensions whatever to originate any thing. It can do whatever we know how to order it to perform. (source)\n\nIn his seminal paper “Computing machinery and intelligence” (1950), Alan Turing referenced Lovelace’s observation as the sixth objection to the possibility that machines might think. He then objected:\n\nThe view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. It is a very useful assumption under many circumstances, but one too easily forgets that it is false. (source).\n\nTuring was led to Lovelace’s objection by debates with Douglas Hartree, who in his book “Calculating Instruments and Machines” (page 70, 1949), quoted Lovelace approvingly. He objected using the phrase “electronic brain” for devices like electronic calculating machines or automatic pilots. He clarified that these machines cannot “think for themselves” and can only execute the instructions provided to them.\nThus, machines, in this view, are akin to flowers—organisms that reproduce and grow according to a predetermined genetic code but do not originate new genetic information on their own. Creativity, like DNA, must be instilled by a designer or operator, who programs the machine with the “genetic code” of what to create.\nAs a short etymological fun fact, the word “development” is a little capsule of the “flower for the DNA” idea:\n\nFirst use 1756, from French développement (“unrolling”). Compare with envelopment (“rolling”).\n\nThe idea is that of “opening up a scroll and showing what has always been written there. In the machines’ creative process can be seen as a similar”unrolling” of predetermined instructions or codes, much like the genetic “unrolling” in a blooming flower.\nThis is most explicitly manifest in the idea of preformationism, prevalent around 17th to 18th century. It seems the same intuitive appeals of preformationism apply to Lovelace’s objection.\n(A brief personal anecdote: When I was a kid, I thought bus cards contained tiny compressed coins inside, and when you “beep” them, those tiny coins fall into the machine through tiny openings on the card. Preformationism in economics!)"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "",
    "text": "The essay is written at the level of two years of undergraduate mathematics. I will keep jargons to a minimum and use as few infinities as possible. For example, instead of particles that can be anywhere on a real-number line, I would talk about particles that can be in one of three boxes."
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Many-world theory",
    "text": "Many-world theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Pilot wave theory",
    "text": "Pilot wave theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Copenhagen interpretation",
    "text": "Copenhagen interpretation"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Relational quantum mechanics",
    "text": "Relational quantum mechanics"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "QBism",
    "text": "QBism"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html",
    "href": "blog/posts/perplexity-turing-test/index.html",
    "title": "When will AI pass the Turing Test?",
    "section": "",
    "text": "Alternative title: How much would it cost to train the first AI scientist?"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#turing-test-as-statistical-hypothesis-testing",
    "href": "blog/posts/perplexity-turing-test/index.html#turing-test-as-statistical-hypothesis-testing",
    "title": "When will AI pass the Turing Test?",
    "section": "Turing test as statistical hypothesis testing",
    "text": "Turing test as statistical hypothesis testing\n\nSequential hypothesis test\nWe need the following equality:\n\\[\\frac 1n E_{X \\sim P(\\cdot | H_0)}\\left[ \\ln\\frac{P(X_{1:n}|H_0)}{P(X_{1:n}|H_1)}\\right] = \\frac 1n\nE_{X \\sim P(\\cdot | H_0)}\\left[ \\ln\\frac{1}{P(X_{1:n}|H_1)}\\right] - \\frac 1n  E_{X \\sim P(\\cdot | H_0)}\\left[ \\frac{1}{\\ln P(X_{1:n}|H_0)}\\right]\\]\nExplain what each of the three terms of the equality mean. Suppose the machine is a perfect replica of the human, what would each term be?\n\\[\\underbrace{\\frac 1n E_{X \\sim P(\\cdot | H_0)}\\left[ \\ln\\frac{P(X_{1:n}|H_0)}{P(X_{1:n}|H_1)}\\right]}_{\\frac 1n D_{KL}(P(\\cdot | H_0)\\| P(\\cdot | H_1)) } = \\underbrace{\\frac 1n\nE_{X \\sim P(\\cdot | H_0)}\\left[ \\ln\\frac{1}{P(X_{1:n}|H_1)}\\right]}_{\\text{negative log-likelihood loss per token}} - \\underbrace{\\frac 1n  E_{X \\sim P(\\cdot | H_0)}\\left[ \\frac{1}{\\ln P(X_{1:n}|H_0)}\\right]}_{\\text{entropy rate of the human itself}}\\]\nThe first term is the KL-divergence between the machine and the human, as two sources of symbolic strings, averaged over sequence length. Roughly speaking, it is how different they are, per symbol emitted. It is an information-theoretic quantity.\nThe second term is negative log-likelihood loss per token. This is what the language model is trained to minimize.\nThe third term is the entropy rate of the human. It is how random the human is, as a source of symbols.\nIf the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.\n\\[T^* \\approx \\frac{\\ln 10}{L - L_\\infty}\\]\nHere, each token on average moves the log-probability-ratio away from 0 by another \\((L-L_\\infty)\\). Decision is triggered when it finally moves out of the interval \\([-\\ln 10, \\ln 10]\\).\nWe are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you’d see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.}\n\n\nSlowdown factor\nHumans are not perfect judges. However, as a crude approximation, we can model them as a slowed-down version of the perfect judge. Specifically, if it takes about \\(T\\) tokens for the perfect judge to reach a likelihood ratio of \\(r\\), it would take about \\(sT\\) tokens for a human judge. Here, \\(s\\) is a number larger than one.\nWe do not have good data on what \\(s\\) is, or whether it is even consistently measurable. However, for our current question, let’s assume \\(s=10\\).\nWhat should the language model’s \\(L-L_\\infty\\) be, before it can pass the Turing test against a human judge for 1000 tokens?\n\\[10 \\times \\ln 10 / 1000 = 0.023\\]\nHow do we estimate the slowdown factor?\n(Jannai et al. 2023)\n\n\nEntropy of natural languages\nWe found that \\(L_\\infty\\) should be interpreted as the intrinsic entropy of the source material. In this case, it is the entropy of natural English. Now, the intrinsic entropy of English is not very easy to estimate, but there had been several attempts.\nThe earliest attempt is by Shannon himself, in 1951. He estimated that the entropy of English is about 0.6 – 1.3 bits per character. Now, we cannot use this number directly, because it is not in the right units – loglikelihood loss is in units of nat/token.\nThe conversion between nat and bit is known exactly: \\(1 \\;\\mathrm{nat} = \\ln(2)\\;\\mathrm{nat}= 0.693\\;\\mathrm{nat}\\). The conversion between character and token can be estimated by running a tokenizer over a large natural English corpus. I have estimated this by running the GPT-2 tokenizer on WikiText2 corpus, and found that on average, 0.22 tokens/character, 1.17 tokens/word.\nWhat is Shannon’s estimated entropy of English, in units of nat/token?\n\\[\\ln 2 \\times [0.6, 1.3] / 0.22 = [1.89, 4.09]\\;\\mathrm{nat/token}\\]\nAnother way to estimate is by attempting to compress a large natural English corpus. It is known in basic information theory that the entropy rate is the lower bound on compression rate. In more detail, if you have a source of information emitting symbols, and its symbol stream has an entropy rate of \\(x \\;\\mathrm{bit/symbol}\\), then it takes \\(xl\\) bits to encode a long segment \\(l\\) symbols long.\nThe Hutter prize is a competition for compressing a \\(10^9\\)-byte segment of the English Wikipedia as much as possible. The competition has been ongoing since 2005.\nThe zipped file is only about 300 Mb in size, meaning that the total entropy in the corpus is no more than \\(3\\times 10^8\\) bytes.\nOver the years, the progress has been slow but somewhat steady. If we extrapolate the prize-winning entries over the years, we see that the best possible compression ratio seems to be about 10x.\nI ran the GPT-2 tokenizer through 1/100 of the dataset, and got 2.96 million tokens. So the entire dataset should have about 300 million tokens. Assuming this, what is the entropy of English, in units of nat/token?\nIf we assume the maximal compression ratio of 10x, then the corpus contains entropy\n\\[10^8\\;\\mathrm{byte} = 8\\times 10^8 \\;\\mathrm{bit} = 5.55\\times 10^8 \\;\\mathrm{nat}\\]\n\\[\\frac{5.55\\times 10^8}{3\\times 10^8}= 1.85 \\;\\mathrm{nat/token}\\]\nAnd the third way is to look at what the scaling laws for the largest language models imply what \\(L_\\infty\\) is. According to page 25 of “Training Compute-Optimal Large Language Models” (2022) (hereafter “Chinchilla scaling law”), \\(L_\\infty = 1.69\\;\\mathrm{nat/token}\\).\nThe estimate by compression and language modelling are remarkably close.\nShannon’s estimate of entropy is above the other two estimates by about 2x. Considering that he measured this by asking volunteers to just look at a small passage of text and keep guessing the next character, we can consider his estimate a noisy estimate biased to be too high (since the volunteers would not be able to extract the very last predictabilities of English by only looking at a small preceding passage).\nCompute scaling law\nThe “Chinchilla scaling law” paper reported a series of training runs on language models, trained by Google DeepMind researchers. According to them, if we have a fixed amount of computing budget \\(C\\) (in units of FLOP), by choosing the model and dataset size correctly, the minimal reducible loss achievable is\n\\[L - L_\\infty = \\frac{1070}{C^{0.154}}\\]\nAssuming slowdown factor \\(s=10\\), and Chinchilla scaling law, then, we have a direct method to predict how long a language model can pass a Turing test, according to how many FLOPs it cost to compute:\n\\[T^* \\sim \\frac{10\\ln 10}{1070}C^{0.154}\\]\nThis gives, as a rule of thumb, 100x compute means 2x length of Turing test.\nIf GPT-4 costs 2e25 FLOP in compute, for how many words can it pass the Turing test? Assume 1 word is 1.2 tokens, as described previously.\n\\[T^* \\approx 170 \\text{ tokens} \\approx 150 \\text{ words}\\] meaning it has a good chance of passing the Turing test if limited to only 150 words. For context, the Attention is All You Need paper has an abstract that’s 200 tokens long.\nA typical scientific paper is about 4000 words long. How much training compute would it cost, in units of of GPT-4? Assuming GPT-4 cost 10 million USD to train, how much money would this model cost to train?\n4000 words is 27x more than 150 words, so it would need \\(27^{1/0.153} = 2e9\\) amount of compute. Assuming 1 GPT-4 cost 10 million USD, that would cost 2e16 USD, or 200 years of global GDP (2023).\nSo it seems like it would take a very long time to train the first AI scientist by just scaling up the GPT-like models. We need more than pure language modelling.\nI leave you with the inspirational quote from Edward “the Bomb” Teller:\n\nThe possibilities of developing an atomic weapon and the desirability of doing it secretly were discussed at a Princeton University conference in which I participated in March 1939… Bohr said this rare variety could not be separated from common uranium except by turning the country into a gigantic factory. Bohr was worried that this could be done and that an atomic bomb could be developed—but he hoped that neither could be accomplished. Years later, when Bohr came to Los Alamos, I was prepared to say, “You see…” But before I could open my mouth, he said: “You see, I told you it couldn’t be done without turning the whole country into a factory. You have done just that.” (Teller and Brown 1975)"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#sequential-hypothesis-test",
    "href": "blog/posts/perplexity-turing-test/index.html#sequential-hypothesis-test",
    "title": "When will AI pass the Turing Test?",
    "section": "Sequential hypothesis test",
    "text": "Sequential hypothesis test\nWe need the following equality:\n\\[\\frac 1n \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\right] = \\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right] - \\frac 1n  \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[ \\frac{1}{\\ln Pr(X_{1:n}|H_0)}\\right]\\]\nExplain what each of the three terms of the equality mean. Suppose the machine is a perfect replica of the human, what would each term be?\n\\[\\underbrace{\\frac 1n E_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\right]}_{\\frac 1n D_{KL}(Pr(\\cdot | H_0)\\| Pr(\\cdot | H_1)) } = \\underbrace{\\frac 1n\nE_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right]}_{\\text{negative log-likelihood loss per token}} - \\underbrace{\\frac 1n  E_{X \\sim Pr(\\cdot | H_0)}\\left[ \\frac{1}{\\ln Pr(X_{1:n}|H_0)}\\right]}_{\\text{entropy rate of the human itself}}\\]\nThe first term is the KL-divergence between the machine and the human, as two sources of symbolic strings, averaged over sequence length. Roughly speaking, it is how different they are, per symbol emitted. It is an information-theoretic quantity.\nThe second term is negative log-likelihood loss per token. This is what the language model is trained to minimize.\nThe third term is the entropy rate of the human. It is how random the human is, as a source of symbols.\nIf the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.\n\\[T^* \\approx \\frac{\\ln 10}{L - L_\\infty}\\]\nHere, each token on average moves the log-probability-ratio away from 0 by another \\((L-L_\\infty)\\). Decision is triggered when it finally moves out of the interval \\([-\\ln 10, \\ln 10]\\).\nWe are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you’d see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.}\n\nSlowdown factor\nHumans are not perfect judges. However, as a crude approximation, we can model them as a slowed-down version of the perfect judge. Specifically, if it takes about \\(T\\) tokens for the perfect judge to reach a likelihood ratio of \\(r\\), it would take about \\(sT\\) tokens for a human judge. Here, \\(s\\) is a number larger than one.\nWe do not have good data on what \\(s\\) is, or whether it is even consistently measurable. However, for our current question, let’s assume \\(s=10\\).\nWhat should the language model’s \\(L-L_\\infty\\) be, before it can pass the Turing test against a human judge for 1000 tokens?\n\\[10 \\times \\ln 10 / 1000 = 0.023\\]\nHow do we estimate the slowdown factor?\n(Jannai et al. 2023)"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#entropy-of-natural-languages",
    "href": "blog/posts/perplexity-turing-test/index.html#entropy-of-natural-languages",
    "title": "When will AI pass the Turing Test?",
    "section": "Entropy of natural languages",
    "text": "Entropy of natural languages\nIn Equation 1, we argued that \\(L_\\infty\\) should be interpreted as the entropy rate of the source, usually human-generated English. Unfortunately, unlike that of coin flips or Markov chains, the entropy rate of English cannot be calculated, only estimated. Fortunately, it can be estimated in several ways, and we can check their agreement.\nSince tokenizers are temporary, but English is permanent, we convert all units to \\(\\;\\rm{bit/character}\\) for easy comparison.\n\nChinchilla scaling\nIn the Chinchilla scaling law paper, the authors trained many language models with various sizes from a single architecture family, and fitted a statistical law to the data, giving \\(L_\\infty = 1.69 \\;\\rm{ nat/token}\\) (without error bars, unfortunately) (Hoffmann et al. 2022, 25).\nTo find the effective \\(\\;\\rm{bit/character}\\) for the Chinchilla scaling law, we need to convert \\(\\rm{nat}\\) to \\(\\rm{bit}\\), and \\(\\rm{token}\\) to \\(\\rm{character}\\). The first is easy: \\(1 \\;\\mathrm{bit} = \\ln(2)\\;\\mathrm{nat}\\). The second can be estimated by running a tokenizer over a large natural English corpus. I have estimated this by running the GPT-2 tokenizer on the WikiText-2 corpus, and found that on average,\n\\[\n1 \\;\\rm{token} = 4.5 \\;\\rm{character} = 0.85 \\;\\rm{word}\n\\]\nThus, \\(L_\\infty \\approx \\frac{1.69}{4.5\\times \\ln 2} = 0.54 \\;\\rm{bit/character}\\).\n\n\nGuessing game\nThe earliest attempt to measure the entropy rate of English is by Shannon himself (Shannon 1951): \\([0.6, 1.3] \\;\\rm{bit/character}\\). He obtained the estimate by presenting human subjects \\(n-1\\) characters from a text, and ask them to guess the next character repeatedly, until they got it right. In this case, the optimal strategy is to construct the \\(n\\)-gram table, and pick the argmax character for the given \\((n-1)\\)-gram, then the arg-next-max, and so on.\nLet \\(N\\) be the total number of characters allowed – Shannon’s experiment used \\(N = 27\\), with 26 lowercase letters and one white space. Let \\(p_k\\) be the frequency that the subject makes exactly \\(k\\) guesses – including the correct guess, so that \\(\\sum_{k=1}^N p_k = 1\\). By convention, \\(p_{N+1} := 0\\). Shannon derived both an upper and a lower bound for the entropy per character:\n\\[\n\\sum_{k=1}^N k(p_k - p_{k+1}) \\ln k \\leq H \\leq - \\sum_{k=1}^N p_k \\ln p_k\n\\]\nThe upper bound is proved by Shannon’s source coding theorem. Taking a human subject, copy it, then they can be used as an encoder-decoder pair.4 The lower bound is not only tricky to prove, but also wrong in general. It is only correct when the human subject is the optimal \\(N\\)-gram predictor.5 Because of this, I do not recommend using this lower bound, but will quote it anyway.4 It still works even if the humans are pseudorandom. We just have to whisper the same RNG seed into both humans’ ears, and then they would behave in the same pseudorandom way.5 The simplest counterexample: Suppose the source is binary, and satisfies \\(X_{n+1} = X_{n} + 1 \\mod 2\\), so it has zero entropy. Nevertheless, the human intentionally guesses wrong the first time. Therefore, we have \\(p_2 = 1\\), and we have violated the lower bound by \\(2\\ln 2 &gt; 0\\).\nThis source can be made ergodic by adding an \\(\\epsilon\\) amount of coin-flip noise: \\(X_{n+1} = X_{n} + 1 \\mod 2\\) with probability \\(1-\\epsilon\\). This would still give us \\(2\\ln 2 + O(\\epsilon) &gt; O(\\epsilon \\ln \\epsilon)\\).\nOver the years, others devised other methods to estimate this entropy. For example, (Cover and King 1978) used a gambling game estimation, in the style of the Kelly criterion. Subjects were required to divide their entire bankroll into 27 differently-sized bets over 27 possibilities (26 letters and 1 whitespace). The right bet pays back 27-fold, and the other bets are lost. Let \\(S_n\\) be the size of bankroll after \\(n\\) rounds of betting, then\n\\[\nH \\leq \\ln 27 - \\limsup_n \\frac 1n \\ln S_n\n\\]\nThey found that \\(H \\leq 1.3 \\;\\rm{bit/character}\\).\nThe guesser does not have to be a human. It can very well be a language model. (Brown et al. 1992) made a simple trigram model over the Brown corpus (600 million words), and found that it gives \\(H \\leq 1.75 \\;\\rm{bit/character}\\). (Behr Jr et al. 2002) used a model that combines multiple n-gram models, giving \\(H \\leq 1.46 \\;\\rm{bit/character}\\).\n\n\nLossless compression\nAnother way to estimate is by lossless compression of a large corpus, since the entropy rate is the lower bound on compression rate. In more detail, if you have a source of information emitting symbols, and its symbol stream has an entropy rate of \\(x \\;\\mathrm{bit/symbol}\\), then it takes at least \\(\\sim xl\\) bits to encode a long segment with \\(l\\) symbols. Furthermore, this lower bound is approachable using the entropy encoding.\nThe Hutter prize is a competition for compressing a \\(10^9\\)-byte corpus from the English Wikipedia (enwik9). For the size of the finished product, both the algorithm and the compressed data must be counted. In particular, if a neural network is used, then the size of the neural network weights must be counted as well.\nThe enwik9 dataset is in XML format, and thus contains a lot of non-English content like &lt;timestamp&gt;2005-12-27T18:46:47Z&lt;/timestamp&gt;. It has \\(10^9\\) bytes. It is tricky to decide how to clean it up to remove all the XML formatting. As a simple estimate, we counted its words and characters directly with Linux command wc without any preprocessing, which gives us\n\\[\n13,147,025 \\text{ words} =  129,347,857 \\text{ characters} = 1,000,000,000 \\text{ bytes}\n\\]\nTherefore, the entropy rate is\n\\[\n\\frac{8\\times 10^8 / 13,147,025}{\\text{compression ratio}} = \\frac{6.15}{\\text{compression ratio}}\\;\\rm{bit/character}\n\\tag{2}\\]\nThe standard zip algorithm can compress it down to about 300 Mb in size, a compression ratio of \\(\\sim 3\\times\\). Over the years, the progress has been slow but somewhat steady. The current winning entry (Saurabh Kumar, 2023) has a compression ratio of \\(8.76\\times\\). If we extrapolate the prize-winning entries over the years, it seems that the best possible compression ratio is \\(\\sim 10\\times\\).\nSimilar to the Hutter prize, the Large Text Compression Benchmark also asks for compressing the enwik9 dataset. However, there is no limit to the algorithm runtime or size, so the compression ratio for this benchmark is always higher. Currently (2024-01-19), the maximal compression rate reached is \\(9.35\\times\\) with nncp v3.2, which uses a small Transformer model.\n(Grassberger 2002) used a substitutional compression algorithm with increasingly large codebooks. When the codebook had 6000 codes, the algorithm gave \\(h \\leq 1.82 \\;\\rm{bit/character}\\). By extrapolating the {codebook size}-{entropy rate} curve to an infinitely large codebook, they estimated that English has entropy rate \\(0.7 \\pm 0.2 \\;\\rm{bit/character}\\).\n\n\nSummary\n\n\n\nestimate\nmethod\nraw number\neffective entropy rate (bit/char)\n\n\n\n\n(Grassberger 2002)\ncompression, extrapolation\n\\(0.7 \\pm 0.2 \\;\\rm{bit/character}\\)\n\\(\\sim[0.5, 0.9]\\)\n\n\nHutter prize (Saurabh Kumar, 2023)\ncompression\ncompression ratio \\(\\geq 8.76\\)\n\\(\\leq 0.70\\)\n\n\nHutter prize extrapolated\ncompression, extrapolation\ncompression ratio \\(\\sim 10\\)\n\\(\\sim 0.62\\)\n\n\nLarge Text Compression Benchmark (nncp v3.2, 2023)\ncompression\ncompression ratio \\(\\geq 9.35\\)\n\\(\\leq 0.66\\)\n\n\n(Shannon 1951)\nguessing game\n\\(\\in [0.6, 1.3] \\;\\rm{bit/character}\\)\n\\(\\in [0.6, 1.3]\\)\n\n\n(Cover and King 1978)\nguessing game\n\\(\\leq 1.3 \\;\\rm{bit/character}\\)\n\\(\\leq 1.3\\)\n\n\n(Brown et al. 1992)\n3-gram language model\n\\(\\leq 1.75 \\;\\rm{bit/character}\\)\n\\(\\leq 1.75\\)\n\n\n(Behr Jr et al. 2002)\nn-gram language model\n\\(\\leq 1.46 \\;\\rm{bit/character}\\)\n\\(\\leq 1.46\\)\n\n\n(Hoffmann et al. 2022)\nTransformer language model, extrapolation\n\\(L_\\infty = 1.69 \\;\\rm{nat/token}\\)\n\\(\\sim 0.54\\)\n\n\n\nNotably, the above table has mostly upper bounds, and only one dubious lower bound (by Shannon) from 1951. Perhaps lower bounds can be established by using randomness extractors on a large corpus, and checking that the output from the extractor passes pseudorandomness tests."
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#compute-scaling",
    "href": "blog/posts/perplexity-turing-test/index.html#compute-scaling",
    "title": "When will AI pass the Turing Test?",
    "section": "Compute scaling",
    "text": "Compute scaling\nThe “Chinchilla scaling law” paper reported a series of training runs on language models, trained by Google DeepMind researchers. According to them, if we have a fixed amount of computing budget \\(C\\) (in units of FLOP), by choosing the model and dataset size correctly, the minimal reducible loss achievable is\n\\[L - L_\\infty = \\frac{1070}{C^{0.154}}\\]"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#forecasting-agi",
    "href": "blog/posts/perplexity-turing-test/index.html#forecasting-agi",
    "title": "When will AI pass the Turing Test?",
    "section": "Forecasting AGI",
    "text": "Forecasting AGI\nAccording to the Chinchilla scaling law (Hoffmann et al. 2022), if we have a fixed amount of computing budget \\(C\\), by choosing the model and dataset size correctly, the minimal reducible loss achievable is\n\\[\nL - L_\\infty = \\frac{1070}{(C/\\;\\rm{FLOP})^{0.154}} \\;\\rm{nat/token}\n\\tag{3}\\]\nAssuming a slowdown factor \\(s\\), that the judge decides when the odds ratio is \\(r:1\\), and the Chinchilla scaling law, we have a direct method to predict how long a language model can survive in a Turing test, according to the cost of training compute \\(C\\):\n\\[T^* \\sim \\frac{s\\ln r}{1070}(C/\\;\\rm{FLOP})^{0.154} \\;\\rm{token}\\]\nThis gives, as a rule of thumb, \\(100\\times\\) compute means \\(2 \\times\\) length of survival in a Turing test.\nFor example, assuming a slowdown factor of \\(s=10\\), and that the judge decides when the odds ratio is \\(10:1\\), for a language model to survive for 1000 tokens, it needs\n\\[L - L_\\infty \\leq 10 \\times \\ln 10 / 1000 = 0.023 \\;\\rm{nat/token}\\]\nIf GPT-4 costs \\(2\\times 10^{25} \\;\\rm{FLOP}\\) in compute, and \\(1 \\;\\rm{word} \\approx 1.2 \\;\\rm{token}\\), then\n\\[T^* \\approx 170 \\text{ tokens} \\approx 150 \\text{ words}\\]\nmeaning it has a good chance of passing the Turing test if limited to only 150 words. For context, the Attention is All You Need paper has an abstract that’s 200 tokens long.\nA typical scientific paper is about 4000 words long, which is \\(27\\times\\) that of 150 words, so it would need \\(27^{1/0.153} = (2\\times 10^9)\\times\\) that of compute. Assuming that GPT-4 cost 10 million USD to train, this hypothetical AI would cost \\(2\\times 10^{16}\\) USD, or 200 years of global GDP2023.\nThis implies that the first AGI will not be a scaled-up GPT – autoregressive transformer generatively pretrained on a lightly filtered text dataset. It has to include something else, perhaps multimodal data, high-quality data, better architecture, etc. Even if we were to attempt to merely scale it up, turning earth into a GPT-factory,6 with even 50% of global GDP devoted,7 and with 2% growth rate forever, it would still take 110 years,8 arriving at year 2133. Whole brain emulation would likely take less time.96 Consider this anecdote from Edward Teller:\n\nThe possibilities of developing an atomic weapon and the desirability of doing it secretly were discussed at a Princeton University conference in which I participated in March 1939… Bohr said this rare variety could not be separated from common uranium except by turning the country into a gigantic factory. Bohr was worried that this could be done and that an atomic bomb could be developed–but he hoped that neither could be accomplished. Years later, when Bohr came to Los Alamos, I was prepared to say, “You see…” But before I could open my mouth, he said: “You see, I told you it couldn’t be done without turning the whole country into a factory. You have done just that.” (Teller and Brown 1975)\n\n7 Only in a life-or-death situation does 50% of GDP get devoted to one purpose. For example, that is about the level of GDP devoted to war production during WWII in the major combatant countries. The USA spent 4 trillion USD2011 over 6 years out of an annual GDP of 1.3 trillion USD2011.8 Solve for \\(x\\) in \\(200 = \\sum_{k=0}^x 0.5 \\times 1.02^k\\).9"
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#generating-and-measuring-data-manifold-dimensions",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#generating-and-measuring-data-manifold-dimensions",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Generating and measuring data manifold dimensions",
    "text": "Generating and measuring data manifold dimensions\nConsider the space of all MNIST images. Each MNIST image is a 28x28 grayscale, so the total space is \\(\\mathbb R^{28\\times 28} = \\mathbb R^{784}\\).\nHowever, as you may have seen in experiments with the VAE, most of the MNIST dataset “collapses” onto a much smaller subset of \\(\\mathbb R^{784}\\). This is the “(intrinsic) data manifold”, with a dimension much smaller than \\(784\\). Indeed, the very fact that the intrinsic dimension is small allows us to have meaningful “2D slices” of the dataset:\n\n\n\nFigure from Convolutional Variational Autoencoder - Tensorflow Core Tutorials. More images can be found in Visualizing the Variational Autoencoder, and can be regenerated in about 10 minutes with a Google Colab GPU.\n\n\nReal data can be expensive, though, which is why we often use “toy” datasets with known dimensions, generated by a known random process. For example, the following is the “Swiss roll” dataset. It is generated by first populating a 2D square \\([0, 1]^2\\), then use a function \\(f: \\mathbb R^2 \\to \\mathbb R^3\\) to “roll up” the square into 3D space.\n\n\n\nThe Isomap algorithm (Tenenbaum, Silva, and Langford 2000), popular for constructing data manifolds. Figure from Wikipedia."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#generating-data-manifold-by-random-neural-networks",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#generating-data-manifold-by-random-neural-networks",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Generating data manifold by random neural networks",
    "text": "Generating data manifold by random neural networks\nConsider the simplest data manifold: \\(\\mathbb R^d\\), affinely transformed, then embedded in \\(\\mathbb R^n\\), with \\(n &gt; d\\).\nTo synthesize such a data manifold, we randomly initialize a teacher network, so-called because it implements the function that a student network will fit to by supervised training. Each teacher network is constructed thus:\n\nThe number of neurons in each layer are: \\([d, 9, 600, 600, 1]\\)\nIt has 0 bias.\nThe weights between layers are sampeled from \\(\\mathcal N(0, m^{-1/2})\\) , where \\(m\\) is the input size of the layer (a form of He initialization).\nThe activation function at the second (with 9 neurons) and last layers are identity. All other activation functions are ReLU.\n\nOnce we have constructed a teacher network, we use it to generate a dataset \\(\\{(x_i, y_i)\\}_i\\) thus:\n\nGenerate random gaussian vectors \\(\\{t_i\\}_i\\) in \\(\\mathbb R^d\\), with mean \\(0\\) and std \\(I_{d\\times d}\\).\nFor each \\(t \\in \\{t_i\\}_i\\), push \\(t\\) through the teacher network.\nLet \\(x \\in \\mathbb R^9\\) be the teacher network activation at the second layer, with 9 neurons.\nLet \\(y \\in \\mathbb R\\) be the teacher network output."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#learning-data-manifold-by-neural-networks",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#learning-data-manifold-by-neural-networks",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Learning data manifold by neural networks",
    "text": "Learning data manifold by neural networks\nAccording to the theory, if the data manifold has dimension \\(d\\), then as we scale up a neural network with \\(N\\) parameters, the MSE loss of a fully-trained network would scale like \\(L \\sim N^{-\\alpha}\\), where \\(\\alpha \\approx 4/d\\).\nLet’s test this.\nFirst, we define the “student” neural network architecture:\n\nThe number of neurons in each layer are: \\([9, n, n, 1]\\).\nThe biases are initialized to 0.\nThe weights between layers are sampeled from \\(\\mathcal N(0, m^{-1/2})\\), where \\(m\\) is the input size of the layer (a form of He initialization).\nAll activation functions are ReLU.\n\nA simple computation shows that the network has exactly \\(N = n^2+12n + 1\\) parameters11 \\(N = \\underbrace{(n+n+1)}_{\\text{first layer}} + \\underbrace{(9n + n^2 + n)}_{\\text{second layer}}\\)\n\n\n\nAn example teacher network architecture with \\([9, 5, 5, 1]\\) neurons."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#the-manifold-hypothesis",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#the-manifold-hypothesis",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "The manifold hypothesis",
    "text": "The manifold hypothesis\nConsider the space of all MNIST images. Each MNIST image is a 28x28 grayscale, so the total space is \\(\\mathbb R^{28\\times 28} = \\mathbb R^{784}\\).\nHowever, as you may have seen in experiments with the VAE, most of the MNIST dataset “collapses” onto a much smaller subset of \\(\\mathbb R^{784}\\). This is the “(intrinsic) data manifold”, with a dimension much smaller than \\(784\\). Indeed, the very fact that the intrinsic dimension is small allows us to have meaningful “2D slices” of the dataset:\n\n\n\nFigure from Convolutional Variational Autoencoder - Tensorflow Core Tutorials. More images can be found in Visualizing the Variational Autoencoder, and can be regenerated in about 10 minutes with a Google Colab GPU.\n\n\nReal data can be expensive, though, which is why we often use “toy” datasets with known dimensions, generated by a known random process. For example, the following is the “Swiss roll” dataset. It is generated by first populating a 2D square \\([0, 1]^2\\), then use a function \\(f: \\mathbb R^2 \\to \\mathbb R^3\\) to “roll up” the square into 3D space.\n\n\n\nThe Isomap algorithm (Tenenbaum, Silva, and Langford 2000), popular for constructing data manifolds. Figure from Wikipedia."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#synthetic-data-manifolds",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#synthetic-data-manifolds",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Synthetic data manifolds",
    "text": "Synthetic data manifolds\nConsider the simplest data manifold: \\(\\mathbb R^d\\), affinely transformed, then embedded in \\(\\mathbb R^n\\), with \\(n &gt; d\\).\nTo synthesize such a data manifold, we randomly initialize a teacher network, so-called because it implements the function that a student network will fit to by supervised training. Each teacher network is constructed thus:\n\nThe number of neurons in each layer are: \\([d, 9, 600, 600, 1]\\)\nIt has 0 bias.\nThe weights between layers are sampeled from \\(\\mathcal N(0, m^{-1/2})\\) , where \\(m\\) is the input size of the layer (a form of He initialization).\nThe activation function at the second (with 9 neurons) and last layers are identity. All other activation functions are ReLU.\n\nOnce we have constructed a teacher network, we use it to generate a dataset \\(\\{(x_i, y_i)\\}_i\\) thus:\n\nGenerate random gaussian vectors \\(\\{t_i\\}_i\\) in \\(\\mathbb R^d\\), with mean \\(0\\) and std \\(I_{d\\times d}\\).\nFor each \\(t \\in \\{t_i\\}_i\\), push \\(t\\) through the teacher network.\nLet \\(x \\in \\mathbb R^9\\) be the teacher network activation at the second layer, with 9 neurons.\nLet \\(y \\in \\mathbb R\\) be the teacher network output.\n\n\nSome proofs\nAssuming that we have Lipschitz continuity, we can make some proofs."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#experiments",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#experiments",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Experiments",
    "text": "Experiments\nAccording to the theory, if the data manifold has dimension \\(d\\), then as we scale up a neural network with \\(N\\) parameters, the MSE loss of a fully-trained network would scale like \\(L \\sim N^{-\\alpha}\\), where \\(\\alpha \\approx 4/d\\). We test this in two ways, once with synthetic datasets, where we know that the data manifold has the desired number of dimensions, and once with the CIFAR-10 dataset, where we do not have the dimension of the data manifold, and must estimate it.\nAll code for generating the dataset, and for analyzing the dataset, are in a GitHub repo: yuxi-liu-wired/scaling-law-by-data-manifold.\n\nSynthetic data manifolds\nSince Consider the simplest data manifold: \\(\\mathbb R^d\\), affine-transformed, then embedded in \\(\\mathbb R^n\\), with \\(n &gt; d\\).\nTo synthesize such a data manifold, we randomly initialize a teacher network, so-called because it implements the function that a student network will fit to by supervised training. Each teacher network is constructed thus:\n\nThe number of neurons in each layer are: \\([d, 9, 600, 600, 1]\\)\nIt has 0 bias.\nThe weights between layers are sampled from \\(\\mathcal N(0, m^{-1/2})\\) , where \\(m\\) is the input size of the layer (a form of He initialization).\nThe activation function at the second (with 9 neurons) and last layers are identity. All other activation functions are ReLU.\n\nOnce we have constructed a teacher network, we use it to generate a dataset \\(\\{(x_i, y_i)\\}_i\\) in this way:\n\nGenerate random gaussian vectors \\(\\{t_i\\}_i\\) in \\(\\mathbb R^d\\), with mean \\(0\\) and std \\(I_{d\\times d}\\).\nFor each \\(t \\in \\{t_i\\}_i\\), push \\(t\\) through the teacher network.\nLet \\(x \\in \\mathbb R^9\\) be the teacher network activation at the second layer, with 9 neurons.\nLet \\(y \\in \\mathbb R\\) be the teacher network output.\n\nFirst, we define the “student” neural network architecture:\n\nThe number of neurons in each layer are: \\([9, n, n, 1]\\).\nThe biases are initialized to 0.\nThe weights between layers are sampled from \\(\\mathcal N(0, m^{-1/2})\\), where \\(m\\) is the input size of the layer (a form of He initialization).\nAll activation functions are ReLU.\n\n\n\n\nAn example teacher network architecture with \\([9, 5, 5, 1]\\) neurons.\n\n\nThe parameter count is\n\\[\nN = \\underbrace{(n+n+1)}_{\\text{first layer}} + \\underbrace{(9n + n^2 + n)}_{\\text{second layer}}\n\\]\nWith these settings, I ran the experiment many times, for \\(N\\) ranging from \\(500\\) to \\(10000\\), and \\(d\\) from \\(2\\) to \\(18\\). The results do not look as clean as given in the paper, despite that I have tried my best to match the experimental design as specified in the paper.\n\n\n\nExperimental data for various synthetic dataset dimensions and student network sizes.\n\n\n\n\nCIFAR-10\nThe CIFAR-10 dataset is a popular benchmark, consisting of 32-by-32 RGB images in 10 different image classes, with 6,000 images per class. While the images live in a space of dimension \\(32^2 \\times 3 = 3072\\), (Sharma and Kaplan 2022) reports that the CIFAR-10 images lies in a data manifold with dimension of only around 16–18.\nTo fit the dataset, I trained a family of convolutional networks with 3 convolution layers and 2 fully connected layers on CIFAR-10. In order to run a controlled experiment, I varied as few parameters as possible, with the following designs:\n\nThe network architecture is fixed, and the network parameter count is changed by changing a single number: the number of channels in the convolutional layers.\nThe experiment is run with 20 different network sizes, from 5408 to 115114.\nEach training run lasts 50 epochs, with batch size 128.\nThe optimizer is AdamW with lr=5e-4.\n\nWith these settings, I generated all the data and logged them into TensorBoard log files, then cleaned them up for quantile regression. Plotting in log-log scale, with the x-axis being the model parameter count, and the y-axis being the cross-entropy loss, we would get a downward sloping line. Our hope is that the line should have a slope of close to \\(-4/d\\), where \\(d \\approx 17\\).\nThis is exactly what I have found. Not only is it true for cross-entropy loss, it is also true for classification accuracy (0-1 loss), except the slope is \\(+4/d\\).\n\n\n\nExperimental data for the train/validation splits of CIFAR-10, and with two different criteria: cross entropy loss and accuracy. We see that in all 4 cases, the scaling exponent is close to the theoretical prediction."
  },
  {
    "objectID": "blog/posts/mathematical-phenomenology/index.html",
    "href": "blog/posts/mathematical-phenomenology/index.html",
    "title": "What does it feel like to be a mathematical object?",
    "section": "",
    "text": "TODO: change the folder name, and title, etc.\nStructuralism"
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#ergodic-theory",
    "href": "blog/posts/perplexity-turing-test/index.html#ergodic-theory",
    "title": "When will AI pass the Turing Test?",
    "section": "Ergodic theory",
    "text": "Ergodic theory\nThis section is foundational, but the full complexity is not necessary. In the next section we will build the theory at two levels of generality, once with ergodic theory and once with just a working knowledge in probability theory.\n\nMeasure-theoretic POV\nI know, you know too, nobody really likes measure theory any more than pianists like practicing scales hundreds of times. Still, it is at the right level of abstraction for many theories, including probability.\nWe omit all mentions of “almost-everywhere”, “except on a set of measure zero”, and similar annoying phrases. As long as you never make a union of uncountable many subsets, you will not be hurt by this omission.\nA probability space is a measurable space with a measure of \\(1\\). We write it as \\((\\Omega, \\mathcal B, Pr)\\), where \\(\\mathcal B\\) is the sigma-algebra of measurable sets, and \\(Pr\\) is the probability measure. We also write \\(\\mu\\) for the measure.22 Pronounced “mu” – it is a pun because both “mu” and “measure” starts with “m”.\nWe consider a single measurable function \\(T : \\Omega \\to \\Omega\\), and call it the shift map.\nWe demand that \\(T\\) must preserve measure. That is, \\(\\forall S \\in \\mathcal B\\), we have \\(Pr(T^{-1}(S)) = Pr(S)\\).\nA subset is measurable iff it is an element of \\(\\mathcal B\\). A measurable set is also called an event.\nA subset \\(S \\in \\mathcal B\\) is \\(T\\)-invariant iff \\(T^{-1}(S) = S\\) almost everywhere.3 Let \\(\\mathcal I\\) be the set of all \\(T\\)-invariant subsets:3 That is, except on a subset of measure zero: \\(Pr(T^{-1}(S) - S) = 0\\) and \\(Pr(S - T^{-1}(S)) = 0\\). This is the last time we will measure this.\n\\[\n\\mathcal I := \\{S \\in \\mathcal B : T^{-1}(S) = S\\}\n\\]\nNow, obviously any set of measure zero or one are \\(T\\)-invariant. We say that those are trivially \\(T\\)-invariant. We say that \\(T\\) is ergodic iff \\(\\mathcal I\\) has only such trivial subsets. In other words, \\(T\\) is ergodic iff it cannot be factored into two nontrivial chunks:\n\\[\nS, S' \\text{ partitions } \\Omega,\\quad \\text{such that } T^{-1}(S) = S ,\\; T^{-1}(S') = S',\\; Pr(S) &gt; 0 ,\\; Pr(S') &gt; 0\n\\]\nWe usually ask \\(T\\) to also be ergodic, though sometimes we don’t need that.\nErgodic maps have many very good properties. We will use the following one. For the theorem, you can picture it as the real space \\(\\mathbb{R}^n\\) with the gaussian probability distribution, but in fact, it applies for just about everything we would care about, such as the space of English texts, queuing jobs, random walks, etc.44 Except pathological examples constructed by logicians who have nothing better to do than to care about the continuum hypothesis, large cardinals, and the arithmetic hierarchy. Those who desire the rigor-mortis of logic, let them have it.\n\nTheorem 1 (Dense orbits) If the state space is a topological space with a countable basis, and any nonempty open set has positive measure, then almost any \\(X\\in\\Omega\\) has a dense orbit.\n\n\nProof. Let \\(U\\) be a nonempty open set.\n\\(\\Omega - \\cup_{i \\geq 0} T^{-i}U\\) is \\(T\\)-invariant, and since it excludes \\(U\\), it does not have the full measure. Since \\(T\\) is ergodic, the set actually has zero measure.\nNow, \\(\\cup(\\Omega - \\cup T^{-i}U)\\) is a union of countably many zero-measure sets, so it still has zero measure. By expanding the definition, this is the set of all points with non-dense orbit.\n\nFinally, there is a common theme in ergodic theory. There are rigorous versions of it, but instead of going for rigor, the spirit is more important:\n\nTheorem 2 (ergodic decomposition) Any interesting map is a partition/sum/integral of ergodic maps.\n\nFor example, the shear map on the unit square \\([0, 1]^2\\) defined by\n\\[\n(x, y) \\mapsto (x, x+y \\mod 1)\n\\]\ncan be thought of as an integral over rotations: For each \\(x \\in [0, 1]\\), we have \\(T_x : y \\mapsto x+y\\mod 1\\). For almost all \\(x\\in [0, 1]\\), we have \\(T_x\\) an irrational rotation, thus ergodic.\n\n\nSequence POV\nWe must interpret the language of measure theory, which is dead like chalk dust, back into the language of sequence predictions, which is alive like reinforced concrete.\nEach point in the state space \\(X\\in \\Omega\\) is a text: a stream of tokens infinite both forwards and backwards. The state space \\(\\Omega\\) is the all possible texts \\((X_n)_n\\). We assume that all tokens come from the same finite-size alphabet, for example, the 128 ASCII symbols.\nThe shift map on the state space \\(T : \\Omega \\to \\Omega\\) is defined by moving the origin to the right by one:\n\\[\nT(\\dots, X_{-1}, X_0, X_1, \\dots) := (\\dots, X_0, X_1, X_2, \\dots)\n\\]\nThe shift map is measure-preserving, meaning that the process is stationary: We could have started reading at any point, and we would still expect to see the same kind of probability distribution. It would not be like “Sorry, the word ‘cat’ appears with zero probability when \\(n \\geq 1000\\).”. It would be like “No matter where we start reading, we should expect to the first three tokens to be ‘cat’ with probability \\(10^{-4}\\).”.\nRepeatedly applying the shift map \\(T\\) is just reading through the stream, one token at a time:\n\\[\n\\text{...Lorem ipsum ...} \\mapsto \\text{...orem ipsum d...} \\mapsto \\text{...rem ipsum do...} \\mapsto \\cdots\n\\]\nA periodic point of \\(T\\) is a text that repeats itself like a broken record. For example, \\(X := \\text{... and and and ...}\\) satisfies \\(T^4X = X\\).\nA \\(T\\)-invariant set \\(S\\subset \\Omega\\) is a set of texts, such that if we take any text \\(X\\) from \\(S\\), and jump either forwards or backwards for an arbitrary amount, we get another set in \\(S\\). In other words, \\(S\\) is a set of token streams where there is no origin: you can start reading from any token.\nA probability distribution over \\(\\Omega\\) describes the probability of observing various kinds of text streams.\nIf we can partition \\(\\Omega\\) into two subsets \\(P, Q\\), with probabilities \\(\\epsilon &gt; 0, 1-\\epsilon &gt; 0\\), then it means that any text from \\(P\\) is different from any text from \\(Q\\), after any shift. It is as if there are two languages, and each text can be exclusively written in one language only.\nWe wish to consider only texts created by some imaginary “universal English speaker”. In particular, we do not want it to get stuck in one sub-language of English, then never escape from it. That is, we assume the universal speaker is ergodic.\nNow imagine that we randomly sample two pieces of text generated by the universal speaker, and we shift the first text around to match it against the second. By Theorem 1, the orbit of the first text is dense in the space of all possible English texts spoken by the universal speaker. We can gamify this situation thus:\n\nProver: “I take one piece of text \\(x\\), then another piece \\(x'\\).”.\nChallenger: “I challenge you to find a stretch of text from \\(x\\) that matches the \\(-1000:1000\\) stretch in \\(x'\\).”.\nProver asks a team of immortal monkeys to do the task. A million years later: “At \\(49134819\\).”.\nChallenger verifies that \\(T^{49134819}(x)_{-1000:1000} = (x')_{-1000:1000}\\).\n\n\n\nShannon–McMillan–Breiman\nIf someone has created an infinite sequence of coin flips \\(X_{-\\infty:+\\infty}\\), then revealed it to us one by one, then each reveal would give us \\(1 \\rm{bit} = \\ln 2 \\rm{nat}\\). The long-term average obtained per reveal is still \\(\\ln 2 \\rm{nat}\\), a rather boring situation.\nHow do we measure the entropy of an English speaker? It speaks token by token, and we have to measure the average information we obtain per token. The problem is that there are two senses of “average”. It could be the time-average: we listen to the speaker speak for a very long time, and calculate the entropy in the speech. It could be the ensemble-average: we listen to the speaker speak for a very long time, then do it again, then again, etc, then average together the time-averages.\nIf the speaker is ergodic, then the speaker essentially has just one speech, and any two samples of its speech are just translations of each other. Consequently, it is intuitively clear that with probability 1, the time-average of the entropy of one speech equals the ensemble-average of the entropy of all speeches. Intuitively, with probability 1,\n\\[\n\\frac{1}{n} \\ln Pr(X_{1:n}) \\to \\mathbb{E}\\left[\\frac{1}{n} \\ln Pr(X_{1:n})\\right]\n\\]\nFor non-ergodic speakers. We simply decompose the speaker into an ensemble of ergodic speakers, then apply the SMB theorem to each one. It is like the strong law of large numbers. Intuitively, it that with probability 1,\n\\[\n\\frac{1}{n} \\ln Pr(X_{1:n}| X \\text{ is type }i)\\to \\mathbb{E}\\left[\\frac{1}{n} \\ln Pr(X_{1:n}) | X \\text{ is type }i\\right]\n\\]\nThis is the Shannon–McMillan–Breiman theorem.\nIn textbooks and Wikipedia, the SMB theorem is stated rigorously, but you have already understood the idea of SMB, and the rigorous versions are simply paraphrases of the idea."
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#turing-test",
    "href": "blog/posts/perplexity-turing-test/index.html#turing-test",
    "title": "When will AI pass the Turing Test?",
    "section": "Turing test",
    "text": "Turing test\n\nTuring test as statistical hypothesis test\nIn the Turing test, there are three players: one judge and two players. The first player is a human, and the second is a machine. The judge asks each player text questions and receives text answers. The judge must decide who is the human.\nWe consider a simplified Turing test. In this test, the judge does not ask, and simply receives one stream of text \\(X_{1:\\infty}\\). The judge must decide whether the stream is produced by the human or the machine, and do so quickly.\nCast in the language of statistical hypothesis testing, we have two hypotheses:\n\n\\(H_0\\) “the stream is produced by the human”\n\\(H_1\\) “the stream is produced by the machine”\n\nThe judge would read from the stream \\(X_{1:\\infty}\\), o-n-e- -t-o-k-e-n at a time, and at each token, decide whether to take another one, or announce its judgment: \\(H_0\\) or \\(H_1\\).\nAs the organizers of the Turing test, we would start the test by flipping a fair coin to decide whether to use the human or the machine. Therefore, \\(Pr(H_0) = Pr(H_1)\\), and by Bayes, the posterior log-probability ratio is\n\\[\n\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} = \\ln\\frac{Pr(H_0|X_{1:n})}{Pr(H_1|X_{1:n})}\n\\]\nThis allows us to use the sequential probability ratio test (SPRT). The judge would decide on two decision boundaries, and calculate \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\) at each token. It would stop and announce the decision as soon as the quantity exceeds one of the boundaries.\nFor example, suppose the judge wants to decide when the odds ratio is 10 to 1, then it would make the decision boundaries to be \\([-\\ln 10, + \\ln 10]\\). If \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\) goes above \\(+\\ln 10\\) when \\(n = 60\\), then the judge would announce “\\(H_0\\)” at that point.\nThe \\(\\ln 10\\) is a good rule of thumb, which we will use for the remainder of the essay.\n\n\nSequential hypothesis testing\nConsider the following simple equation:\n\\[\n\\underbrace{\\frac 1n \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\right]}_{\\text{$\\frac 1n D_{KL}(Pr(\\cdot | H_0)\\| Pr(\\cdot | H_1))$}} = \\underbrace{\\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right]}_{\\text{negative log-likelihood loss per token}} - \\underbrace{\\frac 1n  \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[\\frac{1}{\\ln Pr(X_{1:n}|H_0)}\\right]}_{\\text{entropy rate of the human itself}}\n\\tag{1}\\]\nThe first term is the KL-divergence per token between the machine and the human. Roughly speaking, it is how different they are, per token emitted. It is an information-theoretic quantity.\nThe second term is negative log-likelihood loss per token. This is what language models are trained to minimize. We write it as \\(L\\).\nThe third term is the entropy rate of the human. It is how random the human is. We write it as \\(L_\\infty\\), because it is the theoretical minimal loss that the language model can reach.\nIf the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.\nAssuming that the human is an ergodic speakers of English,2 we can sample an infinite stream \\(X_{1:\\infty}\\) from the human, then call up the Shannon–McMillan–Breiman theorem and find that2 In short, an ergodic speaker is someone who has only one speech. If you hear it speak once for a very long time, then hear it speak again for a very long time, then you can take the first and shift it around, so that it looks like the second over a very long sub-segment. Ergodic speakers allow you to take the average over a single very long speech, and be assured that it is close to the average over all possible speeches.\nIn long, see the appendix on ergodic theory.\n\\[\n\\frac 1n \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} \\to L - L_\\infty\n\\]\nOn the other hand, if the machine is also an ergodic speaker of English, then we can sample an infinite stream \\(X_{1:\\infty}\\) from the machine, then call up the SMB theorem and find that\n\\[\n\\frac 1n \\ln\\frac{Pr(X_{1:n}|H_1)}{Pr(X_{1:n}|H_0)} \\to L' - L_\\infty'\n\\]\nwhere unfortunately, we have the odd \\(L'\\) and \\(L_\\infty'\\), defined by\n\\[\nL' := \\lim_n \\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_1)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_0)}\\right], \\quad L_\\infty' := \\lim_n \\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_1)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right]\n\\]\nWe can interpret them as the loss of the human at imitating the machine, and the entropy rate of the machine itself. When the machine is close enough to the human, we can take the approximation \\(L' \\approx L, L_\\infty' \\approx L_\\infty\\).\nNow, define the log-ratio at step \\(n\\) to be \\(r_n := \\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\). During a Turing test, the judge calculates\n\\[\n\\begin{aligned}\nr_0 &= 1 \\\\\nr_1 &= r_0 + \\frac{Pr(X_{1:1}|H_0)}{Pr(X_{1:1}|H_1)} \\\\\nr_2 &= r_1 + \\frac{Pr(X_{1:2}|X_{1:1}, H_0)}{Pr(X_{1:2}|X_{1:1}, H_1)} \\\\\n&\\cdots\n\\end{aligned}\n\\]\nSo, imagine that such a perfect judge is going through a Turing test, upon receiving “my cat is technically”, and we are listening on its thoughts:\n\n“If it were a human, then it would start with ‘my’ with probability \\(0.01\\). If it were a machine, then \\(0.05\\). Therefore, the odds ratio is 2 to 1.”\n“If it were a human, then it would follow ‘my’ with ‘cat’ with probability \\(0.01\\). If it were a machine, then \\(0.033\\). Therefore, the odds ratio is 3 to 1.”\n“If it were a human, then it would follow ‘is’ with ‘my cat’ with probability… I do not know. However, I do know that the odds ratio is 2 to 1. Now the total odds ratio is 12 to 1, I can decide: \\(H_0\\).”\n\nWe see that the judge does not have to know the probabilities \\(Pr(X_{1:n}|H_0)\\) and \\(Pr(X_{1:n}|H_1)\\), only their ratio. This might be a minor point, but this idea of likelihood ratio is quite important. It is like “I don’t know how often you say ‘cat’ but I know that you say it twice as often than I do!”.\nLet \\(T^*\\) be the time it takes for the judge to decide.\n\\[T^* \\approx \\frac{\\ln 10}{L - L_\\infty}\\]\nIntuitively, each token on average moves the log-probability-ratio away from 0 by another \\((L-L_\\infty)\\). Decision is triggered when it finally moves out of the interval \\([-\\ln 10, +\\ln 10]\\).\nWe are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you’d see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.\n\n\nSlowdown factor\nTo perform the SPRT as described, the judge must know intimately the difference between a human and a machine. Can the judge do that? Can anyone know, with certainty, that I would start my speech with “Forty cats …” with a probability that is exactly 32.42 times that of GPT-3?\nAs a crude approximation, we can model real-world judges as slowed-down version of the perfect judge. We can imagine that at each step, instead of updating the log-ratio by\n\\[\n\\ln r_{n+1} \\leftarrow \\ln r_n + \\ln \\frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}\n\\]\nwe update it by\n\\[\n\\ln r_{n+1} \\leftarrow \\ln r_n + \\frac 1s \\ln \\frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}\n\\]\nwhere \\(s &gt; 1\\) is the slowdown factor. This implies that if it takes \\(\\sim T\\) tokens for the perfect judge to reach a likelihood ratio of \\(r\\), it would take \\(\\sim sT\\) tokens for a human judge.\n\n\nMeasuring the slowdown factor\nThe slowdown factor \\(s\\) is unknown.\n\nInformed by an internal poll, we enforce a lognormal distribution with a median of 53.1, a 15th percentile estimate of 9.84, and an 85th percentile of 290. (Atkinson 2023)\n\nThe original paper (Barnett and Besiroglu 2023a) contains no estimate of \\(s\\). They did propose to measure it experimentally by running the Turing test with a human judge and two language models. One model \\(H_0\\) “perfectly imitates humans” by simply sampling a random text segment from a corpus, and the other model \\(H_1\\) is a trained language model, finetuned to imitate the same corpus. They claimed that for any piece of text \\(X_{1:n}\\), they can calculate the log-ratio \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\), but I found it difficult: Suppose \\(X_{1:n} = \\text{ technically fork}\\), which is unlikely but possible, yet the phrase never appears in the corpus, what should be \\(Pr(X_{1:n}|H_0)\\)? We can use one of the many smoothing tricks (Jurafsky and Martin 2023, chap. 3), but this gets complicated.\nWhat I think would work well is if both \\(H_0\\)and \\(H_1\\) are language models, perhaps even the same model with different sampling temperatures, then the human judge only has to distinguish the two models.\nThere was one large-scale attempt at the Turing test in early 2023, in a game called “Human or Not?” (Jannai et al. 2023). Human participants took 2-minute conversations, and at the end, had to decide whether they were talking to a human or a bot.33 There was no mention of whether the bots had to decide the same question.\n\nThe conversations have a “ping-pong” structure that prevents players from sending two consecutive messages without a response, in order to ensure a balanced and dynamic exchange. Each message, limited to a maximum of 100 characters, has to be composed and sent within a 20-second window, and the chat ends after 2 minutes, usually consisting of 4-5 messages from each side. This ensures that players don’t have to wait for too long, so they can remain engaged with the game and a constant suspense is kept. Once the conversation is over, players are prompted to guess whether their conversational partner was a fellow human or an AI bot. (Jannai et al. 2023)\n\nI counted that during a typical message, each side sends \\([20, 40]\\) English words in total, or \\([30, 50]\\) tokens. In \\([60\\%, 70\\%]\\) of trials, the human participant judged correctly. This suggests that the log-ratio achieved after \\([30, 50]\\) tokens is around the range of \\([\\pm \\ln 6/4, \\pm \\ln 7/3]\\). In other words, the average log-ratio per token is\n\\[\n\\frac{[\\ln 6/4, \\ln 7/3]}{[30, 50]} \\in [0.01, 0.03] \\;\\rm{ nat/token}\n\\]\nThey used several different AI, ranging between Jurassic-2, GPT-4, and Cohere. None of them have published their training compute or loss curves. The only good estimate is for GPT-4, which has training cost \\(C = 2\\times 10^{25}\\rm{FLOP}\\).\nAssuming that Chinchilla scaling holds, average log-ratio per token that an ideal judge should achieve is \\(L - L_\\infty = \\frac{1070}{C^{0.154}} = 0.14 \\;\\rm{ nat/token}\\). Therefore,\n\\[s \\in [5, 14]\\]\nI did not expect the estimate to be nearly symmetric around \\(10\\)."
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#sec-ergodic-theory",
    "href": "blog/posts/perplexity-turing-test/index.html#sec-ergodic-theory",
    "title": "When will AI pass the Turing Test?",
    "section": "Appendix: Ergodic theory",
    "text": "Appendix: Ergodic theory\nSince we used ergodic theory during the essay, we should quickly explain what it is about. This section is foundational, but the full complexity is not necessary.\n\nMeasure-theoretic POV\nI know, you know too, nobody really likes measure theory any more than pianists like practicing scales hundreds of times. Still, it is at the right level of abstraction for many theories, including probability.\nWe omit all mentions of “almost-everywhere”, “except on a set of measure zero”, and similar annoying phrases. As long as you never make a union of uncountable many subsets, you will not be hurt by this omission.\nA probability space is a measurable space with a measure of \\(1\\). We write it as \\((\\Omega, \\mathcal B, Pr)\\), where \\(\\mathcal B\\) is the sigma-algebra of measurable sets, and \\(Pr\\) is the probability measure. We also write \\(\\mu\\) for the measure.1010 Pronounced “mu” – it is a pun because both “mu” and “measure” starts with “m”.\nWe consider a single measurable function \\(T : \\Omega \\to \\Omega\\), and call it the shift map.\nWe demand that \\(T\\) must preserve measure. That is, \\(\\forall S \\in \\mathcal B\\), we have \\(Pr(T^{-1}(S)) = Pr(S)\\).\nA subset is measurable iff it is an element of \\(\\mathcal B\\). A measurable set is also called an event.\nA subset \\(S \\in \\mathcal B\\) is \\(T\\)-invariant iff \\(T^{-1}(S) = S\\) almost everywhere.11 Let \\(\\mathcal I\\) be the set of all \\(T\\)-invariant subsets:11 That is, except on a subset of measure zero: \\(Pr(T^{-1}(S) - S) = 0\\) and \\(Pr(S - T^{-1}(S)) = 0\\). This is the last time we will measure this.\n\\[\n\\mathcal I := \\{S \\in \\mathcal B : T^{-1}(S) = S\\}\n\\]\nNow, obviously any set of measure zero or one are \\(T\\)-invariant. We say that those are trivially \\(T\\)-invariant. We say that \\(T\\) is ergodic iff \\(\\mathcal I\\) has only such trivial subsets. In other words, \\(T\\) is ergodic iff it cannot be factored into two nontrivial chunks:\n\\[\nS, S' \\text{ partitions } \\Omega,\\quad \\text{such that } T^{-1}(S) = S ,\\; T^{-1}(S') = S',\\; Pr(S) &gt; 0 ,\\; Pr(S') &gt; 0\n\\]\nWe usually ask \\(T\\) to also be ergodic, though sometimes we don’t need that.\nErgodic maps have many very good properties. We will use the following one. For the theorem, you can picture it as the real space \\(\\mathbb{R}^n\\) with the gaussian probability distribution, but in fact, it applies for just about everything we would care about, such as the space of English texts, queuing jobs, random walks, etc.1212 Except pathological examples constructed by logicians who have nothing better to do than to care about the continuum hypothesis, large cardinals, and the arithmetic hierarchy. Those who desire the rigor-mortis of logic, let them have it.\n\nTheorem 1 (Dense orbits) If the state space is a topological space with a countable basis, and any nonempty open set has positive measure, then almost any \\(X\\in\\Omega\\) has a dense orbit.\n\n\nProof. Let \\(U\\) be a nonempty open set.\n\\(\\Omega - \\cup_{i \\geq 0} T^{-i}U\\) is \\(T\\)-invariant, and since it excludes \\(U\\), it does not have the full measure. Since \\(T\\) is ergodic, the set actually has zero measure.\nNow, \\(\\cup(\\Omega - \\cup T^{-i}U)\\) is a union of countably many zero-measure sets, so it still has zero measure. By expanding the definition, this is the set of all points with non-dense orbit.\n\nFinally, there is a common theme in ergodic theory. There are rigorous versions of it, but instead of going for rigor, the spirit is more important:\n\nTheorem 2 (ergodic decomposition) Any interesting map is a partition/sum/integral of ergodic maps.\n\nFor example, the shear map on the unit square \\([0, 1]^2\\) defined by\n\\[\n(x, y) \\mapsto (x, x+y \\mod 1)\n\\]\ncan be thought of as an integral over rotations: For each \\(x \\in [0, 1]\\), we have \\(T_x : y \\mapsto x+y\\mod 1\\). For almost all \\(x\\in [0, 1]\\), we have \\(T_x\\) an irrational rotation, thus ergodic.\n\n\nSequence POV\nWe must interpret the language of measure theory, which is dead like chalk dust, back into the language of sequence predictions, which is alive like reinforced concrete.\nEach point in the state space \\(X\\in \\Omega\\) is a text: a stream of tokens infinite both forwards and backwards. The state space \\(\\Omega\\) is the all possible texts \\((X_n)_n\\). We assume that all tokens come from the same finite-size alphabet, for example, the 128 ASCII symbols.\nThe shift map on the state space \\(T : \\Omega \\to \\Omega\\) is defined by moving the origin to the right by one:\n\\[\nT(\\dots, X_{-1}, X_0, X_1, \\dots) := (\\dots, X_0, X_1, X_2, \\dots)\n\\]\nThe shift map is measure-preserving, meaning that the process is stationary: We could have started reading at any point, and we would still expect to see the same kind of probability distribution. It would not be like “Sorry, the word ‘cat’ appears with zero probability when \\(n \\geq 1000\\).”. It would be like “No matter where we start reading, we should expect to the first three tokens to be ‘cat’ with probability \\(10^{-4}\\).”.\nRepeatedly applying the shift map \\(T\\) is just reading through the stream, one token at a time:\n\\[\n\\text{...Lorem ipsum ...} \\mapsto \\text{...orem ipsum d...} \\mapsto \\text{...rem ipsum do...} \\mapsto \\cdots\n\\]\nA periodic point of \\(T\\) is a text that repeats itself like a broken record. For example, \\(X := \\text{... and and and ...}\\) satisfies \\(T^4X = X\\).\nA \\(T\\)-invariant set \\(S\\subset \\Omega\\) is a set of texts, such that if we take any text \\(X\\) from \\(S\\), and jump either forwards or backwards for an arbitrary amount, we get another set in \\(S\\). In other words, \\(S\\) is a set of token streams where there is no origin: you can start reading from any token.\nA probability distribution over \\(\\Omega\\) describes the probability of observing various kinds of text streams.\nIf we can partition \\(\\Omega\\) into two subsets \\(P, Q\\), with probabilities \\(\\epsilon &gt; 0, 1-\\epsilon &gt; 0\\), then it means that any text from \\(P\\) is different from any text from \\(Q\\), after any shift. It is as if there are two languages, and each text can be exclusively written in one language only.\nWe wish to consider only texts created by some imaginary “universal English speaker”. In particular, we do not want it to get stuck in one sub-language of English, then never escape from it. That is, we assume the universal speaker is ergodic.\nNow imagine that we randomly sample two pieces of text generated by the universal speaker, and we shift the first text around to match it against the second. By Theorem 1, the orbit of the first text is dense in the space of all possible English texts spoken by the universal speaker. We can gamify this situation thus:\n\nProver: “I take one piece of text \\(x\\), then another piece \\(x'\\).”.\nChallenger: “I challenge you to find a stretch of text from \\(x\\) that matches the \\(-1000:1000\\) stretch in \\(x'\\).”.\nProver asks a team of immortal monkeys to do the task. A million years later: “At \\(49134819\\).”.\nChallenger verifies that \\(T^{49134819}(x)_{-1000:1000} = (x')_{-1000:1000}\\).\n\n\n\nShannon–McMillan–Breiman\nIf someone has created an infinite sequence of coin flips \\(X_{-\\infty:+\\infty}\\), then revealed it to us one by one, then each reveal would give us \\(1 \\;\\rm{bit} = \\ln 2 \\;\\rm{nat}\\). The long-term average obtained per reveal is still \\(\\ln 2 \\;\\rm{nat}\\), a rather boring situation.\nHow do we measure the entropy of an English speaker? It speaks token by token, and we have to measure the average information we obtain per token. The problem is that there are two senses of “average”. It could be the time-average: we listen to the speaker speak for a very long time, and calculate the entropy in the speech. It could be the ensemble-average: we listen to the speaker speak for a very long time, then do it again, then again, etc, then average together the time-averages.\nIf the speaker is ergodic, then the speaker essentially has just one speech, and any two samples of its speech are just translations of each other. Consequently, it is intuitively clear that with probability 1, the time-average of the entropy of one speech equals the ensemble-average of the entropy of all speeches. Intuitively, with probability 1,\n\\[\n\\frac{1}{n} \\ln Pr(X_{1:n}) \\to \\mathbb{E}\\left[\\frac{1}{n} \\ln Pr(X_{1:n})\\right]\n\\]\nFor non-ergodic speakers. We simply decompose the speaker into an ensemble of ergodic speakers, then apply the SMB theorem to each one. It is like the strong law of large numbers. Intuitively, it that with probability 1,\n\\[\n\\frac{1}{n} \\ln Pr(X_{1:n}| X \\text{ is type }i)\\to \\mathbb{E}\\left[\\frac{1}{n} \\ln Pr(X_{1:n}) | X \\text{ is type }i\\right]\n\\]\nThis is the Shannon–McMillan–Breiman theorem.\nIn textbooks and Wikipedia, the SMB theorem is stated rigorously, but you have already understood the idea of SMB, and the rigorous versions are simply paraphrases of the idea."
  },
  {
    "objectID": "blog/posts/perplexity-turing-test/index.html#turing-test-as-statistical-hypothesis-test",
    "href": "blog/posts/perplexity-turing-test/index.html#turing-test-as-statistical-hypothesis-test",
    "title": "When will AI pass the Turing Test?",
    "section": "Turing test as statistical hypothesis test",
    "text": "Turing test as statistical hypothesis test\n\nTuring test\nIn the Turing test, there are three players: one judge and two players. The first player is a human, and the second is a machine. The judge asks each player text questions and receives text answers. The judge must decide who is the human.\nWe consider a simplified Turing test. In this test, the judge does not ask, and simply receives one stream of text \\(X_{1:\\infty}\\). The judge must decide whether the stream is produced by the human or the machine, and do so quickly.\nCast in the language of statistical hypothesis testing, we have two hypotheses:\n\n\\(H_0\\) “the stream is produced by the human”\n\\(H_1\\) “the stream is produced by the machine”\n\nThe judge would read from the stream \\(X_{1:\\infty}\\), o-n-e- -t-o-k-e-n at a time, and at each token, decide whether to take another one, or announce its judgment: \\(H_0\\) or \\(H_1\\).\nAs the organizers of the Turing test, we would start the test by flipping a fair coin to decide whether to use the human or the machine. Therefore, \\(Pr(H_0) = Pr(H_1)\\), and by Bayes, the posterior log-probability ratio is\n\\[\n\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} = \\ln\\frac{Pr(H_0|X_{1:n})}{Pr(H_1|X_{1:n})}\n\\]\nThis allows us to use the sequential probability ratio test (SPRT). The judge would decide on two decision boundaries, and calculate \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\) at each token. It would stop and announce the decision as soon as the quantity exceeds one of the boundaries.\nFor example, suppose the judge wants to decide when the odds ratio is 10 to 1, then it would make the decision boundaries to be \\([-\\ln 10, + \\ln 10]\\). If \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\) goes above \\(+\\ln 10\\) when \\(n = 60\\), then the judge would announce “\\(H_0\\)” at that point.\nThe \\(\\ln 10\\) is a good rule of thumb, which we will use for the remainder of the essay.\n\n\nSequential hypothesis testing\nConsider the following simple equation:\n\\[\n\\underbrace{\\frac 1n \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[ \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\right]}_{\\text{$\\frac 1n D_{KL}(Pr(\\cdot | H_0)\\| Pr(\\cdot | H_1))$}} = \\underbrace{\\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right]}_{\\text{negative log-likelihood loss per token}} - \\underbrace{\\frac 1n  \\mathbb{E}_{X \\sim Pr(\\cdot | H_0)}\\left[\\frac{1}{\\ln Pr(X_{1:n}|H_0)}\\right]}_{\\text{entropy rate of the human itself}}\n\\tag{1}\\]\nThe first term is the KL-divergence per token between the machine and the human. Roughly speaking, it is how different they are, per token emitted. It is an information-theoretic quantity.\nThe second term is negative log-likelihood loss per token. This is what language models are trained to minimize. We write it as \\(L\\).\nThe third term is the entropy rate of the human. It is how random the human is. We write it as \\(L_\\infty\\), because it is the theoretical minimal loss that the language model can reach.\nIf the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.\nAssuming that the human is an ergodic speakers of English,2 we can sample an infinite stream \\(X_{1:\\infty}\\) from the human, then call up the Shannon–McMillan–Breiman theorem and find that2 In short, an ergodic speaker is someone who has only one speech. If you hear it speak once for a very long time, then hear it speak again for a very long time, then you can take the first and shift it around, so that it looks like the second over a very long sub-segment. Ergodic speakers allow you to take the average over a single very long speech, and be assured that it is close to the average over all possible speeches.\nIn long, see the appendix on ergodic theory.\n\\[\n\\frac 1n \\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} \\to L - L_\\infty\n\\]\nOn the other hand, if the machine is also an ergodic speaker of English, then we can sample an infinite stream \\(X_{1:\\infty}\\) from the machine, then call up the SMB theorem and find that\n\\[\n\\frac 1n \\ln\\frac{Pr(X_{1:n}|H_1)}{Pr(X_{1:n}|H_0)} \\to L' - L_\\infty'\n\\]\nwhere unfortunately, we have the odd \\(L'\\) and \\(L_\\infty'\\), defined by\n\\[\nL' := \\lim_n \\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_1)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_0)}\\right], \\quad L_\\infty' := \\lim_n \\frac 1n\n\\mathbb{E}_{X \\sim Pr(\\cdot | H_1)}\\left[\\ln\\frac{1}{Pr(X_{1:n}|H_1)}\\right]\n\\]\nWe can interpret them as the loss of the human at imitating the machine, and the entropy rate of the machine itself. When the machine is close enough to the human, we can take the approximation \\(L' \\approx L, L_\\infty' \\approx L_\\infty\\).\nNow, define the log-ratio at step \\(n\\) to be \\(r_n := \\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\). During a Turing test, the judge calculates\n\\[\n\\begin{aligned}\nr_0 &= 1 \\\\\nr_1 &= r_0 + \\frac{Pr(X_{1:1}|H_0)}{Pr(X_{1:1}|H_1)} \\\\\nr_2 &= r_1 + \\frac{Pr(X_{1:2}|X_{1:1}, H_0)}{Pr(X_{1:2}|X_{1:1}, H_1)} \\\\\n&\\cdots\n\\end{aligned}\n\\]\nSo, imagine that such a perfect judge is going through a Turing test, upon receiving “my cat is technically”, and we are listening on its thoughts:\n\n“If it were a human, then it would start with ‘my’ with probability \\(0.01\\). If it were a machine, then \\(0.05\\). Therefore, the odds ratio is 2 to 1.”\n“If it were a human, then it would follow ‘my’ with ‘cat’ with probability \\(0.01\\). If it were a machine, then \\(0.033\\). Therefore, the odds ratio is 3 to 1.”\n“If it were a human, then it would follow ‘is’ with ‘my cat’ with probability… I do not know. However, I do know that the odds ratio is 2 to 1. Now the total odds ratio is 12 to 1, I can decide: \\(H_0\\).”\n\nWe see that the judge does not have to know the probabilities \\(Pr(X_{1:n}|H_0)\\) and \\(Pr(X_{1:n}|H_1)\\), only their ratio. This might be a minor point, but this idea of likelihood ratio is quite important. It is like “I don’t know how often you say ‘cat’ but I know that you say it twice as often than I do!”.\nLet \\(T^*\\) be the time it takes for the judge to decide.\n\\[T^* \\approx \\frac{\\ln 10}{L - L_\\infty}\\]\nIntuitively, each token on average moves the log-probability-ratio away from 0 by another \\((L-L_\\infty)\\). Decision is triggered when it finally moves out of the interval \\([-\\ln 10, +\\ln 10]\\).\nWe are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you’d see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.\n\n\nSlowdown factor\nTo perform the SPRT as described, the judge must know intimately the difference between a human and a machine. Can the judge do that? Can anyone know, with certainty, that I would start my speech with “Forty cats …” with a probability that is exactly 32.42 times that of GPT-3?\nAs a crude approximation, we can model real-world judges as slowed-down version of the perfect judge. We can imagine that at each step, instead of updating the log-ratio by\n\\[\n\\ln r_{n+1} \\leftarrow \\ln r_n + \\ln \\frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}\n\\]\nwe update it by\n\\[\n\\ln r_{n+1} \\leftarrow \\ln r_n + \\frac 1s \\ln \\frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}\n\\]\nwhere \\(s &gt; 1\\) is the slowdown factor. This implies that if it takes \\(\\sim T\\) tokens for the perfect judge to reach a likelihood ratio of \\(r\\), it would take \\(\\sim sT\\) tokens for a human judge.\n\n\nMeasuring the slowdown factor\nThe slowdown factor \\(s\\) is unknown.\n\nInformed by an internal poll, we enforce a lognormal distribution with a median of 53.1, a 15th percentile estimate of 9.84, and an 85th percentile of 290. (Atkinson 2023)\n\nThe original paper (Barnett and Besiroglu 2023a) contains no estimate of \\(s\\). They did propose to measure it experimentally by running the Turing test with a human judge and two language models. One model \\(H_0\\) “perfectly imitates humans” by simply sampling a random text segment from a corpus, and the other model \\(H_1\\) is a trained language model, finetuned to imitate the same corpus. They claimed that for any piece of text \\(X_{1:n}\\), they can calculate the log-ratio \\(\\ln\\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\\), but I found it difficult: Suppose \\(X_{1:n} = \\text{ technically fork}\\), which is unlikely but possible, yet the phrase never appears in the corpus, what should be \\(Pr(X_{1:n}|H_0)\\)? We can use one of the many smoothing tricks (Jurafsky and Martin 2023, chap. 3), but this gets complicated.\nWhat I think would work well is if both \\(H_0\\)and \\(H_1\\) are language models, perhaps even the same model with different sampling temperatures, then the human judge only has to distinguish the two models.\nThere was one large-scale attempt at the Turing test in early 2023, in a game called “Human or Not?” (Jannai et al. 2023). Human participants took 2-minute conversations, and at the end, had to decide whether they were talking to a human or a bot.33 There was no mention of whether the bots had to decide the same question.\n\nThe conversations have a “ping-pong” structure that prevents players from sending two consecutive messages without a response, in order to ensure a balanced and dynamic exchange. Each message, limited to a maximum of 100 characters, has to be composed and sent within a 20-second window, and the chat ends after 2 minutes, usually consisting of 4-5 messages from each side. This ensures that players don’t have to wait for too long, so they can remain engaged with the game and a constant suspense is kept. Once the conversation is over, players are prompted to guess whether their conversational partner was a fellow human or an AI bot. (Jannai et al. 2023)\n\nI counted that during a typical message, each side sends \\([20, 40]\\) English words in total, or \\([30, 50]\\) tokens. In \\([60\\%, 70\\%]\\) of trials, the human participant judged correctly. This suggests that the log-ratio achieved after \\([30, 50]\\) tokens is around the range of \\([\\pm \\ln 6/4, \\pm \\ln 7/3]\\). In other words, the average log-ratio per token is\n\\[\n\\frac{[\\ln 6/4, \\ln 7/3]}{[30, 50]} \\in [0.01, 0.03] \\;\\rm{ nat/token}\n\\]\nThey used several different AI, ranging between Jurassic-2, GPT-4, and Cohere. None of them have published their training compute or loss curves. The only good estimate is for GPT-4, which has training cost \\(C = 2\\times 10^{25}\\rm{FLOP}\\).\nAssuming that Chinchilla scaling holds, average log-ratio per token that an ideal judge should achieve is \\(L - L_\\infty = \\frac{1070}{C^{0.154}} = 0.14 \\;\\rm{ nat/token}\\). Therefore,\n\\[s \\in [5, 14]\\]\nI did not expect the estimate to be nearly symmetric around \\(10\\)."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html",
    "href": "blog/posts/vernor-vinge/index.html",
    "title": "The Coming Technological Singularity",
    "section": "",
    "text": "Within thirty years, we will have the technological means to create superhuman intelligence. Shortly after, the human era will be ended.\nIs such progress avoidable? If not to be avoided, can events be guided so that we may survive?These questions are investigated. Some possible answers (and some further dangers) are presented."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#abstract",
    "href": "blog/posts/vernor-vinge/index.html#abstract",
    "title": "The Coming Technological Singularity",
    "section": "",
    "text": "Within thirty years, we will have the technological means to create superhuman intelligence. Shortly after, the human era will be ended.\nIs such progress avoidable? If not to be avoided, can events be guided so that we may survive?These questions are investigated. Some possible answers (and some further dangers) are presented."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#what-is-the-singularity",
    "href": "blog/posts/vernor-vinge/index.html#what-is-the-singularity",
    "title": "The Coming Technological Singularity",
    "section": "What is The Singularity?",
    "text": "What is The Singularity?\nThe acceleration of technological progress has been the central feature of this century. I argue in this paper that we are on the edge of change comparable to the rise of human life on Earth. The precise cause of this change is the imminent creation by technology of entities with greater than human intelligence. There are several means by which science may achieve this breakthrough (and this is another reason for having confidence that the event will occur):\n\nThe development of computers that are “awake” and superhumanly intelligent. (To date, most controversy in the area of AI relates to whether we can create human equivalence in a machine. But if the answer is “yes, we can”, then there is little doubt that beings more intelligent can be constructed shortly thereafter.\nLarge computer networks (and their associated users) may “wake up” as a superhumanly intelligent entity.\nComputer/human interfaces may become so intimate that users may reasonably be considered superhumanly intelligent.\nBiological science may find ways to improve upon the natural human intellect.\n\nThe first three possibilities depend in large part on improvements in computer hardware. Progress in computer hardware has followed an amazingly steady curve in the last few decades 1. Based largely on this trend, I believe that the creation of greater than human intelligence will occur during the next thirty years. (Charles Platt 2 has pointed out the AI enthusiasts have been making claims like this for the last thirty years. Just so I’m not guilty of a relative-time ambiguity, let me more specific: I’ll be surprised if this event occurs before 2005 or after 2030.)1 Moravec, Hans, Mind Children, Harvard University Press, 1988.2 Platt, Charles, Private Communication.\nWhat are the consequences of this event? When greater-than-human intelligence drives progress, that progress will be much more rapid. In fact, there seems no reason why progress itself would not involve the creation of still more intelligent entities – on a still-shorter time scale. The best analogy that I see is with the evolutionary past: Animals can adapt to problems and make inventions, but often no faster than natural selection can do its work – the world acts as its own simulator in the case of natural selection. We humans have the ability to internalize the world and conduct “what if’s” in our heads; we can solve many problems thousands of times faster than natural selection. Now, by creating the means to execute those simulations at much higher speeds, we are entering a regime as radically different from our human past as we humans are from the lower animals.\nFrom the human point of view this change will be a throwing away of all the previous rules, perhaps in the blink of an eye, an exponential runaway beyond any hope of control. Developments that before were thought might only happen in “a million years” (if ever) will likely happen in the next century. (In 3, Greg Bear paints a picture of the major changes happening in a matter of hours.)3 Bear, Greg, “Blood Music”, Analog Science Fiction-Science Fact, June, 1983. Expanded into the novel Blood Music, Morrow, 1985\nI think it’s fair to call this event a singularity (“the Singularity” for the purposes of this paper). It is a point where our models must be discarded and a new reality rules. As we move closer and closer to this point, it will loom vaster and vaster over human affairs till the notion becomes a commonplace. Yet when it finally happens it may still be a great surprise and a greater unknown. In the 1950s there were very few who saw it: Stanislaw Ulam 4 paraphrased John von Neumann as saying:4 Ulam, S., Tribute to John von Neumann, Bulletin of the American Mathematical Society, vol 64, nr 3, part 2, May, 1958, p1-49.\n\nOne conversation centered on the ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue.\n\nVon Neumann even uses the term “singularity”, though it appears he is still thinking of normal progress, not the creation of superhuman intellect. (For me, the superhumanity is the essence of the Singularity. Without that we would get a glut of technical riches, never properly absorbed 5.)5 Stent, Gunther S., The Coming of the Golden Age: A View of the End of Progress, The Natural History Press, 1969.\nIn the 1960s there was recognition of some of the implications of superhuman intelligence. I. J. Good wrote 6:6 Good, I. J., “Speculations Concerning the First Ultraintelligent Machine”, in Advances in Computers, vol 6, Franz L. Alt and Morris Rubinoff, eds, pp31-88, 1965, Academic Press.\n\nLet an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an “intelligence explosion,” and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. … It is more probable than not that, within the twentieth century, an ultraintelligent machine will be built and that it will be the last invention that man need make.\n\nGood has captured the essence of the runaway, but does not pursue its most disturbing consequences. Any intelligent machine of the sort he describes would not be humankind’s “tool” – any more than humans are the tools of rabbits or robins or chimpanzees. Through the ’60s and ’70s and ’80s, recognition of the cataclysm spread 7 8 9 10. Perhaps it was the science-fiction writers who felt the first concrete impact. After all, the “hard” science-fiction writers are the ones who try to write specific stories about all that technology may do for us. More and more, these writers felt an opaque wall across the future. Once, they could put such fantasies millions of years in the future 11. Now they saw that their most diligent extrapolations resulted in the unknowable … soon. Once, galactic empires might have seemed a Post-Human domain. Now, sadly, even interplanetary ones are.7 Vinge, Vernor, “Bookworm, Run!”, Analog, March 1966, pp8-40. Reprinted in True Names and Other Dangers, Vernor Vinge, Baen Books, 1987.8 Alfvén, Hannes, writing as Olof Johanneson, The End of Man?, Award Books, 1969 earlier published as “The Tale of the Big Computer”, Coward-McCann, translated from a book copyright 1966 Albert Bonniers Forlag AB with English translation copyright 1966 by Victor Gollanz, Ltd.9 Vinge, Vernor, First Word, Omni, January 1983, p10.10 Bear, Greg, “Blood Music”, Analog Science Fiction-Science Fact, June, 1983. Expanded into the novel Blood Music, Morrow, 198511 Stapledon, Olaf, The Starmaker, Berkley Books, 1961 (but from the forward probably written before 1937).\nWhat about the ‘90s and the ’00s and the ’10s, as we slide toward the edge? How will the approach of the Singularity spread across the human world view? For a while yet, the general critics of machine sapience will have good press. After all, till we have hardware as powerful as a human brain it is probably foolish to think we’ll be able to create human equivalent (or greater) intelligence. (There is the far-fetched possibility that we could make a human equivalent out of less powerful hardware, if were willing to give up speed, if we were willing to settle for an artificial being who was literally slow 12. But it’s much more likely that devising the software will be a tricky process, involving lots of false starts and experimentation. If so, then the arrival of self-aware machines will not happen till after the development of hardware that is substantially more powerful than humans’ natural equipment.)12 Vinge, Vernor, “True Names”, Binary Star Number 5, Dell, 1981. Reprinted in True Names and Other Dangers, Vernor Vinge, Baen Books, 1987.\nBut as time passes, we should see more symptoms. The dilemma felt by science fiction writers will be perceived in other creative endeavors.(I have heard thoughtful comic book writers worry about how to have spectacular effects when everything visible can be produced by the technically commonplace.) We will see automation replacing higher and higher level jobs. We have tools right now (symbolic math programs, CAD/CAM) that release us from most low-level drudgery. Or put another way: The work that is truly productive is the domain of a steadily smaller and more elite fraction of humanity. In the coming of the Singularity, we are seeing the predictions of true technological unemployment finally come true.\nAnother symptom of progress toward the Singularity: ideas themselves should spread ever faster, and even the most radical will quickly become commonplace. When I began writing, it seemed very easy to come up with ideas that took decades to percolate into the cultural consciousness; now the lead time seems more like eighteen months. (Of course, this could just be me losing my imagination as I get old, but I see the effect in others too.) Like the shock in a compressible flow, the Singularity moves closer as we accelerate through the critical speed.\nAnd what of the arrival of the Singularity itself? What can be said of its actual appearance? Since it involves an intellectual runaway, it will probably occur faster than any technical revolution seen so far. The precipitating event will likely be unexpected – perhaps even to the researchers involved. (“But all our previous models were catatonic! We were just tweaking some parameters…”) If networking is widespread enough (into ubiquitous embedded systems), it may seem as if our artifacts as a whole had suddenly wakened.\nAnd what happens a month or two (or a day or two) after that? I have only analogies to point to: The rise of humankind. We will be in the Post-Human era. And for all my rampant technological optimism, sometimes I think I’d be more comfortable if I were regarding these transcendental events from one thousand years remove … instead of twenty."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#can-the-singularity-be-avoided",
    "href": "blog/posts/vernor-vinge/index.html#can-the-singularity-be-avoided",
    "title": "The Coming Technological Singularity",
    "section": "Can the Singularity be Avoided?",
    "text": "Can the Singularity be Avoided?\nWell, maybe it won’t happen at all: Sometimes I try to imagine the symptoms that we should expect to see if the Singularity is not to develop. There are the widely respected arguments of Penrose 13 and Searle 14 against the practicality of machine sapience. In August of 1992, Thinking Machines Corporation held a workshop to investigate the question “How We Will Build a Machine that Thinks” 15. As you might guess from the workshop’s title, the participants were not especially supportive of the arguments against machine intelligence. In fact, there was general agreement that minds can exist on nonbiological substrates and that algorithms are of central importance to the existence of minds. However, there was much debate about the raw hardware power that is present in organic brains. A minority felt that the largest 1992 computers were within three orders of magnitude of the power of the human brain. The majority of the participants agreed with Moravec’s estimate 16 that we are ten to forty years away from hardware parity. And yet there was another minority who pointed to 17 18, and conjectured that the computational competence of single neurons may be far higher than generally believed. If so, our present computer hardware might be as much as ten orders of magnitude short of the equipment we carry around in our heads. If this is true (or for that matter, if the Penrose or Searle critique is valid), we might never see a Singularity. Instead, in the early ’00s we would find our hardware performance curves begin to level off – this caused by our inability to automate the complexity of the design work necessary to support the hardware trend curves. We’d end up with some very powerful hardware, but without the ability to push it further. Commercial digital signal processing might be awesome, giving an analog appearance even to digital operations, but nothing would ever “wake up” and there would never be the intellectual runaway which is the essence of the Singularity. It would likely be seen as a golden age … and it would also be an end of progress. This is very like the future predicted by Gunther Stent. In fact, on page 137 of 19, Stent explicitly cites the development of transhuman intelligence as a sufficient condition to break his projections.13 Penrose, R., The Emperor’s New Mind, Oxford University Press, 1989.14 Searle, John R., “Minds, Brains, and Programs”, in The Behavioral and Brain Sciences, v.3, Cambridge University Press, 1980. The essay is reprinted in The Mind’s I, edited by Douglas R. Hofstadter and Daniel C. Dennett, Basic Books, 1981. This reprinting contains an excellent critique of the Searle essay.15 Thearling, Kurt, “How We Will Build a Machine that Thinks”, a workshop at Thinking Machines Corporation. Personal Communication.16 Moravec, Hans, Mind Children, Harvard University Press, 1988.17 Conrad, Michael et al., “Towards an Artificial Brain”, BioSystems, vol23, pp175-218, 1989.18 Rasmussen, S. et al., “Computational Connectionism within Neurons: a Model of Cytoskeletal Automata Subserving Neural Networks”, in Emergent Computation, Stephanie Forrest, ed., p428-449, MIT Press, 1991.19 Stent, Gunther S., The Coming of the Golden Age: A View of the End of Progress, The Natural History Press, 1969.\nBut if the technological Singularity can happen, it will. Even if all the governments of the world were to understand the “threat” and be in deadly fear of it, progress toward the goal would continue. In fiction, there have been stories of laws passed forbidding the construction of “a machine in the form of the mind of man” 20.In fact, the competitive advantage – economic, military, even artistic – of every advance in automation is so compelling that passing laws, or having customs, that forbid such things merely assures that someone else will get them first.20 Herbert, Frank, Dune, Berkley Books, 1985. However, this novel was serialized in Analog Science Fiction-Science Fact in the 1960s.\nEric Drexler 21 has provided spectacular insight about how far technical improvement may go. He agrees that superhuman intelligences will be available in the near future – and that such entities pose a threat to the human status quo. But Drexler argues that we can embed such transhuman devices in rules or physical confinement such that their results can be examined and used safely. This is I. J. Good’s ultraintelligent machine, with a dose of caution. I argue that confinement is intrinsically impractical. For the case of physical confinement: Imagine yourself confined to your house with only limited data access to the outside, to your masters. If those masters thought at a rate – say – one million times slower than you, there is little doubt that over a period of years (your time) you could come up with “helpful advice” that would incidentally set you free. (I call this “fast thinking” form of superintelligence “weak superhumanity”. Such a “weakly superhuman” entity would probably burn out in a few weeks of outside time. “Strong superhumanity” would be more than cranking up the clock speed on a human-equivalent mind. It’s hard to say precisely what “strong superhumanity” would be like, but the difference appears to be profound. Imagine running a dog mind at very high speed. Would a thousand years of doggy living add up to any human insight? (Now if the dog mind were cleverly rewired and then run at high speed, we might see something different….) Most speculations about superintelligence seem to be based on the weakly superhuman model. I believe that our best guesses about the post-Singularity world can be obtained by thinking on the nature of strong superhumanity. I will return to this point later in the paper.)21 Drexler, K. Eric, Engines of Creation, Anchor Press/Doubleday, 1986.\nThe other approach to Drexlerian confinement is to build rules into the mind of the created superhuman entity (Asimov’s Laws). I think that performance rules strict enough to be safe would also produce a device whose ability was clearly inferior to the unfettered versions (and so human competition would favor the development of the those more dangerous models).Still, the Asimov dream is a wonderful one: Imagine a willing slave, who has 1000 times your capabilities in every way. Imagine a creature who could satisfy your every safe wish (whatever that means) and still have 99.9% of its time free for other activities. There would be a new universe we never really understood, but filled with benevolent gods (though one of my wishes might be to become one of them).\nIf the Singularity can not be prevented or confined, just how bad could the Post-Human era be? Well … pretty bad. The physical extinction of the human race is one possibility. (Or as Eric Drexler put it of nanotechnology: Given all that such technology can do, perhaps governments would simply decide that they no longer need citizens!). Yet physical extinction may not be the scariest possibility. Again, analogies: Think of the different ways we relate to animals. Some of the crude physical abuses are implausible, yet…. In a Post-Human world there would still be plenty of niches where human equivalent automation would be desirable: embedded systems in autonomous devices, self-aware daemons in the lower functioning of larger sentients. (A strongly superhuman intelligence would likely be a Society of Mind 22 with some very competent components.) Some of these human equivalents might be used for nothing more than digital signal processing. They would be more like whales than humans. Others might be very human-like, yet with a one-sidedness, a dedication that would put them in a mental hospital in our era. Though none of these creatures might be flesh-and-blood humans, they might be the closest things in the new environment to what we call human now. (I. J. Good had something to say about this, though at this late date the advice may be moot: Good 23 proposed a “Meta-Golden Rule”, which might be paraphrased as “Treat your inferiors as you would be treated by your superiors.”It’s a wonderful, paradoxical idea (and most of my friends don’t believe it) since the game-theoretic payoff is so hard to articulate. Yet if we were able to follow it, in some sense that might say something about the plausibility of such kindness in this universe.)22 Minsky, Marvin, Society of Mind, Simon and Schuster, 1985.23 Good, I. J., [Help! I can’t find the source of Good’s Meta-Golden Rule, though I have the clear recollection of hearing about it sometime in the 1960s. Through the help of the net, I have found pointers to a number of related items. G. Harry Stine and Andrew Haley have written about metalaw as it might relate to extraterrestrials: G. Harry Stine, “How to Get along with Extraterrestrials … or Your Neighbor”, Analog Science Fact- Science Fiction, February, 1980, p39-47.]\nI have argued above that we cannot prevent the Singularity, that its coming is an inevitable consequence of the humans’ natural competitiveness and the possibilities inherent in technology. And yet … we are the initiators. Even the largest avalanche is triggered by small things. We have the freedom to establish initial conditions, make things happen in ways that are less inimical than others. Of course (as with starting avalanches), it may not be clear what the right guiding nudge really is:"
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#other-paths-to-the-singularity-intelligence-amplification",
    "href": "blog/posts/vernor-vinge/index.html#other-paths-to-the-singularity-intelligence-amplification",
    "title": "The Coming Technological Singularity",
    "section": "Other Paths to the Singularity: Intelligence Amplification",
    "text": "Other Paths to the Singularity: Intelligence Amplification\nWhen people speak of creating superhumanly intelligent beings, they are usually imagining an AI project. But as I noted at the beginning of this paper, there are other paths to superhumanity. Computer networks and human-computer interfaces seem more mundane than AI, and yet they could lead to the Singularity. I call this contrasting approach Intelligence Amplification (IA). IA is something that is proceeding very naturally, in most cases not even recognized by its developers for what it is. But every time our ability to access information and to communicate it to others is improved, in some sense we have achieved an increase over natural intelligence. Even now, the team of a PhD human and good computer workstation (even an off-net workstation!) could probably max any written intelligence test in existence.\nAnd it’s very likely that IA is a much easier road to the achievement of superhumanity than pure AI. In humans, the hardest development problems have already been solved. Building up from within ourselves ought to be easier than figuring out first what we really are and then building machines that are all of that. And there is at least conjectural precedent for this approach. Cairns-Smith 24 has speculated that biological life may have begun as an adjunct to still more primitive life based on crystalline growth. Lynn Margulis 25 has made strong arguments for the view that mutualism is the great driving force in evolution.24 Cairns-Smith, A. G., Seven Clues to the Origin of Life, Cambridge University Press, 1985.25 Margulis, Lynn and Dorion Sagan, Microcosmos, Four Billion Years of Evolution from Our Microbial Ancestors, Summit Books, 1986.\nNote that I am not proposing that AI research be ignored or less funded. What goes on with AI will often have applications in IA, and vice versa. I am suggesting that we recognize that in network and interface research there is something as profound (and potential wild) as Artificial Intelligence. With that insight, we may see projects that are not as directly applicable as conventional interface and network design work, but which serve to advance us toward the Singularity along the IA path.\nHere are some possible projects that take on special significance, given the IA point of view:\n\nHuman/computer team automation: Take problems that are normally considered for purely machine solution (like hill-climbing problems), and design programs and interfaces that take a advantage of humans’ intuition and available computer hardware. Considering all the bizarreness of higher dimensional hill-climbing problems (and the neat algorithms that have been devised for their solution), there could be some very interesting displays and control tools provided to the human team member.\nDevelop human/computer symbiosis in art: Combine the graphic generation capability of modern machines and the esthetic sensibility of humans. Of course, there has been an enormous amount of research in designing computer aids for artists, as labor saving tools. I’m suggesting that we explicitly aim for a greater merging of competence, that we explicitly recognize the cooperative approach that is possible. Karl Sims 26 has done wonderful work in this direction.\nAllow human/computer teams at chess tournaments. We already have programs that can play better than almost all humans. But how much work has been done on how this power could be used by a human, to get something even better? If such teams were allowed in at least some chess tournaments, it could have the positive effect on IA research that allowing computers in tournaments had for the corresponding niche in AI.\nDevelop interfaces that allow computer and network access without requiring the human to be tied to one spot, sitting in front of a computer. (This is an aspect of IA that fits so well with known economic advantages that lots of effort is already being spent on it.)\nDevelop more symmetrical decision support systems. A popular research/product area in recent years has been decision support systems. This is a form of IA, but may be too focussed on systems that are oracular. As much as the program giving the user information, there must be the idea of the user giving the program guidance.\nUse local area nets to make human teams that really work (ie, are more effective than their component members). This is generally the area of “groupware”, already a very popular commercial pursuit. The change in viewpoint here would be to regard the group activity as a combination organism. In one sense, this suggestion might be regarded as the goal of inventing a “Rules of Order” for such combination operations. For instance, group focus might be more easily maintained than in classical meetings. Expertise of individual human members could be isolated from ego issues such that the contribution of different members is focussed on the team project. And of course shared data bases could be used much more conveniently than in conventional committee operations. (Note that this suggestion is aimed at team operations rather than political meetings. In a political setting, the automation described above would simply enforce the power of the persons making the rules!)\nExploit the worldwide Internet as a combination human/machine tool. Of all the items on the list, progress in this is proceeding the fastest and may run us into the Singularity before anything else. The power and influence of even the present-day Internet is vastly underestimated. For instance, I think our contemporary computer systems would break under the weight of their own complexity if it weren’t for the edge that the USENET “group mind” gives the system administration and support people!) The very anarchy of the worldwide net development is evidence of its potential. As connectivity and bandwidth and archive size and computer speed all increase, we are seeing something like Lynn Margulis’ 27 vision of the biosphere as data processor recapitulated, but at a million times greater speed and with millions of humanly intelligent agents (ourselves).\n\n26 Sims, Karl, “Interactive Evolution of Dynamical Systems”, Thinking Machines Corporation, Technical Report Series, published in Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, Paris, MIT Press, December 1991.27 Margulis, Lynn and Dorion Sagan, Microcosmos, Four Billion Years of Evolution from Our Microbial Ancestors, Summit Books, 1986.The above examples illustrate research that can be done within the context of contemporary computer science departments. There are other paradigms. For example, much of the work in Artificial Intelligence and neural nets would benefit from a closer connection with biological life. Instead of simply trying to model and understand biological life with computers, research could be directed toward the creation of composite systems that rely on biological life for guidance or for the providing features we don’t understand well enough yet to implement in hardware. A long-time dream of science-fiction has been direct brain to computer interfaces 28 29. In fact, there is concrete work that can be done (and has been done) in this area:28 Anderson, Poul, “Kings Who Die”, If, March 1962, p8-36. Reprinted in Seven Conquests, Poul Anderson, MacMillan Co., 1969.29 Vinge, Vernor, “Bookworm, Run!”, Analog, March 1966, pp8-40. Reprinted in True Names and Other Dangers, Vernor Vinge, Baen Books, 1987.\n\nLimb prosthetics is a topic of direct commercial applicability. Nerve to silicon transducers can be made 30.This is an exciting, near-term step toward direct communication.\nSimilar direct links into brains may be feasible, if the bit rate is low: given human learning flexibility, the actual brain neuron targets might not have to be precisely selected. Even 100 bits per second would be of great use to stroke victims who would otherwise be confined to menu-driven interfaces.\nPlugging in to the optic trunk has the potential for bandwidths of 1 Megabit/second or so. But for this, we need to know the fine-scale architecture of vision, and we need to place an enormous web of electrodes with exquisite precision. If we want our high bandwidth connection to be in addition to what paths are already present in the brain, the problem becomes vastly more intractable. Just sticking a grid of high-bandwidth receivers into a brain certainly won’t do it. But suppose that the high-bandwidth grid were present while the brain structure was actually setting up, as the embryo develops. That suggests:\nAnimal embryo experiments. I wouldn’t expect any IA success in the first years of such research, but giving developing brains access to complex simulated neural structures might be very interesting to the people who study how the embryonic brain develops. In the long run, such experiments might produce animals with additional sense paths and interesting intellectual abilities.\n\n30 Kovacs, G. T. A. et al., “Regeneration Microelectrode Array for Peripheral Nerve Recording and Stimulation”, IEEE Transactions on Biomedical Engineering, v 39, n 9, pp 893-902.Originally, I had hoped that this discussion of IA would yield some clearly safer approaches to the Singularity. (After all, IA allows our participation in a kind of transcendence.) Alas, looking back over these IA proposals, about all I am sure of is that they should be considered, that they may give us more options. But as for safety … well, some of the suggestions are a little scarey on their face. One of my informal reviewers pointed out that IA for individual humans creates a rather sinister elite. We humans have millions of years of evolutionary baggage that makes us regard competition in a deadly light. Much of that deadliness may not be necessary in today’s world, one where losers take on the winners’ tricks and are coopted into the winners’ enterprises. A creature that was built de novo might possibly be a much more benign entity than one with a kernel based on fang and talon. And even the egalitarian view of an Internet that wakes up along with all mankind can be viewed as a nightmare 31.31 Swanwick Michael, Vacuum Flowers, serialized in Isaac Asimov’s Science Fiction Magazine, December(?) 1986 - February 1987. Republished by Ace Books, 1988.\nThe problem is not that the Singularity represents simply the passing of humankind from center stange, but that it contradicts some of our most deeply held notions of being. I think a closer look at the notion of strong superhumanity can show why that is."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#strong-superhumanity-and-the-best-we-can-ask-for",
    "href": "blog/posts/vernor-vinge/index.html#strong-superhumanity-and-the-best-we-can-ask-for",
    "title": "The Coming Technological Singularity",
    "section": "Strong Superhumanity and the Best We Can Ask for",
    "text": "Strong Superhumanity and the Best We Can Ask for\nSuppose we could tailor the Singularity. Suppose we could attain our most extravagant hopes. What then would we ask for: That humans themselves would become their own successors, that whatever injustice occurs would be tempered by our knowledge of our roots. For those who remained unaltered, the goal would be benign treatment (perhaps even giving the stay-behinds the appearance of being masters of godlike slaves).It could be a golden age that also involved progress (overleaping Stent’s barrier). Immortality (or at least a lifetime as long as we can make the universe survive 32 33) would be achievable.32 Dyson, Freeman, “Physics and Biology in an Open Universe”, Review of Modern Physics, vol 51, pp447-460, 1979.33 Barrow, John D. and Frank J. Tipler, The Anthropic Cosmological Principle, Oxford University Press, 1986.\nBut in this brightest and kindest world, the philosophical problems themselves become intimidating. A mind that stays at the same capacity cannot live forever; after a few thousand years it would look more like a repeating tape loop than a person. (The most chilling picture I have seen of this is in 34.) To live indefinitely long, the mind itself must grow … and when it becomes great enough, and looks back … what fellow-feeling can it have with the soul that it was originally? Certainly the later being would be everything the original was, but so much vastly more. And so even for the individual, the Cairns-Smith (or Lynn Margulis) notion of new life growing incrementally out of the old must still be valid.34 Niven, Larry, “The Ethics of Madness”, If, April 1967, pp82-108. Reprinted in Neutron Star, Larry Niven, Ballantine Books, 1968.\nThis “problem” about immortality comes up in much more direct ways. The notion of ego and self-awareness has been the bedrock of the hardheaded rationalism of the last few centuries. Yet now the notion of self-awareness is under attack from the Artificial Intelligence people (“self-awareness and other delusions”). Intelligence Amplification undercuts the importance of ego from another direction. The post-Singularity world will involve extremely high-bandwidth networking. A central feature of strongly superhuman entities will likely be their ability to communicate at variable bandwidths, including ones far higher than speech or written messages. What happens when pieces of ego can be copied and merged, when the size of a self-awareness can grow or shrink to fit the nature of the problems under consideration?These are essential features of strong superhumanity and the Singularity. Thinking about them, one begins to feel how essentially strange and different the Post-Human era will be – no matter how cleverly and benignly it is brought to be.\nFrom one angle, the vision fits many of our happiest dreams: a place unending, where we can truly know one another and understand the deepest mysteries. From another angle, it’s a lot like the worst case scenario I imagined earlier in this paper.\nWhich is the valid viewpoint? In fact, I think the new era is simply too different to fit into the classical frame of good and evil. That frame is based on the idea of isolated, immutable minds connected by tenuous, low-bandwidth links. But the post-Singularity world does fit with the larger tradition of change and cooperation that started long ago (perhaps even before the rise of biological life). I think there are notions of ethics that would apply in such an era. Research into IA and high-bandwidth communications should improve this understanding. I see just the glimmerings of this now, in Good’s Meta-Golden Rule, perhaps in rules for distinguishing self from others on the basis of bandwidth of connection. And while mind and self will be vastly more labile than in the past, much of what we value (knowledge, memory, thought) need never be lost. I think Freeman Dyson has it right when he says 35: “God is what mind becomes when it has passed beyond the scale of our comprehension.”35 Dyson, Freeman, Infinite in All Directions, Harper && Row, 1988."
  },
  {
    "objectID": "blog/posts/vernor-vinge/index.html#appendix-metadata",
    "href": "blog/posts/vernor-vinge/index.html#appendix-metadata",
    "title": "The Coming Technological Singularity",
    "section": "Appendix: Metadata",
    "text": "Appendix: Metadata\nModernized from The Coming Technological Singularity on the original author’s website. The original header for the is as follows:\nVernor Vinge\n\nDepartment of Mathematical Sciences San Diego State University\n\n(c) 1993 by Vernor Vinge (Verbatim copying/translation and distribution of this entire article is permitted in any medium, provided this notice is preserved.)\n\n[I wish to thank John Carroll of San Diego State University and Howard Davidson of Sun Microsystems for discussing the draft version of this paper with me.]\n\nThis article was for the VISION-21 Symposium sponsored by NASA Lewis Research Center and the Ohio Aerospace Institute, March 30-31, 1993. It is also retrievable from the NASA technical reports server as part of NASA CP-10129. A slightly changed version appeared in the Winter 1993 issue of _Whole Earth Review_.\nVISION-21 Symposium was a conference held in March 1993, described as:\n\nThe symposium Vision-21: Interdisciplinary Science and Engineering in the Era of Cyberspace was held at the NASA Lewis Research Center on March 30-31, 1993. The purpose of the symposium was to simulate interdisciplinary thinking in the sciences and technologies which will be required for exploration and development of space over the next thousand years. The keynote speakers were Hans Moravec, Vernor Vinge, Carol Stoker, and Myron Krueger. The proceedings consist of transcripts of the invited talks and the panel discussion by the invited speakers, summaries of workshop sessions, and contributed papers by the attendees. (Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace 1993)"
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html",
    "href": "blog/posts/decline-of-mathematics/index.html",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "href": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html",
    "href": "blog/posts/data-manifold/index.html",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "",
    "text": "This is a theory of neural scaling law, proposed by (Bahri et al. 2021; Sharma and Kaplan 2022)\nAccording to this theory, a neural network, when trained to convergence, allocates its \\(N\\) parameters in two parts: * A fixed number of parameters that map the data to an intrinsic data manifold of dim \\(d\\). * All other parameters that handle pieces of this manifold. Loss \\(\\propto\\) the volume of each manifold piece.\nThey argued that the loss function should scale as \\(L \\propto N^{-4/d}\\) for cross-entropy and mean-square losses."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#the-manifold-hypothesis",
    "href": "blog/posts/data-manifold/index.html#the-manifold-hypothesis",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "The manifold hypothesis",
    "text": "The manifold hypothesis\nConsider the space of all MNIST images. Each MNIST image is a 28x28 grayscale, so the total space is \\(\\mathbb R^{28\\times 28} = \\mathbb R^{784}\\).\nHowever, as you may have seen in experiments with the VAE, most of the MNIST dataset “collapses” onto a much smaller subset of \\(\\mathbb R^{784}\\). This is the “(intrinsic) data manifold”, with a dimension much smaller than \\(784\\). Indeed, the very fact that the intrinsic dimension is small allows us to have meaningful “2D slices” of the dataset:\n\n\n\nFigure from Convolutional Variational Autoencoder - Tensorflow Core Tutorials. More images can be found in Visualizing the Variational Autoencoder, and can be regenerated in about 10 minutes with a Google Colab GPU.\n\n\nReal data can be expensive, though, which is why we often use “toy” datasets with known dimensions, generated by a known random process. For example, the following is the “Swiss roll” dataset. It is generated by first populating a 2D square \\([0, 1]^2\\), then use a function \\(f: \\mathbb R^2 \\to \\mathbb R^3\\) to “roll up” the square into 3D space.\n\n\n\nThe Isomap algorithm (Tenenbaum, Silva, and Langford 2000), popular for constructing data manifolds. Figure from Wikipedia."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#synthetic-data-manifolds",
    "href": "blog/posts/data-manifold/index.html#synthetic-data-manifolds",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Synthetic data manifolds",
    "text": "Synthetic data manifolds\nConsider the simplest data manifold: \\(\\mathbb R^d\\), affinely transformed, then embedded in \\(\\mathbb R^n\\), with \\(n &gt; d\\).\nTo synthesize such a data manifold, we randomly initialize a teacher network, so-called because it implements the function that a student network will fit to by supervised training. Each teacher network is constructed thus:\n\nThe number of neurons in each layer are: \\([d, 9, 600, 600, 1]\\)\nIt has 0 bias.\nThe weights between layers are sampeled from \\(\\mathcal N(0, m^{-1/2})\\) , where \\(m\\) is the input size of the layer (a form of He initialization).\nThe activation function at the second (with 9 neurons) and last layers are identity. All other activation functions are ReLU.\n\nOnce we have constructed a teacher network, we use it to generate a dataset \\(\\{(x_i, y_i)\\}_i\\) thus:\n\nGenerate random gaussian vectors \\(\\{t_i\\}_i\\) in \\(\\mathbb R^d\\), with mean \\(0\\) and std \\(I_{d\\times d}\\).\nFor each \\(t \\in \\{t_i\\}_i\\), push \\(t\\) through the teacher network.\nLet \\(x \\in \\mathbb R^9\\) be the teacher network activation at the second layer, with 9 neurons.\nLet \\(y \\in \\mathbb R\\) be the teacher network output.\n\n\nSome proofs\nAssuming that we have Lipschitz continuity, we can make some proofs."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#learning-data-manifold-by-neural-networks",
    "href": "blog/posts/data-manifold/index.html#learning-data-manifold-by-neural-networks",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Learning data manifold by neural networks",
    "text": "Learning data manifold by neural networks\nAccording to the theory, if the data manifold has dimension \\(d\\), then as we scale up a neural network with \\(N\\) parameters, the MSE loss of a fully-trained network would scale like \\(L \\sim N^{-\\alpha}\\), where \\(\\alpha \\approx 4/d\\).\nLet’s test this.\nFirst, we define the “student” neural network architecture:\n\nThe number of neurons in each layer are: \\([9, n, n, 1]\\).\nThe biases are initialized to 0.\nThe weights between layers are sampeled from \\(\\mathcal N(0, m^{-1/2})\\), where \\(m\\) is the input size of the layer (a form of He initialization).\nAll activation functions are ReLU.\n\nA simple computation shows that the network has exactly \\(N = n^2+12n + 1\\) parameters11 \\(N = \\underbrace{(n+n+1)}_{\\text{first layer}} + \\underbrace{(9n + n^2 + n)}_{\\text{second layer}}\\)\n\n\n\nAn example teacher network architecture with \\([9, 5, 5, 1]\\) neurons."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#experiments",
    "href": "blog/posts/data-manifold/index.html#experiments",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Experiments",
    "text": "Experiments\nAccording to the theory, if the data manifold has dimension \\(d\\), then as we scale up a neural network with \\(N\\) parameters, the MSE loss of a fully-trained network would scale like \\(L \\sim N^{-\\alpha}\\), where \\(\\alpha \\approx 4/d\\). We test this in two ways, once with synthetic datasets, where we know that the data manifold has the desired number of dimensions, and once with the CIFAR10 dataset, where we do not have the .\n\nSynthetic data manifolds\nSince Consider the simplest data manifold: \\(\\mathbb R^d\\), affine-transformed, then embedded in \\(\\mathbb R^n\\), with \\(n &gt; d\\).\nTo synthesize such a data manifold, we randomly initialize a teacher network, so-called because it implements the function that a student network will fit to by supervised training. Each teacher network is constructed thus:\n\nThe number of neurons in each layer are: \\([d, 9, 600, 600, 1]\\)\nIt has 0 bias.\nThe weights between layers are sampled from \\(\\mathcal N(0, m^{-1/2})\\) , where \\(m\\) is the input size of the layer (a form of He initialization).\nThe activation function at the second (with 9 neurons) and last layers are identity. All other activation functions are ReLU.\n\nOnce we have constructed a teacher network, we use it to generate a dataset \\(\\{(x_i, y_i)\\}_i\\) in this way:\n\nGenerate random gaussian vectors \\(\\{t_i\\}_i\\) in \\(\\mathbb R^d\\), with mean \\(0\\) and std \\(I_{d\\times d}\\).\nFor each \\(t \\in \\{t_i\\}_i\\), push \\(t\\) through the teacher network.\nLet \\(x \\in \\mathbb R^9\\) be the teacher network activation at the second layer, with 9 neurons.\nLet \\(y \\in \\mathbb R\\) be the teacher network output.\n\nFirst, we define the “student” neural network architecture:\n\nThe number of neurons in each layer are: \\([9, n, n, 1]\\).\nThe biases are initialized to 0.\nThe weights between layers are sampled from \\(\\mathcal N(0, m^{-1/2})\\), where \\(m\\) is the input size of the layer (a form of He initialization).\nAll activation functions are ReLU.\n\n\n\n\nAn example teacher network architecture with \\([9, 5, 5, 1]\\) neurons.\n\n\nThe parameter count is\n\\[\nN = \\underbrace{(n+n+1)}_{\\text{first layer}} + \\underbrace{(9n + n^2 + n)}_{\\text{second layer}}\n\\]\n\n\nExperimental data\nI ran it for days on my laptop.\n\n\nAll code for generating the dataset, and for analyzing the dataset, are in a GitHub repo: yuxi-liu-wired/scaling-law-by-data-manifold."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#brief-history",
    "href": "blog/posts/mixture-of-experts/index.html#brief-history",
    "title": "Mixture of Experts",
    "section": "Brief history",
    "text": "Brief history\nIn the beginning was the gaussian. The gaussian is a beautiful distribution, with linearity, the central limit theorem, fast inference, least squares regression, and so on. The problem is that it has just one peak.\nIf one wants to model a complicated distribution with several bumps, one can make one step up the staircase of complexity, and build distributions from a linear sum of several gaussians. This is the mixture of gaussians. More generally, simple statistical models like the Poisson distribution, the Bernoulli distribution, and so on, can be added together to create mixture models.\n\n\n\nA mixture of three gaussian bumps. Figure from Wikipedia.\n\n\nA mixture of experts is then a simple generalization, and training a mixture of experts, back in the old days, was mostly thought of as statistical inference. The main problem was simply modelling complex data with a larger family of statistical distribution. Their main worry was that the experts would overfit.\nThey had little data (enough to fit onto a floppy disk), and each expert was usually just a gaussian distribution or a logistic classifier (any more complex and they wouldn’t know how to calculate the integrals and derivatives). Consequently, what they ended up trying to solve was to fit a few thousand datapoints using tens of very simple experts.\nIt is a general fact of classical machine learning that they were very worried about overfitting, and it was a reasonable worry back then, since they had such small datasets (MNIST was in 1994). This, combined with their inability to hand-design learning algorithms for complex machine learning architectures and the slowness of pure gradient descent, meant that machine learning algorithms back then were simple ones fitted onto small datasets.\n\n\n\ncost of\n1980s\n2010s\n2020s\n\n\n\n\ndata\nhigh\nlow\nlow\n\n\nalgorithm\nhigh\nlow\nlow\n\n\ntraining\nlow\nmedium\nhigh\n\n\ninference\nlow\nmedium\nhigh\n\n\n\nThe overall effect is:\n\ngetting training data: expensive (you have to do it yourself);\ndesigning the algorithm: expensive (cheaper if you have graduate students);\ntraining compute: low (there was little funding for training);\ninference compute: very cheap (since you could not train large models).\n\nThis should be compared to the very different situation with deep learning since the 2010s:\n\ngetting training data: cheap (just download it online);\ndesigning the algorithm: cheap (make a standard network, add a few decorations, then use backprop with Adam optimizer);\ntraining compute: as expensive as you want;\ninference compute: as expensive as you want.\n\nWhile classical statistics and machine learning was mainly constrained by how many partial derivatives and integrals the statistician can calculate confidently on paper,1 deep learning is mainly constrained by memory and compute budget.1 If you want a taste of the old days, look at the formulas inside (Jordan and Jacobs 1994). They explicitly calculated the expectation-maximization algorithms for learning a hierarchy of linear experts.\nSo when the deep learning era came circa 2012, people immediately started looking into how to perform conditional computing, that is, to save compute by only calling a small portion of the model. The idea is that you would have different portions of the model be specialized for different forms of input, and for each input, the model would first cheaply find out which expert should handle it, then call upon only the few specialized experts to handle this particular input.\nThe first paper on applying MoE to deep learning was (Eigen, Ranzato, and Sutskever 2013), one year after AlexNet. However, the deep MoE (DMoE) proposed in the paper has no sparsity, and so it has no modern offsprings. Let \\(f_{1, 1}, f_{1, 2}, \\dots, f_{1, n}\\) be \\(n\\) layers with the same architecture. Now, each can bo treated as an expert, and be mixed by\n\\[\nf_1(x) = \\sum_i g_{1, i}(x) f_{1, i}(x)\n\\]\nwhere \\(g_{1, i}\\) is a tiny neural network, the gating network for the first layer. Now, stack multiple such layers, and we obtain the DMoE. As one can see, such a network still has to use all the parameters in each forward pass, and therefore saves no compute. It is simply a case of the dense MoE.\nModern2020s deep learning really arrived with the sparsely-gated MoE (Shazeer et al. 2017), which saves compute. Specifically, if each layer contains \\(8\\) experts, but only \\(2\\) are consulted, then the cost of compute is only about \\(1/4\\) for the full model."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#load-balancing",
    "href": "blog/posts/mixture-of-experts/index.html#load-balancing",
    "title": "Mixture of Experts",
    "section": "Load balancing",
    "text": "Load balancing\nThe main problem with MoE is a kind of rich-get-richer effect. If at the start of training, some experts are consulted often by random fluctuation, they would be heavily trained by backpropagation, and become even better experts, a upward spiral resulting in a few good experts and many useless experts.\nFor example, in the very first paper on MoE, they trained up to 8 experts to recognize phonemes from 6 Japanese speakers. They found that:\n\nOnly experts 4, 5, and 6 are active in the final mixture. This solution is typical – in all simulations with mixtures of 4 or 8 experts all but 2 or 3 experts had mixing proportions that were effectively 0 for all cases. (Jacobs et al. 1991)\n\nThis might not have been a serious problem in the past, when neural networks were seen as merely a form of high-dimensional statistical model learnable by any one of the typical statistical algorithms (maximal likelihood, Bayesian inference, expectation maximization…), but nowadays, MoE are used because you need to throw more compute at the problem, but cannot afford a larger dense model. In this case, it would defeat the purpose of MoE if some experts end up neglected.\nIt is no coincidence, then, that the sparsely-gated MoE paper (Shazeer et al. 2017) specifically used two auxiliary loss functions to encourage the experts to have equal “weight” over time. It was simplified to just one in the Switch Transformers paper (Fedus, Zoph, and Shazeer 2022).\nSpecifically, consider the sparsely-gated MoE with \\(k=1\\) – where just the top-ranked expert is consulted every time. Let \\(n\\) be the number of experts, and consider a batch of queries \\(\\{x_1, x_2, ..., x_T\\}\\), then the auxiliary loss of the batch is\n\\[\nL := n \\sum_{i=1}^n f_i P_i\n\\]\nwhere \\(f_i=\\frac{1}{T} \\#(\\text{queries sent to expert $i$})\\) is the fraction of time where expert \\(i\\) is ranked highest, and \\(P_i=\\frac{1}{T} \\sum_{j=1}^T w_i\\left(x_j\\right)\\) is the fraction of weight on expert \\(i\\).\nIn the original paper, they claimed that we can obtain the minimal auxiliary loss \\(L\\) at the limit where every expert has equal weight \\(1 / n\\) on all samples, and every expert is ranked the highest equally often.\nPlugging in the equations, we find it is \\(1\\). Unfortunately, this is technically wrong. When there are many experts and large batch, a way to let \\(L\\) approach \\(1/2\\). It is not difficult to show that \\(1/2\\) is the true lower bound. Seeing that Google has been training those huge models since 2017, this definitely works in practice, despite being slightly incorrect.\nThere are plenty of other choices for load balancing, which are rather technical details. For example, the z-loss stabilizes mixed-precision training by discouraging logits that are too far from zero, avoiding large round-off errors (Zoph et al. 2022, secs. 3.3–3.4)."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#sec-appendix-error",
    "href": "blog/posts/mixture-of-experts/index.html#sec-appendix-error",
    "title": "Mixture of Experts",
    "section": "Appendix: Error in load balancing",
    "text": "Appendix: Error in load balancing\n\nLet one expert get \\(1/2 - \\epsilon\\) on every question, but never consulted on anything, and let every other \\(n-1\\) expert evenly divide the rest of the questions. For example, this is how the weights should be distributed when there are 3 experts on 4 questions:\n\\[\n\\begin{bmatrix}\n\\frac 12 - \\epsilon & \\frac 12 + \\epsilon & 0 \\\\\n\\frac 12 - \\epsilon & \\frac 12 + \\epsilon & 0 \\\\\n\\frac 12 - \\epsilon & 0 & \\frac 12 + \\epsilon \\\\\n\\frac 12 - \\epsilon & 0 & \\frac 12 + \\epsilon \\\\\n\\end{bmatrix}\n\\]\ngiving \\(L = \\frac 34 (1+2\\epsilon)\\)."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#sec-appendix-load-balancing-error",
    "href": "blog/posts/mixture-of-experts/index.html#sec-appendix-load-balancing-error",
    "title": "Mixture of Experts",
    "section": "Appendix: Error in load balancing",
    "text": "Appendix: Error in load balancing\n\nLet one expert get \\(1/2 - \\epsilon\\) on every question, but is never consulted on anything, and let every other \\(n-1\\) expert evenly divide the rest of the questions. For example, this is how the weights should be distributed when there are 3 experts on 4 questions:\n\\[\n\\begin{bmatrix}\n\\frac 12 - \\epsilon & \\frac 12 + \\epsilon & 0 \\\\\n\\frac 12 - \\epsilon & \\frac 12 + \\epsilon & 0 \\\\\n\\frac 12 - \\epsilon & 0 & \\frac 12 + \\epsilon \\\\\n\\frac 12 - \\epsilon & 0 & \\frac 12 + \\epsilon \\\\\n\\end{bmatrix}\n\\]\ngiving \\(L = \\frac 34 (1+2\\epsilon)\\). By generalizing this construction, when there are many experts and large batch, we have \\(L \\to 1/2\\). It is not difficult to show that \\(1/2\\) is the true lower bound.\nWith the global optimization method of dual annealing2, Python found something close to the true lower bound, as shown in the figure. The load balancing matrix has a bright strip of \\(1/2 - \\epsilon\\), and slightly brighter dots of \\(1/2+\\epsilon\\) jumping around the matrix, as expected.2 I tried using local optimization with SciPy’s minimize, but it always fails to converge to \\(\\sim 1/2\\). It even fails to converge to \\(\\sim 1\\). Indeed, often it just moves around the initial point a bit then immediately gives up and stops. My suspicion is that the loss landscape is too jagged.\n\n\n\nThe result of minimizing load-balancing loss, with 10 experts and 10 questions."
  },
  {
    "objectID": "blog/posts/mixture-of-experts/index.html#sparsifying-moe",
    "href": "blog/posts/mixture-of-experts/index.html#sparsifying-moe",
    "title": "Mixture of Experts",
    "section": "Sparsifying MoE",
    "text": "Sparsifying MoE\nGiven a MoE, there are two ways to use it. One can use it as-is, but then every expert must be consulted on every query, defeating the main purpose of MoE in the age of large models: conditional computing.\nWe will try out two ways to sparsify a trained MoE. In the first MoE paper (1991), they inspected the weights (the matrix \\(A\\) in our notation), and found that some experts would never be called on any input. Then they just removed those experts. This can be understood as sparsification “at compile time”.\nHere, we implement sparsification “at compile time” by ranking the rows of \\(A\\) according to their L2-norm, find the top-k rows of them, then mask out all the other experts.\nThis implementation is given to you as the method sparse_forward in class MoE.\nIn the sparsely-gated MoE, the sparsification is done “at runtime”. That is:\n\\[w(x) = \\mathrm{softmax}(\\mathrm{top}_k(Ax))\\]\nwhere \\(\\mathrm{top}_k(v)\\) preserves the top-k entries of \\(v\\), but set all other entries to \\(-\\infty\\)."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#deriving-the-scaling-law",
    "href": "blog/posts/data-manifold/index.html#deriving-the-scaling-law",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Deriving the scaling law",
    "text": "Deriving the scaling law\nWe can get a feel for where the number \\(4/d\\) came from by studying a simpler model.\n\nPrototype case\nConsider a problem of regression. We have to learn the true function on the \\(n\\)-dimensional cube: \\(f: [0, 1]^d \\to \\mathbb{R}\\). Assume it is Lipschitz continuous, that is, its first derivative is upper bounded by \\(\\lambda\\). In particular, this means \\(|f(x) - f(y)| \\leq \\lambda |x-y|\\) for all \\(x, y\\) in the domain.\nWe approximate the true function with a piecewise-constant function \\(\\hat f: [0, 1]^d \\to \\mathbb{R}\\), meaning that its graph looks like a staircase. We divide the cube into \\(N\\) equal smaller cubic pieces, and define \\(\\hat f\\) to be equal to the value of \\(f\\) at the center of each cubic piece.\n\nTheorem 1 When the loss is mean square error, it scales like \\(L = \\Theta(N^{-2/d})\\).\n\n\nProof. With \\(N\\) parameters, we can divide the \\([0, 1]^d\\) cube into \\(N\\) equal parts, therefore, each cube has side length \\(N^{-1/d}\\). Therefore, the distance between the center of each cube and the point farthest from the center is also \\(\\Theta(N^{-1/d})\\).\nNow, since the function has bounded first derivative, we know that the difference between the function value at the center of the cube and the function value at the farthest point is bounded by \\(\\lambda \\cdot \\Theta(N^{-1/d}) = \\Theta(N^{-1/d})\\). Therefore, the mean square loss on each individual little cube is bounded by \\(\\Theta(N^{-2/d})\\).\nAnd since the overall mean square loss is the average of the loss on each individual cube, the total loss is also bounded by \\(\\Theta(N^{-2/d})\\).\n\n\n\nGeneralization\nMore generally, if \\(f\\) has bounded second-derivative, and we use a piecewise-linear \\(\\hat f\\) function approximator, then the mean square loss scales like \\(\\Theta(N^{-4/d})\\). By piece-wise linear, we mean that the domain of \\(\\hat f\\) is divided into little cubes, and it is linear on each little cube.\nIndeed, this generalizes in the obvious way:\n\nTheorem 2 If the loss is mean \\(p\\)-th power loss, \\(f\\) has bounded \\(k+1\\)-th order derivatives, and \\(\\hat f\\) is composed of piece-wise \\(k\\)-degree polynomials, then the loss scales like \\(\\Theta(N^{-p(k+1)/d})\\).\n\n\nProof. We prove another case where the loss is still mean square error, but \\(f\\) has bounded \\(2\\)-th order derivatives.\nBy Taylor expansion, if we use the first-order Taylor expansion to approximate \\(f\\) at the center of each cube, then the error is bounded by \\(\\Theta(N^{-2/d})\\). And since the mean square loss is the average of the square of the error, the total mean squared loss is bounded by \\(\\Theta(N^{-4/d})\\) on each little cube.\nAnd since the overall mean square loss is the average of the loss on each individual cube, the total loss is also bounded by \\(\\Theta(N^{-4/d})\\).\nFor the general case, take the Taylor expansion to the \\(k\\)-th order at the center of each little cube.\n\n\n\nScaling of nearest neighbor rule\nWhat is the worst possible scaling? It would be when \\(k=0\\) and \\(p=1\\), giving us \\(L = \\Theta(N^{-1/d})\\). What does this mean? To have \\(k=0\\) means that we use piecewise-constant fitting function \\(\\hat f\\). To have \\(p=1\\) means that we are using the L1-loss. This is essentially piecewise constant, median regression.\nUnder mild assumptions, the nearest neighbor rule for classification has the same form of scaling, where the loss is not L1-loss, but 0-1 loss.\nPeople have found sharper scaling laws under assuming nicer datasets, using complicated functional analysis tools scaling laws. A dataset can be “nice” in several ways. One way is to have few outliers: it should have a thin tail, looking more like a box, rather than a gently rising hill. Another way is to have smoothly varying boundaries: its boundary should not look “bumpy”. See Two Phases of Scaling Laws for Nearest Neighbor Classifiers (TODO?) for a brief review and further citations to the literature."
  },
  {
    "objectID": "blog/posts/data-manifold/index.html#experiments-1",
    "href": "blog/posts/data-manifold/index.html#experiments-1",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Experiments",
    "text": "Experiments\nI ran it for days on my laptop."
  },
  {
    "objectID": "blog/posts/scaling-law-by-data-manifold/index.html#deriving-the-scaling-law",
    "href": "blog/posts/scaling-law-by-data-manifold/index.html#deriving-the-scaling-law",
    "title": "Neural scaling law by data manifold dimensions",
    "section": "Deriving the scaling law",
    "text": "Deriving the scaling law\nWe can get a feel for where the number \\(4/d\\) came from by studying a simpler model.\n\nPrototype case\nConsider a problem of regression. We have to learn the true function on the \\(n\\)-dimensional cube: \\(f: [0, 1]^d \\to \\mathbb{R}\\). Assume it is Lipschitz continuous, that is, its first derivative is upper bounded by \\(\\lambda\\). In particular, this means \\(|f(x) - f(y)| \\leq \\lambda |x-y|\\) for all \\(x, y\\) in the domain.\nWe approximate the true function with a piecewise-constant function \\(\\hat f: [0, 1]^d \\to \\mathbb{R}\\), meaning that its graph looks like a staircase. We divide the cube into \\(N\\) equal smaller cubic pieces, and define \\(\\hat f\\) to be equal to the value of \\(f\\) at the center of each cubic piece.\n\nTheorem 1 When the loss is mean square error, it scales like \\(L = \\Theta(N^{-2/d})\\).\n\n\nProof. With \\(N\\) parameters, we can divide the \\([0, 1]^d\\) cube into \\(N\\) equal parts, therefore, each cube has side length \\(N^{-1/d}\\). Therefore, the distance between the center of each cube and the point farthest from the center is also \\(\\Theta(N^{-1/d})\\).\nNow, since the function has bounded first derivative, we know that the difference between the function value at the center of the cube and the function value at the farthest point is bounded by \\(\\lambda \\cdot \\Theta(N^{-1/d}) = \\Theta(N^{-1/d})\\). Therefore, the mean square loss on each individual little cube is bounded by \\(\\Theta(N^{-2/d})\\).\nAnd since the overall mean square loss is the average of the loss on each individual cube, the total loss is also bounded by \\(\\Theta(N^{-2/d})\\).\n\n\n\nGeneralization\nMore generally, if \\(f\\) has bounded second-derivative, and we use a piecewise-linear \\(\\hat f\\) function approximator, then the mean square loss scales like \\(\\Theta(N^{-4/d})\\). By piece-wise linear, we mean that the domain of \\(\\hat f\\) is divided into little cubes, and it is linear on each little cube.\nIndeed, this generalizes in the obvious way:\n\nTheorem 2 If the loss is mean \\(p\\)-th power loss, \\(f\\) has bounded \\(k+1\\)-th order derivatives, and \\(\\hat f\\) is composed of piece-wise \\(k\\)-degree polynomials, then the loss scales like \\(\\Theta(N^{-p(k+1)/d})\\).\nSince the KL-divergence is approximately MSE loss when the predictor is close to correct, the loss scales like \\(\\Theta(N^{-2(k+1)/d})\\) in this case.\n\n\nProof. We prove another case where the loss is still mean square error, but \\(f\\) has bounded \\(2\\)-th order derivatives.\nBy Taylor expansion, if we use the first-order Taylor expansion to approximate \\(f\\) at the center of each cube, then the error is bounded by \\(\\Theta(N^{-2/d})\\). And since the mean square loss is the average of the square of the error, the total mean squared loss is bounded by \\(\\Theta(N^{-4/d})\\) on each little cube.\nAnd since the overall mean square loss is the average of the loss on each individual cube, the total loss is also bounded by \\(\\Theta(N^{-4/d})\\).\nFor the general case, take the Taylor expansion to the \\(k\\)-th order at the center of each little cube.\n\n\n\nScaling of nearest neighbor rule\nWhat is the worst possible scaling? It would be when \\(k=0\\) and \\(p=1\\), giving us \\(L = \\Theta(N^{-1/d})\\). What does this mean? To have \\(k=0\\) means that we use piecewise-constant fitting function \\(\\hat f\\). To have \\(p=1\\) means that we are using the L1-loss. This is essentially piecewise constant, median regression.\nUnder mild assumptions, the nearest neighbor rule for classification has the same form of scaling, where the loss is not L1-loss, but 0-1 loss.\nPeople have found sharper scaling laws under assuming nicer datasets, using complicated functional analysis tools scaling laws. A dataset can be “nice” in several ways. One way is to have few outliers: it should have a thin tail, looking more like a box, rather than a gently rising hill. Another way is to have smoothly varying boundaries: its boundary should not look “bumpy”. See Two Phases of Scaling Laws for Nearest Neighbor Classifiers (TODO?) for a brief review and further citations to the literature."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html",
    "href": "blog/posts/grokking-modular-arithmetics/index.html",
    "title": "Grokking modular arithmetics",
    "section": "",
    "text": "This essay reproduces the paper A simple and interpretable model of grokking modular arithmetic tasks (TODO?). The code is available on GitHub at yuxi-liu-wired/grokking-modular-arithmetics."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#problem-setup",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#problem-setup",
    "title": "Grokking modular arithmetics",
    "section": "Problem setup",
    "text": "Problem setup\nGiven a natural number \\(N\\), we have modular arithmetic on \\(\\mathbb Z_N = \\{0, 1, ..., N-1\\}\\). For example, \\(\\mathbb Z_{12}\\) is the “clock face modular arithmetic”. The problem for our neural network is to learn binary functions on \\(\\mathbb Z_N\\). That is, we are to learn a binary function \\(f: \\mathbb Z_N\\times \\mathbb Z_N \\to \\mathbb Z_N\\).\nEach such binary function can be exactly specified by a \\(N\\times N\\) table, so there are \\(N^{N^2}\\) possible such functions. Most of them are completely random and uninteresting, both for us and for neural networks, but a few are very interesting, and modular addition is one such interesting function.\nFor example, modular addition on \\(\\mathbb Z_6\\) has the following multiplicative table:\n\n\n\n+\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n0\n1\n2\n3\n4\n5\n\n\n1\n1\n2\n3\n4\n5\n0\n\n\n2\n2\n3\n4\n5\n0\n1\n\n\n3\n3\n4\n5\n0\n1\n2\n\n\n4\n4\n5\n0\n1\n2\n3\n\n\n5\n5\n0\n1\n2\n3\n4\n\n\n\nSince the entire dataset is known and specified in advance, we can define the train set ratio \\(\\alpha = \\frac{|D_{train}|}{|D|}\\), where \\(D\\) is the full dataset (the multiplication table), and \\(D_{train}\\) is the training dataset. We expect that, as \\(\\alpha\\) approaches \\(1\\), the network becomes better at generalizing to the test set.\nThe network architecture we use has 3 layers:\n\nInput is \\(x = [x^{(1)}, x^{(2)}]\\). Both \\(x^{(1)}, x^{(2)} \\in \\mathbb R^N\\) are one-hot encodings of \\(\\mathbb Z_N\\).\nHidden layer activation is \\(z = \\phi(\\frac{1}{\\sqrt M} W^{(1)}z)\\), where \\(\\phi\\) is the activation function. Here \\(z \\in \\mathbb R^M\\) can be of any width.\nOutput is \\(y = \\frac 1N W^{(2)}z\\), where \\(y \\in \\mathbb R^N\\) should be a one-hot encoding of \\(\\mathbb Z_N\\).\nAll entries of \\(W^{(1)}, W^{(2)} \\sim \\mathcal N(0, 1)\\) are initialized as standard gaussians.\n\\(W^{(1)}, W^{(2)}\\) are all the parameters of the network. There is no bias. Thus the network has \\(3MN\\) parameters in total.\n\n\n\n\nAn example network with the given architecture, with \\(N=3, M = 10\\).\n\n\nIn the paper, Gromov found that grokking occurs under different choices of activation functions \\(\\phi\\), different training methods (SGD, Adam, etc), and different training set ratio \\(\\alpha\\).\nThe simplest example where grokking occurs is with\n\nQuadratic activation function: \\(\\phi(t) = t^2\\).\nFull-batch gradient descent.\nMSE loss.\n\nI used AdamW optimizer instead of standard gradient descent, since it converges faster. The dataset is formatted as an array of triples of form \\((x_1, x_2, y)\\), interpreted as \\(x_1 + x_2 = y \\mod N\\). I split the dataset randomly into two datasets."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#experiments",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#experiments",
    "title": "Grokking modular arithmetics",
    "section": "Experiments",
    "text": "Experiments\n\n\n\n\nThe test set accuracy curve decreases as train set accuracy increases to perfection.\nThe test set accuracy curves rises only after train set accuracy is perfect. First slowly, then rapidly (“grokking”). This can be quite puzzling, since if the network has really achieved perfection on the training set, then there is nothing left to learn, and so it shouldn’t be able to improve any further – and yet it does improve.\nPerfect accuracy on train set is reached at epoch 10x that of train set.\nThe learning curves shows something smoother, but also something interesting: the train loss decreases monotonically, but the test loss rises, then decreases.\nFor a while, test loss rose while test accuracy increased!\n\nSome lessons:\n\nGrokking might look less dramatic when plotted not by argmax-accuracy, but by MSE.\n\nSee for example [2201.02177] Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets (TODO?). One wonders what they would have found if they had plotted MSE losses instead of accuracies?\n[2301.05217] Progress measures for grokking via mechanistic interpretability (TODO?) does plot train and test loss, and in this paper, the grokking appears in the loss curves as well. This seems harder to understand using our small model (they used a Transformer).\n\nTrain loss can decrease while test loss increase, but this trend can also be reversed. The shape of learning curves is quite complex.\n\nWe see that the network has learned some sine waves. It seems to be a robust fact that networks trained to do modular arithmetics, with one-hot encoding, learns to use trigonometry for this task. (the use of one-hot encoding seems very relevant, as noted here).\n\nThe null hypothesis\nAs a good comparison with the above interpretation of the neural network, we leverage the same tools on the “null hypothesis”. There are two ways to do the null hypothesis: either initialize the neural network randomly and then interpret it, or initialize it, train it to perform a randomly generated binary operation, then interpret it.\nIn short, I tried both null hypotheses, and they look as well as one might have expected: noise.\n\n\n\n\n\n\n\nExtensions\nThis toy is small and simple. It runs in a minute. Here are some ideas for playing with the toy:\n\nModular multiplication.\nRandom operation (as a null hypothesis).\nDifferent activation functions (sine, ReLU).\nDifferent accelerators (SGD, Adam, etc)\nTwo hidden layers."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#extensions",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#extensions",
    "title": "Grokking modular arithmetics",
    "section": "Extensions",
    "text": "Extensions\nThis toy is small and simple. It runs in a minute. Here are some ideas for playing with the toy:\n\nModular multiplication.\nRandom operation (as a null hypothesis).\nDifferent activation functions (sine, ReLU).\nDifferent accelerators (SGD, Adam, etc)\nTwo hidden layers."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#some-other-quotes",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#some-other-quotes",
    "title": "Grokking modular arithmetics",
    "section": "Some other quotes",
    "text": "Some other quotes\n[2301.02679] Grokking modular arithmetic\n\nIn particular, random feature models such as infinitely-wide neural networks (in the NTK regime) do not exhibit grokking, at least on the tasks that involve modular functions.\nIn our minimal setup, the simplest explanation for grokking is that once training loss reached a certain value, the only way to further minimize it is to start learning the right features.\n\nGeirhos, Robert, et al. “Shortcut learning in deep neural networks.” Nature Machine Intelligence 2.11 (2020): 665-673. (TODO?)\n\nmany of deep learning’s failures can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in comparative psychology, education and linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike.\n\n\n\n\nFigure 3 from (TODO?)\n\n\nThe Bitter Lesson (Sutton 2019)\n\nOne thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.\n\nThe Scaling Hypothesis # Why Does Pretraining Work?\n\nEarly on in training, a model learns the crudest levels: that some letters like ‘e’ are more frequent than others like ‘z’, that every 5 characters or so there is a space, and so on. It goes from predicted uniformly-distributed bytes to what looks like Base-60 encoding—alphanumeric gibberish. As crude as this may be, it’s enough to make quite a bit of absolute progress: a random predictor needs 8 bits to ‘predict’ a byte/character, but just by at least matching letter and space frequencies, it can almost halve its error to around 5 bits…\n… a sample will state that someone is “alive” and then 10 sentences later, use the word “dead”, or it will digress into an irrelevant argument instead of the expected next argument, or someone will do something physically improbable, or it may just continue for a while without seeming to get anywhere.All of these errors are far less than &lt;0.02 bits per character; we are now talking not hundredths of bits per characters but less than ten-thousandths.The pretraining thesis argues that this can go even further: we can compare this performance directly with humans doing the same objective task, who can achieve closer to 0.7 bits per character. What is in that missing &gt;0.4?\nThe last bits are deepest. The implication here is that the final few bits are the most valuable bits, which require the most of what we think of as intelligence."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#the-null-hypothesis",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#the-null-hypothesis",
    "title": "Grokking modular arithmetics",
    "section": "The null hypothesis",
    "text": "The null hypothesis\nAs a good comparison with the above interpretation of the neural network, we leverage the same tools on the “null hypothesis”. There are two ways to do the null hypothesis: either initialize the neural network randomly and then interpret it, or initialize it, train it to perform a randomly generated binary operation, then interpret it.\nIn short, I tried both null hypotheses, and they look as well as one might have expected: noise."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#results",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#results",
    "title": "Grokking modular arithmetics",
    "section": "Results",
    "text": "Results\n\nGrokking\n\n\n\nLearning curves showing grokking.\n\n\nSome observations:\n\nThe test set accuracy curve decreases as train set accuracy increases to perfection.\nThe test set accuracy curves rises only after train set accuracy is perfect. First slowly, then rapidly (“grokking”). This can be quite puzzling, since if the network has really achieved perfection on the training set, then there is nothing left to learn, and so it shouldn’t be able to improve any further – and yet it does improve.\nPerfect accuracy on train set is reached at epoch 10x that of train set.\nThe learning curves shows something smoother, but also something interesting: the train loss decreases monotonically, but the test loss rises, then decreases.\nFor a while, test loss rose while test accuracy increased!\n\nSome lessons:\n\nGrokking might look less dramatic when plotted not by argmax-accuracy, but by MSE.\n\nSee for example [2201.02177] Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets (TODO?). One wonders what they would have found if they had plotted MSE losses instead of accuracies?\n[2301.05217] Progress measures for grokking via mechanistic interpretability (TODO?) does plot train and test loss, and in this paper, the grokking appears in the loss curves as well. This seems harder to understand using our small model (they used a Transformer).\n\nTrain loss can decrease while test loss increase, but this trend can also be reversed. The shape of learning curves is quite complex.\n\n\n\nInterpretation\nSince the neural network is so small, we can interpret it. What kind of neural network did we end up, that could do modular addition?\nDirectly inspecting the weight matrices, we notice suggestive wavy bands that resemble sine waves.\n\n\n\nThe weight matrices.\n\n\nLet’s sort them according to frequency, as found by running a Fourier transform and picking the highest peak:\n\n\n\nThe weight matrices, with columns ordered by frequency.\n\n\nWe see that the learned neural network is probably doing some Fourier transform. This can be confirmed by plotting the activation map on every hidden neuron. Specifically, for each hidden neuron, we can calculate its activation upon each of the \\(N\\times N\\) possible inputs. THis is plotted as a heatmap with \\(N\\times N\\) pixels. We then get one heatmap per hidden neuron, and display all of them in a grid:\n\n\n\nThe activation pattern of neurons in the hidden layer as one scans through all possible inputs.\n\n\nWe see that the network has learned some sine waves. It seems to be a robust fact that networks trained to do modular arithmetics, with one-hot encoding, learns to use trigonometry for this task. (the use of one-hot encoding seems very relevant, as noted here).\n\n\nThe null hypothesis\nAs a good comparison with the above interpretation of the neural network, we leverage the same tools on the “null hypothesis”. There are two ways to do the null hypothesis: either initialize the neural network randomly and then interpret it, or initialize it, train it to perform a randomly generated binary operation, then interpret it.\nAs one would expect, the neural network can successfully memorize arbitrary binary operations, without generalization (as there is no pattern to generalize).\n\n\n\nLearning curves for a neural network trained on a randomly initialized binary operation.\n\n\nFor both null hypotheses, I tried interpreting them using the same methodology, they look as well as one might have expected: complete noise.\n\nFigure 1: The network randomly initialized.\n\n\n\n\n\n\nActivation maps.\n\n\n\n\n\n\n\nWeight matrices.\n\n\n\n\n\n\n\nFigure 2: The network trained to perform a randomly initialized binary operation.\n\n\n\n\n\n\nActivation maps.\n\n\n\n\n\n\n\nWeight matrices.\n\n\n\n\n\n\n\n\nExtensions\nThis toy is small and simple. It runs in a minute. Here are some ideas for playing with the toy:\n\nModular multiplication.\nRandom operation (as a null hypothesis).\nDifferent activation functions (sine, ReLU).\nDifferent accelerators (SGD, Adam, etc)\nTwo hidden layers."
  },
  {
    "objectID": "blog/posts/grokking-modular-arithmetics/index.html#setup",
    "href": "blog/posts/grokking-modular-arithmetics/index.html#setup",
    "title": "Grokking modular arithmetics",
    "section": "Setup",
    "text": "Setup\nGiven a natural number \\(N\\), we have modular arithmetic on \\(\\mathbb Z_N = \\{0, 1, ..., N-1\\}\\). For example, \\(\\mathbb Z_{12}\\) is the “clock face modular arithmetic”. The problem for our neural network is to learn binary functions on \\(\\mathbb Z_N\\). That is, we are to learn a binary function \\(f: \\mathbb Z_N\\times \\mathbb Z_N \\to \\mathbb Z_N\\).\nEach such binary function can be exactly specified by a \\(N\\times N\\) table, so there are \\(N^{N^2}\\) possible such functions. Most of them are completely random and uninteresting, both for us and for neural networks, but a few are very interesting, and modular addition is one such interesting function.\nFor example, modular addition on \\(\\mathbb Z_6\\) has the following multiplicative table:\n\n\n\n+\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n0\n1\n2\n3\n4\n5\n\n\n1\n1\n2\n3\n4\n5\n0\n\n\n2\n2\n3\n4\n5\n0\n1\n\n\n3\n3\n4\n5\n0\n1\n2\n\n\n4\n4\n5\n0\n1\n2\n3\n\n\n5\n5\n0\n1\n2\n3\n4\n\n\n\nSince the entire dataset is known and specified in advance, we can define the train set ratio \\(\\alpha = \\frac{|D_{train}|}{|D|}\\), where \\(D\\) is the full dataset (the multiplication table), and \\(D_{train}\\) is the training dataset. We expect that, as \\(\\alpha\\) approaches \\(1\\), the network becomes better at generalizing to the test set.\nThe network architecture we use has 3 layers:\n\nInput is \\(x = [x^{(1)}, x^{(2)}]\\). Both \\(x^{(1)}, x^{(2)} \\in \\mathbb R^N\\) are one-hot encodings of \\(\\mathbb Z_N\\).\nHidden layer activation is \\(z = \\phi(\\frac{1}{\\sqrt M} W^{(1)}z)\\), where \\(\\phi\\) is the activation function. Here \\(z \\in \\mathbb R^M\\) can be of any width.\nOutput is \\(y = \\frac 1N W^{(2)}z\\), where \\(y \\in \\mathbb R^N\\) should be a one-hot encoding of \\(\\mathbb Z_N\\).\nAll entries of \\(W^{(1)}, W^{(2)} \\sim \\mathcal N(0, 1)\\) are initialized as standard gaussians.\n\\(W^{(1)}, W^{(2)}\\) are all the parameters of the network. There is no bias. Thus the network has \\(3MN\\) parameters in total.\n\n\n\n\nAn example network with the given architecture, with \\(N=3, M = 10\\).\n\n\nIn the paper, Gromov found that grokking occurs under different choices of activation functions \\(\\phi\\), different training methods (SGD, Adam, etc), and different training set ratio \\(\\alpha\\).\nThe simplest example where grokking occurs is with\n\nQuadratic activation function: \\(\\phi(t) = t^2\\).\nFull-batch gradient descent.\nMSE loss.\n\nI used AdamW optimizer instead of standard gradient descent, since it converges faster. The dataset is formatted as an array of triples of form \\((x_1, x_2, y)\\), interpreted as \\(x_1 + x_2 = y \\mod N\\). I split the dataset randomly into two datasets."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html",
    "href": "blog/posts/principia-mathematicarum/index.html",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "",
    "text": "# The world as theories and interpretations\nWhat is light? Newton said it was a particle1. Huygens said it was a wave. Schrödinger said it was both. Some clever fool said it was a wavicle. And Feynman said it was whatever helps you sleep at night shuts you up and lets you calculate.\nSo is light a particle, or a wave? None of these explanations satisfied me, so I figured it out for myself."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "href": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "The wave-particle duality",
    "text": "The wave-particle duality\nThere are more than one wave-particle duality. In fact, there is nothing particularly two-ful or wave-ful or particle-ful about physics! Why are we so confused about wave-particle duality? I blame force of habit and evolution.\n\nA particle is a curve. That is, it is a function \\(\\gamma: (a, b) \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathcal M\\) is a manifold.\nA field is a function \\(\\phi: \\mathcal M \\to Y\\), where \\(Y\\) is any manifold you like. We say the field is \\(Y\\)-valued.\nA scalar field is a real-valued field.\nA wave is a more confusing name for a field. Why \"confusing\"? Because the word \"wave\" makes people think the field must be \"going up and down\" here, there, or everywhere, but the fact is, a field can be exactly flat everywhere, and still be a wave! So why did physicists call it a \"wave\" when they really mean a field? Well, force of habit... back in the old days, the only field they knew of is the water-wave, which can be described mathematically as \\(h: \\R^2 \\to \\R\\), where \\(h(x)\\) is the height of water at location \\(x\\).\nA particle theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain paths in \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA field theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain fields over \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA wave theory is a field theory.\nA wave-particle duality over a manifold \\(\\mathcal M\\) is a tuple \\((T, T', f)\\). Here, \\(T\\) is a particle theory over \\(\\mathcal M\\), and \\(T'\\) is a field theory over \\(\\mathcal M\\), and \\(f\\) is an equivalence between \\(T, T'\\).\nA wave-equation is a differential equation satisfied by a field.\nAn equation of motion (of a particle) is a differential equation satisfied by a particle.\n\nIf our physical theory has a very special \"physical space\" \\(\\mathcal M\\), then a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\R\\) represents time. In other words, a particle is nothing more and nothing less than a trajectory in spacetime. This is what we mean by a \"particle\" by default, even though sometimes we would deal with \"timeless particles\", for which time is meaningless, and a particle must instead be a function \\(\\gamma: (a, b) \\to \\mathcal M\\).\nTimeless particles? Why yes! That’s how we study geometric optics as the study of light-rays.\n\nIn geometric optics\n\n\nIn Hamiltonian mechanics\n\n\nIn quantum mechanics"
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "href": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Crash course in modern theoretical physics",
    "text": "Crash course in modern theoretical physics\nRecall that a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\). But what if we don’t use an interval \\((a, b)\\), but use a square, or a cylinder, or even a cube? This leads us to the idea of strings, branes, and other such fancy frontiers of theoretical physics.\n\nString theory\nA closed string is a function \\(\\mu: (a, b) \\times \\mathbb S^1 \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathbb S^1\\) is the circle.\nAn open string is a function \\(\\mu: (a, b) \\times (0, 1)\\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers.\nA string theory is made of two parts: one, the types of strings that it decides about; two, a way to decide if a string is physical or unphysical.\n\n\nHow to make your own variational physical theory\n\nFind a manifold \\(\\mathcal A\\).\nFind another manifold \\(\\mathcal B\\).\nDefine a family of functions of type \\(\\mu: \\mathcal A \\to \\mathcal B\\). This will be the domain of your physical theory.\nWrite down an action function \\(S(\\mu)\\).\nSpecify a way to \"vary \\(\\mu\\) infinitesimally\". Write that as \\(\\delta\\).\nDerive consequences of \\[\\delta S(\\mu) = 0.\\]\n\nFollowing the recipe, we immediately get Lagrangian mechanics and Hamiltonian mechanics.\nNow, we made a small sleight of hand in the recipe. Can you spot it? It is in steps 4 and 5. Namely, we have claimed that we can \"write down an action function\" and \"vary \\(\\mu\\) infinitesimally\". However, not every \\(\\mathcal A, \\mathcal B\\) has enough structure to allow us to do that. The art of doing theoretical physics is mostly in putting in enough structure in \\(\\mathcal A, \\mathcal B\\) so that you can define \\(S(\\mu)\\) and \\(\\delta S(\\mu)\\).\n\n\nHow to clothe your manifolds\n::: epigraph The world found nothing sacred in the abstract nakedness of being human.\nHannah Arendt, The origins of totalitarianism :::\nSince a mere manifold is not structured enough for defining actions and infinitesimal variations, we will \"clothe\" the manifolds with enough structures so that they do. To make this concrete, we will consider how we could construct Lagrangian mechanics and Hamiltonian mechanics according to the recipe.\nLagrangian\nHamiltonian\nAnd if you go deep into theoretical physics, you will eventually encounter Calabi–Yau manifolds, which are \"compact Kähler manifolds with a vanishing first Chern class and a Ricci-flat metric\". All these extra structures give them enough theoretical niceness for elegant string theories.\n\n\nExercise for the reader\nApply the recipe to your favorite manifolds, and get it published in a journal of physics with an impact factor of at least 2."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of classical mechanics",
    "text": "Interpretations of classical mechanics\nFigure 3 shows six main interpretations of classical mechanics. They are all equivalent in some exact mathematical sense.\n\n\n\nSix main interpretations of classical mechanics.\n\n\n\nPosthuman classical mechanics\nWhat is it like to be a bat? What is it like to be a robot? The umwelt, seeing in infrared."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of quantum mechanics",
    "text": "Interpretations of quantum mechanics"
  },
  {
    "objectID": "blog/posts/art/index.html",
    "href": "blog/posts/art/index.html",
    "title": "Analytical mechanics",
    "section": "",
    "text": "One overarching goal is to show that classical mechanics is bursting at the seams, and to unmask classical mechanics, revealing the quantum mechanics that is deep inside.\n\n\nEarly 2023, I undertook a serious study of economics. When I was studying Ramsey’s theory of optimal saving, I saw, to my great surprise, something they call a “Hamiltonian” (Campante, Sturzenegger, and Velasco 2021, chap. 3). I was shocked, but after studying it carefully, and thinking it over, I realized that it was no mistake – the Hamiltonian really occurs in economics. Moreover, the Hamiltonian in physics really has an economic interpretation. At that moment, suddenly everything fell into place. Those enlightenment-era philosophers saying things like “God has chosen the best of all possible worlds.”1, or “Nature always acts in the simplest possible manner to produce its effects.”2\n1 Leibniz, an originator of calculus and universal genius. In his [1710 book Theodicy], the phrase “best of all” appeared for no less than 13 times:\n\nIt is thus one must think of the creation of the best of all possible universes, all the more since God not only decrees to create a universe, but decrees also to create the best of all.\n… the City of God must be the most perfect of all possible states, since it was formed and is perpetually governed by the greatest and best of all Monarchs.\n\nEtc, etc. Reading a chapter of the book, I felt a hypnotic numbing effect on the brain.2 Maupertuis proposed a version of the principle of least action in Mémoires de l’académie royale des sciences, 1748, 417-426. We will see him soon enough."
  },
  {
    "objectID": "blog/posts/art/index.html#optimization-as-making-money",
    "href": "blog/posts/art/index.html#optimization-as-making-money",
    "title": "Analytical mechanics",
    "section": "Optimization as making money",
    "text": "Optimization as making money\n\nThe shortest line problem\n\n\n\n\n\n\nWarning\n\n\n\nIn this problem, the so-called “time” \\(t\\) has units of length as well. So, please don’t panic when we see something like \\(\\sqrt{1 + \\dot x^2}\\). If it worries we, we can replace \\(t\\) by \\(v\\tau\\), where \\(v\\) is a constant speed of one, and \\(\\tau\\) is time.\n\n\nStart with the easiest problem: shortest path problem. What is the shortest path from \\((0, 0)\\) to \\((A, B)\\)? We parametrize the path by a function \\(t \\mapsto (x(t), y(t))\\), with \\(t\\in [0, 1]\\). The problem is then\n\\[\\begin{cases} \\min \\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt \\\\ \\int_0^1 \\dot x dt = A \\\\ \\int_0^1 \\dot y dt = B \\\\ \\end{cases}\\]\n\n\n\nWhat is the shortest path from \\((0, 0)\\) to \\((A, B)\\)?\n\n\nThis is a standard constraint-optimization problem, and could be solved by the Lagrangian multiplier method:\n\\[\\delta \\left(\\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt + p_x \\left( A - \\int_0^1 \\dot x dt\\right) + p_y \\left( B - \\int_0^1 \\dot y dt\\right) \\right) = 0\\]\nwhere \\(p_x, p_y\\) are the Lagrangian multipliers, each responsible for enforcing one constraint.\nVarying the path functions \\(x, y\\) gives us\n\\[\\delta \\int_0^1 (\\sqrt{\\dot x^2 + \\dot y^2} - p_x \\dot x - p_y \\dot y)dt = 0\\]\nEach of \\(\\dot x, \\dot y\\) could be independently perturbed with a tiny concentrated \"pulse\", so for the integral to be stationary, the integrand must be zero with respect to derivatives of \\(\\dot x, \\dot y\\). That is, we have\n\\[\\begin{cases} \\partial_{\\dot x}(\\sqrt{\\dot x^2 + \\dot y^2} - p_x \\dot x - p_y \\dot y )= 0\\\\ \\partial_{\\dot y}(\\sqrt{\\dot x^2 + \\dot y^2} - p_x \\dot x - p_y \\dot y ) = 0 \\end{cases}\\]\nand we are faced with the solution\n\\[(p_x, p_y) = \\frac{1}{\\sqrt{\\dot x^2 + \\dot y^2}}(\\dot x, \\dot y)\\]\nSince \\(p_x, p_y\\) are independent of time, they are constants, and since we have from the above equation \\(p_x^2 + p_y^2 = 1\\), we find that \\(p_x = \\cos\\theta, p_y = \\sin\\theta\\) for some \\(\\theta\\). Thus, the curve is a straight line making an angle \\(\\theta\\) to the x-axis.\n\n\nEconomic interpretation\nInterpret \\(x, y\\) as two goods that we can produce (let’s say, tons of steel and tons of copper).\nWe are a factory manager, and we are given a task: produce \\(A\\) of \\(x\\) (tons of steel), and \\(B\\) of \\(y\\) (tons of copper), in \\([0, 1]\\) (one year). If we don’t do it, we will be sacked. Our problem is to accomplish the task at minimal cost.\n\\(\\dot x, \\dot y\\) are the speed at which we produce the goods, which we can freely control. In control theory, we say \\(x, y\\) are state variables, and \\(\\dot x, \\dot y\\) are control variables.\nThe cost function is \\(L(t, x, y, \\dot x, \\dot y) = \\sqrt{\\dot x^2 + \\dot y^2}\\). Its integral \\(S = \\int_0^1 L dt\\) is the total cost of production, which we must minimize.\nWe are also given a free market on which we are allowed to buy and sell the goods. If we cannot achieve the production target, we buy from the market. If we achieve more than the production target, we sell them off.\nThen, the total cost is\n\\[\\left(\\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt + p_x \\left( A - \\int_0^1 \\dot x dt\\right) + p_y \\left( B - \\int_0^1 \\dot y dt\\right) \\right)\\]\nwhere \\(p_x, p_y\\) are the market prices which do not change with time.\nIf our production plan is optimal, then the plan must have stationary cost. That is, if we make a change in our production plan \\((\\dot x, \\dot y)\\) by \\(O(\\delta)\\), our production cost must not change by \\(O(\\delta)\\), or else we could achieve lower cost. For example, if the plan \\((\\dot x + \\delta \\dot x, \\dot y + \\delta \\dot y)\\) achieves higher cost, then \\((\\dot x - \\delta \\dot x, \\dot y - \\delta \\dot y)\\) achieves lower cost.\nMathematically, it means the optimal production plan must satisfy\n\\[\\delta \\left(\\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt + p_x \\left( A - \\int_0^1 \\dot x dt\\right) + p_y \\left( B - \\int_0^1 \\dot y dt\\right) \\right) = 0\\]\nNow, the great thing about the market is that it is always there and we can trade with it, So, we have completely transformed the question into a problem of profit maximization – we’ll always sell to the market, and then buy back from the market right at the end.\nNow we can perform profit maximization moment-by-moment: raise production until marginal profit reaches cost:\n\\[\\begin{cases} \\partial_{\\dot x}(\\sqrt{\\dot x^2 + \\dot y^2} - p_x \\dot x - p_y \\dot y )= 0\\\\ \\partial_{\\dot y}(\\sqrt{\\dot x^2 + \\dot y^2} - p_x \\dot x - p_y \\dot y ) = 0 \\end{cases}\\]\nwhich may be solved as before.\nNow we can interpret \\(p_x, p_y\\). What are they? Suppose we perturb \\(\\dot x\\) by \\(\\delta \\dot x\\), then since the production plan is already optimal, we have\n\\[\\delta \\left(\\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt + p_x \\left( A - \\int_0^1 \\dot x dt\\right) + p_y \\left( B - \\int_0^1 \\dot y dt\\right) \\right) = 0\\]\nthat is,\n\\[p_x \\delta \\int_0^1 \\dot xd t = \\delta\\int_0^1 \\sqrt{\\dot x^2 + \\dot y^2}dt\\]\nWe have our interpretation \\(p_x\\): the marginal cost of producing one unit of \\(A\\), That is, if we want an extra \\(\\delta A\\), we have to incur an extra cost \\(p_x \\delta A\\).\nWe actually have \\(p_x = \\cos \\theta, p_y = \\sin\\theta\\), which means that when \\(x, y\\) are perturbed by \\(\\delta x, \\delta y\\), the shortest length between them is perturbed by\n\\[p_x \\delta x + p_y \\delta y = \\cos\\theta \\delta x + \\sin\\theta \\delta y\\]\nwhich is clearly true by geometry.\n\n\n\n\n\n\nThe market inside our head\n\n\n\n\n\nWe actually don’t need an external market. We could have put up such a fictional market inside the factory, and simply read out its price \\(p_x, p_y\\) without ever trading with it. Why? Because in this problem, a solution exists, and under some niceness assumptions, there exists a \"fair\" market price at which we are indifferent to trading with the market – we can sell \\(\\delta x\\) and buy \\(\\delta y\\), but there is \"no point to it\" because it doesn’t change our eventual cost. Thus, although the market exists, we never actually trade with it, so the market might as well be a card-board cutout with a number display of the latest prices. As long as we don’t actually try to trade with it, we would be behaving exactly as if we are facing a real market with the same prices.\nIt is perhaps best to think of the markets as things inside the head, a system of mental accounting to assign the proper price of everything. If the market prices are truly efficient, then we don’t need a real market to trade with.\n\nWhen the producer is ready, the market appears.\nWhen the producer is truly ready, the market disappears.\n\n\n\n\n\n\nIsoperimetric problem\nIf we have a rope of length \\(S\\), and wish to span it from \\((0, 0)\\) to \\((T, h)\\), what shape should the rope have, in order to maximize the area under the rope? In formulas, we model the rope as a differentiable function \\(x(t): [0, T] \\to \\mathbb R\\), such that\n\\[\\begin{cases}\n\\max \\int_0^T xdt\\\\\n\\int_0^T \\sqrt{1 + \\dot x^2}dt = S \\\\\n\\int_0^T \\dot x dt = h\n\\end{cases}\\]\nHere we have two constraints, but the solution is essentially the same. First, to take care of the two constraints, we open two markets \\(p_h, p_S\\) – one for the price of height, and another for the price of rope. Then, solve for\n\\[\\delta \\int_0^T \\left(x + p_h \\left(\\frac hT - \\dot x\\right) +  p_S\\left(\\frac ST - \\sqrt{1+\\dot x^2}\\right)\\right) dt = 0\\]\nThe state variable is \\(x\\), and the control variable is \\(\\dot x\\). Unlike the previous problem, here we need to maximize the integral of the state variable. Consequently, we consider it as a problem of \"profit flows\".\nTo make things more clear, let’s explicitly write \\(v\\) as a control variable, and say that the control system satisfies:\n\\[\\begin{cases}\nv \\text{ is a control variable}\\\\\nx \\text{ is a state variable}\\\\\n\\dot x = v\n\\end{cases}\\]\nGiven that, how do we control the system? Again, it comes down to putting a price on everything, and maximizing at each instant. So, let’s open a market on commodity \\(x\\), such that the \"fair\" price is \\(p(t)\\) at time \\(t\\). With that, we can write down the profit flow\n\\[H = x + p_h \\left(\\frac hT - v\\right) +  p_S\\left(\\frac ST - \\sqrt{1+v^2}\\right) + p v\\]\nand maximizing profit over all time implies maximizing profit flow at every instant:\n\\[\\partial_v H= 0\\]\nThis gives us one equation, but we need one more equation. Namely, we need to know how \\(p(t)\\), the “fair” price of \\(x\\), changes with time.\nThe fundamental problem in pricing theory is this: how do we put a price on something? The fundamental reply from pricing theory is: no-arbitrage (no free money).\nHere is how the no-arbitrage argument works. Suppose that we have been following our optimal production plan. Then at time \\(t\\), we suddenly decide to buy an extra \\(\\delta x\\) from the market, save it, then sell \\(\\delta x\\) at time \\(t+ \\delta t\\).\nNow, since \\(\\dot x = v\\), this buying-and-selling plan does not change how much \\(x\\) grows, so after time \\(\\delta t\\), we have \\(\\delta x(t + \\delta t) = \\delta x(t)\\). Thus, the no-arbitrage equation states:\n\\[p(t)\\delta x(t) = p(t + \\delta t)\\delta x(t + \\delta t)  + \\delta x(t) \\delta t \\implies p(t+ \\delta t) = p(t) - \\delta t\\]\nand consequently, \\(\\dot p = -1\\). This is the price dynamics. Intuitively, we see that the value of a standing stock of \\(x\\) decreases as we run out of time to use it for producing.\nTo solve\n\\[\\partial_v  H= 0\\]\nfirst expand it to\n\\[-p_h + p - p_S \\frac{\\dot x}{\\sqrt{1 + \\dot x^2}} =  0\\]\nthen take derivative with respect to \\(t\\), to obtain\n\\[-\\frac{\\ddot x}{(1+\\dot x^2)^{3/2}} = \\frac{1}{p_S}\\]\nFrom elementary calculus, we know the item on the left is the curvature, so we find that the line \\(x(t)\\) is a constant-curvature curve – circular arc. The radius of the circle is the inverse of curvature, which is exactly \\(p_S\\). Thus we find that, if we are given \\(\\delta S\\) more rope, we can encircle \\(R\\delta S\\) more area under the rope, where \\(R\\) is the radius of curvature for the circular arc.\nNotice that there we are not given the sign of \\(p_S\\). There are in general two solutions, one being a circular arc curving downwards, and the other curving upwards. If we use \\(p_S &lt; 0\\), then we get the one curving upwards, and so we get the solution that achieves minimal area under the rope. If we use \\(p_S &gt; 0\\), then we get the maximal solution. This is a general fact about such problems."
  },
  {
    "objectID": "blog/posts/art/index.html#isoperimetric-problem",
    "href": "blog/posts/art/index.html#isoperimetric-problem",
    "title": "Analytical mechanics",
    "section": "Isoperimetric problem",
    "text": "Isoperimetric problem\nIf we have a rope of length \\(L\\), and wish to span it from \\((0, 0)\\) to \\((T, h)\\), what shape should the rope have, in order to maximize the area under the rope? In formulas, we model the rope as a differentiable function \\(x(t): [0, T] \\to \\mathbb R\\), such that\n\\[\\begin{cases}\n\\max \\int_0^T xdt\\\\\n\\int_0^T \\sqrt{1 + \\dot x^2}dt = L \\\\\n\\int_0^T \\dot x dt = h\n\\end{cases}\\]\nHere we have two constraints, but the solution is essentially the same. First, we write down two Lagrangian multipliers \\(p_h, p_L\\) to take care of the two constraints, then solve for\n\\[\\delta \\int_0^T \\left(x + p_h \\left(\\frac hT - \\dot x\\right) +  p_L\\left(\\frac LT - \\sqrt{1+\\dot x^2}\\right)\\right) dt\\]\nThe state variable is \\(x\\), and the control variable is \\(\\dot x\\). Unlike the previous problem, here we need to maximize the integral of the state variable. Consequently, we consider it as a problem of \"profit flows\".\nTo make things more clear, let’s explicitly write \\(v\\) as a control variable, and say that the control system satisfies:\n\\[\\begin{cases}\nv \\text{ is a control variable}\\\\\nx \\text{ is a state variable}\\\\\n\\dot x = v\n\\end{cases}\\]\nGiven that, how do we control the system? Again, it comes down to putting a price on everything, and maximizing at each instant. So, let’s open a market on commodity \\(x\\), such that the \"fair\" price is \\(p(t)\\) at time \\(t\\). With that, we can write down the profit flow\n\\[H = x + p_h \\left(\\frac hT - v\\right) +  p_L\\left(\\frac LT - \\sqrt{1+v^2}\\right) + p v\\]\nand maximizing profit over all time implies maximizing profit flow at every instant:\n\\[\\partial_v H= 0\\]\nThe fundamental problem in pricing theory is this: how do you put a price on something? The fundamental reply from pricing theory is: no-arbitrage. That is, you pay exactly what you get. So now assume that we get gifted an extra \\(\\delta x\\) at time \\(t\\). We should be indifferent to whether to sell it now, or use it for production now and sell it at time \\(t+\\delta t\\). Now, since \\(\\dot x = v\\), the shock does not change how much \\(x\\) grows, so we have \\(\\delta x(t + \\delta t) = \\delta x(t)\\). Thus, the no-arbitrage equation states:\n\\[p(t)\\delta x(t) = p(t + \\delta t)\\delta x(t + \\delta t)  + \\delta x(t) \\delta t \\implies p(t+ \\delta t) = p(t) - \\delta t\\]\nand consequently, \\(\\dot p = -1\\). This is the price dynamics. Intuitively, the value of holding a stock of \\(x\\) keeps decreasing as you run out of time to use it for producing.\nTo solve\n\\[\\partial_v  H= 0\\]\nfirst expand it to\n\\[-p_h + p - p_L \\frac{\\dot x}{\\sqrt{1 + \\dot x^2}} =  0\\]\nthen take derivative with respect to \\(t\\), to obtain\n\\[-\\frac{\\ddot x}{(1+\\dot x^2)^{3/2}} = \\frac{1}{p_L}\\]\nFrom elementary calculus, we know the item on the left is the curvature, so we find that the line \\(x(t)\\) is a constant-curvature curve – circular arc. The radius of the circle is the inverse of curvature, which is exactly \\(p_L\\). Thus we find that, if we are given \\(\\delta L\\) more rope, we can encircle \\(R\\delta L\\) more area under the rope, where \\(R\\) is the radius of curvature for the circular arc.\nNotice that there we are not given the sign of \\(p_L\\). There are in general two solutions, one being a circular arc curving downwards, and the other curving upwards. If we use \\(p_L &lt; 0\\), then we get the one curving upwards, and so we get the solution that achieves minimal area under the rope. If we use \\(p_L &gt; 0\\), then we get the maximal solution. This is a general fact about such problems."
  },
  {
    "objectID": "blog/posts/art/index.html#lagrangian-and-hamiltonian-mechanics",
    "href": "blog/posts/art/index.html#lagrangian-and-hamiltonian-mechanics",
    "title": "Analytical mechanics",
    "section": "Lagrangian and Hamiltonian mechanics",
    "text": "Lagrangian and Hamiltonian mechanics\nGeneralizing from our experience above, we consider a generic function \\(L(t, q, v)\\), with finitely many state variables \\(q_1, ..., q_N\\). For each state variable \\(q_i\\), we regard its time-derivative as a control variable \\(v_i\\), which we are free to vary. Our goal is to design a production plan \\(t \\mapsto v(t)\\), such that\n\\[\\delta \\int L(t, q(t), v(t)) dt = 0, \\quad \\dot q = v\\]\nTo comply with general sign conventions, we interpret \\(L\\) as cost-per-time, so we say we want to minimize it (even though we only want to stationarize it).\nWe can understand \\(i\\in\\{1, 2,..., N\\}\\) to denote a commodity, say timber and sugar (let’s say there is such a thing as \"negative 1 ton timber\" – that is, we can short-sell commodities). Let \\(p_i\\) be the market price of commodity \\(i\\). Again, there is no need for real market to trade with if the prices are right, since at the right price (no-arbitrage price), we are indifferent between buying and selling, or producing and consuming. It is purely a \"mental accounting\" device.\nWith access to a market, our profit flow is:\n\\[H(t, q, p, v) := \\underbrace{\\sum_i p_i v_i}_{\\text{revenue flow}} - \\underbrace{L(t, q, v)}_{\\text{cost flow}}\\]\nIn words, \\(H(t, q, p, v)\\) is the rate of profit at time \\(t\\) if we hold a stock of commodity \\(q\\), is producing at rate \\(v\\), and the market price of commodities is \\(p\\). This is close to the Hamiltonian, but not yet. We still need to remove the dependence on \\(v\\).\nMoment-by-moment profit-flow maximization is myopic, and could lead us into deadends. That is, it is not a sufficient condition for global profit-maximization. However, it is a necessary condition. That is, suppose we are given a profit-maximizing trajectory, then it must maximize profit flow at every moment, since otherwise we could improve it. In formula:\n\\[v = \\mathop{\\mathrm{arg\\,max}}_v \\left(\\sum_i p_i v_i - L(t, q, v)\\right)\\]\nSo, define the \"optimal controller\" as\n\\[v^\\ast (t, q, p) = \\mathop{\\mathrm{arg\\,max}}_v \\left(\\sum_i p_i v_i - L(t, q, v)\\right)\\]\nand define \\(H\\) as the \"maximal profit flow\" function:\n\\[H(t, q, p) = \\max_{v} \\left(\\sum_i p_i v_i - L(t, q, v)\\right) = \\sum_i p_i v_i^\\ast(t, q, p) - L(t, q, v^\\ast(t, q, p))\\]\nBy basic convex analysis, if \\(L\\) is strictly convex with respect to \\(v\\), then \\(v^*\\) is determined uniquely by \\((t, q, p)\\), and furthermore, it is a continuous function of \\((t, q, p)\\). Consequently, \"profit maximization\" allows us to model the system in \\((t, q, p)\\) instead of \\((t, q, v)\\) coordinates, and the dynamics of the system is equivalently specified by either \\(H\\) or \\(L\\).\nThis is the mysterious \"Legendre transform\" that they whisper of. It is better called \"convex dual\". I also like to joke that the real reason that momentum is written as \\(p\\) is because it secretly means \"price\"!\n\nDerivatives of \\(H\\)\n\nTheorem 1 (Hotelling’s lemma) \\(H(t, q, p)\\) is differentiable with respect to \\(p\\), and \\[\n\\begin{cases}\n    \\partial_t H(t, q, p) &= -(\\partial_t L)(t, q, v^\\ast(t, q, p)) \\\\\n    \\nabla_p H(t, q, p) &= v^\\ast(t, q, p) \\\\\n    \\nabla_q H(t, q, p) &= -(\\nabla_q L)(t, q, v^\\ast(t, q, p)) \\\\\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe prove the first formula. The other two are proved in the same way.\nThe argument is by no-arbitrage. We can imagine what happens if we were to suffer a little price-shock \\(\\delta p\\), adjust our production plan accordingly to \\(v + \\delta v\\), then hold that production plan and suffer another little price-shock \\(-\\delta p\\). Since we are back to the original price \\(p\\) again, we should have no more than the maximal profit rate. That is, we should have\n\\[\\underbrace{H(t, q, p)}_{\\text{maximal rate before shock}} \\geq \\underbrace{H(t, q, p+\\delta p)}_{\\text{maximal rate after shock}} + \\underbrace{\\langle -\\delta p, v^\\ast(t, q, p+\\delta p) \\rangle}_{\\text{undoing the shock, holding price steady}}\\]\nSince \\(\\delta p\\) is infinitesimal, this implies \\(\\left\\langle-\\delta p , \\nabla_v H\\right\\rangle \\geq \\left\\langle-\\delta p , v^*(t, q, p)\\right\\rangle + O(\\delta^2)\\) for all \\(\\delta p\\), implying \\(\\nabla_v H = v^\\ast(v^*(t, q, p))\\).\n\n\n\nHere, we explicitly put a bracket around \\(\\partial_t L\\) to emphasize that we mean\n\\[\\lim_{\\epsilon \\to 0} \\frac{L(t + \\epsilon, q, v^\\ast(t, q, p)) - L(t, q, v^\\ast(t, q, p))}{\\epsilon}\\]\nrather than\n\\[\\lim_{\\epsilon \\to 0} \\frac{L(t + \\epsilon, q, v^\\ast(t + \\epsilon, q, p)) - L(t, q, v^\\ast(t, q, p))}{\\epsilon}\\]\nand similarly for \\(\\nabla_q L\\).\n\n\nHamiltonian equations of motion\nWe are given free control over \\(\\dot q\\), and we saw that the cost-minimizing trajectory must maximize the profit flow moment-by-moment. That is,\n\\[\\dot q(t) = v^\\ast(t, q(t), p(t)) = (\\nabla_p H)(t, q(t), p(t))\\]\nor more succinctly (you can see why we tend to be rather sloppy with notations!)\n\\[\\dot q \\underbrace{=}_{\\text{optimality}} v^\\ast \\underbrace{=}_{\\text{Hotelling's lemma}} \\nabla_p H\\]\nMore evocatively speaking, we have two opposing forces of greed and no-arbitrage, clashing together to give something interesting:\n\\[\\dot q \\underbrace{=}_{\\text{we are greedy}} v^\\ast \\underbrace{=}_{\\text{but the market gives us no free money}} \\nabla_p H\\]\nIt remains to derive \\(\\dot p\\) by the no-arbitrage condition: If we shock the system with some \\(\\delta q_i\\), it does not matter if we sell it now, or carry it \\(\\delta t\\), incurring additional cost, and sell it later. That is,\n\\[p_i(t) \\delta q_i = p_i(t+\\delta t) \\delta q_i - \\partial_{q_i} L(t, q, v) \\delta q_i \\delta t \\implies \\dot p_i = \\partial_{q_i} L(t, q, v)\\]\n\n\n\n\n\n\nTip 1: higher-order infinitesimal\n\n\n\nThe equality should be more precisely read as \"up to a higher-order infinitesimal than \\(\\delta q_i\\delta t\\)\". That is, we should be writing:\n\\[\np_i(t) \\delta q_i = p_i(t+\\delta t) \\delta q_i - \\partial_{q_i} L(t, q, v) \\delta q_i \\delta t  + o(\\delta q_i\\delta t)\n\\]\nThis detail would come up later in our proof of the Hamilton–Jacobi equation.\n\n\nSince we are only concerned with what happens on the optimal trajectory, we always choose \\(v = v^\\ast\\), so\n\\[\\dot p_i = (\\partial_{q_i} L)(t, q, v^\\ast(t, q, p)) \\underbrace{=}_{\\text{Hotelling's lemma}} -\\partial_{q_i} H(t, q, p)\\]\nThus, we obtain the two fundamental equations of Hamiltonian mechanics:\n\nTheorem 2 (Hamilton equations of motion) \\[\\begin{cases}  \n\\partial_t H &= -\\partial_t L \\\\\n\\dot p = -\\nabla_q H \\\\     \n\\dot q = \\nabla_p H\n\\end{cases}\\]\n\n\n\nEuler–Lagrange equations of motion\nBy definition,\n\\[H(t, q, p) =  \\max_{v} \\left(\\sum_i p_i v_i - L(t, q, v)\\right) =  \\sum_i p_i v_i^\\ast(t, q, p) - L(t, q, v^\\ast(t, q, p))\\]\nand since \\(L\\) is strictly convex in \\(v\\), this can be inverted (this is called \"convex duality\") to give\n\\[L(t, q, v) =  \\max_{p} \\left(\\sum_i p_i v_i - H(t, q, p)\\right) =  \\sum_i p^\\ast_i v_i - H(t, q, p^\\ast(t, q, p))\\]\nwhere \\(p^\\ast = \\mathop{\\mathrm{arg\\,max}}_p \\sum_i p_i v_i - H(t, q, p)\\). It is a basic theorem in convex geometry that, if \\(L\\) is strictly convex in \\(v\\), then \\(H\\) is strictly convex in \\(p\\), so the inversion works.\nBy the same argument as in Hotelling’s lemma, we have\n\\[\\nabla_v L(t, q, v) = p^\\ast(t, q, v)\\]\nBy definition of the convex dual, for any \\(t, q, p, v\\), we have\n\\[H(t, q, p) + L(t, q, v) \\leq \\sum_i p_i v_i\\]\nwith equality reached iff both \\(p = p^\\ast(t, q, v)\\) and \\(v = v^\\ast(t, q, p)\\). Thus, on any optimal trajectory, since \\(v = v^\\ast(t, q, p)\\), we must also have \\(p = p^\\ast(t, q, v)\\), and consequently,\n\\[\\frac{d}{dt} \\nabla_v L \\underbrace{=}_{\\text{Hotelling's lemma}} \\dot p^\\ast \\underbrace{=}_{\\text{optimality}} \\dot p \\underbrace{=}_{\\text{no-arbitrage}} \\nabla_q L\\]\nThis is the famous\n\nTheorem 3 (Euler–Lagrange equations of motion) \\[\n\\frac{d}{dt} (\\partial_{v_i} L) = (\\nabla_{q_i} L) \\quad \\forall i \\in \\{1, 2, \\dots, N\\}\n\\]\nor more succinctly,\n\\[\n\\frac{d}{dt} (\\nabla_v L) = \\nabla_q L\n\\]\n\n\n\n\n\n\n\nexplaining the notation\n\n\n\n\n\nPhysicists are often sloppy with notations, but the Euler–Lagrange equation is particularly egregious in this regard, so I will describe it carefully.4\nThe function \\(L\\) is a function of type \\(\\underbrace{\\mathbb{R}}_{\\text{time}} \\times \\underbrace{\\mathbb{R}^N}_{\\text{state}} \\times \\underbrace{\\mathbb{R}^N}_{\\text{control}} \\to \\mathbb{R}\\).\nThe function \\(\\partial_{v_i} L\\) is also a function of type \\(\\mathbb{R}\\times \\mathbb{R}^N \\times \\mathbb{R}^N \\to \\mathbb{R}\\). It is obtained by taking derivative of \\(L\\) over its \\((1 + i)\\)-th input. Let’s write that as \\(f_i\\) to make sure we are not confused by it. It is absolutely important to be clear about this! \\(f_i\\) is not a function defined only along a trajectory, but over the entire space of \\(\\mathbb{R}\\times \\mathbb{R}^N \\times \\mathbb{R}^N\\). We can similarly define \\(f_{i + N}\\) to be \\(\\partial_{q_i} L\\).\nNow, suppose we are given a purportedly optimal trajectory \\(q: \\mathbb{R}\\to \\mathbb{R}^N\\), then for any coordinate \\(i \\in \\{1, 2, \\dots, N\\}\\), we can define a function \\(g_i\\), of type \\(\\mathbb{R}\\to \\mathbb{R}\\) by\n\\[\ng_i(t) = f_i(t, q(t), \\dot q(t))\n\\]\nand similarly, we can define \\(g_{i + N} = f_{i + N}(t, q(t), \\dot q(t))\\).\nThe Euler–Lagrange equations say that, we need only check\n\\[\ng_i'(t) = g_{i+N}(t) \\quad \\forall t \\in [0, T], i \\in 1:N\n\\]\nto certify that the purportedly stationary trajectory \\(q\\) is truly stationary.\n\n\n\n4 I am okay with sloppy notation sometimes, but in this case, the sloppy notation often leads to calculational mistakes and conceptual confusions, as teachers of undergrad courses can testify.\n\nWhat does it all mean?\nIn the Lagrangian formalism, we are given a system with \\(q\\) coordinates, and allowed to manipulate \\(\\dot q\\) however we want, in order to minimize a \"cost\" function \\(\\int_0^T L(t, q, \\dot q)dt\\).\nIn the Hamiltonian formalism, we are also given a market to trade with. We attempt to maximize profit by varying production, buying, and selling. However, the market simultaneously adjusts its prices \\(p\\) in just the right way so that we are always indifferent about the market (if we are ever not indifferent, the market is in serious trouble – it doesn’t actually carry any real commodity!), so we never actually make any trade. The market has been in our heads all along, but its effects are very real.\nAssuming this kind of double optimization (we against the market, and the market against us), the trajectory is uniquely determined by several possible specifications. We may fix it by \\((t_0, q_0, p_0)\\), or by \\((t_0, q_0), (t, q)\\), or by \\((t_0, q_0, v_0)\\), or perhaps more exotic constraints that mix up \\(t, q, p, v\\).\nIronically, the Hamiltonian equations of motion flow out naturally in this economic interpretation, with no fuss whatsoever. The Euler–Lagrange equations are derived only as an after-thought. This is exactly backwards compared to the usual way of teaching, where the EL equations are derived first, and the Hamiltonian equations are derived by an unmotivated “Let us define \\(H = \\sum_i p_i q_i - L\\) …”, followed by some clumsy and unjustified derivations.\nIn classical control theory, the price vector \\(p\\) is called \"costate\" since it is multiplied with the state \\(q\\), and \\(\\dot p= -\\nabla_q H\\) is called the \"costate equation\". The above methods can be generalized to account for constraints, yielding Pontryagin’s maximum principle, among other results.\n\n\nCyclic coordinates\nGiven a system defined by a Lagrangian function \\(L(t, q, v)\\), we say that it is cyclic in the coordinate \\(q_i\\) if \\(L\\) does not depend on \\(q_i\\). By definition of\n\\[H(t, q, p) = \\max_v \\left(\\sum_i p_i v_i - L(t, q, v)\\right)\n\\]\nwe see that if \\(L\\) does not depend on \\(q_i\\), then \\(H\\) also does not depend on \\(q_i\\). Consequently, any optimal trajectory satisfies \\(\\dot p_i = -\\partial_{q_i} H = 0\\). That is, \\(p_i\\) is conserved – conservation of generalized momentum.\n\n\nBonus: Routhian mechanics\nSuppose that the market does not contain all commodities, but only the last \\(n\\) commodities. That is, let \\(q_{1:N} = (q_{1:s}, q_{s+1:s+n})\\), and only open markets on \\(q_{s+1:s+n}\\). The optimal cash flow equation then gives us the \"Routhian\":\n\\[\nR(t, q, v_{1:s}, p_{s+1:N}) = \\max_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\n\\]\nAs before, the optimal control variables are \\(v_{s+1:N}^\\ast = \\mathop{\\mathrm{arg\\,max}}_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\\).\n\nTheorem 4 (Routhian equations of motion) \\[\n\\begin{cases}\n    \\partial_t R &= -\\partial_t L \\\\\n    \\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n    \\begin{cases}\n    \\dot q_i = \\partial_{p_i} R \\\\ \\dot p_i = -\\partial_{q_i} R\n    \\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy the same argument as in Hotelling’s lemma, we have\n\\[\n\\begin{cases}\n    \\partial_t R = -\\partial_t L \\\\\n    \\nabla_q R = -\\nabla_q L \\\\\n    \\nabla_{v_{1:s}} R = -\\nabla_{v_{1:s}} L \\\\\n    \\nabla_{p_{s+1 : N}} R = v^*_{s+1 : N}\n\\end{cases}\n\\]\nPlugging the 2-th and 3-th equations into the original Euler–Lagrange equations, we obtain\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThe 4-th equation gives\n\\[\\dot q_i =v_i^\\ast = \\partial_{p_i} R, \\quad \\forall i\\in s+1:N\\]\nFor \\(i\\in s+1:N\\), we can obtain the price dynamic of the partial market by the no-arbitrage condition, giving\n\\[\\dot p_i = \\partial_{q_i} L = -\\partial_{q_i} R\\]\n\n\n\nWe see that the first \\(s\\) equations look just like the EL equations, but the next \\(2n\\) equations look just like the Hamiltonian equations. The Routhian equations make an awkward hybrid.\n\n… as a fundamental entity, the Routhian is a sterile hybrid, combining some of the features of both the Lagrangian and the Hamiltonian pictures. For the development of various formalisms of classical mechanics, the complete Hamiltonian formulation is more fruitful.\n(Goldstein, Poole, and Safko 2008, sec. 8.3)\n\n\nApplication to cyclic coordinates\nThough the Routhian equations are theoretically useless, they are useful for solving specific problems. For some worked examples of using the Routhian, see the Wikipedia page.\nWhile the Euler–Lagrangian equations are \\(N\\) second-degree differential equations, the Hamiltonian equations are \\(2N\\) first-degree differential equations. We are essentially trading derivatives for equation numbers.\nThough the EL equations and the Hamiltonian equations are philosophically different, for solving particular problems, they often end up giving the same equations anyway. Specifically, if we are solving the Hamiltonian equations for a concrete example, by eliminating the variables \\(p\\), we often end up right back to the Euler–Lagrange equations. This would be quite the detour, and if there are cyclic coordinates, the Routhian could save us some trouble.\nIf we have a system that is cyclic in the last \\(n\\) coordinates, then since \\(\\nabla_q R = -\\nabla_q L\\), its Routhian satisfies \\(\\partial_{q_i} R = 0\\) for the last \\(n\\) coordinates too. Then we find that the Routhian equations become:\n\\[\n\\begin{cases}\n\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} R \\\\  p_i = p_i(0)\n\\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\ngiving us \\(n\\) first-degree equations and \\(N-n\\) second-degree equations. If we were to start with the Hamiltonian equations of motion, we would get\n\\[\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} H \\\\  p_i = p_i(0)\n\\end{cases}\\quad i\\in s+1:N\n\\]\nby the same reasoning, and then laboriously eliminate the variables \\(p_i\\) for \\(i \\in 1:s\\), and end up with \\(s\\) second-degree differential equations, often exactly the same as the first \\(s\\) Routhian equations:\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThis is how the Routhian saves us some effort in practical calculations. It is useful in this way, and in this way only."
  },
  {
    "objectID": "blog/posts/art/index.html#higher-order-lagrangians-and-hamiltonians",
    "href": "blog/posts/art/index.html#higher-order-lagrangians-and-hamiltonians",
    "title": "Analytical mechanics",
    "section": "Higher-order Lagrangians and Hamiltonians",
    "text": "Higher-order Lagrangians and Hamiltonians\nWhat happens if we use a Lagrangian with higher-order derivatives? It turns out that even in this case, we can still use economic reasoning to derive its Hamiltonian and Euler–Lagrangian equations\n\nExercise 1 Read the following sections, then generalize the derivation to \\(n\\)-th-order derivatives.\n\nThis construction of Hamiltonians from higher-order Lagrangians is often called Ostrogradsky theorem or Ostrogradsky instability, because Ostrogradsky published it in 1850 (Ostrogradsky 1850) after seeing Hamilton’s paper of 1833 (Hamilton 1833). He did not note its implications for instability, which was first noted by Pais and Uhlenbeck in 1950 (Pais and Uhlenbeck 1950). For this reason, it’s also called the Pais–Uhlenbeck model.\n\nWhen Lagrangian also depends on acceleration\nWhen the Lagrangian depends not just on position and velocity, but also acceleration, the total cost to be optimized is:\n\\[S(q) := \\int L(t, q^{(0)}, q^{(1)}, q^{(2)})dt\\]\nwhere \\(q^{(n)}\\) is a symbol that suggests itself to be the \\(n\\)-th time-derivative of the optimal trajectory \\(q\\), although it is actually defined for any tuple of real numbers, even when we don’t have \\(q^{(1)}(t) = \\frac{d}{dt}q^{(0)}(t)\\).\nOur previous method, which is to open a market on position \\(q\\), fails for two reasons:\n\nThe producer cannot optimize its velocity, because now velocity is no longer a control variable. Now, both position and velocity are state variables, and only acceleration is a control variable.\nThe producer cannot buy and sell velocity, so it has no price signal to optimize its acceleration (how fast it produces velocity).\n\nIf the market fails, make it bigger: allow the market to buy and sell not just position, but also velocity.\nWe open a market of both positions and velocities. The price vector of positions is \\(p^{(0)}\\) and the price vector of velocities is \\(p^{(1)}\\). Then, the maximal profit flow is\n\\[H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}) = \\max_{ q^{(2)}} (\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nand the optimal production plan is\n\\[q^{(2)\\ast} = \\mathop{\\mathrm{arg\\,max}}_{ q^{(2)}}(\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - L)\\]\n\n\nHamiltonian equations\nWe can prove the Hotelling’s lemma for this Hamiltonian, using the same no-arbitrage argument as before:\n\\[\\begin{cases}     \n    \\partial_t H = -\\partial_t L \\\\  \n    \\nabla_{q^{(0)}} H = -\\nabla_{q^{(0)}} L \\\\     \n    \\nabla_{q^{(1)}} H = p^{(0)}-\\nabla_{q^{(1)}} L \\\\     \n    \\nabla_{p^{(0)}} H = q^{(1)} \\\\     \n    \\nabla_{p^{(1)}} H = q^{(2)\\ast}\n\\end{cases}\\]\nAlong an optimal trajectory, the producer always chooses \\(\\dot q^{(1)} = q^{(2)\\ast}\\), and has no choice in \\(\\dot q^{(0)} = q^{(1)}\\), so we have two equations of motion:\n\\[\\begin{cases}     \n\\dot q^{(1)} = q^{(2)\\ast} = \\nabla_{p^{(1)}} H\\\\    \n\\dot q^{(0)} = q^{(1)} = \\nabla_{p^{(0)}} H\n\\end{cases}\\]\nThe market must adjust its prices by the no-arbitrage condition, as before. If we inflict a position shock of \\(\\delta q^{(0)}\\), then by no-arbitrage, selling it now or later is equally (up to order \\(\\delta^2\\)) profitable:\n\\[\\langle p^{(0)} , \\delta q^{(0)}\\rangle = \\langle p^{(0)} + \\dot p^{(0)} \\delta t , \\delta q^{(0)}\\rangle - \\langle \\nabla_{q^{(0)}} L , \\delta q^{(0)}\\rangle \\delta t\\]\nyielding \\(\\dot p^{(0)} = \\nabla_{q^{(0)}} L = -\\nabla_{q^{(0)}} H\\).\nFor the last equation of motion, inflict a velocity shock of \\(\\delta q^{(1)}\\). The effect of the shock include both its effect on \\(q^{(0)}\\) and \\(L\\), thus the no-arbitrage equation states:\n\\[\\underbrace{\\langle p^{(1)} , \\delta q^{(1)}\\rangle}_{\\text{selling now}} =  \\underbrace{\\langle p^{(1)} + \\dot p^{(1)} \\delta t , \\delta q^{(1)}\\rangle}_{\\text{selling later}} + \\underbrace{\\langle p^{(0)} + \\dot p^{(0)} \\delta t , \\delta q^{(1)}\\delta t\\rangle}_{\\text{profit from extra }p^{(0)}} - \\underbrace{\\langle \\nabla_{q^{(1)}} L , \\delta q^{(1)}\\rangle \\delta t}_{\\text{cost from holding extra }p^{(1)}}\\]\nwhich yields the last equation \\(\\dot p^{(1)} = \\nabla_{q^{(1)}} L - p^{(0)} = -\\nabla_{q^{(1)}} H\\).\nIn summary, we have\n\nTheorem 5 (higher-order Hamiltonian equations of motion:) \\[\n\\begin{cases}     \n    \\dot q^{(1)} = \\nabla_{p^{(1)}} H\\\\     \n    \\dot q^{(0)} = \\nabla_{p^{(0)}} H \\\\     \n    \\dot p^{(0)} = -\\nabla_{q^{(0)}} H \\\\     \n    \\dot p^{(1)} = -\\nabla_{q^{(1)}} H  \n\\end{cases}\n\\]\n\n\n\nEuler–Lagrange equations\nIn order to obtain the Euler–Lagrange equations of motion, we need to work backwards from the Hamiltonian equations of motion as before.\nFrom the Hamiltonian, we can go back to the Lagrangian by inverting the convex transform:\n\\[L(t, q^{(0)}, q^{(1)}, q^{(2)})  = \\max_{p^{(0)} ,p^{(1)}} (\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}))\\]\nHere we are given a hint of the troubles ahead. Since \\(H\\) is linear in \\(p^{(1)}\\):\n\\[H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}) = \\langle p^{(0)} , q^{(1)}\\rangle + \\max_{ q^{(2)}} (\\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nthere is no way to fix \\(p^{(1)}\\) in the inverse transform! In detail, we plug the equation for \\(H\\) into the equation for \\(L\\), to get\n\\[L(t, q^{(0)}, q^{(1)}, q^{(2)}) = \\max_{p^{(0)} ,p^{(1)}} (\\langle p^{(1)} , q^{(2)}\\rangle - \\max_{ q^{(2)}} (\\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nand we see that there is no optimality constraint on \\(p^{(0)}\\). This is a hint of instabilities ahead.\nDifferentiating \\(L\\), we get\n\\[\\begin{cases}\n\\partial_t L = -\\partial_t H\\\\\n\\nabla_{q^{(0)}}L = -\\nabla_{q^{(0)}}H \\\\\n\\nabla_{q^{(1)}}L = p^{(0)} - \\nabla_{q^{(1)}}H \\\\\n\\nabla_{q^{(2)}}L = p^{(1)\\ast}  \n\\end{cases}\\]\nNow, along the optimal trajectory, we must have \\(\\nabla_{q^{(2)}}L = p^{(1)\\ast}\\), so taking its time-derivative, we get\n\\[\\frac{d}{dt}\\nabla_{q^{(2)}}L = \\dot p^{(1)} = -\\nabla_{q^{(1)}}H = \\nabla_{q^{(1)}}L - p^{(0)}\\]\nTake another time-derivative, to obtain the Euler–Lagrange equations of motion:\n\\[\\sum_{i=0}^2\\left(-\\frac{d}{d t}\\right)^i (\\nabla_{q^{(i)}} L ) =0\\]\nThe generalization to \\(L(t, q^{(0)}, ..., q^{(N-1)})\\) is immediate. It can be derived by a similar argument through the market economy.\n\n\nA higher-order oscillator\nConsider the oscillator perturbed by \\(\\epsilon\\):\n\\[L = \\frac 12 m\\dot x^2 - \\frac 12 kx^2 - \\frac 12 \\epsilon \\ddot x^2\\]\nIts EL equation is\n\\[\\epsilon x^{(4)} + m\\ddot x + kx = 0\\]\na linear order-4 equation, so its solutions are of the form \\(x = \\sum_{i=1}^4 a_i e^{z_i t}\\), where \\(z_1, z_2, z_3, z_4\\) are its fundamental (complex) frequencies. Plug them in the equation and solve it simply:\n\\[z = \\pm \\sqrt{-\\frac{1}{2\\epsilon} (m \\pm \\sqrt{m^2 - 4\\epsilon k})}\\]\nAt small \\(|\\epsilon|\\) limit, we have\n\\[z \\approx \\pm i\\sqrt{\\frac km}, \\pm\\sqrt{-\\frac m\\epsilon}\\]\nand so if \\(\\epsilon &lt; 0\\), one of the modes is exponentially growing at rate \\(\\sqrt{m/|\\epsilon|}\\).\n\n\nTwo coupled higher-order oscillators\nNow, if \\(\\epsilon &gt; 0\\), then the oscillator survives just fine, with two modes of oscillation of frequency \\(\\sqrt{\\frac km}\\) and \\(\\sqrt{\\frac{m}{\\epsilon}}\\), but now consider what happens if we make two copies of it and couple them weakly, perhaps by a weak rubber band.\n\n\nThird-order equations of motion\nThird order equations of motion and the Ostrogradsky instability"
  },
  {
    "objectID": "blog/posts/art/index.html#alternative-forms",
    "href": "blog/posts/art/index.html#alternative-forms",
    "title": "Analytical physics",
    "section": "Alternative forms",
    "text": "Alternative forms\n\nRouth’s equation\nWe could open a \"partial\" market where only some, but not all, the commodities are tradable. This would lead us to the Routh’s equations of motion, which are sometimes useful in applications, but never in theoretical physics.\n\nas a fundamental entity, the Routhian is a sterile hybrid, combining some of the features of both the Lagrangian and the Hamiltonian pictures. For the development of various formalisms of classical mechanics, the complete Hamiltonian formulation is more fruitful.\n(Goldstein, Poole, and Safko 2008, sec. 8.3)\n\nLet’s consider the case of performing the convex dual on only the last \\(n\\) coordinates. That is, let \\(q_{1:N} = (q_{1:s}, q_{s+1:s+n})\\), and let \\(L(t, q, v) = L(t, q_{1:s}, v_{1:N})\\). Now performing the convex duality on only the cyclic coordinates, we obtain the \"Routhian\":\n\\[R(t, q, v_{1:s}, p_{s+1:N}) = \\max_{v_{s+1:N}} \\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\]\nBy the same argument as in Hotelling’s lemma, we have\n\\[\\nabla_q R(t, q, v_{1:s}, p_{s+1:N}) = (-\\nabla_q L)(t, q, v_{1:s}, v_{s+1:N}^\\ast(t, q, v_{1:s}, p_{s+1:N}))\\]\nwhere \\(v_{s+1:N}^\\ast = \\mathop{\\mathrm{arg\\,max}}_{v_{s+1:N}} \\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\). More succinctly, \\(\\nabla_q R = -\\nabla_q L\\). Also,\n\\[v_{s+1:N}^\\ast  = \\partial_{p_{s+1:N}} R\\]\nFor \\(i\\in s+1:N\\), the price dynamic of the partial market is found by no-arbitrage condition: \\(\\dot p_i = \\partial_{q_i} L = -\\partial_{q_i} R\\). And as we found in the last paragraph, \\(\\dot q_i =v_i^\\ast = \\partial_{p_i} R\\).\nFor \\(i\\in 1:s\\), by Hotelling’s lemma, \\(\\partial_{v_i} R = -\\partial_{v_i} L\\), and \\(\\partial_{q_i} R = -\\partial_{q_i} L\\), so the Euler–Lagrange equations become\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R\\]\nAll together now:\n\\[\\begin{cases}\n\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\\\\n\\dot q_i = \\partial_{p_i} R, \\dot p_i = -\\partial_{q_i} R \\quad i\\in s+1:N\n\\end{cases}\\]\n\n\nCyclic coordinates\nThe Hamiltonian equations are \\(2N\\) first-degree differential equations:\n\\[\\begin{cases}\n\\dot p_i = -\\partial_{q_i} H \\\\\n\\dot q_i = \\partial_{p_i} H\n\\end{cases}\\]\nWe are essentially trading derivatives for equation numbers – \\(2N\\) first-degree differential equations, or \\(N\\) second-degree differential equations.\nFor explicitly solving (analytically or numerically) equations of motion, we often solve the Hamiltonian equations by eliminating the variables \\(p\\), which leads right back to the Euler–Lagrange equations. In such situations, the Routhian could help.\nGiven a system defined by a Lagrangian function \\(L(t, q, v)\\), we say that it is cyclic in the coordinate \\(q_i\\) if \\(L\\) does not depend on \\(q_i\\). By definition of \\(H(t, q, p) = \\max_v \\sum_i p_i v_i - L(t, q, v)\\), we find that \\(H\\) also does not depend on \\(q_i\\). Consequently, any optimal trajectory satisfies \\(\\dot p_i = -\\partial_{q_i} H = 0\\). That is, \\(p_i\\) is conserved.\nFor example, if the system is a particle of mass \\(m\\) in a potential field \\(V(x)\\), then \\(L = \\frac 12 mv^2 - V(x)\\), and if the field \\(V\\) does not depend on \\(x_3\\), then we find that \\(p_3\\) is a constant of motion – that is, the particle has conserved momentum along the third dimension.\nNow, if we have a system that is cyclic in the last \\(n\\) coordinates, then its Routhian also satisfies \\(\\partial_{q_i} R = 0\\) if \\(q_i\\) is cyclic. Then we find that the Routhian equations become:\n\\[\\begin{cases}\n\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\\\\n\\dot q_i = \\partial_{p_i} R, p_i = p_i(0) \\quad i\\in s+1:N\n\\end{cases}\\]\ngiving us \\(n\\) first-degree equations and \\(N-n\\) second-degree equations."
  },
  {
    "objectID": "blog/posts/art/index.html#hamiltonjacobi-equation",
    "href": "blog/posts/art/index.html#hamiltonjacobi-equation",
    "title": "Analytical mechanics",
    "section": "Hamilton–Jacobi equation",
    "text": "Hamilton–Jacobi equation\nConsider again the integral of Lagrangian: \\(\\int L dt\\). If we fix the starting point \\((t_0, q_0)\\) and the ending point \\((t, q)\\), then in general there can be a countable number of paths that connect both points. This is a serious problem, but we are saved by the fact that these paths are separated, in the sense that around each path \\(\\gamma\\), there is a small neighborhood, in which there exists no other path \\(\\gamma\\) that connects the two points \\((t_0, q_0), (t, q)\\).\nAs a prototype, consider a billiard ball in a circular table.\n\nBilliards in a circular board\nWhen both \\(q_0, q\\) are the center of the billiard table, then there are \\(S^1 \\times \\mathbb{N}\\) ways to go from \\(q_0\\) to \\(q\\) over the interval \\([t_0,t]\\). Here, \\(S^1\\) denotes the circle of possible directions, and \\(\\mathbb{N}\\) denotes the discrete number of starting speeds: \\(\\frac{2R}{t-t_0}, \\frac{4R}{t-t_0}, \\dots\\).\nWhen not both of them are in the center, then there are only in general \\(\\mathbb{N}\\) ways to go from \\(q_0\\) to \\(q\\) over the interval \\([t_0,t]\\).\nConsider a billiard ball in a circular (not elliptical) table. Let \\(q, q_0\\) be any two points inside the table, not both on the center, and \\(t_0 &lt; t\\) be two moments in time, then there are a countable infinity of possible trajectories that reach \\((t, q)\\) from \\((t_0, q_0)\\).\nThere are two ways to see this visually, a particle way and a wave way.\nFor the particle way, define:\n\nthe billiard’s starting angle is \\(\\theta\\), with \\(\\theta\\) chosen such that when \\(\\theta = 0\\), the billiard would move on a diameter of the table.\n\\(l(\\theta, n)\\) is the oriented line segment that starts at the point where the billiard’s hits the table for the \\(n\\)-th time, and ends at the point where it hits for the \\((n+1)\\)-th time.\n\nFor any \\(n = 1, 2, ...\\), as \\(\\theta\\) moves from \\(\\theta = 0\\) to \\(\\theta = \\pi\\), the line \\(l(\\theta, n)\\) smoothly varies from the diameter in one direction to the diameter in the opposite direction. Now, if you take a diameter in the circle, and smoothly turn it around by \\(180^\\circ\\), then no matter how much you shift the line around in the mean time, you are forced to sweep it over every point at least once.5 Consequently, every point can be reached after \\(n\\) reflections, for any positive integer \\(n\\)\n5 If you want a hands-on approach, imagine hammering in a nail at some point \\(q\\) in the circle, and putting a long stick on the diameter. Now grab the stick and start turning it around. There is no way for you to turn it by \\(180^\\circ\\) without hitting the nail at some time.For the wave way, imagine simultaneously shooting out a billiard in every direction with constant speed, and watch the \"wavefront\" of billiards evolve. The wavefront is reflected by the table edges and assumes increasingly complicated shapes, but it remains a closed curve (with possible self-intersections). As the closed curve reverberates across the table again and again, it sweeps across every point in the table again and again at discrete intervals.\nHowever, there is no way to smoothly reach one trajectory from any other – you either have to make a very discrete jump in how hard you strike the billiard ball, or in which direction you strike. This contrasts with the case with both \\(q, q_0\\) at the center, where you can smoothly vary your striking angle while keeping the same striking force.\nSimilarly, for a table with smooth boundary, for almost all point-pairs in the table, there are also a countable infinity of trajectories between them. We must say \"almost all\" to exclude singular cases such as the two focal points of an ellipse, where there is a whole continuum of trajectories between them.6\n6 Exactly counting the singular cases, and studying polygonal, or even non-convex tables, is an ongoing research program, with the name of \"dynamical billiard flow\".What is the general lesson for defining \\(S\\)? In general, we also need to fix a particular optimal path \\(\\tilde\\gamma\\), and only consider optimal paths that are in a small neighborhood of \\(\\tilde \\gamma\\). This is the same idea as selecting a branch cut when dealing with multi-valued functions like the complex logarithm.\nWhy are we so concerned with reflections? Read on!\n\n\n\nThe two ways to find trajectories from \\(q_0\\) to \\(q\\). The particle way involves sending out rays from \\(q_0\\), reflecting off the walls of the table, until a ray hits \\(q\\). The wave way involves sending out an expanding wavefront from \\(q_0\\), rippling through the table, passing over \\(q\\) again and again. The rays are perpendicular to the wavefront in this case.\n\n\n\n\n\nSimilarly, in a rectangular billiard table, there are infinitly many possible ways to go from one point to another, but one cannot go from one way to another continuously.\n\n\n\n\nHamilton’s principal function\nConsider a problem in traveling: Given a starting spacetime \\((t_0, q_0)\\) and an ending spacetime \\((t, q)\\), what is the lowest cost of traveling between them? We want to define it as:\n\\[\nS(t, q; t_0, q_0) = \\int_{t_0}^t L(\\tau, \\gamma(\\tau), \\dot\\gamma(\\tau))d\\tau\n\\]\nwhere \\(\\gamma(\\tau)\\) is the unique path from \\((t_0, q_0)\\) to \\((t, q)\\). However, as we saw in the case of circular billiards, we don’t have a unique path in general. Therefore, we should be a bit more careful.\nFirst, we select a prototypical path \\(\\gamma_{prototype}\\). Next, we smoothly vary \\(\\gamma_{prototype}\\) until it becomes some path \\(\\gamma\\) that goes from \\((t_0, q_0)\\) to \\((t, q)\\). Finally, define the Hamilton’s principal function using this particular \\(\\gamma\\). The construction is a bit awkward, but it would allow us to avoid the non-uniqueness problem.\nThus, we define the Hamilton’s principal function:\n\\[\nS(t, q; t_0, q_0) = \\int_{t_0}^t L(\\tau, \\gamma(\\tau), \\dot\\gamma(\\tau))d\\tau\n\\tag{1}\\]\n\n\nHamilton–Jacobi equation\nFor all nice enough Lagrangian \\(L\\), Hamilton’s principal function \\(S\\) is differentiable with respect to \\((t, q)\\), so we will study its differential equation.\nLet’s first consider the easy case: we simply let the trajectory \"run a little longer\". That is, we let the trajectory run from \\((t_0, q_0)\\) to \\((t, q)\\), then let it keep running for \\(\\delta t\\), reaching \\((t+\\delta t, q + \\delta q)\\). It’s clear that we have \\(\\delta q = \\dot q(t) \\delta t\\), and\n\\[\nS(t+\\delta t, q + \\delta q; t_0, q_0) - S(t, q; t_0, q_0) = \\left(\\sum_i p_i \\dot q_i - H\\right)\\delta t\n\\]\nso we have:\n\\[\n\\partial_t S + \\sum_i \\partial_{q_i}S \\dot q_i = - H + \\sum_i p_i \\dot q_i\n\\tag{2}\\]\nwhich strongly suggests\n\nTheorem 6 \\[\n(-\\partial_t, \\nabla_q)S(t, q; t_0, q_0) = (H, p), \\quad (-\\partial_{t_0}, \\nabla_{q_0})S(t, q; t_0, q_0) = (H_0, p_0)\n\\tag{3}\\]\n\nIf Equation 3 is indeed true, then we have\n\nTheorem 7 (Hamilton–Jacobi equation) \\[\\partial_t S + H(t, q, \\nabla_q S) = 0\\]\n\nIt suffices to prove \\(\\nabla_q S = p\\), since then \\(\\partial_t S = -H\\) follows from Equation 2.\nIt suffices to prove \\((-\\partial_t, \\nabla_q)S(t, q; t_0, q_0) = (H, p)\\), since the other one is proved by the same argument, time-reversed.\nRecall the economic construction of \\(p\\). It is a price vector designed specifically to destroy all arbitrage opportunities. Consequently, we can consider an entire family of paths shown in Figure (a, b).\n\n\n\nDerivation of the Hamilton–Jacobi equation.\n\n\nHere, \\(\\gamma\\) is the path from \\((t_0, q_0)\\) to \\((t, q)\\), and \\(\\gamma + \\delta \\gamma\\) is the path to \\((t, q+\\delta q)\\). We interpolate between them by a family of paths \\(\\{\\gamma_\\tau\\}_{\\tau}\\), where \\(\\gamma_\\tau\\) is the path obtained by first moving on \\(\\gamma\\) for time \\(t\\in [t_0, \\tau]\\), then making a \"jump\" by \"purchasing from the market\"7 an infinitesimal bundle of commodities so that we fall onto the \\(\\gamma + \\delta \\gamma\\) path, then continue along that path.\n7 We are using the market for real now, so the marketeer had better had stocked up on those commodities!8 More precisely, a higher-order infinitesimal than the area of the parallelogram. See Tip 1.Now consider two such jumped-paths, \\(\\gamma_{\\tau}\\) and \\(\\gamma_{\\tau + \\delta \\tau}\\), where \\(\\delta \\tau\\) is an infinitesimal, shown in Figure (c). The cost difference between them is that between two sides of the parallelogram. By the no-arbitrage construction, the difference is zero.8\nThus, we can smoothly \"glide\"9 the path \\(\\gamma\\) to \\(\\gamma + \\delta\\gamma\\) by the family of jumped-paths \\(\\gamma_\\tau\\), with \\(\\tau\\) going from \\(t\\) to \\(t_0\\), with no change in cost.10 Thus, the only cost difference between \\(\\gamma\\) and \\(\\gamma + \\delta\\) is the cost it takes to buy the bundle of commodities \\(\\delta q\\) at the very last instance:\n9 In the jargon of topology, this is a homotopy of paths.10 More precisely, their difference in cost is a higher-order infinitesimal than the area of the curvy triangle between them. Since the curvy triangle is an infinitesimal of order \\(\\delta q\\), the difference in cost is a higher-order infinitesimal than \\(\\delta q\\).\\[S(t, q+\\delta q; t_0, q_0) - S(t, q; t_0, q_0) = \\sum_i p_i \\delta q_i\\]\nfinishing the proof.\n\n\n\n\n\n\nthe usual proof\n\n\n\n\n\nThe HJE has a standard proof, such as the one appearing in (Goldstein, Poole, and Safko 2008, chap. 8). It does not require reasoning with different orders of infinitesimals, but it is less geometrical.\nSketch of the proof:\n\nStart with the original system with configuration space \\((t, q_{1:N}, \\dot q_{1:N})\\).\nMove to the Hamiltonian equations on phase space \\((t, q_{1:N}, p_{1:N})\\).\nRegard that as part of a larger system with configuration space \\((t, q_{1:N}, p_{1:N}, \\dot q_{1:N}, \\dot q_{1:N}))\\)\nWrite down the Euler–Lagrange equations for that larger system.\n\n\n\n\n\nTheorem 8 (Poincaré–Cartan integral invariant (Arnol’d 2001, 237–38)) Draw an arbitrary closed cycle \\(\\alpha\\) in phase space-time. Let every point \\(A \\in \\alpha\\) evolve for some time (not necessarily the same amount of time) to reach some other point \\(A'\\). Let \\(\\alpha'\\) be the cycle consisting of those points \\(A'\\). Then we have the Poincaré–Cartan integral invariant\n\\[\n\\oint_\\alpha \\left\\langle p, dq\\right\\rangle - Hdt = \\oint_{\\alpha'} \\left\\langle p, dq\\right\\rangle - Hdt\n\\]\nAs a special case, if both \\(\\alpha\\) and \\(\\alpha'\\) consists of simultaneous points, then it reduces to the Poincaré relative integral invariant\n\\[\n\\oint_\\alpha \\left\\langle p, dq\\right\\rangle = \\oint_{\\alpha'} \\left\\langle p, dq\\right\\rangle\n\\]\n\n\n\n\n\n\n\nproof\n\n\n\n\n\nDivide the tube into ribbons, like a barrel, then note that the integral around each barrel-plank is zero, as argued before. This is a case of the Stokes’ theorem.\n\nIn more detail, we can consider the four ends of a barrel-plank parallelogram. Label those points as \\(A, B, A', B'\\) as shown. Though the points \\(A, B, A', B'\\) exist in phase space-point, we can forget their momenta, thus projecting them to configuration space-time. Each phase space-time trajectory projects to a trajectory in configuration space-time, and we obtain \\(S_{A \\to B} = S(t_A, q_A; t_B, q_B)\\), etc.\nNow, by Equation 3, we can shift \\(S_{A \\to B}\\) to \\(S_{A \\to B'}\\), then to \\(S_{A' \\to B'}\\):\n\\[\nS_{A \\to B} = S_{A \\to B'}  -H_B \\delta t_B + \\left\\langle p_B , \\delta q_B\\right\\rangle = S_{A' \\to B'} + H_A \\delta t_A - \\left\\langle p_A , \\delta q_A\\right\\rangle -H_B \\delta t_B + \\left\\langle p_B , \\delta q_B\\right\\rangle\n\\]\nNow, if we shift around one entire cycle, we would get back the same \\(S_{A \\to B}\\). Thus the two integrals are equal.\nWe will prove Noether’s theorem similarly.\n\n\n\n\nExercise 2 A one-dimensional family of trajectories in phase space sweep out a curved surface. Prove that for any cycle \\(\\gamma\\) on the curved surface, \\(\\oint_\\gamma \\left\\langle p, dq\\right\\rangle = 0\\).\n\n\n\nIllustration for \\(\\oint_\\gamma \\left\\langle p, dq\\right\\rangle = 0\\).\n\n\n\n\n\nHamilton characteristic function\nIn most situations, the system is time-independent. In this case we can simplify the HJE to\n\\[\\partial_t S = -H(q, \\nabla_q S)\\]\nSince the left side depends on \\(t\\), but the right side does not explicitly, we can solve this by separation of variables.\nSuppose there exists some function \\(W\\), called the Hamilton characteristic function, that satisfies\n\\[\nH(q, \\nabla_q W(q)) = E\n\\tag{4}\\]\nfor some \\(E\\in \\mathbb{R}\\), then \\(S(t, q) = W(q) - Et\\) is a solution to the HJE.\nWe might naively think, by analogy with Fourier transform, that any solution to the HJE is a linear combination, of the form \\(S(t, q) = \\int (W_E(q) - Et)dE\\), but this is not true, since the HJE is nonlinear. Nevertheless, solutions of the form \\(S(t, q) = W(q) - Et\\) are often sufficient for applications.\n\n\nMore proofs of HJE\n\n\n\n\n\n\nproof by positional arbitrage\n\n\n\n\n\nWe only need to prove \\(p = \\nabla S\\), which is sufficient to prove Equation 3, and thus the HJE.\nGiven a starting position \\((t_0, q_0)\\) and a reference trajectory, there exists some \\(S(t, q; t_0, q_0)\\), the cost function of arriving at any point in configuration space-time in a neighborhood of the reference trajectory. For each trajectory \\(\\gamma\\) in the neighborhood that arrives at \\((t, q)\\), there exists a final market price \\(q(t)\\). We need to show that \\(q = \\nabla S\\).\nSuppose not, then we can perform positional arbitrage. First, we arrive at \\(q + \\delta q\\) by the efficient route, then sell off some \\(\\delta q\\). This would cost us\n\\[S(t, q+\\delta q; t_0, q_0) - \\left\\langle p, \\delta q\\right\\rangle = S(t, q; t_0, q_0) + \\left\\langle\\nabla S - p, \\delta q\\right\\rangle\\]\nIf \\(\\nabla S \\neq p\\), then we can take \\(\\delta q = -(\\nabla S - p)\\epsilon\\), and thus magically make the journey cost less by a first-order infinitesimal. This means the market is inefficient, a contradiction.\n\n\n\nHere is a proof in the spirit of wave mechanics and dynamical programming. Though I did not study his proof,11 I believe this is how the inventor of dynamical programming, Richard Bellman, proved his extension, the Hamilton–Jacobi–Bellman equation. The HJBE reduces to the HJE under certain conditions – they do not talk about the same thing, because while HJ is about stationary action, HJB is about maximal action.\n11 In his autobiography, he said,\n\nProblems of this type had been worked on before by many mathematicians, Euler, Hamilton, and Steiner, but the systematic study of problems of this type was done at RAND starting in 1948 under the inspiration of von Neumann. (Bellman 1984, 208)\n… one can use dynamic programming for the minimum principles of mathematical physics. For example, with dynamic programming one has a very simple derivation of the eikonal equation. In addition, the Hamilton-Jacobi equation of mechanics can easily be derived. (Bellman 1984, 289)\n\nSuppose that we have found all points at which the action is equal to \\(S\\). Now we would like to expand that surface a little further, to the surface of action \\(S + \\delta S\\). We do that in the spirit of economics (of course!) and traveling.\nInterpret the action of a path as the cost of traveling along that path. The surfaces of constant action, then, become the isochrone maps. The problem we face is then a matter of travel planning: Given that we can reach up to surface \\(X_S\\) if we are willing to pay cost \\(S\\), how much further can we travel if we are willing to pay an additional \\(\\delta S\\)?\n\n\n\nIsochrone maps of travel time in America, 1800 – 1930. (Paullin 1932, plate 138, page 366)\n\n\nLet us stand at a point \\((t, q)\\) on the surface of action \\(S\\), and consider all the points we can reach by an additional action \\(\\delta S\\). Suppose we go from \\((t, q)\\) to \\((t + \\epsilon t, q + \\epsilon q)\\), then the cost of that is \\(L\\left(t, q, \\frac{\\epsilon q}{\\epsilon q}\\right)\\epsilon t\\). (We write \\(\\epsilon t\\) instead of \\(\\delta t\\), because we have to use that symbol later.)\nTherefore, the “wave” of action \\(\\delta S\\) coming out of the point \\((t, q)\\) are those points \\((t + \\epsilon t, q + \\epsilon q)\\) satisfying the equation\n\\[\nL\\left(t, q, \\frac{\\epsilon q}{\\epsilon q}\\right)\\epsilon t = \\delta S\n\\]\nAnd the surface of action \\(S + \\delta S\\) is the envelope of all those little waves (“wavelets”). This is the wave perspective, but we still need to return to the particle perspective.\nSuppose you are already at \\((t, q)\\), and you just want to reach the surface of \\(S + \\delta S\\). It doesn’t matter where you end up on that surface – you just have to get to that surface somewhere. You also have exactly \\(\\delta S\\) to spend, so you have to plan optimally. Now, looking at that picture, you see that the only place you can possibly reach is a certain point \\((t + \\delta t, q + \\delta q)\\) where the wavelet is tangent to the surface of \\(S + \\delta S\\). At that point, the tangent surfaces of \\(S\\) at \\((t, q)\\) is parallel to the tangent surface of wavelet. That is,\n\\[\n\\begin{aligned}\nd\\left(L\\left(t, q,-\\frac{\\epsilon q}{\\epsilon t}\\right) \\epsilon t\\right) |_{\\epsilon t = \\delta t, \\epsilon q = \\delta q} &= \\left\\langle(\\left(\\nabla_q L\\right) \\underbrace{\\delta t}_{\\rightarrow 0}+\\nabla_v L), d q\\right\\rangle +\\left(L-\\frac{\\delta q}{\\delta t} \\nabla_v L\\right) d t \\\\\n&\\propto dS\n\\end{aligned}\n\\]\nThus, there exists some constant \\(c &gt; 0\\) such that\n\\[\n(\\partial_t S, \\nabla_q S) = c \\left(\\left\\langle\\nabla_v L, \\frac{\\delta q}{\\delta t}\\right\\rangle - L , \\nabla_v L\\right) = (-cH, cp)\n\\]\nSince we also have\n\\[\n\\partial_t S \\delta t + \\left\\langle\\nabla_q S, \\delta q\\right\\rangle = \\delta S = L \\delta t\n\\]\nwe see \\(c=1\\).\n\n\n\n\n\n\n\n\n\n\n\nconvexity of the wavelet\n\n\n\n\n\nIf the wavelet is convex, then the tangent point is unique, and there is only one way to proceed from \\((t, q)\\). However, if the wavelet is not, then there could exist two or more particle paths shooting out from \\((t, q)\\). It is similar to birefringence and conical refraction (Lunney and Weaire 2006).\n\n\n\n\nExercise 3 If you have studied, or intend to study, control theory, then prove the Hamilton–Jacobi–Bellman equation using the exact same picture. You can also prove the stochastic HJB equation in the same way, though you would need to insert the expectation \\(\\mathbb{E}\\) somewhere.\n\n\n\nBonus: Noether’s theorem\nIn Noether’s theorem, symmetries of the Lagrangian give us conserved quantities of motion.\n\n\\(\\epsilon\\) is an infinitesimal number.\nAn infinitesimal transform is an infinitesimal deformation \\((\\delta t, \\delta q)\\) of configuration space-time.\n\n\\(\\delta t = \\epsilon T\\), where \\(T\\) a function of type \\(\\underbrace{\\mathbb{R}}_{\\text{time}} \\times \\underbrace{\\mathcal C}_{\\text{configuration space}} \\to \\mathbb{R}\\)\n\\(\\delta q = \\epsilon Q\\), where \\(Q\\) is a function of type \\(\\mathbb{R}\\times \\mathcal C \\to \\mathbb{R}^d\\), where \\(d\\) is the dimension of configuration space \\(\\mathcal C\\).\n\nAn infinitesimal transform is a symmetry of the Lagrangian, iff taking any path \\(\\gamma\\) (not necessarily physically real), and deforming it to \\(\\gamma'\\), the action is conserved: \\(\\int_\\gamma L dt = \\int_{\\gamma'} L dt\\).\nA conserved quantity of motion is a number depending on \\(t, q, \\dot q\\), such that it is constant along any physically real path \\(\\gamma\\).\n\n\nExercise 4 We defined “symmetry of the Lagrangian” by a condition on an integral: \\(\\int_\\gamma L dt = \\int_{\\gamma'} L dt\\). Reformulate this to a condition at a point, involving \\(L, Q, T\\) and their derivatives.\n\n\n\n\n\n\n\nWarning\n\n\n\n\n\nA symmetry of the Lagrangian conserves all actions, even those of unphysical paths, but a conserved quantity of motion is only conserved along physical paths. We may call them “conserved quantity of physical motion” to emphasize the distinction.\n\n\n\nTake a trajectory \\(\\gamma_{AA'}\\) from point \\(A\\) to \\(A'\\). Now, shift it by \\(\\delta t, \\delta q\\), resulting in a trajectory \\(\\gamma_{BB'}\\) from point \\(B\\) to \\(B'\\). Since \\(L\\) is invariant under symmetry, any such shifting gives us \\(S_{AA'} = S_{BB'}\\). Now, suppose that \\(\\delta S \\neq 0\\) in a neighborhood of the given trajectory \\(\\gamma_{AA'}\\), then we can take this variation \\(\\delta \\gamma\\), and shift it by the symmetry, showing that \\(\\delta S \\neq 0\\) in a neighborhood of \\(\\gamma_{BB'}\\) too.\nTherefore, by Hamilton’s principle, the infinitesimal transform sends any physically real trajectory into another physically real trajectory.\n\nTheorem 9 (Noether’s theorem) If \\((t, q) \\mapsto (t + \\epsilon T, q + \\epsilon Q)\\) is an infinitesimal symmetry of the Lagrangian, then\n\\[\nH T - \\left\\langle p, \\delta Q\\right\\rangle = (\\left\\langle\\nabla_v L, \\dot q\\right\\rangle - L)T - \\left\\langle\\nabla_v L, Q\\right\\rangle\n\\]\nis a conserved quantity of motion.\n\nTechnically speaking, we should not confuse the left side and the right side of\n\\[\nH T - \\left\\langle p, \\delta Q\\right\\rangle = (\\left\\langle\\nabla_v L, \\dot q\\right\\rangle - L)T - \\left\\langle\\nabla_v L, Q\\right\\rangle\n\\]\nThe left side is defined on the phase space-time, while the right side is defined on the configuration space-time. They are equal only because we have soldered together the phase space and the configuration space.\nIndeed, again and again we see that Lagrangian and Hamiltonian mechanics are different worlds, with their own dreams and phantasies, but always agreeing on the same reality.\nIf this were the case, then why do we bother creating two mechanics, since there are no physical experiment to distinguish them? It is because in quantum mechanics, virtual trajectories are just as real as the “real” trajectories. A particle can very well go around the earth once before it arrives at its destination, taking the long way around. In this case, what is virtually possible matters just as much as what is classically real, and if Lagrangian mechanics and Hamiltonian mechanics can entertain different kinds of dreams, we might be able to tell them apart.\n\n\n\n\\(S\\) is a source of photons, and \\(P\\) is a receiver. A photon can go from \\(S\\) to \\(P\\) by bouncing off the mirror below, along many paths. Each path has a certain amplitude, and the sum of all their amplitudes is the total amplitude. While the amplitude is dominated by the amplitudes near the classical path \\(SGP\\), it is not the only path, and all paths, even the “virtual” paths like \\(SAP\\), contributes to what we observe. (Feynman 2006, fig. 24)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven any physically real trajectory \\(\\gamma_{AA'}\\) from point \\(A\\) to \\(A'\\), the infinitesimal transform sends it to another physically real \\(\\gamma_{BB'}\\). By symmetry, both paths have the same action. Thus, we have\n\\[\nS(A, A') = S(B, B')\n\\]\nNow, consider an intermediate path \\(\\gamma_{A, B'}\\). By Equation 3,\n\\[\nS(A, B') = S(A, A') - H \\delta t + \\left\\langle p, \\delta q\\right\\rangle, \\quad S(B, B') = S(A, B') + H_0 \\delta t_0 - \\left\\langle p_0, \\delta q_0\\right\\rangle\n\\]\nTherefore, \\(H T - \\left\\langle p, \\delta Q\\right\\rangle\\) is a conserved quantity of motion.\n\n\n\nThe proof is similar to the proof of Theorem 8, though they differ in that Noether’s theorem shows a quantity, defined at a single point, is conserved over a trajectory, while the Poincaré–Cartan invariant is not defined at a single point, but as an integral over an entire cycle."
  },
  {
    "objectID": "blog/posts/art/index.html#sec:geometric_optics",
    "href": "blog/posts/art/index.html#sec:geometric_optics",
    "title": "Analytical physics",
    "section": "Geometric optics",
    "text": "Geometric optics\nWhen Hamilton developed his Hamiltonian approach, it was to study geometric optics, which can be derived from Fermat’s principle: light paths have stationary travel time. In other words, the action of a path is\n\\[S(\\text{path}) = \\int_{\\text{path}} dt\\]\nThus, \\(L = 1\\)...? Well, here we see the problem: in geometric optics, if you fix the starting and ending point as \\((t_0, q_0), (t, q)\\), then any path between them takes exactly \\(t-t_0\\) time, and there is nothing to vary. Consequently, we need to remove time from consideration, so that there is something to vary.\nFermat’s principle, reformulated, states light paths have stationary adjusted length. Let the medium be isotropic (light speed does not depend on direction), then we have\n\\[S(\\text{path}) = \\int_{\\text{path}} n(q) \\|dq\\|\\]\nwhere \\(n = \\frac cn\\) is the refractive index. with \\(L(q) = n(q)\\). Here we encounter a brief difficulty: time flows in one direction only, but space flows in infinitely many possible directions!\nThe solution might seem like a joke, but it would work out well: select one direction8, say \\(q_0\\), and pretend that it is time. With this trick, all previous mathematical formalism immediately applies, and we have\n8 This direction is usually selected to be the direction of the principal optic axis. For example, the long-axis of a camera is a principal optic axis, and so is the barrel-axis of a telescope.\\[S(\\text{path}) = \\int_{\\text{path}} n(q_0, q_1, q_2) \\sqrt{1 + \\left(\\frac{dq_1}{dq_0}\\right)^2 + \\left(\\frac{dq_2}{dq_0}\\right)^2}dq_0\\]\n\nDerivation\nLet’s make the notation cleaner, by rewriting \\(q_0\\) as \\(t\\), \\((q_1, q_2)\\) as \\(q\\), and using \\(v\\) to mean \\(\\left(\\frac{dq_1}{dq_0}, \\frac{dq_2}{dq_0}\\right)\\). Then we have\n\\[L(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\]\nRoutine calculation yields\n\\[\\begin{cases}     \nL(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\\\     \nH(t, q, p) = -\\sqrt{n^2 - \\|p\\|^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\frac{nv}{\\sqrt{1 + \\|v\\|^2}} \\\\     \nv^\\ast = \\frac{p}{\\sqrt{n^2 - \\|p\\|^2}}\n\\end{cases}\\]\nwe continue with the HJE, which simplifies to:\n\\[(\\partial_t S)^2 + \\|\\nabla_q S\\|^2 = n^2\\]\nReverting notation back to \\((q_0, q_1, q_2)\\), we find the eikonal equation:\n\\[\\|\\nabla_q S\\| = n(q)\\]\nWhy did the trick work? Well, if we look back to how we derived the Hamiltonian, we could see that what we called \"time\" is really just a special copy of \\(\\R\\), along which we organized all other state and control variables. We don’t really need time to be anything more than the domain of functions, as in \\(q_i: \\R \\to \\R\\) and \\(v_i : \\R\\to \\R\\). It most definitely does not need to \"flow\", or flow only from the past to the future, or have any psychological significance.\n\n\nInterpretation\nStarting with Fermat’s principle for light rays, we ended up with the eikonal equation for light waves. In general, we find the duality between , shown in Table 1.\n\n\nThe particle-wave duality.\n\n\nperspective\nparticle-path\nwave-field\n\n\n\n\naction \\(S\\)\na function of particle path\na field on configuration-spacetime\n\n\nequation\n\\(\\delta S(\\text{path})=0\\)\n\\(\\partial_t S + H(t, q, \\nabla_q S) = 0\\)\n\n\nin optics\nlight rays, Fermat’s principle\nlight waves, Huygens principle\n\n\nin mechanics\npoint particles\nmatter waves\n\n\n\n\n: The particle-wave duality.\nSee Figure 3.\n\n\n\nThe Eikonal equation."
  },
  {
    "objectID": "blog/posts/art/index.html#the-geometry-of-physical-states",
    "href": "blog/posts/art/index.html#the-geometry-of-physical-states",
    "title": "Analytical physics",
    "section": "The geometry of physical states",
    "text": "The geometry of physical states\nConsider a particle in a field, in polar coordinates. We have\n\\[L = \\frac 12 m (\\dot r^2 + r^2 \\dot \\theta^2) - V(r, \\theta)\\]\nNow suppose we want to use a rotating frame at angular velocity \\(+\\Omega\\), then we can use the change of variables by \\(\\theta = \\phi + \\Omega t\\), plug into the Euler–Lagrange equations, and obtain\n\\[\\begin{cases}     \nm\\ddot r = mr\\dot\\phi^2 -\\partial_r V(r, \\phi + \\Omega t)  + mr\\Omega^2 + 2m(r\\dot \\phi)\\Omega \\\\     \nm(r\\ddot\\phi + 2\\dot r\\dot \\phi) = -\\frac 1r \\partial_\\theta(r, \\phi+ \\Omega t) - 2m\\dot r\\Omega\n\\end{cases}\\]\nIn the above procedure, we simply performed a change of variables, then plugged into the Euler–Lagrange equations without comment, but are we allowed to do that? Yes, but there are conditions – the change of variables must not depend on velocity.\n\nState space, configuration space, phase space, and coordinate systems\nAt this point, it is important to be as explicit as possible, carefully distinguishing between often confused concepts:\n\nphysical state: An intuitive concept that cannot be made more precise than say \"this is what physicists study\", much like how a geometric point cannot be made more precise than say \"this is what geometers study\".\nsame: As in most modern mathematics, two things are \"the same\" when they are really just \"equivalent\" or \"not distinguished in use\". For example, there is really just one \\(\\R\\), but we can have as many 1-dimensional vector spaces as we want, and they are all equivalent to \\(\\R\\), though not literally the same as it (if they were, then we wouldn’t have as many vector spaces as we want!).\n(n-dimensional smooth) manifold \\(\\mathcal M\\): a space that is locally the same as \\(\\R^n\\). More precisely, at every point \\(x\\in \\mathcal M\\), there exists a coordinate system around \\(x\\).\ncoordinate system of a manifold \\(\\mathcal M\\): a diffeomorphism from an open subset of \\(\\mathcal M\\) to an open subset of \\(\\R^n\\).\ndiffeomorphism: a smooth, one-to-one function between two smooth spaces. (What is a smooth space? ... it’s a space smooth enough to do calculus in. Making it more precise would be too much of a detour.)\nstate space \\(\\mathcal S\\): the manifold of distinct physical states. Every point \\(x\\in \\mathcal S\\) is a particular state that the system can assume. The manifold is built such that close-by points on the manifold are close-by physical states. That is, the topology of the state space (a precisely defined mathematical concept) is an exact representation of the topology of physical states (an intuitive concept that cannot be made more precise than that).\ntangent space \\(\\mathcal T_x\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible velocities at that state. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\).\ncotangent space \\(\\mathcal T_x^\\ast\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible momenta at that state. From the abstract perspective, a momentum is nothing more than a linear map of type \\(p: \\mathcal T_x\\mathcal S \\to \\R\\). That is, the only way to really \"use\" a momentum is to combine it with a velocity, mutually annihilating both of them and leaving behind nothing but a little real number representing the energy. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\). Neither is it literally the same as \\(\\mathcal T_x\\mathcal S\\).\nconfiguration space \\(\\mathcal C = \\mathcal T\\mathcal S\\): The tangent bundle of state space. That is, at each \\(x\\in \\mathcal S\\), we \"glue\" the space of velocities \\(\\mathcal T_x \\mathcal S\\) to the point. The totality of \\(\\mathcal C\\) with all its \\(\\mathcal T_x \\mathcal S\\) is the configuration space.\nphase space \\(\\mathcal P = \\mathcal T^\\ast\\mathcal S\\): The cotangent bundle of state space. That is, at each point \\(x\\in \\mathcal S\\), we attach the space of momenta \\(\\mathcal T_x^\\ast\\mathcal S\\).\n\nDo not worry if the words do not make much sense. The example will make it clear.\nFor concreteness, consider a pendulum-cart system, shown in Figure 4. It is clear that its state space is shaped like a cylinder: one circle for the angle of the pendulum, and one line being the location of the cart.\nMore examples are shown in Table 2. Most of them are obvious, except the one about particle on a sphere.\nIt’s clear that its state space is \\(\\mathbb S^2\\). However, that is not equivalent to the torus \\(\\mathbb S^1 \\times \\mathbb S^1\\). There is simply no way to split the sphere into a direct product of two circles (as a casual comparison between a donut and a ball can verify).\nFurthermore, its configuration space \\(\\mathcal\\mathbb S^2\\) is not equivalent to \\(\\R^2 \\times \\mathbb S^2\\). To prove that, we invoke the hairy ball theorem: there is no smooth and everywhere nonzero vector field on \\(\\mathbb S^2\\). Now, if it were equivalent to \\(\\R^2 \\times \\mathbb S^2\\), then there is an obvious smooth and everywhere nonzero vector field: \\(x \\mapsto ((1, 0), x)\\).\n\n\n\nThe pendulum-cart system.\n\n\n\n\nSome physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nphysical system\nstate space\nconfiguration space\n\n\n\n\nparticle in 3D space\n\\(\\R^3\\)\n\\(\\R^6\\)\n\n\npendulum\ncircle \\(\\mathbb S^1\\)\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\n\ndouble pendulum\ntorus \\(\\mathbb S^1 \\times \\mathbb S^1\\)\ncylinder-squared \\(\\R^2 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\npendulum-cart\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\\(\\R^3 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\nparticle on a sphere\nsphere \\(\\mathbb S^2\\)\ntangent bundle of sphere \\(\\mathcal T\\mathbb S^2\\)\n\n\n\n\n: Some physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nLagrangian and Hamiltonian\nWith the above formalism, we can precisely define more concepts\n\ntrajectory, or path, in a manifold \\(\\mathcal M\\): a function of type \\(\\gamma: [t_0, t] \\to \\mathcal M\\).\nLagrangian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal L: \\R \\times \\mathcal T\\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on configuration space.\n\nHamiltonian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal H: \\R \\times \\mathcal T^\\ast \\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on phase space.\n\naction of a path\n\n\\[S(\\gamma) = \\int_{t_0}^t \\mathcal L(\\tau, \\gamma(\\tau), \\dot \\gamma(\\tau))d\\tau.\\]\nNow, the convex duality between Lagrangian and Hamiltonian transfers with almost no change in notation:\n\\[\\begin{cases}     \n\\mathcal L(t, q, v) = \\max_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\     \n\\mathcal H(t, q, p) = \\max_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\n\\[\n\\begin{cases}     \np^\\ast(t, q, v) = \\mathop{\\mathrm{arg\\,max}}_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\     \nv^\\ast(t, q, p) = \\mathop{\\mathrm{arg\\,max}}_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\nThe economic argument almost goes through without problem, but we need to be careful with some notations. In particular, we take another look at gradients. What does it mean to write \\(\\nabla_v \\mathcal L(t, q, v)\\)? The defining property is\n\\[\\mathcal L(t, q, v + u\\tau) = \\mathcal L(t, q, v) + \\lra{\\nabla_v \\mathcal L(t, q, v), u} \\tau + O(\\tau^2)\\]\nwhich implies the following operational definition:\n\\[\\nabla_v \\mathcal L(t, q, v) := u \\mapsto \\lim_{\\tau \\to 0} \\frac 1\\tau (\\mathcal L(t, q, v + u\\tau) - \\mathcal L(t, q, v))\\]\nThis definition makes it clear that \\(\\nabla_v \\mathcal L(t, q, v)\\) is a function of type \\(\\mathcal T_q \\mathcal S \\to\\R\\), thus it is an element of \\(\\mathcal T_q^\\ast \\mathcal S\\). Similarly, \\(\\nabla_p \\mathcal H(t, q, p)\\) is an element of \\(\\mathcal T_q \\mathcal S\\). Succinctly, \\(\\nabla_q \\mathcal L, \\nabla_v \\mathcal L, \\nabla_q \\mathcal H\\) are covector fields (like momentum), and \\(\\nabla_p \\mathcal H\\) is a vector field (like velocity).\nWith these, the types of every equation come out correctly again:\n\\[\\begin{cases}  \nv = \\nabla_p \\mathcal H(t, q, p^\\ast(t, q, v))\\\\  \np = \\nabla_v \\mathcal L(t, q, v^\\ast(t, q, p))\n\\end{cases},  \n\\frac{d}{dt}(\\nabla_v \\mathcal L) = \\nabla_q \\mathcal L,\\quad  \n\\begin{cases}\n\\dot p = -\\nabla_q \\mathcal H \\\\\n\\dot q = -\\nabla_p \\mathcal H\n\\end{cases}\\]\nLet’s call these the coordinate-free equations, to be contrasted with the coordinate-based equations, to be defined below.\n\n\nPoint transformation\nManifolds are geometrically pristine, but you can’t calculate numerically with them unless you lay down coordinate systems over them. Concretely, consider a state space \\(\\mathcal S\\). We take an open subset \\(U\\) of it, and define a coordinate system (with a possible dependence on time):\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nThis coordinate system then induces a coordinate system over the configuration space:\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nNow consider a different coordinate system\n\\[(Q_1, ..., Q_N): \\R \\times U \\to \\R^N\\]\nand suppose they are related by a function \\(f: \\R \\times \\R^N \\to \\R^N\\) such that\n\\[q(t, x) = f(t, Q(t, x))\\]\nThis is then a point transformation of the coordinate system.\nThe point transformation induces a transformation of the velocities, too. To find the transformation of velocities, consider a path \\(\\gamma: \\R \\to \\mathcal S\\). Its velocity at time \\(t\\) is \\(\\dot \\gamma(t) \\in \\mathcal T_{\\gamma(t)}\\mathcal S\\), a vector that looks like it literally lives in \\(\\R^N\\), but is not. It is not a native of \\(\\R^N\\), but thanks to the \\(q\\)-coordinate system, it is represented by the \\(\\R^N\\)-vector\n\\[\\frac{d}{dt} q(t, \\gamma(t)) \\in \\R^N\\]\nNow plug in \\(q(t, x) = f(t, Q(t, x))\\), to find a relationship between the representation of \\(\\dot \\gamma(t)\\) in \\(q\\)-coordinate system and \\(Q\\)-coordinate system:\n\\[\\frac{d}{dt} q(t, \\gamma(t)) = \\frac{d}{dt} f(t, Q(t, \\gamma(t))) = \\partial_t f(t, Q(t, \\gamma(t))) + \\frac{\\partial f}{\\partial Q} \\frac{d}{dt}Q(t, \\gamma(t))\\]\nMore succinctly, we have the following transformation from \\((t, Q, V)\\) to \\((t, q, v)\\):\n\\[\\begin{cases}     \nq = f(t, Q) \\\\     \nv= \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\n\\end{cases}\\]\nA note on matrix algebra: Conventionally, vectors are written as column-matrices, that is, \\(q, v, Q, V\\) are written as \\(N\\times 1\\) matrices. Correspondingly, gradients, being covectors, are written as row-matrices, that is, \\(\\nabla_q l, \\nabla_v l, \\nabla_Q L, \\nabla_V L\\), are written as \\(1 \\times N\\) matrices. Finally, gradients of vector-valued functions, like \\(\\frac{\\partial f}{\\partial Q}\\), are \\(N\\times N\\) matrices, with each row being a gradient of one vector coordinate. This convention makes everything come out cleanly, with no need to take the transpose of anything.\nThe point transformation also induces a transformation of the Lagrangians. While the Lagrangian itself is a function \\(\\mathcal L\\) of type \\(\\R \\times \\mathcal T \\mathcal S \\to \\R\\), the Lagrangians \\(L(t, Q, V), l(t, q, v)\\) are functions of type \\(\\R \\times \\R^N \\times \\R^N \\to \\R\\). Both \\(L, l\\) are induced from \\(\\mathcal L\\) by the choice of coordinates. We have\n\\[\\mathcal(t, x, u) = L(t, Q(t, x), V(t, x, u)) = l(t, q(t, x), v(t, x, u))\\]\nand plug in \\(q(t, x) = f(t, Q(t, x)), v = \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\\), we have\n\\[l\\left(t, f(t, Q), \\partial_t f(t, Q)  + \\frac{\\partial f}{\\partial Q}(t, Q) V\\right) = L(t, Q, V)\\]\nBrute computation shows that\n\\[\\frac{d}{dt}(\\nabla_V L) - \\nabla_Q L = \\left(\\frac{d}{dt}(\\nabla_v l) - \\nabla_q l\\right)\\frac{\\partial f}{\\partial Q}\\]\nimplying that the coordinate-based Euler–Lagrange equation is true in \\((Q, V)\\) coordinates iff it is true in \\((q, v)\\) coordinates.\nWhat, in the final analysis, is a point transformation? It is nothing more than changing a time-varying coordinate system on the state space. Since our derivation of the coordinate-based Euler–Lagrange equations required no special property of the coordinate system, it must be preserved by point transformations. All the above verification was really nothing but \"ceremonial\".\nIn more detail: we know that the coordinate-free EL equations are true, which implies that the \\(q\\)-coordinate-based EL equations and the \\(Q\\)-coordinate-based EL equations are both true (since they are merely two coordinate-based representations on the coordinate-free equation). No \\(Q\\)-to-\\(q\\) translation is necessary!\nWhat, then, is the phrase \"point transformation\" supposed to be contrasted with? It is contrasted with more general coordinate transforms that also depend on velocities, as \\(q = f(t, Q, V)\\). From the perspective given here, the contrast is really between \"state space coordinate systems\" and \"configuration space coordinate systems\". Whereas state space coordinate system is first defined as some\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nand that is then extended to \\((q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\), a configuration space coordinate system defines \"all at once\" a complete coordinate system\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nIt is no wonder that such overly general coordinate systems do not have nice properties, and do not satisfy the coordinate-based Euler–Lagrange equations.\n\n\nCanonical transformation\nWhereas for the Lagrangian \\(\\mathcal L\\), we can only perform point-transformations \\(q = f(t, Q)\\), lest the Euler–Lagrange equation is mangled, for the Hamiltonian, we can simultaneously transform both \\(q, p\\), while preserving the Hamiltonian equations of motion. Such transformations are called canonical transformations. They are of the form:\n\\[\\begin{cases}     \nQ = f_Q(t, p, q)\\\\     \nP = f_P(t, p, q)\n\\end{cases}\\]\nwhere the functions \\(f_Q, f_P: \\R \\times \\R^N \\times \\R^N \\to \\R^N\\) are required to satisfy some functional equations.\nThis is usually derived by brute force without comments. However, to truly understand the meaning, we need to understand phase space from a perspective even more modern than \\(\\mathcal T^\\ast \\mathcal S\\)."
  },
  {
    "objectID": "blog/posts/art/index.html#the-geometry-of-phase-space",
    "href": "blog/posts/art/index.html#the-geometry-of-phase-space",
    "title": "Analytical physics",
    "section": "The geometry of phase space",
    "text": "The geometry of phase space\nGiven a state space \\(\\mathcal S\\), both its configuration space and its phase space are obtained by attaching vector spaces to every point of it. Despite this, the geometry of phase space turns out to be a far richer thing than the geometry of configuration space. This fundamentally comes down to the difference between a cotangent vector and a tangent vector.\nConsider an infinitesimal parallelogram in the phase space, around the point \\((q, p)\\). The parallelogram has (signed) sides \\((\\delta q_1, ..., \\delta q_N; \\delta p_1, ..., \\delta p_N)\\). What should be its (signed) volume? The natural answer is of course\n\\[\\prod_i \\delta q_i \\delta p_i\\]\nbut is this a meaningful answer? That is, is this a mirage in \\(\\R^N \\times \\R^N\\) created by our choice of coordinates, or is this a faithful representation of something that truly takes place in the phase space \\(\\mathcal T^\\ast\\mathcal S\\) itself?\nThis answer is critically important, since if a concept takes place in the phase space itself, then it will be coordinate-free, and every coordinate system automatically translates that one coordinate-free concept. This is how we could have predicted that the coordinate-based Euler–Lagrange equations are preserved, by going up to the coordinate-free version of it, then coming back down again.\nHaving a coordinate-free thing is like having a lingua-franca between different coordinate-based representations.\n\nPoisson bracket\nThe Poisson bracket notation is convenient:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nFor any differentiable function \\(f(t, q, p)\\), and any path \\(p(t), q(t)\\) that conforms to a Hamiltonian \\(H(t, q, p)\\), we have by Hamiltonian’s equations of motion\n\\[\\frac{d}{dt} f(t, p(t), q(t)) = \\partial_t f(t, p(t), q(t)) + \\{f, H\\}\\]\nor more succinctly, \\(\\dot f = \\partial_t f + \\{f, H\\}\\).\n\n\nLiouville’s theorem\nProof taken from (Tolman 1980, sec. 19).\n\n\nThe interpretation of phase space geometry\nLiouville’s theorem is a delicate construction, having several moving parts. We have a phase space, a volume-measurement on the phase space, a Hamiltonian on the phase space, and a density field on the phase space which flows according to the Hamiltonian. Only when all four moving parts come together do we get Liouville’s theorem.\nWhat is a phase space, in the final analysis? A phase space \\(\\mathcal T^\\ast \\mathcal S\\) is a state space \\(\\mathcal S\\), with each state \\(x\\) attached with \\(\\mathcal T^\\ast_x \\mathcal S\\), the vector space of all possible momenta at that state. Good... but not quite! This interpretation of phase space is still bound firmly to the economic interpretation, where each momentum \\(p\\) at state \\(x\\) is a vector of prices, with which we are allowed to measure the profit flow, as \\(\\langle p, \\dot x \\rangle\\).\nWhile this perspective is how Hamiltonian mechanics got its start, the modern abstract viewpoint of Hamiltonian mechanics has sailed far away from the safe harbor of \\(\\R^{2N}\\), past \\(\\mathcal T^\\ast \\mathcal S\\), and voyaged deep into the strange seas of symplectic geometry. Since the early days of the 20th century, there is a tacit understanding among physicists where the humble origin of the phase space \\(\\mathcal T^\\ast \\mathcal S\\) is suppressed, and it is presented instead as a \\(2N\\)-dimensional smooth manifold \\(\\mathcal P\\) equipped with some \\(\\omega\\), a way to measure volumes. The seams where \\(\\mathcal T^\\ast_x \\mathcal S\\) was attached to \\(\\mathcal S\\) are now plastered over, never there, never will be mentioned again... And this abstract viewpoint actually works.\nSpeak not how the phase space was born, but what you can use it for! This is a principle useful not only in programming (encapsulation, API, abstract interfacing), but also in modern mathematics (speak not of equality, but equivalences and isomorphisms...), and perhaps in society (Ye shall know them by their fruits. Do men gather grapes of thorns, or figs of thistles?).\nWhat do we gain and what do we lose when we go from \\(\\R^{2N}\\) to \\(\\mathcal T^\\ast \\mathcal S\\) to \\((\\mathcal P, \\omega)\\)? What we gain are new interpretations, and what we lose are old interpretations. See Table 3.\n\n::: {#table:three_abstractions} \\(\\R^{2N}\\) \\(\\mathcal T^\\ast \\mathcal S\\) \\((\\mathcal P, \\omega)\\) ———————– ——————————– —————————- tuples of real number points, vectors, and covectors points, areas, and volumes multivariate calculus vector bundle geometry symplectic geometry\n\nThe three steps of abstraction. :::\n\n\nIn \\(\\R^{2N}\\), we can interpret each point \\((q, p)\\in \\R^{2N}\\) economically: \\(q_1, ..., q_N\\) are the amounts of commodities, and \\(p_1, ..., p_N\\) are their market prices. In \\(\\mathcal T^\\ast \\mathcal S\\), half of this interpretation is lost, since we are not allowed to interpret \\(x\\in \\mathcal S\\) as a tuple of commodities, unless we lay down a more or less arbitrary coordinate system over it.\nNevertheless, half of this interpretation is preserved. While we are no longer able to interpret a point \\(x\\in \\mathcal S\\) as a stock of commodities that we own, we are still able to interpret a vector \\(v \\in \\mathcal T_x \\mathcal S\\) as a flow of commodities. This then allows us to interpret \\(\\langle p, v \\rangle\\) as a flow of profits: if we are producing at speed \\(v\\), and the market price vector is \\(p\\), then our profit flow is \\(\\langle p, v \\rangle\\). In economic language, we can’t talk of the stock, but we can still talk of the flow.\nGiving up half of the economic interpretation allows us to gain in coordinate-freedom. The Hamiltonian equations of motion become coordinate-free equations on \\(\\mathcal T^\\ast \\mathcal S\\), and we are given the guarantee that it is preserved by any coordinate system on \\(\\mathcal S\\).\nWhen we get to \\((\\mathcal P, \\omega)\\), the economic interpretation is totally destroyed, because there is no more separation between commodities and prices. A point in \\(\\mathcal P\\) simply is a point \\(y\\in \\mathcal P\\), not a 2-tuple \\((x, p)\\) with \\(x\\in \\mathcal S\\) and \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\). There is no way to seize the \"second half\" of \\(y\\) and interpret it as a price vector.\nFurthermore, we cannot even interpret it as a physical state with a momentum covector, either. A momentum covector still looks like an arrow. It has a direction, a length, and can be scaled linearly, and added. Out there in \\(\\mathcal P\\), every point is just a point, not \"half base point, half vector\" like for \\(\\mathcal T^\\ast \\mathcal S\\).\nGiving this much up allows us to gain in even more coordinate-freedom. We are allowed to interpret a physical system not as a base state \\(x\\in \\mathcal S\\) plus a momentum state \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\) , but simply as a phase state \\(y\\in \\mathcal P\\). This in particular gives us the freedom to consider coordinate systems on \\(\\mathcal P\\) that are \"fully nonlinear\", which is what canonical transforms are all about.\nRecall how we defined point transforms in Lagrangian mechanics. We start with a coordinate system \\((q_1, ..., q_N)\\) on an open subset \\(U\\) of the state space \\(\\mathcal S\\), then induced a coordinate system \\((q_1, ..., q_N; v_1, ..., v_N)\\) on \\(\\mathcal T U\\). We also stated that, while we could have went directly for a coordinate system on \\(\\mathcal T\\), this would break the Euler–Lagrange equation.\nIt turns out that the Hamiltonian equations of motion are sturdier than the Euler–Lagrange equation: there are large families of coordinate systems \\((q_1, ..., q_N; p_1, ..., p_N)\\) that we can directly define on open subsets of \\(\\mathcal T^\\ast \\mathcal S\\), and the resulting coordinate-based Hamiltonian equations would still be \\(\\dot p = -\\nabla_q H, \\dot q = \\nabla_p H\\), even if \\((q_1, ..., q_N; p_1, ..., p_N)\\) is not induced by any coordinate system on the state space!\nTo fully exploit the freedom, of course, means that we must break down the strict segregation between a state-point and a momentum-vector. In particular, this means that we no longer require \\(\\mathcal T_x \\mathcal S\\) to be treated with the rigid dignity of a linear space, but the rough freedom of a manifold space:\n\\[p(x, ku) \\neq k p(x, u) \\text { in general, for } (x, u)\\in \\mathcal T^\\ast \\mathcal S, \\: k\\in \\R\\]\nGiven that, we can immediately see why canonical transforms are in general of the form\n\\[Q(t, x, u) = f_Q(t, q(t, x, u), p(t, x, u)),\\quad P(t, x, u) = f_P(t, q(t, x, u), p(t, x, u))\\]\nor more succinctly,\n\\[Q = f_Q(t, q, p),\\quad P = f_P(t, q, p)\\]\nThey have to nonlinearly \"mix up\" state and momentum, because that’s the only way to truly exploit all the freedoms that the sturdy Hamiltonian’s equations of motion grants us.9\n9 Mathematicians exploit every freedom that they are given... sounds evil, but it works in math.Of course, the Hamiltonian equations are not that tough. Some restraint is needed. Not everything goes. What is the restraint? The volume must be preserved! That is precisely what \\(\\omega\\) is there for: it measures areas. A coordinate system on the phase space is only given the title of \"canonical\" iff the coordinate system represents \\(\\omega\\) correctly.\nThus, we find that by exploiting exactly as much freedom as Hamiltonian mechanics gives us, while keeping track of the boundaries so that we are not giving ourselves too much freedom and shooting ourselves in the foot, we walked inexorably into treating the phase space as \\((\\mathcal P, \\omega)\\) – as an object of symplectic geometry."
  },
  {
    "objectID": "blog/posts/art/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "href": "blog/posts/art/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "title": "Analytical physics",
    "section": "All the variational principles of physics that you’re likely to ever see",
    "text": "All the variational principles of physics that you’re likely to ever see\nLet’s be clear here.\n\na variation of a function \\(\\gamma: \\R^n \\to \\R^m\\) is a function \\(\\gamma + \\delta \\eta\\), such that \\(\\eta: \\R^n \\to \\R^m\\), and \\(\\delta\\) is an infinitesimal.\na constrained variation of a function \\(\\gamma\\) is a variation \\(\\gamma + \\delta \\eta\\), such that \\(\\eta\\) satisfies certain constraints \\(c\\).\na functional is a function that maps a function to a real number. For example, the Lagrangian action \\(S\\) is a functional, defined by\n\n\\[S(\\gamma) = \\int L(t, \\gamma(t), \\dot \\gamma(t))dt.\\]\n\na functional \\(S\\) has zero variation at \\(\\gamma\\) under constraint \\(c\\) iff for any variation \\(\\delta\\eta\\) satisfying constraint \\(c\\), we have \\(S(\\gamma + \\delta \\eta) = S(\\gamma) + o(\\delta)\\). We often write it simply as \\((\\delta S(\\gamma))_c = 0\\).\nvariational calculus is a collection of techniques for solving calculus problems involving variations.\na variational principle is a statement with the following format:\n\n::: center A trajectory \\(\\gamma\\) of the system is a physically valid trajectory iff \\((\\delta S(\\gamma))_c = 0\\). :::\nNow that we are clear on that, we can tabulate just about every variational principles of physics that you’re likely to ever see in Table [table:var-prin].\n\n\n1.0|L|L|L|L|L| name & Where is the trajectory? & specification & constraint & the functional\nHamilton’s principle & state spacetime & Lagrangian \\(L(t, q, v)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma L(t, q, \\dot q)dt\\)\nmodified Hamilton’s principle & phase spacetime & Hamiltonian \\(H(t, q, p)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma (\\sum_i p_i \\dot q_i - H(t, q, p))dt\\)\nMaupertuis’ principle10 & phase space & time-independent Hamiltonian \\(H(q, p)\\) & fixed \\(q_0, q_1\\), constant \\(H(q, p)\\) & \\(\\int_\\gamma \\sum_i p_i dq_i\\)\nJacobi’s form of Maupertuis’ principle & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), bonuded \\(V(q) \\leq 0\\) & \\(\\int_\\gamma \\sqrt{(E - V(q)) dq^T M dq}\\)\ntimed Maupertuis’ principle & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q + V(q)\\) & \\(\\int_\\gamma (\\dot q^T M \\dot q) dt\\)\nFermat’s principle of stationary pathlength11 & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(\\int_\\gamma \\sqrt{dq^T M dq}\\)\nFermat’s principle of stationary time & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(t_1 - t_0\\)\n\n10 \"principle of least action\" in (Goldstein, Poole, and Safko 2008)11 Corollary: Hertz’s principle of least curvature\n\n\nHamilton’s principle and modified Hamilton’s principle\nThere are two principles that are often confused with impunity by physicists. The fact is that they are indeed equivalent (which is why they can be confused with impunity), but that is no excuse for bad mathematics.\nHamilton’s principle is a principle about trajectories of type \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\). That is, \\(\\gamma(t)\\) is a state of the system. Variations can be thought of as making a state perturbation \\(\\delta \\eta(t)\\) at every time.\nIn contrast, modified Hamilton’s principle is a principle about trajectories of type \\(\\Gamma: [t_0, t_1] \\to \\mathcal P\\). That is, \\(\\Gamma(t)\\) is a phase of the system, specifying both its state and momentum. Variations can be thought of as making a state perturbation \\(\\delta \\eta_p(t)\\) and a momentum perturbation \\(\\delta \\eta_p(t)\\) at every time.\nOne may object that modified Hamilton’s principle is performing physically impossible variations: how could you perform variations on position and momentum independently of each other? Shouldn’t we have \\(\\delta p = m\\delta \\dot q = \\delta (\\nabla_{v} L(t, q, \\dot q))\\) at all times? To this objection, there are four layers of replies.\n\nThe equivalence of Hamilton’s principle and modified Hamilton’s principle, to be proved below, is a theorem in pure mathematics. It makes no demand on physical reality. It merely states that Hamilton’s principle specifies the same trajectories as modified Hamilton’s principle. Consequently, if it happens that these trajectories are physically real, then they can be specified by either principle.\nThe economic interpretation of momentum \\(p\\) is merely the market price. The equation \\(p = \\nabla_{v} L(t, q, \\dot q)\\) is true if we also assume that the producer is profit-maximizing. Now, if the trajectory \\(\\gamma\\) is optimal, then it implies that the producer is profit-maximizing. But after a perturbation of \\(\\gamma\\) to \\(\\gamma + \\delta \\eta\\), the producer is not necessarily profit-maximizing.12 Consequently, even in Hamilton’s principle, there is no requirement that \\(p = \\nabla_{v} L(t, q, \\dot q)\\). The modified Hamilton’s principle makes this interactive dance between the producer and the market explicit: we allow both the production schedule and the market price schedule to vary independently. Then, the equation \\(\\delta \\int (\\sum_i p_i \\dot q_i - H)dt = 0\\) is a statement about the trajectory of the producer-market system, and solving it would simultaneously solve both the producer and the market. In contrast, the equation \\(\\delta \\int L dt = 0\\) is a statement about the producer, and solving it by imagining a market \\(p\\) is useful, but not necessary.\nEven in classical mechanics, momentum is not real. We are fooled by our long habit of thinking about classical mechanics as if it is merely a more mathematical version of our intuition. Classical mechanics is actually unintuitive.13 In classical mechanics, there is no necessary connection between momentum and velocity – \"If \\(L = \\frac 12 v^T M v\\), then \\(p = Mv\\) on physically valid paths\" actually needs to be proved from Hamilton’s principle, not baked into the definition of momentum!\nThough in classical mechanics, both principles are equivalent, in modern physics, the modified Hamilton’s principle is primary, and the Hamilton’s principle a mere derivative. Furthermore, the phase space is primary, and the division of it into position-momentum is arbitrary. At a more fundamental level, there is no distinction between position and momentum. A \"rotation in phase space\" can transform position and momentum into each other.\n\n12 Unless the market price is perturbed in just the right way to make the producer profit-maximizing – If the producer messes up, the market can still accommodate the producer and make the producer look as if it is still profit-maximizing... Just like Potemkin villages!13 Why else did Newton come two thousand years after Aristotle? Though quantum mechanics is certainly more unintuitive.::: prop Hamilton’s principle and modified Hamilton’s principle are equivalent.\nGiven a state space \\(\\mathcal S\\), a Lagrangian \\(L(t, q, v)\\) on the configuration space, and a Hamiltonian \\(H(t, q, p)\\) on the phase space, related by convex duality, then a path \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) on state space satisfies\n\\[\\delta \\int_\\gamma L(t, q, \\dot q) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\), iff its corresponding path \\(\\Gamma: [t_0, t_1]: \\to \\mathcal T^\\ast \\mathcal S\\) on phase space satisfies\n\\[\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\) (and variable \\(p_0, p_1\\)). :::\n::: proof Proof. \\((\\Rightarrow):\\) Since \\(\\gamma\\) has zero variation for the action \\(\\int_\\gamma L(t, q, \\dot q)dt\\), and \\(H\\) is related to \\(L\\) by convex duality, by our previous results, the Hamiltonian equations of motion are satisfied along \\(\\gamma\\). That is, \\(-\\nabla_q H = \\dot p, \\nabla_p H = \\dot p\\).\nPerform variation \\(\\Gamma + \\delta \\eta\\) on phase space. The variation in the action is\n\\[\\begin{aligned} \\delta S(\\Gamma) &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle \\nabla_q H, \\delta q\\rangle - \\langle \\nabla_p H, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle -\\dot p, \\delta q\\rangle - \\langle \\dot q, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle  p, \\delta \\dot q\\rangle + \\langle \\dot p, \\delta q\\rangle] dt \\\\ &= \\langle p, \\delta q\\rangle \\Big|_{t_0}^{t_1} = 0 \\end{aligned}\\]\nsince \\(\\delta q= 0\\) at the end points.\n\\((\\Leftarrow):\\) Since \\(\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\) at \\(\\Gamma\\) under constraint of fixed \\((t_0, q_0), (t_1, q_1)\\), it must also have zero variation if we use the stronger constraint of fixed \\((t_0, q_0, p_0), (t_1, q_1, p_1)\\). Then the Euler–Lagrange equations state14\n14 One can interpret this as treating the phase space as if it is a state space of a physical system with \\(2N\\) degrees of freedom.\\[-\\nabla_q H = \\dot p, \\quad \\nabla_p H = \\dot p\\]\nwhich, as we proved, are precisely the conditions (no arbitrage pricing, and stationary profit flow) for \\(\\delta \\int_\\gamma L = 0\\). ◻ :::\n\n\nMaupertuis’ principle\nMaupertuis’ principle is a principle for specifying orbits in phase space. An orbit is a trajectory of the physical system, but with timing information lost. We know that the system traveled through the states on the orbit, one after another, but we don’t know how fast is the traversal.\nIn order to be very explicit about it, we will write orbits in phase space as \\(\\mu: [a, b] \\to \\mathcal P\\). Here \\(a, b\\) look like \"start and end times\" and \\(\\mu(s)\\) looks like \"location of the path at time \\(s\\)\", but \\(s\\) is not time, and \\(a, b\\) are not moments in time either. It is really just a parametrization of the curve, with no implications about how fast, or how slow, the system would actually traverse the orbit.\nThe integral \\(\\int_\\mu \\sum_i p_i \\dot q_i ds\\) is unchanged by stretching and pressing the timing of \\(\\mu\\). That is, let \\(f: [a', b'] \\to [a, b]\\) be a strictly increasing differentiable function, then \\(\\int_{\\mu\\circ f} \\sum_i p_i \\dot q_i ds = \\int_\\mu \\sum_i p_i \\dot q_i ds\\). Consequently, Maupertuis’ principle is really concerned only with the orbit, not the timing of the orbit.\nSince timing is lost, the constraint of fixed \\((t_0, q_0), (t_1, q_1)\\) cannot apply. However, merely fixing \\(q_0, q_1\\) is too little constraint. The solution is to add a new constraint: the variation must stay on the surface of constant energy \\(E\\). That is, \\(H(\\mu'(s')) = E\\) for any variation \\(\\mu'\\) and parameter \\(s'\\). This is how we arrive at Maupertuis’ principle.\n::: prop\nWhen the Hamiltonian is time-independent, Hamilton’s principle and Maupertuis’ principle are equivalent (after a retiming scaling).\nGiven phase space \\(\\mathcal P\\) and a time-independent Hamiltonian \\(H(q, p)\\) over the phase space, such that \\((\\nabla_q H, \\nabla_p H)\\) is never zero, then any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) that satisfies Hamilton’s principle also satisfies Maupertuis’ principle.\nConversely, given any orbit \\(\\mu: [a, b] \\to \\mathcal P\\) with constant \\(H\\) that satisfies Maupertuis’ principle, there exists a \"retiming map\" \\(f: [t_0, t_1]\\to [a, b]\\) such that \\(f\\) is monotonically increasing, and \\(\\mu\\circ f\\) satisfies Hamilton’s principle. :::\n::: proof Proof. We show that Maupertuis’ principle is equivalent to Hamilton’s equations of motion after a retiming map.\nConsider orbit \\(\\mu: [a, b] \\to \\mathcal P\\) in phase space, with constant \\(H(\\mu(s)) = E_0\\). By integration-by-parts, we have\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int \\langle \\delta p, \\dot q\\rangle - \\langle \\dot p, \\delta  q\\rangle ds + \\cancel{\\langle p, \\delta q\\rangle} \\Big|_{a}^{b}\\]\nwhere the variation fixes \\(q_0, q_1\\) and \\(H\\).\nNow, \\(\\delta H = \\langle \\nabla_p H, \\delta p\\rangle +  \\langle \\nabla_q H, \\delta q\\rangle = 0\\). So, if the orbit satisfies Hamilton’s equations of motion after a retiming map \\(f\\), that is,\n\\[\\begin{cases}     \\dot p = -f'(s)\\nabla_p H \\\\     \\dot q = f'(s)\\nabla_q H \\end{cases}\\]\nthen plugging it back, we get\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int f'(s) \\delta H ds = 0\\]\nIt is routine to check that, given four vectors \\(a, b, c, d\\in \\R^N\\), if \\(\\forall x, y\\in \\R^N\\),\n\\[\\langle a, x\\rangle - \\langle b, y\\rangle = 0 \\implies \\langle c, x\\rangle - \\langle d, y\\rangle = 0\\]\nthen there exists \\(\\lambda &gt; 0\\) such that \\(c = \\lambda a, d = \\lambda d\\).\nThus, if the variation is zero for all \\(\\delta q, \\delta p\\) with fixed \\(H\\), then there exists some continuous and positive function \\(\\lambda: [a, b] \\to \\R\\) such that\n\\[\\begin{cases}     \\dot p = -\\lambda(s)\\nabla_p H \\\\     \\dot q = \\lambda(s)\\nabla_q H \\end{cases}\\]\nNow solve for \\(f' = \\lambda^{-1}\\) by integration15, then \\(f\\) is the desired retiming map. ◻ :::\n15 Since \\(\\lambda\\) is continuous and positive, with compact domain, its range must be bounded below by some positive constant \\(\\epsilon &gt; 0\\), thus the integration would not diverge."
  },
  {
    "objectID": "blog/posts/art/index.html#canonical-transformations",
    "href": "blog/posts/art/index.html#canonical-transformations",
    "title": "Analytical physics",
    "section": "Canonical transformations",
    "text": "Canonical transformations\n\nGenerating functions\nThe dynamics of a physical system can be fully defined by its Lagrangian function. However, the Lagrangian function is not fully defined by the dynamics. There are many possible functions that can all play the role of the Lagrangian.\nSuppose \\(L(t, q, v)\\) is a Lagrangian function, then take any twice-differentiable function \\(F(t, q)\\), and define\n\\[L' dt := L dt + dF\\]\nwhich implies\n\\[L'(t, q, v) := L(t, q, v) + \\partial_t F(t, q) + \\langle \\nabla_q F(t, q), v\\rangle\\]\nthen it is easy to directly verify that a trajectory \\(\\gamma(t)\\) satisfies the Euler–Lagrange equations for \\(L\\) iff it satisfies them for \\(L'\\). Consequently, both \\(L\\) and \\(L'\\) are different functions that can both play the role of Lagrangian for the same physical system.\nInstead of directly computing the Euler–Lagrangian equations, we can also do it directly by variational principles: For any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) we have\n\\[\\int_{t_0}^{t_1} L'(t, \\gamma(t), \\dot \\gamma(t))dt = F(t, \\gamma(t))|_{t_0}^{t_1} + \\int_{t_0}^{t_1} L(t, \\gamma(t), \\dot \\gamma(t))dt\\]\nConsequently, \\(\\delta \\int Ldt = 0\\) iff \\(\\delta \\int L'dt = 0\\), so a trajectory has stationary action according to one Lagrangian iff according to the other.\nSuch \\(F(t, q)\\) are called a generating function for transforming a Lagrangian function. Generating functions are really just functions that are picked to play a certain role. That is, being a generating function is not an intrinsic property of a function, but extrinsic, because some human physicist has decided to use it for generating a new Lagrangian from an old one. This is why I don’t like saying \"\\(F\\) a generating function...\". Instead, I prefer to say \"Now we use \\(F\\) to generate a new Lagrangian...\" Nevertheless I am forced to use the term because it is a venerable error, a bug that became a feature.\n\n\nGenerating functions for Hamiltonians\nHamiltonians are freer than Lagrangians. Instead of one way, there are many ways to generate new Hamiltonians from old.\nTaking inspiration from Lagrangian generating functions, we write down the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nwhere \\(G: \\R \\times \\mathcal P \\to \\R\\) is any twice-differentiable function on phase spacetime.\n::: theorem If \\((q, p), (Q, P)\\) are two coordinate systems on the phase spacetime, and \\(h, H, G\\) are twice-differentiable functions on phase spacetime, and\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nThen along any trajectory in phase spacetime, \\((q, p)\\) satisfies Hamiltonian equations of motion for \\(h\\), iff \\((Q, P)\\) satisfies Hamiltonian equations of motion for \\(H\\). :::\n::: proof Proof. Let \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) be any trajectory, not necessarily satisfying Hamilton’s equations of motion. Then for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\), we have by integration-by-parts,\n\\[\\begin{aligned}     &\\delta\\int_\\gamma \\langle p , dq \\rangle - hdt = \\delta\\int_\\gamma \\langle P, dQ \\rangle - Hdt + dG\\\\     &= \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt + (\\langle P, \\delta Q \\rangle + \\delta G)\\Big|_{t_0}^{t_1} \\\\     &= \\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt + \\langle p, \\delta q \\rangle \\Big|_{t_0}^{t_1}  \\end{aligned}\\]\nThe boundary terms are equal, since \\(\\langle p , \\delta q \\rangle - h \\delta t = \\langle P, \\delta Q \\rangle - H\\delta t + \\delta G\\), and \\(\\delta t = 0\\) as we fixed \\(t_0, t_1\\).\nThus, for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\),\n\\[\\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt = \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt\\]\nThus, if \\(\\gamma\\) satisfies Hamiltonian equations of motion for \\((q, p), h\\), then it also does so for \\((Q, P), H\\). ◻ :::\n\n\nCoordinate-based canonical transforms\nThis section might make more sense after reading the next section.\nThe equation\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nlives in phase spacetime. That is, \\(dq, dt, dQ, dG\\) are all differentials in \\(\\R \\times \\mathcal P\\). This is elegant, but not good for concrete computations, which requires coordinate-based equations.\nGenerally, \\(G(t, y)\\) is a function on phase spacetime, so it could be represented in any coordinate system of phase spacetime. For example, we can represent it as \\(G(t, y) = G_{q, p}(t, q(t, y), p(t, y))\\), or \\(G(t, y) = G_{Q, P}(t, Q(t, y), P(t, y))\\), or even mixed coordinates like \\(G(t, y) = G_{q, P}(t, q(t, y), P(t, y))\\), etc.\nMost representations result in intractable coordinate-based equations, but a few are actually usable. These are traditionally classified as \"type 1\" to \"type 5\".\nType 1: \\(G(t, y) = F_1(t, q(t, y), Q(t, y))\\).\nPlugging it in, we find\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_1 dt + \\langle \\nabla_q F_1, dq \\rangle + \\langle \\nabla_Q F_1, dQ \\rangle\\]\nyielding the equations\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q) \\\\     p = \\nabla_q F_1(t, q, Q) \\\\     P = - \\nabla_Q F_1(t, q, Q) \\end{cases}\\]\nIn order to solve for the canonical transform, first invert \\(p = \\nabla_p F_1(t, q, Q)\\) to obtain \\(Q = f_Q(t, q, p)\\), then plug it into \\(P = - \\nabla_Q F_1(t, q, Q)\\) to obtain \\(P = f_P(t, q, p)\\). Inverting them gives us \\(q = g_q(t, Q, P), p = g_p(t, Q, P)\\).\nThen, given any Hamiltonian \\(h(t, q, p)\\), the corresponding \\(H(t, Q, P)\\) is found by \\(H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q)\\), or very explicitly,\n\\[H(t, Q, P) = h(t, g_q(t, Q, P), g_p(t, Q, P)) + \\partial_t F_1(t, g_q(t, Q, P), Q)\\]\nType 2: \\(G(t, y) = F_2(t, q(t, y), P(t, y)) - \\langle P(t, y), Q(t, y)\\rangle\\).\nWhy \\(\\langle P, Q\\rangle\\)? Directly writing down \\(G = F_2(t, q, P)\\) results in the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_2 dt + \\langle \\nabla_q F_2, dq \\rangle + \\langle \\nabla_P F_2, dP \\rangle\\]\nHere, there is an entanglement between terms \\(dq, dQ, dP\\). Since there are only \\(2N\\) dimensions in the phase space, but there are \\(3N\\) differentials in \\(dq, dQ, dP\\), it must be possible to represent \\(N\\) of them as a linear combination of the other \\(2N\\) differentials. In particular, we can represent \\(dQ\\) as a linear combination of \\(dq, dP\\).\nInstead, we can directly cancel out \\(\\langle P, Q\\rangle\\) from the equation by writing \\(G\\) as \\(G + \\langle P, Q\\rangle - \\langle P, Q\\rangle\\), then represent \\(G + \\langle P, Q\\rangle\\) as \\(F_2(t, q, P)\\). This then gives\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_2(t, q, P) \\\\     Q = \\nabla_P F_2(t, q, P) \\\\     p = \\nabla_q F_2(t, q, P) \\end{cases}\\]\nType 3: \\(G = F_3(t, p, Q) + \\langle p, q\\rangle\\).\nType 4: \\(G = F_4(t, p, P) + \\langle p, q\\rangle  - \\langle P, Q\\rangle\\).\nType 5: \\(G = F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) + \\langle p_{I_1}, q_{I_1} \\rangle - \\langle P_{I_3}, Q_{I_3} \\rangle\\).\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     q_{I_1} = -\\nabla_{p_{I_1}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     p_{I_2} = \\nabla_{q_{I_2}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     Q_{I_3} = \\nabla_{P_{I_3}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     P_{I_4} = -\\nabla_{Q_{I_4}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\end{cases}\\]\nHere, \\(I_1, I_2, I_3, I_4\\) stand for subsets of the indexing set \\(\\{1, 2, ..., N\\}\\). We also require \\(I_1 \\cup I_2 = I_3 \\cup I_4 = \\{1, 2, ..., N\\}\\)\nNote that types 1 to 4 are all special cases of type 5.\n\n\nExamples of canonical transforms\n\nPoint transforms\nIf \\(G= 0\\), then we need to solve only the equation \\(\\langle p, dq \\rangle = \\langle P, dQ \\rangle\\), which can be done in general iff \\(dQ\\) is a linear combination of \\(dq\\), thus \\(Q = f_Q(t, q)\\) for some function \\(f_Q\\). This is just the point transform, with solution\n\\[P = ([\\nabla_q f_Q]^T)^{-1}p\\]\n\n\nInterpolating a canonical transform\nGiven any canonical transform from \\((q, p)\\) to \\((Q, P)\\), for any two times \\(t_0 &lt; t_1\\), we can interpolate between \\((q, p), (Q, P)\\) over the period \\([t_0, t_1]\\). That is, we construct a canonical transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) such that \\((\\bar q, \\bar p) = (q, p)\\) at \\(t=t_0\\), and \\((\\bar q, \\bar p) = (Q, P)\\) at \\(t = t_1\\).\nThe idea is to note that any canonical transform can be written in type 2, including the identity transform.\nThe identity transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) can be represented in type 2 as\n\\[G_0 = \\langle q, \\bar p \\rangle - \\langle \\bar p, \\bar q \\rangle\\]\nGenerate the transform from \\((q, p)\\) to \\((Q, P)\\) by \\(G\\), and represent it in type 2 as\n\\[G_1 = F_2(t, q, P) - \\langle P, Q \\rangle\\]\nNow interpolate them by\n\\[G = \\frac{t_1-t}{t_1 - t_0} \\langle q, \\bar p \\rangle + \\frac{t - t_0}{t_1 - t_0} F_2(t, q, \\bar p)  - \\langle \\bar p, \\bar q \\rangle\\]\n\n\nTime-evolution is a canonical transform generated by the action\nRecall that, for any coordinate system \\((q, p)\\) and Hamiltonian \\(h\\), we defined the action function (\"Hamilton’s principal function\") \\(S(t_1, q_1; t_0, q_0)\\) to be the action for the path \\(\\gamma\\) from \\((t_0, q_0)\\) to \\((t_1, q_1)\\). We also proved, during derivation of the HJE,\n\\[dS = \\langle p_1, dq_1 \\rangle -h(t_1, q_1, p_1) dt_1 - \\langle p_0, dq_0 \\rangle + h(t_0, q_0, p_0) dt_0\\]\nRearrange, and using suggestive notation, we get...\n\\[\\langle p_0, dq_0 \\rangle - h_0 dt_0 = \\langle p_1, dq_1 \\rangle -h_1 dt_1 + dS\\]\nSo we find that time evolution is a canonical transformation generated by \\(S\\).\nIn more detail, fix some coordinate system \\((q, p)\\). Then for any Hamiltonian \\(\\mathcal H : \\R \\times \\mathcal P \\to \\R\\), define its time-evolution function \\(\\phi\\), such that \\(\\phi(t_0, t_1; y)\\) is the point that we end up with at time \\(t_1\\), if we start at \\(y\\) at time \\(t_0\\), and evolve according to \\(\\dot q = \\nabla_p h, \\dot p = -\\nabla_q h\\), where \\(h(t, q(t, x), p(t, x)) = \\mathcal H(t, x)\\) is the coordinate-based version of the coordinate-free \\(\\mathcal H\\).\nNow, fix some time-interval \\(s\\in \\R\\), then define the (coordinate-free) function \\(\\mathcal G\\), the action of the trajectory starting at \\((t, y)\\) and lasting for \\(s\\):\n\\[\\mathcal G(t, y) := S(t+s, q(t+s, \\phi(t, t+s; y)); t, q(t, y))\\]\nand the new coordinate system with a new Hamiltonian, obtained by \"evolving for \\(s\\) time\": \\[\\begin{aligned} Q(t, y) = q(t+s, \\phi(t, t+s; y)) \\\\ P(t, y) = p(t+s, \\phi(t, t+s; y)) \\\\ H(t, Q(t, y), P(t, y)) = \\mathcal H(t + s, \\phi(t, t+s; y)) \\end{aligned}\\]\nwhich allows a coordinate-based representation of \\(\\mathcal G\\):\n\\[G(t, q, Q) = S(t+s, Q; t, q)\\]\nWith these definitions, we have\n\\[dG = -Hdt + \\langle P, dQ \\rangle + hdt -\\langle p, dq \\rangle\\]\nthat is, \\((Q, P), H\\) is canonically transformed from \\((q, p), h\\) via the function \\(G\\).\n\n\n\nSimple harmonic oscillator\nConsider a SHO with \\(N\\) degrees of freedom. Its Hamiltonian is\n\\[H = \\frac 12 p^T M^{-1} p + \\frac 12 q^T K q\\]\nwhere \\(M\\) is the matrix representing the masses of the system, and \\(K\\) is the matrix representing the elastic constants of the system.\n\nTranslation is a canonical transform generated by momentum\n\n\nRotation is a canonical transform generated by angular momentum\n\n\n\nCanonical transforms, in general\nThere are two possible ways to define canonical transforms. The more concrete way is by using generating functions: two coordinate systems \\((q, p), (Q, P)\\) on phase spacetime are generated canonical transforms of each other iff\n\\[\\langle p, dq\\rangle - \\langle P, dQ\\rangle = dG\\]\nfor some \\(G\\) functions on phase spacetime. Remember that \\(dq, dQ\\) are differentials with constant time.\nAs for the more abstract form... long story short: every canonical transform has a generating function. This is usually called \"Carathéodory Theorem\". See (Goldstein, Poole, and Safko 2008, sec. 9.5).\nThis has a more elegant form with exterior calculus. Take exterior differentiation (again, only in phase space, not in time), we get\n\\[\\sum_i dp_i \\wedge dq_i = \\sum_i dP_i \\wedge dQ_i\\]\nNow take wedge product \\(N\\) times with itself, we get\n\\[\\bigwedge_i dp_i \\wedge dq_i = \\bigwedge_i dP_i \\wedge dQ_i\\]\nInterpretation: canonical transforms preserve phase space volumes. That is, if we have an open subset in phase space, defined coordinate-free, then we can compute its volume by writing down a canonical coordinate system \\((q, p)\\) and integrating \\(\\prod_i dp_i dq_i\\). The result is unchanged by a canonical transform to \\((Q, P)\\).\nThis gives us a new proof of Liouville’s theorem:\n\nProof. Since time-evolution is a canonical transform, time-evolution preserves volumes.\nGiven a particle flow in phase space, with density \\(\\rho(t, p, q)\\), flowing according to Hamiltonian \\(H(t, q, p)\\). Take an infinitesimal cube around \\((q, p)\\) at time \\(t\\), with volume \\(\\delta V = \\prod_i \\delta p_i \\delta q_i\\), then it contains \\(\\delta N = \\rho(t, q, p) \\delta V\\) number of particles. Then, let it flow for time \\(s\\).\nThe infinitesimal cube is transported to some other parallelogram around some point \\((q', p')\\), but its volume is unchanged, thus the density at the new location is still the same: \\(\\rho(t+s, q', p') = \\rho(t, q, p)\\). Thus \\(\\dot \\rho = 0\\). \n\n\n\nPoisson brackets are preserved by canonical transforms\nThe Poisson bracket \\(\\{f, g\\}\\) was defined in a coordinate-based way:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nWe show that it is preserved by canonical transforms. That is, if \\((Q, P)\\) is a canonical transform of \\((p, q)\\) then\n\\[\\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right) = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial Q_{i}} \\frac{\\partial g}{\\partial P_{i}} - \\frac{\\partial f}{\\partial P_i} \\frac{\\partial g}{\\partial Q_i}\\right)\\]\n\nProof. (From the Landau–Lifshitz textbook) Since the Poisson bracket does not depend on time, and if \\(Q(t, q, p), P(t, q, p)\\) is a canonical transform, so is \\(Q(t, q, p), P(t, q, p)\\), so we consider only canonical transforms that are independent of time.\nIf we started with only \\(f(q, p), g(q, p)\\), then extend them to phase spacetime by\n\\[\\mathcal F(t, y) = f(q(0, y), p(0, y)),\\quad \\mathcal G(t, y) = g(q(0, y), p(0, y))\\]\nNext, impose \\(\\mathcal G\\) as a Hamiltonian, and evolve the physical system according to Hamilton’s equations of motion for \\((q, p), \\mathcal G\\). Since \\((q, p)\\) and \\((Q, P)\\) are canonical transforms of each other, we have\n\\[\\{\\mathcal F, \\mathcal G\\}_{q, p} + \\partial_t \\mathcal F = \\dot{\\mathcal F} = \\{\\mathcal F, \\mathcal G'\\}_{Q, P} + \\partial_t \\mathcal F\\]\nOkay, what is \\(\\mathcal G'\\)? It is a solution to\n\\[\\langle p, dq \\rangle - \\mathcal G dt  = \\langle P, dQ \\rangle - \\mathcal G' dt + d\\mathcal K\\]\nsince \\(\\mathcal K\\) does not depend on time, \\(d\\mathcal K\\) contains zero \\(dt\\) term, so \\(\\mathcal G = \\mathcal G'\\).\n\n\n\nInterpretation of canonical transforms\nWhat is invariant under canonical transforms is what is really real about the physical system. Other things are mirages, illusions caused by our choice of coordinates.\nThus, position and momentum are mirages. Hamiltonian equations are real. \\(p, q\\) are mirages. \\(\\int \\sum_i p_i dq_i\\) is real. \\(\\nabla_p, \\nabla_q\\) are mirages. Poisson brackets \\(\\{f, g\\}\\) are real. Phase space lengths \\(dp, dq\\) are mirages. Phase space areas \\(\\sum_i p_i dq_i\\), volumes \\(\\prod_i dp_i dq_i\\), and densities \\(\\rho\\) are real."
  },
  {
    "objectID": "blog/posts/art/index.html#action-angle-variables-and-integrability",
    "href": "blog/posts/art/index.html#action-angle-variables-and-integrability",
    "title": "Analytical mechanics",
    "section": "Action-angle variables and integrability",
    "text": "Action-angle variables and integrability\n\n1-dimensional oscillators\nConsider a SHO (simple harmonic oscillator), with Hamiltonian \\(H\\) in the \\((q, p)\\) coordinates:\n\\[H(t, q, p) = \\frac{p^2}{2m} + \\frac 12 kq^2\\]\nThe motion of the system is very simple: a circular motion around \\((q, p) = (0, 0)\\):\n\\[\\begin{cases} \\dot q = p/m \\\\ \\dot p = - kq \\end{cases}\\quad  \\begin{cases} (q, p) = (q_0 \\cos(\\omega t), -m\\omega q_0 \\sin(\\omega t)) \\\\ \\omega = \\sqrt{k/m} \\end{cases}\\]\nNow consider the action of an entire cycle:\n\\[\\oint pdq - Hdt\\]\nThe \\(\\oint pdq\\) term is the area enclosed by the ellipse, so it is \\(\\pi p_0 q_0\\), and the \\(\\oint Hdt\\) term is just \\(HT = \\frac{2\\pi}{\\omega} \\frac 12 kq_0^2\\), since the system conserves energy. Now direct computation shows\n\\[\\oint pdq = HT\\]\nWe prove that this is generally true for 1D oscillators.\nConsider a generic 1D oscillator, with phase plot as shown in Figure 5. Its phase space is split into cycles, which are not generally circular in shape, and generally each cycle has a different cycling period.\n\n\n\nPhase plot of the 1D oscillator.\n\n\nTake a particular cycle as shown, starting and ending at \\(q_0 = q_1\\). Now consider this variation that fixes \\((t_0, q_0), (t_1, q_1)\\): move from point 0 to point 1, then go around the larger cycle to point 1, then return to point 0. The action of the varied cycle consists of three parts: \\(0\\to 1, 1 \\to 1, 1 \\to 0\\). By modified Hamilton’s principle, the variation is zero.\nNow, let \\(T(E) = t_1 - t_0\\) be the cycle period for the cycle with energy \\(E\\), then from our above argument, we have\n\\[\\oint_E pdq - E T(E) = \\oint_{E + \\delta E} pdq - (E + \\delta E) T(E) + O(\\delta E^2)\\]\nwhere the \\(O(\\delta E^2)\\) term deals with the \\(0\\to 1, 1\\to 0\\) parts of \\(\\int -Hdt\\). Thus we obtain\n\\[\\frac{d}{dE} \\oint_E pdq = T(E)\\]\nNow, it would be great if we could \"unwind\" the rotatory dynamics by a time-independent canonical transform to some \\((Q, P)\\), by setting \\(P\\) constant along the cycles, and \\(Q\\) increasing along the cycles. That is, we want \\(P\\) to be the analog of \"amplitude\", and \\(Q\\) to be the analog of \"phase angle\". Since the transform is time-independent and canonical, the Hamiltonian \\(H\\) is unmodified, so \\(H\\) is a function of \\(P\\) only, not \\(Q\\) (since \\(H\\) is constant around any cycle). Then, since the transform is canonical, Hamilton’s equations of motion read \\(\\dot Q = \\partial_P H(P)\\). Consequently, the equations of motion would become\n\\[\\begin{cases} P(t) = P(0) \\\\ Q(t) = Q(0) + H'(P) t \\end{cases}\\]\nas simple as it could be! It remains to find such a canonical transform.\nWe are already mostly there: we know that \\(P\\) is constant along the cycles, and \\(Q\\) increasing along the cycles. It remains to find the right scaling, so that the transform is canonical, that is, the coordinates preserve area: \\(dP \\wedge dQ = dp \\wedge dq\\).\nDefine \\(P = \\frac{1}{2\\pi} \\oint pdq\\). Here the \\(2\\pi\\) factor is not essential, since we could always do a point transform, scale down \\(Q\\) by \\(2\\pi\\), and scale up \\(P\\) by \\(2\\pi\\). However, the factor will make many formulas look cleaner.\nFrom previous argument, we know that increasing the energy of the cycle by \\(\\delta H\\) would increase the cycle area by \\(T(H)\\delta H\\), and the cycle area is \\(2\\pi P\\), thus\n\\[\\delta(2\\pi P) = T(H) \\delta H \\implies \\frac{2\\pi}{T(H)} = H'(P)\\]\nso we find that the equations of motion are:\n\\[\\begin{cases} P(t) = P(0) \\\\ Q(t) = Q(0) + 2\\pi \\frac{t}{T(H)} \\end{cases}\\]\nThis allows us to graphically construct the \\((Q, P)\\) coordinates on phase space: start by drawing the cycles in phase space, then select a \"line of longitude\" arbitrarily as \\(Q= 0\\) line. Then follow the trajectory of each point on the line of longitude, and mark down a new line of longitude at equal phases. We construct the \\(Q= \\theta\\) curve thus. Release one particle at a point of the \\(Q=0\\) line, and watch how long it takes for it to complete one cycle. Let that time be \\(T\\). Now mark the point that it reached at time \\(\\theta T/2\\pi\\). The set of all such points is the curve \\(Q=\\theta\\). See Figure 6.\n\n\n\nConstructing a canonical coordinate system over the phase space of the 1D oscillator.\n\n\nNow, we can graphically see that this construction really preserves areas. Take an infinitesimal parallelogram at \\((Q, P)\\) with sides \\(\\delta Q, \\delta P\\), such that \\(\\delta Q = \\frac{2\\pi}{N}\\) for some large integer \\(N\\). Next evolve the system in discrete steps of \\(\\frac{T(P)}{N}\\), and follow the parallelogram along. It would tile the thin ring between \\(P\\) and \\(P+ \\delta P\\). The thin ring has area \\(\\delta(2\\pi P) = 2\\pi \\delta P\\), so each parallelogram has area \\(2\\pi \\delta P/N = \\delta P \\delta Q\\).\nThe entire construction of \\((Q, P)\\) from \\((q, p)\\) is often done in one divinely-inspired move by a generating function.\n\n\nAside: pendulum in gravity\nThe 1D pendulum in gravity, with length \\(l\\) and mass \\(m\\), has Lagrangian \\(L = \\frac 12 m(l\\dot q)^2 + mgl\\cos q\\), momentum \\(p = ml^2 \\dot q\\), and Hamiltonian\n\\[H = \\frac{p^2}{2ml^2} - mgl \\cos(q)\\]\nWe know that the pendulum is not a SHO. Indeed, the cycle period \\(T(E)\\) strictly increases with energy \\(E\\) of the cycle, and it diverges as the pendulum swing approaches the highest point: \\(\\lim_{E \\to mgl} T(E) = +\\infty\\).\nConsider the cycle with maximum swing angle \\(\\theta\\). The cycle encloses an oval-shaped region in phase space, with equation \\(p^2 = 2m^2 gl^3(\\cos q - \\cos\\theta)\\). Consequently, we have the somewhat mysterious result:\n\\[\\int_0^{E(\\theta)} T(E) dE = 4\\sqrt{2m^2 gl^3} \\int_0^\\theta \\sqrt{\\cos q - \\cos\\theta} dq\\]\nwhere \\(E(\\theta) = -mgl \\cos\\theta\\) is the energy of the system when it has maximum swing angle \\(\\theta\\).\nWhen \\(\\theta\\) is small, the integral is approximately\n\\[\\int_0^\\theta \\sqrt{\\frac 12 (\\theta^2 - q^2)}dq = \\frac{\\pi\\theta^2}{4\\sqrt 2}\\]\nwhich does correspond to \\(T(E) \\approx 2\\pi\\sqrt{\\frac lg}\\), and \\(\\delta E = mgl(1 - \\cos(\\theta)) \\approx \\frac 12 mgl \\theta^2\\).\nWhen \\(\\theta = \\pi\\), the integral can be exactly evaluated:\n\\[\\int_0^{mgl} T(E) dE = 16\\sqrt{m^2 gl^3}\\]\nWe are unable to interpret this strange but satisfying equality.\nDifferentiating under the integral sign wirt \\(\\theta\\), we get\n\\[T(E) = \\sqrt{\\frac{8l}g} \\int_0^\\theta \\frac{dq}{\\sqrt{\\cos q - \\cos \\theta}}\\]\nwhich may be directly verified.\n\n\nN-dimensional oscillators\n\n\nThe adiabatic pendulum\nThe Lorentz pendulum is a famous example that connects the classical and the quantum world. At the 1911 Solvay Conference, the great physicists grappled with the new quantum phenomena.14 At the end of Einstein’s presentation on the quantum hypothesis, Lorentz asked a question about the Lorentz pendulum. The conversation went as follows:\n14 The entire conference is summarized in (Straumann 2011).\nMr. Lorentz recalls a conversation he had with Mr. Einstein some time ago, in which they discussed a simple pendulum that could be shortened by holding the string between two fingers and sliding them downwards. Suppose that initially, the pendulum has exactly one energy element corresponding to the frequency of its oscillations. It then seems that at the end of the experiment, its energy will be less than the element corresponding to the new frequency.\nMr. Einstein - If the length of the pendulum is changed infinitely slowly, the energy of the oscillation remains equal to  \\(h\\nu\\) , if it was initially equal to  \\(h\\nu\\) ; it varies proportionally to the frequency. The same is true for a resistance-free oscillating electrical circuit, and also for free radiation.\nMr. Lorentz - This result is very curious and removes the difficulty. In general, the hypothesis of energy elements gives rise to interesting problems in all cases where one can change the frequency of vibrations at will.\n(Instituts Solvay et al. 1912, 450)\n\nWhy is this interesting? The quantum hypothesis states that for quantum oscillators, \\(E/\\nu = nh\\), where \\(n\\) can only take values in the natural numbers. The Lorentz pendulum seems to show that the quantity \\(E/\\nu\\) can change continuously, thus we can go from \\(E/\\nu = 100h\\) to \\(100.5h\\), invalidating the quantum hypothesis for macroscopic systems. And if macroscopic systems do not follow the quantum hypothesis, then as the macroscopic system becomes microscopic, it seems the quantum hypothesis would be invalidated as well.\nEinstein replied that \\(E/\\nu\\) of the oscillator is conserved if the length of the pendulum is changed infinitely slowly. Surprising, but it saves the quantum hypothesis.\n\nSimple examples\nParametric resonance . For more on the solution to the periodically forced pendulum, see (de Oliveira 2022).\nConsider the 1-dimensional system in Figure 7. The pendulum keeps swinging, but its string length \\(\\lambda\\) is slowly changed over time. How slow? Slow enough that the system completes many cycles before \\(\\lambda\\) makes any appreciable change. That is,\n\\[\\dot \\lambda \\ll \\frac{\\lambda}{T(\\lambda)}\\]\n\n\n\nThe adiabatic pendulum.\n\n\nLet the system have Hamiltonian \\(H(t, q, p) = H(q, p; \\lambda(t))\\).\nLet \\(T(\\lambda)\\) be the cycle length of the system at \\(\\lambda\\). Note that this does not depend only on \\(\\lambda\\), but also the starting state of the pendulum. If the pendulum started on a fast orbit then it stands to reason that \\(T(\\lambda)\\) would always be shorter than if the pendulum started on a slow orbit.\nExercise: Perform the same analysis on a vibrating string. The string is fixed at both ends, and the length of the string is slowly changed. The string is in a standing wave pattern, and the length of the string is changed so slowly that the string completes many cycles before the length changes appreciably. What is the adiabatic invariant in this case? The answer is in Lord Rayleigh’s 1911 paper [@?].\nExercise: Prove that \\(I\\) is conserved, by calculating the average force \\(\\bar F\\) on the piston, then use that to derive the work done by the piston.\n\n\n\n\n\n\nAdiabatic invariance to all orders\n\n\n\n\n\nThe adiabatic invariance is actually much stronger than what we have shown. It is not just that the enclosed action \\(I\\) is conserved up to \\(O(\\dot\\lambda)\\), but that it is conserved to all orders in \\(O(\\dot \\lambda^n)\\) (Lenard 1959). Under stronger restrictions, it is even conserved to order \\(O(e^{c/\\dot \\lambda})\\). See (Henrard 1993, sec. 4) for more theorems in this style.\n\n\n\n\n\nGeneral proof\nThe general proof of adiabatic invariance is as follows. Consider a system with Hamiltonian \\(H(q, p; \\lambda)\\), where \\(\\lambda\\) is a slowly changing parameter. The action of the system is\n\n\nConnection to quantum mechanics\n\nSommerfeld, in the new edition of his book [Atombau und Spektrallinien], has introduced the adiabatic hypothesis through a couple of very elegant changes and footnotes, in such a way that my participation in that can rather appear reduced to — a plagiarism. Lorentz and Einstein have founded the subject, I have given it a name and Burgers has put everything in order. I was first very, very depressed. I know that I have never discovered anything, and quite surely never will discover anything, that I can love so fervently as this line of thought which I found out with so large joy.\nEhrenfest’s letter to Bohr, 8 May 1922. Emphasis in original. Quoted in (Navarro and Pérez 2006)\n\n\n\nConnection to thermodynamics\nA simpler example is when we put one ball moving in a piston. We hold one wall of the piston constant, and slowly move the other. The phase space diagram of the ball is then a rectangle. Let the ball have speed \\(v\\), and the walls of the piston have separation \\(L\\). The action enclosed by one cycle of the system is \\(I = 2mvL\\). If we slowly move the wall of the piston, then the action is conserved, giving us\n\\[\n2mv_0 L_0 = 2mvL \\implies v = \\frac{L_0}{L} v_0\n\\]\nWe can formulate this into the language of thermodynamics. First, expand our system to three dimensions – from a piston to a box. Since the motion of the ball in the \\(x, y, z\\) directions are independent, we can treat them separately. We also assume equipartition of energies, that is, the energy of the ball is equally distributed among the three dimensions, so \\(v_{x, 0} = v_{y, 0} = v_{z, 0}\\). The conservation of action then states that\n\\[\nv_i = \\frac{L_{i, 0}}{L_i} v_{i, 0} \\quad \\text{for } i = x, y, z\n\\]\nImagine the ball is a gas molecule, and the piston is a wall of a container. Let \\(E = \\sum_{i = x, y, z} \\frac 12 mv_i^2\\) be the energy of the gas molecule, and \\(V = \\prod_{i = x, y, z}L_i\\) be the volume of the gas. We then have\n\\[\nV = V_0 \\prod_i \\frac{L_i}{L_{i, 0}} \\approx V_0 \\left(1 + \\sum_i \\frac{\\delta L_{i}}{L_{i, 0}}\\right), \\quad\n\\begin{aligned}\nE &= \\frac 12 m \\sum_i \\left(\\frac{L_{i,0}}{L_i}\\right)^2 v_{i, 0}^2\\\\\n&= \\frac 32 m v_0^2 \\frac 13 \\sum_i \\left(\\frac{L_{i,0}}{L_i}\\right)^2 \\\\\n&\\approx E_0 \\left(1 - \\frac 23 \\sum_i \\frac{\\delta L_{i}}{L_{i, 0}}\\right)\n\\end{aligned}\n\\]\nThese imply that \\(E^{3/2}V \\approx E_0^{3/2}V_0\\). Now, this happens to be what happens if you compress an ideal gas adiabatically. This explains the connection between the use of the word “adiabatic” in classical mechanics and in thermodynamics.[^adiabatic-equivalence]\n\n\nMore examples\nGiven a Lorentz pendulum and a schedule for varying its arm length, we can plot the angle \\(x\\) as a function of time, and see directly that \\(I = T (\\frac 12 m \\dot x_{max}^2)\\) is conserved over many swings of the pendulum.\n\n\n\nA Lorentz pendulum with length increasing linearly with time. As its length increases, \\(\\dot x_{max}\\) decreases while \\(T\\) increases, keeping \\(I\\) conserved. Annotated from (Sánchez-Soto and Zoido 2013, fig. 1)\n\n\nFor a more rigorous proof of adiabatic invariance at the level of first-year graduate student, see (Wells and Siklos 2007). (Henrard 1993) is a good comprehensive review of adiabatic invariance in classical mechanics, and points to the literature on a lot of applications in celestial mechanics, magnetism, and the geometry of phase space plots.\n\n\nHistory\nThere are two ways to interpret the word “adiabatic”. In thermodynamics, “adiabatic” means “no exchange of heat”. In mechanics, “adiabatic” means “gradual”.15 It is a winding story of how one word “adiabatic” came to mean two things that fortuitously are connected after all, the details of which are given in (Jammer 1966, chap. 3; Laidler 1994). The story is almost as interesting as that of the word “entropy”, which also has two meanings that are fortuitously connected after all.\n15 Because “adiabatic” has two meanings in English, in Chinese, it also has two different translations based on the two meanings. There is 绝热, which means “no exchange of heat”, and 浸渐, which means “gradually, like moisture soaking into something”.Rankine first coined the term “adiabatic” in 1858, to denote a process in which no heat is exchanged with the surroundings. Later, Boltzmann and Clausius tried to explain the second law of thermodynamics mechanically, by using purely mechanical models of the microscopic world. In this sense, they defined an “adiabatic” mechanical process to be one where a certain variable is slowly changed (for example, if we have a box of little bouncing balls, and we very slowly move its walls), because an adiabatic thermodynamic process in their view is actually an adiabatic mechanical process.\n“Adiabatic motion” in mechanics was introduced by Helmholtz and Hertz, to denote mechanical processes where external forces act upon a system, but only on a few parameters, with no action on the underlying details. For example, think back to the case of bouncing balls in a box. The external force only moves the walls of the box on average, with no attempt to move the walls to manipulate the precise location of the ball. They used the thermodynamic terminology, because the work done on the system during an adiabatic motion results exclusively in changes in its energy. (Jammer 1966, chap. 3)\nAfter Pyotr Lebedev experimentally proved that radiation pressure exists, and follows Maxwell’s theory of electromagnetism, Lord Rayleigh (Rayleigh 1902) generalized the concept of radiation pressure to all kinds of mechanical vibrations. Since his goal was to understand what happens when you adiabatically compress a photon gas, that is, Wien’s displacement law,16 he studied the effect of adiabatic motion on some simple mechanical systems undergoing wave motion, such as the Lorentz pendulum, a vibrating cord, a piston of gas with a standing acoustic ave, etc.\n16 Since he didn’t actually know what a photon was, it might be better to say that he was studying what would happen when you compress a hot chamber of light. Though Wien’s displacement law is nowadays proved straight from quantum mechanics, back when ien discovered it in 1893, he used a thermodynamic argument using the adiabatic compression of a photon gas.Like Lord Kelvin, Paul Ehrenfest was also trying to explain Wien’s displacement law. He was puzzled by the fact that while Wien’s displacement law was derived without the quantum hypothesis, yet somehow, it remains true. Suppose we start with a box of light, then it follows a certain black body radiation, which can only be derived by the quantum hypothesis. Now suppose we adiabatically compress the box of light. Though the compression process is studied classically, without the quantum hypothesis, the final state of the light is still the black body radiation. So, it seems that if we start with a system following the quantum hypothesis, then any adiabatic classical process would give us a system that still follows the quantum hypothesis. This is the adiabatic hypothesis/principle of Ehrenfest, for which he was famous for.\nDuring the 1910s, Paul Ehrenfest published a series of papers to subsume the many ad-hoc quantum rules that were being discovered. His idea is as follows: If, in a system described by classical mechanics (such as the Lorentz pendulum), a certain quantity \\(I\\) is conserved as it undergoes adiabatic motion, then we can proclaim that \\(I\\) is quantized. That is, \\(I = nh\\) for the Heisenberg constant \\(h\\), and \\(n \\in \\mathbb{N}\\). Then, we can proceed to calculate its properties, such as its energy levels, its absorption and emission spectra, etc. He essentially gave the recipe of “old quantum mechanics”:\n\nFind a system that has a conserved quantity \\(I\\) under adiabatic motion.\n\nYou can do this by solving the equations of motion, then integrate \\(\\oint pdq\\).\nAlternatively, you can start with a harmonic oscillator, and adiabatically deform the system until it becomes the system you want. Ehrenfest called such systems “adiabatically related to the harmonic oscillator” (Jammer 1966, 99).\n\nProclaim that \\(I = nh\\) for some constant \\(h\\).\nCalculate the properties of the system.\n\nAs an example, consider the pinnacle of old quantum theory, the Bohr–Sommerfeld model of the hydrogen atom. First, treat the hydrogen atom as if it is a relativisitic solar system, with the electron as a planet, moving at relativistic speeds17 under the inverse-square force \\(F \\propto \\frac{1}{r^2}\\). Next, assume that the adiabatic invariant is quantized:\n17 Because the electron moves faster closer to the atom than further away, it has more mass close to the atom than further away. This allows the orbit to precess in a way that is not predicted by Newtonian mechanics. Generally, any perturbation of the inverse-square force will cause the orbit to precess. Even special relativity would predict some precession for the perihelion of Mercury, though it predicts a value of \\(7''/\\text{year}\\) only \\(1/6\\) of the correct value (McDonald 2023; Goldstein, Poole, and Safko 2008, exercise 7.27, page 332). Only general relativity predicts the correct value. Assuming that only special relativity contributes, the perihelion of Mercury would take \\(7.5e7\\) Mercury-years to go around the sun once.As the electron moves a lot faster than Mercury, it takes much shorter time, but still it takes \\(4e4\\) electron-years to go around the nucleus once, as noted in Bohr’s Nobel lecture (Bohr 1923).\n\\[\\int_0^T p_r \\,dq_r = n' h\\]\nwhere \\(q_r\\) is the radial position of the electron, \\(p_r\\) is the momentum conjugate to it, \\(n'\\) is the “auxiliary quantum number”, and \\(T\\) is the period of the electron’s orbit. This, when combined with the hypothesis of quantized angular momentum \\(mvr = nh\\) (here, \\(n\\) is the “principal quantum number”), would predict the emission spectrum of the hydrogen atom.\nSommerfeld went further, piling epicycles upon epicycles, to explain the fine structure of atomic spectra. All those has been swept away by the new quantum theory like how the new astronomy of Kepler swept away the epicycles of Ptolemy. But the adiabatic hypothesis remains to this day a fruitful meeting point between the classical, the quantum, and the thermodynamic world.\nHave some cool pictures, because I like cool pictures.\n\n\n\n\n\nSelection from (Sommerfeld 1923).\n\n\n\n\n\nThis looks familiar… it looks just like the phase space plot of a ball bouncing in a piston. Page 197.\n\n\n\n\n\n\n\n\n\nQuantization of the adiabatic invariant. Page 199.\n\n\n\n\n\n\n\nOrbits of the hydrogen atom with the same principal quantum number \\(n\\), but different auxiliary quantum number \\(n'\\). Page 240.\n\n\n\n\n\n\n\n\n\n5 electrons with the same principal and auxiliary quantum numbers, interacting by the pentagonal dance. Page 502.\n\n\n\n\n\n\n\nThree adiabatic invariants, one for each of the three paraboloidal coordinates. Page 283.\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nSelection from (Kramers 1923).\n\n\n\n\n\nOrbits of the Bohr–Sommerfeld model of the hydrogen atom, labelled by their principal quantum numbers and auxiliary quantum numbers. The jumps from 31, 32, 33 to 22 all create the Balmer spectral line Hα, but they differ at the fine structure. Figure 27.\n\n\n\n\n\n\n\n\n\nOrbits of the Bohr–Sommerfeld model of the Radium atom. End plates.\n\n\n\n\n\n\n\nA modern redrawing. (Holtebekk and Linder 2023)\n\n\n\n\n\n\nFigure 2\n\n\n\n\nWhat we are nowadays hearing of the language of spectra is a true “ music of the spheres ” within the atom, chords of integral relationships, an order and harmony that becomes ever more perfect in spite of the manifold variety. The theory of spectral lines will bear the name of Bohr for all time. But yet another name will be permanently associated with it, that of Planck. All integral laws of spectral lines and of atomic theory spring originally from the quantum theory. It is the mysterious organon on which Nature plays her music of the spectra, and according to the rhythm of which she regulates the structure of the atoms and nuclei.\nPreface to the first edition of Atomic structure and spectral lines, Arnold Sommerfeld, 1919. (Sommerfeld 1923)"
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#theodicy-economic-thermodynamics",
    "href": "blog/posts/thermoeconomics/index.html#theodicy-economic-thermodynamics",
    "title": "Thermodynamics and economics",
    "section": "Theodicy: economic thermodynamics",
    "text": "Theodicy: economic thermodynamics\nAlternative title: The Gospel of Nature according to Yuxi.\nIn classical thermodynamics, we consider only equilibrium systems. Similarly, in classical microeconomics, we consider only general equilibrium. As we will see, this allows us to make a mathematical analogy.\nI must warn you, before you enter, to forget all about molecules and atoms. Forget all about statistics and statistical mechanics. Forget about \\(S = k_B\\ln \\Omega\\) or \\(S = -\\sum_i p_i \\ln p_i\\) . None of these fits into the logical structure of classical thermodynamics.\n\nTable\n\n\n\n\n\n\nthermodynamics\nmicroeconomics\n\n\n\n\nsystem\ncompany\n\n\ncompound system\nconglomerate\n\n\nsubsystem\nchild company\n\n\nentropy\nmarket value (according to an accounting agency)\n\n\nentropies are additive\nvalue of conglomerate is the sum of its child companies\n\n\nenergy, volume, and other conserved quantities\ncommodities that cannot be created or destroyed\n\n\ninverse temperature \\(\\beta = \\partial_E S\\)\nmarginal value of energy\n\n\nunnamed quantity \\(\\beta p = \\partial_V S\\)\nmarginal value of volume\n\n\nunnamed quantity \\(-\\beta \\mu_i = \\partial_{N_i} S\\)\nmarginal value of chemical \\(i\\)\n\n\n\n\nsecond law\nThe second law of thermodynamics is all important: maximizing entropy is all of classical thermodynamics! Everything else are just tricks for us to understand how to maximize entropy.\n\n\nfirst law\n\nAs a student, I read with advantage a small book by F. Wald entitled “The Mistress of the World and her Shadow”. These meant energy and entropy. In the course of advancing knowledge the two seem to me to have exchanged places. In the huge manufactory of natural processes, the principle of entropy occupies the position of manager, for it dictates the manner and method of the whole business, whilst the principle of energy merely does the book- keeping, balancing credits and debits.\n(The? Mistress of the World and her Shadow)\n\nThe first law of thermodynamics is entirely trivial. Energy is nothing special!\nEnergy is just a conserved quantity, much like volume, mass, and some other things… In particular, the conservation of energy is not nearly as important as it sounds like. It does not deserve the title of “the first law of thermodynamics”. You might as well say “conservation of mass” is “the second-first law of thermodynamics” and “conservation of volume” is “the third-first law of thermodynamics”, and “conservation of electrons” and “conservation of protons” and “conservation of length” (if you are studying a thermodynamic system restricted to move on a line) and “conservation of area” (if you are studying a thermodynamic system restricted on the surface of a lake) and so on…\nThis sounds extraordinary, but that is merely how classical thermodynamics works. The first law of thermodynamics does not deserve its title. There should not even be a first law of thermodynamics.\nProperly speaking, “conservation of energy” is not a law of thermodynamics, but a law of physics. Why? Well, energy is nothing special inside classical thermodynamics, but it is extremely special if we zoom out to consider the whole of physics, because whereas in classical thermodynamics, you can consider systems that conserve energy, or volume, or length, or mass… when you move outside of thermodynamics, such as when you add in electrodynamics, special relativity, and quantum mechanics, all kinds of conservations breakdown. You don’t have conservation of mass, or number of electrons, or even volume, but energy is always conserved.\nSince energy is nothing special, we will demote it to “just another commodity”, like volume, number of electrons, protons, and so on.\nEvery conserved quantity is a commodity. The company has some commodity. Commodities themselves have no intrinsic value. Instead, the company is valued by a certain accounting agency. The CEO’s job is to move around the commodities so that the accounting agency gives it the highest value on the book.\nA compound system is a conglomerate: a giant company made of little companies.\nA subsystem has an inverse temperature \\(\\beta = 1/T\\) , which equals \\[\\beta = \\frac{d(\\text{value of a sub-company})}{d(\\text{energy owned by the sub-company})}\\]\nIn other words, the marginal value of energy. Electricity price!\nIf a subsystem has variable volume then it has a pressure \\(P\\) , which satisfies \\[\\beta P= \\frac{d(\\text{value of a sub-company})}{d(\\text{volume owned by the sub-company})}\\]\nIn other words, the marginal value of space. Real estate price!\nYes, I know it sounds weird to say (Pressure/Temperature), but that’s just how the math works out. It turns out that (Pressure/Temperature) is more fundamental than Pressure… Pressure, indeed, is actually Real estate price / Electricity price. That’s why it has units of ($/m^3)/($/Joule) = Joule/m^3!\nWhy, then, do we speak of pressure \\(P\\) and temperature \\(T\\) , instead of \\(\\beta\\) and \\(\\beta P\\) ? I blame habit and the general inability to visualize classical entropy.\n\n\nzeroth law\nThe zeroth law of thermodynamics, too, becomes trivial: Temperature is nothing special!\nThe zeroth law states that if A, B in energy-contact are in equilibrium, and B, C in energy-contact are in equilibrium, then A, C in energy-contact are in equilibrium.\nThe exact same statement works if we replace “energy” with “volume”, or “chemical \\(i\\)”, or “commodity”.\nThey are all merely special cases of the general economic law: If several sub-companies are allowed to trade commodity \\(x\\) , then when the total value of the conglomerate is maximized, the marginal value of \\(x\\) is the same for each sub-company.\n\n\nthird law\nThis is not actually important for classical thermodynamics."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#nonequilibrium-and-equilibrium",
    "href": "blog/posts/thermoeconomics/index.html#nonequilibrium-and-equilibrium",
    "title": "Thermodynamics and economics",
    "section": "Nonequilibrium and equilibrium",
    "text": "Nonequilibrium and equilibrium\n\nFreedom is an iron cage.\nConstraints set it free again.\n\nClassical thermodynamics is a strange kind of science. It is quite subtle, subtle as general equilibrium microeconomics. The key to understanding it is to distinguish equilibrium and nonequilibrium.\nI must warn you again, to forget all about molecules and atoms. Forget all about statistics and statistical mechanics. Forget about \\(S = k_B\\ln \\Omega\\) or \\(S = -\\sum_i p_i \\ln p_i\\) . None of these fits into the logical structure of classical thermodynamics.\n\n\n\nequilibrium\nnonequilibrium\n\n\n\n\nphysical\nvirtual\n\n\ndefined by external constraints\ndefined by internal variables\n\n\n\n\nA little story.\nOn the African savannah there lived a bunch of meerkats. Meerkats love to stand on the tallest place.\nAt first, they could stand wherever they wanted, so they all stood on one single hill. It was crowded. A blind lion who had memorized the landscape came and ate all of them.\nThen humans came and added walls that divided the savannah into tiny little stripes. Now each meerkat’s location is determined by which stripe it happened to fall in. The blind lion could find the meerkat if he knew the stripe location. In other words, optimizing for height, when there is one constraint, leads to one dimension of uncertainty.\nThis is a subtle point, so I will say it again. If you want to optimize for a quantity, and you don’t have a constraint, then you would always go to the globally best solution. The whole space of possibilities is open to you, but you don’t need them.\nBut if you have one constraint, then you have one unique solution for each possible setting of constraint. You are still not free, but at least now you have a puppet master.\nIn classical thermodynamics, only equilibrium states are “real”. Nonequilibrium states are “virtual”, much like a virtual path in Lagrangian mechanics. Sure, you could imagine that if you throw a rock upwards, it would execute a complex figure-8 motion before returning to ground again, but that’s a virtual path. The only real path is the unique virtual path that stationarizes the action integral.\nSimilarly, in classical thermodynamics, you could imagine that a tank of gas contains all its gas on the left side, but that’s a virtual state that does not satisfy the optimization constraint. Consequently, it is only a virtual state, not a real state. Only one virtual state is real – the unique virtual state that maximizes entropy under constraint.\n\n\nEquilibrium vs nonequilibrium entropy.\nFor example, consider this statement, an important consequence of the second law: &gt; A closed system maximizes its entropy under its constraint.\nIf we think of “equilibrium” states only, then the statement makes no sense. Under a fixed constraint, there is only one possible equilibrium state, so we get something sounding as ridiculous as “A customer can have a car painted in his favorite color as long as it’s black.”\nThe statement is actually saying this: &gt; A closed system under constraint has many satisfying nonequilibrium states, but only one equilibrium state: the one with the lowest nonequilibrium entropy. Consequently, for every constraint, there are many nonequilibrium states that satisfy the constraint, but only one equilibrium entropy, and so equilibrium entropy is a function of constraints, even though the nonequilibrium entropy is not."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#mechanical-and-other-forms-of-work",
    "href": "blog/posts/thermoeconomics/index.html#mechanical-and-other-forms-of-work",
    "title": "Thermodynamics and economics",
    "section": "mechanical and other forms of work",
    "text": "mechanical and other forms of work\nTo perform work, one must perform work upon something. In other words, there is no such thing as “system A performed work”. There is really “some energy and length is traded between A to B in compliance with a work-equation-constraint”."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#the-most-important-systems",
    "href": "blog/posts/thermoeconomics/index.html#the-most-important-systems",
    "title": "Thermodynamics and economics",
    "section": "the most important systems",
    "text": "the most important systems\n\nBaths\nA heat bath, or more accurately an energy bath, is a system that you can take or dump as much energy as you want, always at constant temperature.\nAn atmosphere, or more accurately an energy-and-volume bath, is a system that you can take or dump as much energy or volume as you want, always at constant temperature and pressure.\nIn general, a bath is an infinite source of a conserved quantity at constant marginal entropy.\nWe can imagine other forms of baths. For example, the surface of a lake could serve as an energy-and-area bath. A large block of salt can serve as a salt-chemical bath.\n\nphoton gas: $S = E V{1/4}E{3/4} $\nideal gas: \\(S \\propto \\ln (VE^{\\hat c_V})\\)\nideal spring: \\(S = 0\\) and \\(E = \\frac 12kx^2\\)\nbespoke energy storage: \\(S=0\\) and \\(E = f(x)\\), where \\(f\\) is whatever you want.\nideal battery: \\(S=0\\) and ???"
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#heat-engine-systems",
    "href": "blog/posts/thermoeconomics/index.html#heat-engine-systems",
    "title": "Thermodynamics and economics",
    "section": "heat engine systems",
    "text": "heat engine systems\nA heat engine is a subsystem that is used as a component of a large system. The large system contains 4 parts: two energy baths, one heat engine, and one bespoke energy storage.\nIf you only want a heat engine that works, then the bespoke energy storage does not necessarily need to be so bespoke. However, if you want a heat engine that works reversibly, i.e. at maximal efficiency, then the energy storage must be designed to be exactly right. It must be designed to follow the exact parameters of the heat engine, as well as the two energy baths’ inverse temperatures. If any of those is ignored, the energy storage would fail to “mesh” with the rest of the compound system, and cause waste.\nThis is why we insist on calling it a heat engine system. Every part of it depends on every other part. The energy storage unit is just as important and precisely designed as the heat engine."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#common-errors",
    "href": "blog/posts/thermoeconomics/index.html#common-errors",
    "title": "Thermodynamics and economics",
    "section": "Common errors",
    "text": "Common errors\nHeat is not a noun, but a verb.\nEnergy is not special, but only one more conserved quantity.\nEntropy is special, because it is the one quantity that is maximized.\nClassical thermodynamics\n\nCarnot’s metaphor\n\n\nin a waterwheel\nin a heat engine\n\n\n\n\nwater\ncaloric\n\n\nheight\ntemperature\n\n\nmechanical work\nmechanical work"
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#carathéodory-geometric-thermodynamics",
    "href": "blog/posts/thermoeconomics/index.html#carathéodory-geometric-thermodynamics",
    "title": "Thermodynamics and economics",
    "section": "Carathéodory: geometric thermodynamics",
    "text": "Carathéodory: geometric thermodynamics\n\nFrobenius theorem\nSuppose we are to find the trajectory of a particle in a subset of 3D space, but we do not know its trajectory formula. Instead, we know only that its trajectory satisfies \\(a d x+b d y+c d z=0\\), where \\(a, b, c\\) are smooth functions of \\((x, y, z)\\). Thus, our only certainty is that if at some moment in time the particle is at location \\(\\left(x_0, y_0, z_0\\right)\\), then its velocity at that moment is restricted within the plane with equation\n\\[\na\\left(x_0, y_0, z_0\\right)\\left[x-x_0\\right]+b\\left(x_0, y_0, z_0\\right)\\left[y-y_0\\right]+c\\left(x_0, y_0, z_0\\right)\\left[z-z_0\\right]=0\n\\]\nIn other words, we can draw a “local plane” at each point in 3D space, and we know that the particle’s trajectory must be tangent to the local plane at all times. If we have two equations\n\\[\n\\left\\{\\begin{array}{l}\na d x+b d y+c d z=0 \\\\\na^{\\prime} d x+b^{\\prime} d y+c^{\\prime} d z=0\n\\end{array}\\right.\n\\]\nthen we can draw two local planes at each point, and their intersection is generically a line, allowing us to uniquely solve for the curve starting at any point. In other words, with two 1 -forms, we can foliate the domain into curves.\nIf we have only one equation \\(a d x+b d y+c d z=0\\), then we might be able to foliate \\(\\mathbb{R}^3\\) into surfaces, in which case, we can be sure that a curve starting at a certain surface must be restricted to wander within that surface. If not, then a curve starting at any point might end up at any other point in \\(\\mathbb{R}^3\\).\n\n\n\nThe 1 -form \\(dz - ydx\\). on \\(\\R^3\\) maximally violates the assumption of Frobenius’ theorem. These planes appear to twist along the \\(y\\)-axis. It is not integrable, as can be verified by drawing an infinitesimal square in the \\(x\\)-\\(y\\) plane, and follow the path along the one-forms. The path would not return to the same z-coordinate after one circuit.\n\n\nOne can imagine starting with a cloud of little planes, and quilting them together to form a full surface. The main danger is that, if we quilt the little planes two at a time, we might go on a cycle and return to where we began, but shifted by a small amount. If this happens, then we would not get a 2-dimensional surface, but a 3-dimensional blob. An example is shown in the diagram on the right.\nIf the one-form is integrable, then loops exactly close upon themselves, and each surface would be 2-dimensional. Frobenius’ theorem states that this happens precisely when \\(\\omega \\wedge d \\omega=0\\) over all of the domain, where \\(\\omega:=a d x+b d y+c d z\\). The notation is defined in the article on one-forms.\nDuring his development of axiomatic thermodynamics, Carathéodory proved that if \\(\\omega\\) is an integrable one-form on an open subset of \\(\\mathbb{R}^n\\), then \\(\\omega=f d g\\) for some scalar functions \\(f, g\\) on the subset. This is usually called Carathéodory’s theorem in axiomatic thermodynamics. \\({ }^{[1][2]}\\) One can prove this intuitively by first constructing the little planes according to \\(\\omega\\), quilting them together into a foliation, then assigning each surface in the foliation with a scalar label. Now for each point \\(p\\), define \\(g(p)\\) to be the scalar label of the surface containing point \\(p\\).\nNow, \\(d g\\) is a one-form that has exactly the same planes as \\(\\omega\\). However, it has “even thickness” everywhere, while \\(\\omega\\) might have “uneven thickness”. This can be fixed by a scalar scaling by \\(f\\), giving \\(\\omega=f d g\\).\n\n\n\nFor each point \\(p\\), the one-form \\(\\omega(p)\\) is visualized as a stack of parallel planes. The planes are quilted together, but with “uneven thickness”. With a scaling at each point, \\(\\omega\\) would have “even thickness”, and become an exact differential.\n\n\nFor each point \\(p\\), the one-form \\(\\omega(p)\\) is visualized as a stack of parallel planes. The planes are quilted together, but with “uneven thickness”. With a scaling at each point, \\(\\omega\\) would have “even thickness”, and become an exact differential.\n\n\nThermodynamics\nConsider a thermodynamic system (concretely one can imagine a piston of gas) that can interact with the outside world by either heat conduction (such as setting the piston on fire) or mechanical work (pushing on the piston). He then defined “adiabatic process” as any process that the system may undergo without heat conduction, and defined a relation of “adiabatic accessibility” thus: if the system can go from state \\(\\mathrm{A}\\) to state \\(\\mathrm{B}\\) after an adiabatic process, then \\(B\\) is adiabatically accessible from \\(A\\). Write it as \\(A \\succeq B\\).\nNow assume that\n\nFor any pair of states \\(A, B\\), at least one of \\(A \\succeq B\\) and \\(B \\succeq A\\) holds.\nFor any state \\(A\\), and any neighborhood of \\(A\\), there exists a state \\(B\\) in the neighborhood, such that \\(B\\) is adiabatically inaccessible from \\(A\\).\n\nThen, we can foliate the state space into subsets of states that are mutually adiabatically accessible. With mild assumptions on the smoothness of \\(\\succeq\\), each subset is a manifold of codimension 1 . Call these manifolds “adiabatic surfaces”.\nBy the first law of thermodynamics, there exists a scalar function \\(U\\) (“internal energy”) on the state space, such that \\[\nd U=\\delta W+\\delta Q=\\sum_i X_i d x_i+\\delta Q\n\\] where \\(X_1 d x_1, \\ldots, X_n d x_n\\) are the possible ways to perform mechanical work on the system. For example, if the system is a tank of ideal gas, then \\(\\delta W=-p d V\\). Now, define the one-form on the state space \\[\n\\omega:=d U-\\sum_i X_i d x_i\n\\]\nNow, since the adiabatic surfaces are tangent to \\(\\omega\\) at every point in state space, \\(\\omega\\) is integrable, so by Carathéodory’s theorem, there exists two scalar functions \\(T, S\\) on state space, such that \\(\\omega=T d S\\). These are the temperature and entropy functions, up to a multiplicative constant.\nBy plugging in the ideal gas laws, and noting that Joule expansion is an (irreversible) adiabatic process, we can fix the sign of \\(d S\\), and find that \\(A \\succeq B\\) means \\(S(A) \\leq S(B)\\). That is, entropy is preserved in reversible adiabatic processes, and increases during irreversible adiabatic processes."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#chemical-thermodynamics",
    "href": "blog/posts/thermoeconomics/index.html#chemical-thermodynamics",
    "title": "Thermodynamics and economics",
    "section": "Chemical thermodynamics",
    "text": "Chemical thermodynamics\nStandard chemistry textbooks are utter nonsense when it comes to the condition for equilibrium. You usually see things like \\(\\Delta G = 0\\) for chemical reactions in open atmosphere, or \\(\\Delta H = 0\\) for chemical reactions in a sealed container in a heat bath. When I took the chemistry courses, I was terribly confused because I felt they did not make sense. I passed the exams, but only by learning to speak the right kind of nonsense. During my study of classical thermodynamics, I rederived everything for myself, and in the process finally made everything come out the right way.\nTo set the scene, consider a few problems in typical books on chemistry that does not make sense. For concreteness, consider a typical chemical demonstration, the dimerization reaction of\n\\[2 NO_2 \\to N_2 O_4\\]\nNow seal a certain amount of the gas inside a glass tube. Since \\(NO_2\\) is brown, but \\(N_2 O_4\\) is transparent, if we heat it up, the pressure would rise, forcing the reaction to go towards the \\(N_2O_4\\) side by Le Chatelier’s principle, and the glass tube would turn transparent. Putting the tube inside an ice bath would turn it brown again.\nThe equilibrium for reaction is typically described as follows.\nDefine the reaction quotient for this reaction as \\(Q = \\frac{[N_2 O_4]}{[NO_2]^2}\\). According to the standard textbook, it states that the reaction reaches equilibrium when \\(\\Delta H = 0\\), where\n\\[\n\\Delta H = \\Delta H^\\circ + RT \\ln Q\n\\]\nand \\(\\Delta H^\\circ\\) is the change in Helmholtz energy for the reaction at the standard state. This description is nonsense.\n\n\\(Q\\) is always used inside a logarithm, like \\(RT\\ln Q\\). Logarithms can never have a unit, even though here \\(Q\\) has units of molar density.\nThe reaction quotient’s unit depends on the reaction itself. How could this possibly be true? Imagine a physical quantity \\(X\\) that has units of meters in one problem, but units of meters\\(^{-3}\\) in another.\nWhy can’t I rewrite the equation as \\(4 NO_2 \\to 2 N_2 O_4\\)? This would instantly change \\(Q\\) to \\(Q' = Q^2\\). How could the physics of the situation depend on our convention for describing it?\nThe unit for \\(\\Delta H\\) is \\(J/mol\\), but the units for \\(H\\) is \\(J\\), so somehow there is an extra \\(mol\\) appearing out of nowhere.\n\nThe real answer is as follows:\nThe state of a chemical reaction system in a closed container depends on not just its temperature, but also its chemical composition. Thus, the standard state of a chemical reaction system must specify its temperature, and the concentration of all its molecules.\nConsider a chemical system \\[\n\\sum_i x_i X_i \\leftrightarrow \\sum_j y_i Y_j\n\\]\nWe must arbitrarily fix some standard concentrations \\(\\left[X_i\\right]^o,\\left[Y_j\\right]^o\\), then the reaction quotient with respect to these arbitrary conventions is\n\\[\n\\ln Q:=\\sum_j \\ln y_j \\frac{\\left[Y_j\\right]}{\\left[Y_j\\right]^o}-\\sum_i x_i \\ln \\frac{\\left[X_i\\right]}{\\left[X_i\\right]^o}\n\\]\nThen, if we immerse the system in an energy and volume bath (i.e. the open air, or maybe we throw it in a plastic bag and throw it under the sea), then\n\\[\n\\frac{d G}{d \\xi}=\\frac{d G^{\\circ}}{d \\xi}+R T \\ln Q\n\\]\nis independent of our choice of standard concentrations."
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#classical-statistical-mechanics",
    "href": "blog/posts/thermoeconomics/index.html#classical-statistical-mechanics",
    "title": "Thermodynamics and economics",
    "section": "Classical statistical mechanics",
    "text": "Classical statistical mechanics\nLet there be an amusement park that you are going, with many amusements i. You have exactly 1 day to spend there, so you need to spend p_i of a day on amusement i. Now your total utility at the end of the day is equal to -_i p_i p_i. Suppose that’s all there is to the amusement park, then the solution is clear: you should spend an equal amount of time at each amusement. This can be proved by Lagrange multiplier. But we can also do it more intuitively as follows. Suppose your parents gave you a schedule for your amusement. You look at the schedule and notice that p_i &lt; p_j. You can reject the plan and say, “I can always do better just by spending equal time at i, j, even holding the other times fixed.” The proof is simple (“partial equilibrium”): If we are only allowed to trade between time at i and j (that is, we have a “partial market”) The marginal utility of amusement i is ln(1/p_i) - 1 The marginal utility of amusement j is ln(1/p_j) - 1 So, if p_i p_j, then the partial market is not at partial equilibrium. At partial equilibrium, we must have p_i = p_j\nNow at general equilibrium, all partial markets must be at partial equilibrium. Thus at general equilibrium, all p_i are equal.\nParents tell you that unfortunately there is no general equilibrium, because the amusement park is actually infinite.\nThen you remembered that the amusement park has a token system: when you enter the park you would buy a certain number of tokens. Then you spend tokens at the rides. The amount of tokens spent is proportional to the time you spend in the ride. So your parents tell you that they’ll buy you a certain number of tokens \\(E\\) at the start of the day. Then you can plan your trip yourself. Free market, indeed. Assuming that The prices of amusements are 0 &lt; E_0 &lt; E_1 &lt; E_2 &lt; . Here “E_0” is the “zero-point energy”, or in other words, “just relax”. You must spend exactly all your tokens. Your parents hate wastefulness and would beat you up if you don’t use all the tokens. It is possible to spend exactly all your tokens: E_0 &lt;= E &lt;= _i E_i.\nThus we have reduced the problem to \\[\n\\begin{cases}\n\\max S(p) \\\n\\sum_i p_i \\cdot 1 = 1 \\\n\\sum_i p_i \\cdot E_i = E \\\n\\end{cases}\n\\]\nUnder these assumptions, you can calculate that there is a unique schedule that maximizes your fun, or entropy.\nNow there is a slight difficulty with your previous approach. Doing partial equilibrium between 2 amusements is not possible now, because you must balance between not just time, but also tokens. Suppose you spend less time at i to spend more time at j, this might cause you to under- or over-spend your tokens. So, to make a partial equilibrium calculation, you must use at least 3 amusements, not 2. (And you are not allowed to “just relax”, since relaxing is actually “the 0th amusement”, and thus it also costs you tokens and time.) That is, you must open partial markets with i, j, k at once, and then you can run the system to partial equilibrium. This is pretty annoying. There’s a better way.\nLagrange’s devil makes an appearance!\n“You can’t solve the general equilibrium problem, you say? Why not try to use multivariable calculus?” “Too annoying.” “Alright, how about I make you a deal –” “Sorry but I don’t sell my soul.” “Don’t be stupid – only something as stupid as God could still believe in souls these days! I am proposing that you trade happiness for time and for tokens. I will make a set price for time and another set price for tokens. Both prices are in units of your happiness. You can buy happiness with time, or time with happiness, also for tokens.” “Uhmm…” “That’s all that I offer. You should read up on microeconomics so you can make the right choice. See you when the day comes!”\nSo the day came and the devil showed up. It gave the prices as follows: 1 unit of time = alpha unit of utility. 1 unit of token = beta unit of utility. So you realized that you must solve the following problem\n\\[\\max_p (S(p) - \\alpha \\sum_i p_i - \\beta \\sum_i p_i E_i)\\]\nAnd that’s when you found out that your parents = Lagrange’s devil = Boltzmann’s devil.\nYou realized what a great luck you have that the devil is there – it has split a whole general equilibrium problem into so many partial equilibria: \\[\\forall i, \\max_{p_i} p_i \\ln \\frac{1}{p_i} - \\alpha p_i - \\beta p_i E_i\\]\nSo you solve the problem: \\[p_i = e^{-1-\\alpha} e^{-\\beta E_i}\\]\nAfter you solved the problem, you are about to go to the devil, but then the devil stopped you and asked you to not make individual trades, but make a bulk one-time trade. So you calculate \\(\\sum_i p_i\\) and \\(\\sum_i p_i E_i\\), and to your surprise, you found that they equal exactly 1 and E. That is, you actually would spend all your time and tokens without needing to trade with the devil. “So you see? If the mortal is ready to make a trade, the devil appears…” “But why must you appear at all, if you are not actually going to trade with me anyway?” “And when the mortal is truly ready to make a trade, the devil disappears…”\nAnd so you sat there looking at your two equations in strange amusement: \\[p_i = \\frac{e^{-\\beta E_i}}{e^{1+\\alpha}}, \\quad \\alpha+1 = \\ln\\sum_i e^{-\\beta E_i} , \\quad E = \\sum_i E_i \\frac{e^{-\\beta E_i}}{e^{1+\\alpha}}\\] A physicist comes and points out that they are better known as \\[p_i =  \\frac{e^{-\\beta E_i}}{Z}, \\quad Z = e^{-\\beta F} = \\sum_i e^{-\\beta E_i}, \\quad E = \\sum_i p_i E_i\\] and said that \\(Z\\) is called “partition function”, \\(F\\) is “Helmholtz free energy”, and \\(\\beta\\) is “inverse temperature”.\nThere is just one question left to solve: why did the devil design the prices this way? “Because I don’t want you to actually be happier!” is the answer. What did the devil mean? Well, after doing the pointless trade, you realized that you didn’t actually need the devil. But then suppose the devil suddenly increased the price of tokens, then what would you do? You would realize that you can profit by spending a little less time at amusement i, and sell both the time and the tokens you saved to the devil, and increase your happiness! Similarly for any other form of price change.\n(With a little calculation, you can show that, if there exists E_i E_j, then any change in devil’s prices would strictly allow you to increase happiness just by changing p_i and p_j.)\nTherefore, the devil knows that any price change would increase your happiness, so it chose the prices that would minimize your happiness. “And when the mortal is truly ready to make a trade, the devil disappears…”"
  },
  {
    "objectID": "blog/posts/thermoeconomics/index.html#annotated-references",
    "href": "blog/posts/thermoeconomics/index.html#annotated-references",
    "title": "Thermodynamics and economics",
    "section": "Annotated references",
    "text": "Annotated references\n\n\n(Lemons 2019). A very readable introduction to classical thermodynamics, slim but deep. I finally understood the meaning of thermodynamics means after reading it.\n(Lemons 2008). A textbook version of the author’s (Lemons 2019), weaving in history and philosophical contemplation at every turn.\n(Carnot, Clapeyron, and Clausius 1988). A reprint of the most important papers in thermodynamics published before 1900. Useful to have on hand if you are reading (Lemons 2019).\n(Pippard 1964). Slim, elegant, both mathematical and applied. In the best British tradition of mathematics – think James Maxwell and G. H. Hardy.\n(Fermi 1956). The same as above. However, it also covers chemical thermodynamics.\n(Buchdahl 1966). A textbook based on Carathéodory’s axiomatic thermodynamics. The notation is ponderous, and the payoff is unclear. I don’t know what is its intended audience – perhaps professional pedants and differential geometers? Nevertheless, if you need to do research in Carathéodory’s axiomatic thermodynamics, I think this is your best bet."
  },
  {
    "objectID": "blog/posts/art/index.html#overview",
    "href": "blog/posts/art/index.html#overview",
    "title": "Analytical mechanics",
    "section": "Overview",
    "text": "Overview\n\nThe economics-mechanics analogy.\n\n\nSymbol\nPhysics\nEconomics\nControl Theory\n\n\n\n\n\\(L\\)\nLagrangian\ntime-rate of cost\ntime-rate of cost\n\n\n\\(t\\)\ntime\ntime\ntime\n\n\n\\(q\\)\nlocation/coordinate\ncommodity/capital\nstate variable\n\n\n\\(\\dot q\\)\nvelocity\ninvestment rate/saving rate/cash flow/etc\ncontrol variable\n\n\n\\(S = \\int L(t, q, \\dot q)dt\\)\naction\ntotal cost\ntotal cost\n\n\n\\(p\\)\nmomentum\n(shadow) price\nco-state variable\n\n\n\\(H = \\sum_i p_i\\dot q_i - L\\)\nHamiltonian\n(market equivalent) cash flow3\nHamiltonian\n\n\n\n3 also known as \"mark to market cash flow\"\nConventions\nWe always assume all functions are analytic (that is, they have Taylor expansions).\nWe would often say \"minimize cost\" or \"maximize revenue\" or such, but we are actually merely \"stationarizing\" everything. For example, when we say “Let’s maximize \\(f(x)\\)”, what we mean is “Let’s solve \\(f'(x) = 0\\)”. We don’t need to check \\(f''(x) &lt; 0\\). This is not a problem for physics, where the principle of stationary action rules, but in optimal control and economics, we should check if the solution is actually a minimum/maximum."
  },
  {
    "objectID": "blog/posts/art/index.html#introduction",
    "href": "blog/posts/art/index.html#introduction",
    "title": "Analytical mechanics",
    "section": "",
    "text": "One overarching goal is to show that classical mechanics is bursting at the seams, and to unmask classical mechanics, revealing the quantum mechanics that is deep inside.\n\n\nEarly 2023, I undertook a serious study of economics. When I was studying Ramsey’s theory of optimal saving, I saw, to my great surprise, something they call a “Hamiltonian” (Campante, Sturzenegger, and Velasco 2021, chap. 3). I was shocked, but after studying it carefully, and thinking it over, I realized that it was no mistake – the Hamiltonian really occurs in economics. Moreover, the Hamiltonian in physics really has an economic interpretation. At that moment, suddenly everything fell into place. Those enlightenment-era philosophers saying things like “God has chosen the best of all possible worlds.”1, or “Nature always acts in the simplest possible manner to produce its effects.”2\n1 Leibniz, an originator of calculus and universal genius. In his [1710 book Theodicy], the phrase “best of all” appeared for no less than 13 times:\n\nIt is thus one must think of the creation of the best of all possible universes, all the more since God not only decrees to create a universe, but decrees also to create the best of all.\n… the City of God must be the most perfect of all possible states, since it was formed and is perpetually governed by the greatest and best of all Monarchs.\n\nEtc, etc. Reading a chapter of the book, I felt a hypnotic numbing effect on the brain.2 Maupertuis proposed a version of the principle of least action in Mémoires de l’académie royale des sciences, 1748, 417-426. We will see him soon enough."
  },
  {
    "objectID": "blog/posts/art/index.html#hotellings-lemma",
    "href": "blog/posts/art/index.html#hotellings-lemma",
    "title": "Analytical mechanics",
    "section": "Hotelling’s lemma",
    "text": "Hotelling’s lemma\n\\(H(t, q, p)\\) is differentiable with respect to \\(p\\), and\n\\[v^\\ast(t, q, p) = \\nabla_p H(t, q, p)\\]"
  },
  {
    "objectID": "blog/posts/art/index.html#routhian-mechanics",
    "href": "blog/posts/art/index.html#routhian-mechanics",
    "title": "Analytical mechanics",
    "section": "Routhian mechanics",
    "text": "Routhian mechanics\n\nRouthian equations\nSuppose that the market does not contain all commodities, but only the last \\(n\\) commodities. That is, let \\(q_{1:N} = (q_{1:s}, q_{s+1:s+n})\\), and only open markets on \\(q_{s+1:s+n}\\). The optimal cash flow equation then gives us the \"Routhian\":\n\\[\nR(t, q, v_{1:s}, p_{s+1:N}) = \\max_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\n\\]\nAs before, the optimal control variables are \\(v_{s+1:N}^\\ast = \\mathop{\\mathrm{arg\\,max}}_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\\).\n\nTheorem 4 (Routhian equations of motion) \\[\n\\begin{cases}\n    \\partial_t R &= -\\partial_t L \\\\\n    \\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n    \\begin{cases}\n    \\dot q_i = \\partial_{p_i} R \\\\ \\dot p_i = -\\partial_{q_i} R\n    \\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy the same argument as in Hotelling’s lemma, we have\n\\[\n\\begin{cases}\n    \\partial_t R = -\\partial_t L \\\\\n    \\nabla_q R = -\\nabla_q L \\\\\n    \\nabla_{v_{1:s}} R = -\\nabla_{v_{1:s}} L \\\\\n    \\nabla_{p_{s+1 : N}} R = v^*_{s+1 : N}\n\\end{cases}\n\\]\nPlugging the 2-th and 3-th equations into the original Euler–Lagrange equations, we obtain\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThe 4-th equation gives\n\\[\\dot q_i =v_i^\\ast = \\partial_{p_i} R, \\quad \\forall i\\in s+1:N\\]\nFor \\(i\\in s+1:N\\), we can obtain the price dynamic of the partial market by the no-arbitrage condition, giving\n\\[\\dot p_i = \\partial_{q_i} L = -\\partial_{q_i} R\\]\n\n\n\nWe see that the first \\(s\\) equations look just like the EL equations, but the next \\(2n\\) equations look just like the Hamiltonian equations. The Routhian equations make an awkward hybrid.\n\n… as a fundamental entity, the Routhian is a sterile hybrid, combining some of the features of both the Lagrangian and the Hamiltonian pictures. For the development of various formalisms of classical mechanics, the complete Hamiltonian formulation is more fruitful.\n(Goldstein, Poole, and Safko 2008, sec. 8.3)\n\n\n\nApplication to cyclic coordinates\nThough the Routhian equations are theoretically useless, they are useful for solving specific problems. For some worked examples of using the Routhian, see the Wikipedia page.\nWhile the Euler–Lagrangian equations are \\(N\\) second-degree differential equations, the Hamiltonian equations are \\(2N\\) first-degree differential equations. We are essentially trading derivatives for equation numbers.\nThough the EL equations and the Hamiltonian equations are philosophically different, for solving particular problems, they often end up giving the same equations anyway. Specifically, if we are solving the Hamiltonian equations for a concrete example, by eliminating the variables \\(p\\), we often end up right back to the Euler–Lagrange equations. This would be quite the detour, and if there are cyclic coordinates, the Routhian could save us some trouble.\nIf we have a system that is cyclic in the last \\(n\\) coordinates, then since \\(\\nabla_q R = -\\nabla_q L\\), its Routhian satisfies \\(\\partial_{q_i} R = 0\\) for the last \\(n\\) coordinates too. Then we find that the Routhian equations become:\n\\[\n\\begin{cases}\n\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} R \\\\  p_i = p_i(0)\n\\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\ngiving us \\(n\\) first-degree equations and \\(N-n\\) second-degree equations. If we were to start with the Hamiltonian equations of motion, we would get\n\\[\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} H \\\\  p_i = p_i(0)\n\\end{cases}\\quad i\\in s+1:N\n\\]\nby the same reasoning, and then laboriously eliminate the variables \\(p_i\\) for \\(i \\in 1:s\\), and end up with \\(s\\) second-degree differential equations, often exactly the same as the first \\(s\\) Routhian equations:\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThis is how the Routhian saves us some effort in practical calculations. It is useful in this way, and in this way only."
  },
  {
    "objectID": "blog/posts/art/index.html#hje",
    "href": "blog/posts/art/index.html#hje",
    "title": "Analytical mechanics",
    "section": "HJE",
    "text": "HJE"
  },
  {
    "objectID": "blog/posts/art/index.html#bonus-routhian-mechanics",
    "href": "blog/posts/art/index.html#bonus-routhian-mechanics",
    "title": "Analytical mechanics",
    "section": "Bonus: Routhian mechanics",
    "text": "Bonus: Routhian mechanics\n\nRouthian equations\nSuppose that the market does not contain all commodities, but only the last \\(n\\) commodities. That is, let \\(q_{1:N} = (q_{1:s}, q_{s+1:s+n})\\), and only open markets on \\(q_{s+1:s+n}\\). The optimal cash flow equation then gives us the \"Routhian\":\n\\[\nR(t, q, v_{1:s}, p_{s+1:N}) = \\max_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\n\\]\nAs before, the optimal control variables are \\(v_{s+1:N}^\\ast = \\mathop{\\mathrm{arg\\,max}}_{v_{s+1:N}} \\left(\\sum_{i=s+1}^n p_i v_i - L(t, q, v)\\right)\\).\n\nTheorem 4 (Routhian equations of motion) \\[\n\\begin{cases}\n    \\partial_t R &= -\\partial_t L \\\\\n    \\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n    \\begin{cases}\n    \\dot q_i = \\partial_{p_i} R \\\\ \\dot p_i = -\\partial_{q_i} R\n    \\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy the same argument as in Hotelling’s lemma, we have\n\\[\n\\begin{cases}\n    \\partial_t R = -\\partial_t L \\\\\n    \\nabla_q R = -\\nabla_q L \\\\\n    \\nabla_{v_{1:s}} R = -\\nabla_{v_{1:s}} L \\\\\n    \\nabla_{p_{s+1 : N}} R = v^*_{s+1 : N}\n\\end{cases}\n\\]\nPlugging the 2-th and 3-th equations into the original Euler–Lagrange equations, we obtain\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThe 4-th equation gives\n\\[\\dot q_i =v_i^\\ast = \\partial_{p_i} R, \\quad \\forall i\\in s+1:N\\]\nFor \\(i\\in s+1:N\\), we can obtain the price dynamic of the partial market by the no-arbitrage condition, giving\n\\[\\dot p_i = \\partial_{q_i} L = -\\partial_{q_i} R\\]\n\n\n\nWe see that the first \\(s\\) equations look just like the EL equations, but the next \\(2n\\) equations look just like the Hamiltonian equations. The Routhian equations make an awkward hybrid.\n\n… as a fundamental entity, the Routhian is a sterile hybrid, combining some of the features of both the Lagrangian and the Hamiltonian pictures. For the development of various formalisms of classical mechanics, the complete Hamiltonian formulation is more fruitful.\n(Goldstein, Poole, and Safko 2008, sec. 8.3)\n\n\n\nApplication to cyclic coordinates\nThough the Routhian equations are theoretically useless, they are useful for solving specific problems. For some worked examples of using the Routhian, see the Wikipedia page.\nWhile the Euler–Lagrangian equations are \\(N\\) second-degree differential equations, the Hamiltonian equations are \\(2N\\) first-degree differential equations. We are essentially trading derivatives for equation numbers.\nThough the EL equations and the Hamiltonian equations are philosophically different, for solving particular problems, they often end up giving the same equations anyway. Specifically, if we are solving the Hamiltonian equations for a concrete example, by eliminating the variables \\(p\\), we often end up right back to the Euler–Lagrange equations. This would be quite the detour, and if there are cyclic coordinates, the Routhian could save us some trouble.\nIf we have a system that is cyclic in the last \\(n\\) coordinates, then since \\(\\nabla_q R = -\\nabla_q L\\), its Routhian satisfies \\(\\partial_{q_i} R = 0\\) for the last \\(n\\) coordinates too. Then we find that the Routhian equations become:\n\\[\n\\begin{cases}\n\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad & i \\in 1:s\\\\\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} R \\\\  p_i = p_i(0)\n\\end{cases}\\quad & i\\in s+1:N\n\\end{cases}\n\\]\ngiving us \\(n\\) first-degree equations and \\(N-n\\) second-degree equations. If we were to start with the Hamiltonian equations of motion, we would get\n\\[\n\\begin{cases}\n\\dot q_i = \\partial_{p_i} H \\\\  p_i = p_i(0)\n\\end{cases}\\quad i\\in s+1:N\n\\]\nby the same reasoning, and then laboriously eliminate the variables \\(p_i\\) for \\(i \\in 1:s\\), and end up with \\(s\\) second-degree differential equations, often exactly the same as the first \\(s\\) Routhian equations:\n\\[\\frac{d}{dt} \\partial_{v_i} R = \\partial_{q_i}R \\quad i \\in 1:s\\]\nThis is how the Routhian saves us some effort in practical calculations. It is useful in this way, and in this way only."
  },
  {
    "objectID": "blog/posts/art/index.html#bonus-higher-order-lagrangians-and-hamiltonians",
    "href": "blog/posts/art/index.html#bonus-higher-order-lagrangians-and-hamiltonians",
    "title": "Analytical mechanics",
    "section": "Bonus: Higher-order Lagrangians and Hamiltonians",
    "text": "Bonus: Higher-order Lagrangians and Hamiltonians\nWhat happens if we use a Lagrangian with higher-order derivatives? It turns out that even in this case, we can still use economic reasoning to derive its Hamiltonian and Euler–Lagrangian equations\n\nExercise 1 Read the following sections, then generalize the derivation to \\(n\\)-th-order derivatives.\n\nThis construction of Hamiltonians from higher-order Lagrangians is often called Ostrogradsky theorem or Ostrogradsky instability, because Ostrogradsky published it in 1850 (Ostrogradsky 1850) after seeing Hamilton’s paper of 1833 (Hamilton 1833). He did not note its implications for instability, which was first noted by Pais and Uhlenbeck in 1950 (Pais and Uhlenbeck 1950). For this reason, it’s also called the Pais–Uhlenbeck model.\n\nWhen Lagrangian also depends on acceleration\nWhen the Lagrangian depends not just on position and velocity, but also acceleration, the total cost to be optimized is:\n\\[S(q) := \\int L(t, q^{(0)}, q^{(1)}, q^{(2)})dt\\]\nwhere \\(q^{(n)}\\) is a symbol that suggests itself to be the \\(n\\)-th time-derivative of the optimal trajectory \\(q\\), although it is actually defined for any tuple of real numbers, even when we don’t have \\(q^{(1)}(t) = \\frac{d}{dt}q^{(0)}(t)\\).\nOur previous method, which is to open a market on position \\(q\\), fails for two reasons:\n\nThe producer cannot optimize its velocity, because now velocity is no longer a control variable. Now, both position and velocity are state variables, and only acceleration is a control variable.\nThe producer cannot buy and sell velocity, so it has no price signal to optimize its acceleration (how fast it produces velocity).\n\nIf the market fails, make it bigger: allow the market to buy and sell not just position, but also velocity.\nWe open a market of both positions and velocities. The price vector of positions is \\(p^{(0)}\\) and the price vector of velocities is \\(p^{(1)}\\). Then, the maximal profit flow is\n\\[H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}) = \\max_{ q^{(2)}} (\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nand the optimal production plan is\n\\[q^{(2)\\ast} = \\mathop{\\mathrm{arg\\,max}}_{ q^{(2)}}(\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - L)\\]\n\n\nOstrogradsky instability and the anthropic principle\nWe will show that the quantity does deserve the name of “Hamiltonian”:\n\\[H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}) = \\langle p^{(0)} , q^{(1)}\\rangle + \\max_{ q^{(2)}} (\\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nAssuming that, we have a serious problem. Consider an oscillator with higher-order derivatives. Since its Hamiltonian contains a term \\(\\langle p^{(0)} , q^{(1)}\\rangle\\), it is linear with respect to \\(p^{(0)}\\) and \\(q^{(1)}\\). In other words, it can have arbitrarily low energy states.\nNow, this could be alright if we live in a classical world, but we live in a world described by quantum field theory. In QFT, the world is a giant network of oscillators. If a quantum oscillator has higher-order derivatives, then its energy levels can go both infinitely high and low. If there is any coupling at all between its energy levels, it would instantly evaporates into infinitely many positive and negative energy particles, in a blaze of vacuum decay.\nThis is an anthropic explanation for “Why Newton’s laws?” Newton’s laws, because the Lagrangian depends on only up to velocity. Why? Because if it also depends on acceleration, the vacuum would decay (Swanson 2022). We can similarly explain anthropically why space has 3 dimensions, and time has 1 dimension.\n\nWith more or less than one time dimension, the partial differential equations of nature would lack the hyperbolicity property that enables observers to make predictions. In a space with more than three dimensions, there can be no traditional atoms and perhaps no stable structures. A space with less than three dimensions allows no gravitational force and may be too simple and barren to contain observers.\n(Tegmark 1997).\n\n\n\nHamiltonian equations\nWe can prove the Hotelling’s lemma for this Hamiltonian, using the same no-arbitrage argument as before:\n\\[\\begin{cases}     \n    \\partial_t H = -\\partial_t L \\\\  \n    \\nabla_{q^{(0)}} H = -\\nabla_{q^{(0)}} L \\\\     \n    \\nabla_{q^{(1)}} H = p^{(0)}-\\nabla_{q^{(1)}} L \\\\     \n    \\nabla_{p^{(0)}} H = q^{(1)} \\\\     \n    \\nabla_{p^{(1)}} H = q^{(2)\\ast}\n\\end{cases}\\]\nAlong an optimal trajectory, the producer always chooses \\(\\dot q^{(1)} = q^{(2)\\ast}\\), and has no choice in \\(\\dot q^{(0)} = q^{(1)}\\), so we have two equations of motion:\n\\[\\begin{cases}     \n\\dot q^{(1)} = q^{(2)\\ast} = \\nabla_{p^{(1)}} H\\\\    \n\\dot q^{(0)} = q^{(1)} = \\nabla_{p^{(0)}} H\n\\end{cases}\\]\nThe market must adjust its prices by the no-arbitrage condition, as before. If we inflict a position shock of \\(\\delta q^{(0)}\\), then by no-arbitrage, selling it now or later is equally (up to order \\(\\delta^2\\)) profitable:\n\\[\\langle p^{(0)} , \\delta q^{(0)}\\rangle = \\langle p^{(0)} + \\dot p^{(0)} \\delta t , \\delta q^{(0)}\\rangle - \\langle \\nabla_{q^{(0)}} L , \\delta q^{(0)}\\rangle \\delta t\\]\nyielding \\(\\dot p^{(0)} = \\nabla_{q^{(0)}} L = -\\nabla_{q^{(0)}} H\\).\nFor the last equation of motion, inflict a velocity shock of \\(\\delta q^{(1)}\\). The effect of the shock include both its effect on \\(q^{(0)}\\) and \\(L\\), thus the no-arbitrage equation states:\n\\[\\underbrace{\\langle p^{(1)} , \\delta q^{(1)}\\rangle}_{\\text{selling now}} =  \\underbrace{\\langle p^{(1)} + \\dot p^{(1)} \\delta t , \\delta q^{(1)}\\rangle}_{\\text{selling later}} + \\underbrace{\\langle p^{(0)} + \\dot p^{(0)} \\delta t , \\delta q^{(1)}\\delta t\\rangle}_{\\text{profit from extra }p^{(0)}} - \\underbrace{\\langle \\nabla_{q^{(1)}} L , \\delta q^{(1)}\\rangle \\delta t}_{\\text{cost from holding extra }p^{(1)}}\\]\nwhich yields the last equation \\(\\dot p^{(1)} = \\nabla_{q^{(1)}} L - p^{(0)} = -\\nabla_{q^{(1)}} H\\).\nIn summary, we have\n\nTheorem 5 (higher-order Hamiltonian equations of motion:) \\[\n\\begin{cases}     \n    \\dot q^{(1)} = \\nabla_{p^{(1)}} H\\\\     \n    \\dot q^{(0)} = \\nabla_{p^{(0)}} H \\\\     \n    \\dot p^{(0)} = -\\nabla_{q^{(0)}} H \\\\     \n    \\dot p^{(1)} = -\\nabla_{q^{(1)}} H  \n\\end{cases}\n\\]\n\n\n\nEuler–Lagrange equations\nIn order to obtain the Euler–Lagrange equations of motion, we need to work backwards from the Hamiltonian equations of motion as before.\nFrom the Hamiltonian, we can go back to the Lagrangian by inverting the convex transform:\n\\[L(t, q^{(0)}, q^{(1)}, q^{(2)})  = \\max_{p^{(0)} ,p^{(1)}} (\\langle p^{(0)} , q^{(1)}\\rangle + \\langle p^{(1)} , q^{(2)}\\rangle - H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}))\\]\nHere we are given a hint of the troubles ahead. Since \\(H\\) is linear in \\(p^{(1)}\\):\n\\[H(t,  q^{(0)}, q^{(1)}, p^{(0)}, p^{(1)}) = \\langle p^{(0)} , q^{(1)}\\rangle + \\max_{ q^{(2)}} (\\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nthere is no way to fix \\(p^{(1)}\\) in the inverse transform! In detail, we plug the equation for \\(H\\) into the equation for \\(L\\), to get\n\\[L(t, q^{(0)}, q^{(1)}, q^{(2)}) = \\max_{p^{(0)} ,p^{(1)}} (\\langle p^{(1)} , q^{(2)}\\rangle - \\max_{ q^{(2)}} (\\langle p^{(1)} , q^{(2)}\\rangle - L(t, q^{(0)}, q^{(1)}, q^{(2)}))\\]\nand we see that there is no optimality constraint on \\(p^{(0)}\\). This is a hint of instabilities ahead.\nDifferentiating \\(L\\), we get\n\\[\\begin{cases}\n\\partial_t L = -\\partial_t H\\\\\n\\nabla_{q^{(0)}}L = -\\nabla_{q^{(0)}}H \\\\\n\\nabla_{q^{(1)}}L = p^{(0)} - \\nabla_{q^{(1)}}H \\\\\n\\nabla_{q^{(2)}}L = p^{(1)\\ast}  \n\\end{cases}\\]\nNow, along the optimal trajectory, we must have \\(\\nabla_{q^{(2)}}L = p^{(1)\\ast}\\), so taking its time-derivative, we get\n\\[\\frac{d}{dt}\\nabla_{q^{(2)}}L = \\dot p^{(1)} = -\\nabla_{q^{(1)}}H = \\nabla_{q^{(1)}}L - p^{(0)}\\]\nTake another time-derivative, to obtain the Euler–Lagrange equations of motion:\n\\[\\sum_{i=0}^2\\left(-\\frac{d}{d t}\\right)^i (\\nabla_{q^{(i)}} L ) =0\\]\nThe generalization to \\(L(t, q^{(0)}, ..., q^{(N-1)})\\) is immediate. It can be derived by a similar argument through the market economy.\n\n\nAn unstable higher-order oscillator\nIt is beyond our scope to discuss Ostrogradsky instability in quantum field theory, however, we can have a taste of it here. Consider the oscillator perturbed by \\(\\epsilon\\):\n\\[L = \\frac 12 m\\dot x^2 - \\frac 12 kx^2 - \\frac 12 \\epsilon \\ddot x^2\\]\nIts EL equation is\n\\[\\epsilon x^{(4)} + m\\ddot x + kx = 0\\]\na linear order-4 equation, so its solutions are of the form \\(x = \\sum_{i=1}^4 a_i e^{z_i t}\\), where \\(z_1, z_2, z_3, z_4\\) are its fundamental (complex) frequencies. Plug them in the equation and solve it simply:\n\\[z = \\pm \\sqrt{-\\frac{1}{2\\epsilon} (m \\pm \\sqrt{m^2 - 4\\epsilon k})}\\]\nAt small \\(|\\epsilon|\\) limit, we have\n\\[z \\approx \\pm i\\sqrt{\\frac km}, \\pm\\sqrt{-\\frac m\\epsilon}\\]\nand so if \\(\\epsilon &lt; 0\\), one of the modes is exponentially growing at rate \\(\\sqrt{m/|\\epsilon|}\\).\nIf \\(\\epsilon &gt; 0\\), then the oscillator survives, with two modes of oscillation of frequency \\(\\sqrt{\\frac km}\\) and \\(\\sqrt{\\frac{m}{\\epsilon}}\\). When there is viscous force, however, this delicate stability is destroyed. (Nesterenko 2007)\nThe equation of motion in this case is\n\\[\\epsilon x^{(4)} + m\\ddot x + \\gamma \\dot x + kx = 0\\]\nThe algebraic equation to solve is now \\(\\epsilon z^4 - mz^2 + i\\gamma z + k = 0\\)."
  },
  {
    "objectID": "blog/posts/art/index.html#particle-wave-duality",
    "href": "blog/posts/art/index.html#particle-wave-duality",
    "title": "Analytical mechanics",
    "section": "Particle-wave duality",
    "text": "Particle-wave duality\n\nExtended example: particle in free space\nConsider a particle of mass \\(m\\) in free space \\(\\mathbb{R}^n\\). Its configuration space is \\(\\mathbb{R}^3\\), with Lagrangian:\n\\[L(t, q, v) = \\frac 12 m\\|v\\|^2\\]\nBy convex duality, we have\n\\[\\begin{cases} L(t, q, v) = \\frac 12 m\\|v\\|^2\\\\ H(t, q, p) = \\frac{\\|p\\|^2}{2m} \\end{cases}\\quad  \\begin{cases} p^\\ast(t, q, v) = mv\\\\ v^\\ast(t, q, p) = \\frac{p}{m} \\end{cases}\\quad\\]\nFor any \\(t_0, q_0, t, q\\) with \\(t_0\\neq t\\), we can directly solve for the trajectory from \\((t_0, q_0)\\) to \\((t, q)\\), then find the action:\n\\[S_{t_0, q_0}(t, q) = \\frac 12 m \\frac{\\|q-q_0\\|^2}{t-t_0}\\]\nEach \\(S\\) defines a paraboloid wavefront in spacetime:\n\\[\n(t - t_0) = \\frac{\\|q-q_0\\|^2}{2S/m}\n\\]\nWe can see this directly when the space is one-dimensional. That is, when the particle is moving on a line. Set \\(t_0 = 0, q_0 = 0\\), then the wavefronts in spacetime are\n\\[\nt = \\frac{q^2}{2S/m}\n\\]\nThese solutions are all solutions to the HJE that are interpretable in Newtonian mechanics. However, the HJE itself is merely a PDE with its own logic and meaning, and consequently, it may have different solutions that are hard to interpret in Newtonian mechanics.\nFrom our 21st-century perspective, we can say that the HJE is generally true, and Newtonian mechanics is only a special case. Some solutions to the HJE may not be interpretable in Newtonian mechanics, but they are nevertheless physically real, since Newtonian mechanics is incomplete. Given that, we simply try to solve HJE, confident that its solutions are physically real, even if its meaning is not interpretable in Newtonian mechanics.\nThe Lagrangian is time-independent, so any solution to Equation 4:\n\\[S(t, q) = W(q) - Et, \\quad \\| \\nabla_q W \\| = \\sqrt{2mE}\\]\nfor any constant \\(E &gt; 0\\) also gives a solution to the HJE. This is just the eikonal equation12 for a medium of constant wave speed! More on this in the section on geometric optics.\n12 From Greek εἰκών (eikon, \"image\"), from which the word icon derived.One can of course solve the eikonal equation by putting it into a numerical package and let it grind out the solution. However, there is a simple pictorial solution, often called the Huygens principle.\nSuppose you know a surface of constant \\(W = W_0\\), and you know that the arrows of \\(\\nabla_q W\\) point outwards, then since \\(\\nabla W\\) is perpendicular to the surface, and is of constant length \\(\\sqrt{2mE}\\), you can step out a small distance \\(ds\\) perpendicularly out of the whole surface \\(W= W_0\\), and arrive at the surface of \\(W=W_0 + \\sqrt{2mE} ds\\). Alternatively, you can draw small spheres of radius \\(ds\\), and their outwards envelope is the \\(W=W_0+ \\sqrt{2mE} ds\\) surface.\nThe two procedures given above are in fact equivalent, but in one, we constructed \"rays\" while the other we constructed \"wave fronts\". This duality of particle ray and wave has well-known implications. Newton believed light to be particle rays, while Huygens believed it to be waves. This is resolved (?) by the wave-particle duality of quantum mechanics.\nFor the free particle, the simplest solution is the plane wave:\n\\[W(q) = \\sqrt{2mE} \\langle \\hat k, q \\rangle\\]\nwhere \\(\\hat k\\) is any unit-vector, interpreted as the direction of wave propagation.\nPlugging it back to Equation [eq:HJ], we find that the \"planar wave particle\" has\n\\[(H, p) = (E, \\sqrt{2mE}\\hat k)\\]\nWell, bravely stretching the interpretation, we say that a planar wave is a particle with energy \\(E\\) and momentum \\(\\sqrt{2mE} \\hat k\\). Knowing that the wave vector \\(k\\) is generally related to the wavelength by \\(k \\propto \\lambda^{-1}\\), we find that the particle has wavelength proportional to \\(\\frac 1p = \\frac{1}{\\sqrt{2mE}}\\), Now compare that with what quantum mechanics states: \\(\\lambda = \\frac hp\\).\n\n\nExample: particle in a potential field\nConsider particle in a potential field. Its Lagrangian is\n\\[L(t, q, v) = \\frac 12 m\\|v\\|^2 - V(q)\\]\nand by convex duality\n\\[\\begin{cases}     L(q, v) = \\frac 12 m\\|v\\|^2 - V(q)\\\\     H(q, p) = \\frac{\\|p\\|^2}{2m} + V(q) \\end{cases} \\quad \\begin{cases}     p^\\ast = mv \\\\     v^\\ast = \\frac pm \\end{cases}\\]\nThe HJE gives\n\\[\\partial_t S + \\frac 1{2m} \\|\\nabla_q S\\|^2 = -V(q)\\]\nNow, the Schrödinger equation for the same situation is\n\\[i \\hbar \\frac{\\partial \\psi}{\\partial t}=-\\frac{\\hbar^2}{2 m} \\nabla_q^2\\psi+V(q) \\psi\\]\nTypically, solutions to the Schrödinger equation have the form of \\(\\psi(q) = \\exp(iS(t, q) / \\hbar)\\), where \\(S(t, q)\\) is the \"phase\" of the particle at \\((t, q)\\). Plugging it in, and praying that it would work out, we get\n\\[\\partial_t S + \\frac 1{2m} \\|\\nabla_q S\\|^2 = -V(q) + \\frac{i\\hbar}{2m} \\nabla_q^2 S\\]\nwhich is the same except a \"quantum correction term\" proportional to \\(\\hbar\\). This is one way to interpret \"classical mechanics is quantum mechanics at the \\(\\hbar \\to 0\\) limit\".\n\n\nExample: Relativistic particle in free space\nSince the HJE is fully general for any function \\(L(t, q, v)\\) that is smooth and strictly convex in \\(v\\), we can simply write down the Lagrangian for relativistic particle in a field, and it would just workTM.\nLet’s first consider particle in free space. In relativity, the one thing that is coordinate-independent is the proper time of a trajectory, so it is reasonable to guess that the action is the proper time, then deduce what the Lagrangian is. So, let \\(t_0 = 0, q_0 = 0\\), then by basic relativity, the proper time for the particle to arrive at \\((t, q)\\) is\n\\[S(t, q) = \\frac{\\|q\\|}{v\\gamma} = \\sqrt{t^2- \\frac{\\|q\\|^2}{c^2}}\\]\nwhere \\(\\gamma = \\frac{1}{\\sqrt{1-v^2/c^2}}\\) is the well-known factor used everywhere in special relativity.\nTaking \\(\\nabla_q\\), and simplifying, we find the relativistic momentum to be...\n\\[p = \\nabla_q S = -\\frac{\\gamma v}{c^2}\\]\nwhich is not what we expect: \\(p = \\gamma mv\\). This is fixed by multiplying the action with a constant factor \\(-mc^2\\). Multiplying a constant factor in action has no effect on the calculus of variations. Thus we find that the action of a path is the proper time of the path, multiplied by \\(-mc^2\\):\n\\[S(\\text{path}) = -mc^2 \\int_{\\text{path}}d\\tau = -mc^2 \\int_{\\text{path}}\\frac 1\\gamma dt\\]\nWith this, we can derive the familiar equations by the HJE and convex duality:\n\\[\\begin{cases}     \nL(q, v) = -\\frac{mc^2}{\\gamma}\\\\     \nH(q, p) = \\sqrt{(\\|p\\|c)^2 + (mc^2)^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\gamma mv \\\\     \nv^\\ast = \\frac{pc}{\\sqrt{\\|p\\|^2 + (mc)^2}}\n\\end{cases}\\]\nIn particular, at low \\(v\\), the Newtonian kinetic energy appears:\n\\[L \\approx -mc^2 + \\frac 12 m\\|v\\|^2\\]\nThe HJE then becomes\n\\[\\frac 1{c^2} \\left(\\partial_t S \\right)^2 - \\|\\nabla S \\|^2 = m^2 c^2\\]\nIn particular, the time-independent solutions are of the form\n\\[S = W(q)-Et, \\quad \\| \\nabla W \\| = \\frac 1c \\sqrt{E^2 - m^2 c^4 }\\]\nfor any \\(E &gt; mc^2\\). In particular, if we plug in the usual relativistic energy \\(E = \\gamma mc^2\\), we get\n\\[\\| \\nabla W \\| = \\gamma mv\\]\nwhich is similar to what we obtained for the free particle in classical mechanics, with \\(\\|\\nabla W \\| = \\sqrt{2mE}\\), just with classical momentum upgraded to relativistic momentum.\nJust as how the HJE of a classical particle can be derived as the \\(\\hbar \\to 0\\) limit of the Schrödinger equation, one can derive the HJE of the non-quantum relativistic particle as the \\(\\hbar \\to 0\\) limit limit of the Klein–Gordon equation. The Klein–Gordon equation is essentially the simplest possible way to combine special relativity with Schrödinger equation:\n\\[\\left( \\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2} - \\nabla^2 + \\frac{m^2 c^2}{\\hbar^2} \\right) \\psi(t, \\mathbf{x}) = 0\\]\nAgain, plugging in \\(\\psi = e^{iS(t, q)/\\hbar}\\), we find with great satisfaction\n\\[\\frac 1{c^2} \\left(\\partial_t S \\right)^2 - \\|\\nabla S \\|^2 = m^2 c^2 + \\frac{i\\hbar}{c^2}(\\partial_t^2 S - \\nabla^2 S)\\]\nThe derivation in this section is similar to how Schrödinger derived his formula. Roughly speaking, he derived it by thinking that if electrons behave as waves, as de Broglie said, then they must obey some sort of wave equation. Then, he recalled that the Hamilton–Jacobi equations describes motion of particles by a wave equation, and he followed the analogy along, until he arrived at his equation (Derbes 1996; Hamill 2013, sec. 6.4).\n\n\nThe particle-wave duality of HJE\n(Houchmandzadeh 2020)\nWhat does the Hamilton–Jacobi equation mean? Let’s write the function \\(S(t, q; t_0, q_0)\\) as \\(S_{t_0, q_0}(t, q)\\), then \\(S_{t_0, q_0}\\) is a real-valued function of type \\(\\mathbb{R}\\times \\mathcal C \\to \\mathbb{R}\\), where \\(\\mathbb{R}\\) stand for time, and \\(\\mathcal C\\) stand for configuration space. Let’s call \\(\\mathbb{R}\\times \\mathcal C\\) the configuration spacetime.\nWe know that \\(S_{t_0, q_0}\\) is a real-valued potential field on configuration spacetime, and we know its value at the source: \\(S_{t_0, q_0}(t_0, q_0) = 0\\). The HJE tells us how the potential field \"propagates out from the source to the rest of configuration spacetime\". The equation of its propagation is then:\n\\[(-\\partial_t, \\nabla_q)S_{t_0, q_0}(t, q) = (H(t, q, p), p)\\]\nThere is just one problem: the quantity on the right depends on \\(p\\), where \\(p\\), as we found, is the momentum that the system would have at the end if it really arrives at configuration \\((t, q)\\). But how do we find out what \\(p\\) is without already finding how the system moves across configuration spacetime? Presumably, we can solve for \\(S_{t_0, q_0}\\), then use that to find out how the system moves across configuration spacetime, and then solve for \\(p\\)... a circular situation!\nLet’s try again.\n\n\nGeometric optics\nWhen Hamilton developed his Hamiltonian approach, it was to study geometric optics, which can be derived from Fermat’s principle: light paths have stationary travel time. In other words, the action of a path is\n\\[S(\\text{path}) = \\int_{\\text{path}} dt\\]\nThus, \\(L = 1\\)...? Well, here we see the problem: in geometric optics, if you fix the starting and ending point as \\((t_0, q_0), (t, q)\\), then any path between them takes exactly \\(t-t_0\\) time, and there is nothing to vary. Consequently, we need to remove time from consideration, so that there is something to vary.\nFermat’s principle, reformulated, states light paths have stationary adjusted length. Let the medium be isotropic (light speed does not depend on direction), then we have\n\\[S(\\text{path}) = \\int_{\\text{path}} n(q) \\|dq\\|\\]\nwhere \\(n = \\frac cn\\) is the refractive index. with \\(L(q) = n(q)\\). Here we encounter a brief difficulty: time flows in one direction only, but space flows in infinitely many possible directions!\nThe solution might seem like a joke, but it would work out well: select one direction13, say \\(q_0\\), and pretend that it is time. With this trick, all previous mathematical formalism immediately applies, and we have\n13 This direction is usually selected to be the direction of the principal optic axis. For example, the long-axis of a camera is a principal optic axis, and so is the barrel-axis of a telescope.\\[S(\\text{path}) = \\int_{\\text{path}} n(q_0, q_1, q_2) \\sqrt{1 + \\left(\\frac{dq_1}{dq_0}\\right)^2 + \\left(\\frac{dq_2}{dq_0}\\right)^2}dq_0\\]\n\nDerivation\nLet’s make the notation cleaner, by rewriting \\(q_0\\) as \\(t\\), \\((q_1, q_2)\\) as \\(q\\), and using \\(v\\) to mean \\(\\left(\\frac{dq_1}{dq_0}, \\frac{dq_2}{dq_0}\\right)\\). Then we have\n\\[L(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\]\nRoutine calculation yields\n\\[\\begin{cases}     \nL(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\\\     \nH(t, q, p) = -\\sqrt{n^2 - \\|p\\|^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\frac{nv}{\\sqrt{1 + \\|v\\|^2}} \\\\     \nv^\\ast = \\frac{p}{\\sqrt{n^2 - \\|p\\|^2}}\n\\end{cases}\\]\nwe continue with the HJE, which simplifies to:\n\\[(\\partial_t S)^2 + \\|\\nabla_q S\\|^2 = n^2\\]\nReverting notation back to \\((q_0, q_1, q_2)\\), we find the eikonal equation:\n\\[\\|\\nabla_q S\\| = n(q)\\]\nWhy did the trick work? Well, if we look back to how we derived the Hamiltonian, we could see that what we called \"time\" is really just a special copy of \\(\\mathbb{R}\\), along which we organized all other state and control variables. We don’t really need time to be anything more than the domain of functions, as in \\(q_i: \\mathbb{R}\\to \\mathbb{R}\\) and \\(v_i : \\mathbb{R}\\to \\mathbb{R}\\). It most definitely does not need to \"flow\", or flow only from the past to the future, or have any psychological significance.\n\n\nInterpretation\nStarting with Fermat’s principle for light rays, we ended up with the eikonal equation for light waves. In general, we find the duality between , shown in Table 1.\n\nThe particle-wave duality.\n\n\n\n\n\n\n\nperspective\nparticle-path\nwave-field\n\n\n\n\naction \\(S\\)\na function of particle path\na field on configuration-spacetime\n\n\nequation\n\\(\\delta S(\\text{path})=0\\)\n\\(\\partial_t S + H(t, q, \\nabla_q S) = 0\\)\n\n\nin optics\nlight rays, Fermat’s principle\nlight waves, Huygens principle\n\n\nin mechanics\npoint particles\nmatter waves\n\n\n\n\n\n\nThe Eikonal equation."
  },
  {
    "objectID": "blog/posts/art/index.html#the-particle-wave-duality",
    "href": "blog/posts/art/index.html#the-particle-wave-duality",
    "title": "Analytical mechanics",
    "section": "The particle-wave duality",
    "text": "The particle-wave duality\n\nParticle in free space\nConsider a particle of mass \\(m\\) in free space \\(\\mathbb{R}^n\\). Its Lagrangian is \\(L(t, q, v) = \\frac 12 m\\|v\\|^2\\). By convex duality, we have\n\\[\\begin{cases} L(t, q, v) = \\frac 12 m\\|v\\|^2\\\\ H(t, q, p) = \\frac{\\|p\\|^2}{2m} \\end{cases}\\quad  \n\\begin{cases} p^\\ast(t, q, v) = mv\\\\ v^\\ast(t, q, p) = \\frac{p}{m} \\end{cases}\\]\nFor any \\(t_0, q_0, t, q\\) with \\(t_0\\neq t\\), we can directly solve for the trajectory from \\((t_0, q_0)\\) to \\((t, q)\\), then find the action:\n\\[S_{t_0, q_0}(t, q) = \\frac 12 m \\frac{\\|q-q_0\\|^2}{t-t_0}\\]\nEach \\(S\\) defines a paraboloid wavefront in spacetime, with apex \\(t_0, q_0\\). The wavefront is translation-symmetric, so we set both to zero, yielding the equation of the wavefront:\n\\[\nt = \\frac{\\|q\\|^2}{2S/m}\n\\]\nThe wavefront of \\(S = 0\\) is just the positive \\(t\\)-axis, and as \\(S\\) increases, the wavefront widens out.\nNow, we interpret this wave from the HJE point of view. Let’s say we have the wavefront at \\(S=S_0\\), and we want to construct the wavefront at \\(S = S_0 + \\delta S\\). This we perform by rippling out a little wavelet at each point \\((t', q')\\) on the wavefront. The little wavelet has shape \\((t-t') = \\frac{\\|q - q'\\|^2}{2\\delta S/m}\\), and as we move \\(t', q'\\) around the parabola of wavefront \\(S = S_0\\), the envelope of these wavelets is the wavefront of \\(S = S_0 + \\delta S\\).\nThis is the wave point of view. We can switch back to the particle point of view. What is the velocity of the particle passing the point \\((t', q')\\)? We know that it must be traveling in the optimal direction, and the optimal direction allows it to go as far as possible. Therefore, we simply draw the wavelet of \\(\\delta S\\) at \\((t', q')\\), then find the intersection of the wavelet with the wavefront of \\(S = S_0 + \\delta S\\).\nThe entire procedure is pictured below.\n\n\n\nThe two red curves are two wavefronts \\(S = S_0\\) and \\(S = S_0 + \\delta S\\). At select points on the first wavefront, we draw a wavelet of \\(\\delta S\\), which is tangent to the second wavefront. The particle trajectory connects the point and the tangent point of the wavelet with the second wavefront.\n\n\n\n\nParticle-wave in free space\nThe paraboloid-shaped solution for \\(S\\) is interpretable in Newtonian mechanics, as the motion of a single particle moving from the origin. However, the HJE itself is merely a PDE with its own logic and meaning, and consequently, it may have different solutions that are hard to to interpret in Newtonian mechanics.\nFrom our 21st-century perspective, we can say that the HJE is generally true, and Newtonian mechanics is only a special case. Some solutions to the HJE may not be interpretable in Newtonian mechanics, but they are nevertheless physically real, since Newtonian mechanics is incomplete. Given that, we simply try to solve HJE, then try to interpret it, even if not in Newtonian mechanics.\nBecause the Lagrangian is time-independent, so any time-independent solution:\n\\[S(t, q) = W(q) - Et, \\quad \\| \\nabla_q W \\| = \\sqrt{2mE}\\]\nfor any constant \\(E &gt; 0\\) also gives a solution to the HJE. This is just the eikonal equation12 for a medium of constant wave speed! More on this in the section on geometric optics. One can of course solve the eikonal equation by putting it into a numerical package and let it grind out the solution. However, we can interpret it by the Huygens principle.\n12 From Greek εἰκών (eikon, \"image\"), from which the word “icon” derived.Suppose you know a surface of constant \\(W = W_0\\), and you know that the arrows of \\(\\nabla_q W\\) point outwards, then since \\(\\nabla W\\) is perpendicular to the surface, and is of constant length \\(\\sqrt{2mE}\\), you can step out a small distance \\(ds\\) perpendicularly out of the whole surface \\(W= W_0\\), and arrive at the surface of \\(W=W_0 + \\sqrt{2mE} ds\\). Alternatively, you can draw small spheres of radius \\(ds\\), and their outwards envelope is the \\(W=W_0+ \\sqrt{2mE} ds\\) surface. These procedures are equivalent, but in one, we constructed \"rays\" while the other we constructed \"wave fronts\".\nFor the free particle, the simplest solution is the plane wave:\n\\[W(q) = \\sqrt{2mE} \\langle \\hat k, q \\rangle\\]\nwhere \\(\\hat k\\) is any unit-vector, interpreted as the direction of wave propagation. Plugging it back to Equation 3, we find that the \"planar wave particle\" has\n\\[(\\partial_t S, \\nabla S) = (-H, p) = (-E, \\sqrt{2mE}\\hat k)\\]\nwhere \\(\\hat k\\) is the direction of the group velocity of the wave. The group velocity of the wave is \\(\\frac{\\partial_t S}{\\nabla S} = \\frac{E}{\\sqrt{2mE}}\\hat k\\).\n\n\n\nThe two red curves are two wavefronts \\(S = S_0\\) and \\(S = S_0 + \\delta S\\). At select points on the first wavefront, we draw a wavelet of \\(\\delta S\\), which is tangent to the second wavefront. The particle trajectory connects the point and the tangent point of the wavelet with the second wavefront.\n\n\nTaking the particle-wave analogy seriously, we say that:\n\na planar wave is a particle with energy \\(E\\) and momentum \\(p \\propto k \\propto \\sqrt{2mE} \\hat k\\).\na particle with energy \\(E\\) and momentum \\(p\\) is a planar wave traveling at group velocity \\(E/p\\).\n\nTypically, waves have a wavelength \\(\\lambda\\), which is related to the wave vector \\(k\\) by \\(k \\propto \\lambda^{-1}\\), we find that the particle has wavelength \\(\\lambda \\propto \\frac 1k \\propto \\frac 1p\\). Thus, we arrived at de Broglie’s matter-wave hypothesis, which Schrödinger expanded into his equation. Both de Broglie and Schrödinger were inspired by Hamilton’s optics-mechanics analogy, so we are treading the same path as them a century ago.\nIn fact, we could start with an arbitrary wavefront in configuration-spacetime, and use Huygens’ principle to construct the wavefront in the next moment. In general, we can’t do Fourier analysis on such wavefronts – they are not decomposable into planar waves, because the HJE is a nonlinear equation. Fourier analysis only works on linear differential equations.\n\n\n\nGiven a wavefront in the shape of \\(t = q^3\\), we can construct the next wavefront as the envelope of the parabolic wavelets at every point on the wavefront.\n\n\n\n\nParticle in a potential field\nA particle in a time-dependent potential field \\(V\\) has Lagrangian \\(L(t, q, v) = \\frac 12 m\\|v\\|^2 - V(t, q)\\). By convex duality\n\\[\\begin{cases}     \nL(t, q, v) = \\frac 12 m\\|v\\|^2 - V(t, q)\\\\     \nH(t, q, p) = \\frac{\\|p\\|^2}{2m} + V(t, q)\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = mv \\\\     \nv^\\ast = \\frac pm\n\\end{cases}\\]\nThe HJE gives\n\\[\\partial_t S + \\frac 1{2m} \\|\\nabla_q S\\|^2 = -V(t, q)\\]\nAs before, if we interpret the equation as a wave equation, then the group velocity is \\(\\frac{\\partial_t S}{\\nabla S} = \\frac{-E}{p} \\hat k\\), with magnitude \\(v_g = \\frac{E}{\\sqrt{2m(E-V)}}\\).\n\n\n\n\n\n\nexample: particle in free fall\n\n\n\n\n\nWe consider the classical problem of a body in free fall, thrown from the origin \\((t, q) = (0, 0)\\). Basic physics tells us that the position and velocity of the body are given by\n\\[q(t) = v_0 t - \\frac{1}{2}gt^2, \\quad v = v_0 - gt = \\frac{q}{t} - \\frac{1}{2}gt\\]\nPlugging these expressions into the Hamilton-Jacobi equation, we obtain a system of partial differential equations for the action function \\(S\\):\n\\[\n\\begin{cases}\n\\partial_t S &= -H = -\\frac{1}{2}m(\\frac{q}{t} - \\frac{gt}{2})^2 - mgq \\\\\n\\partial_q S &= m(\\frac{q}{t} - gt)\n\\end{cases}\n\\]\nSolving this system, we find the unique solution for the action:\n\\[S = \\frac{x^2}{y} - xy - \\frac{y^3}{12}\\]\nwhere we have introduced convenience variables \\(x = gq\\), \\(y = gt\\), and \\(s = \\frac{2gS}{m}\\).\nThe contour lines of the action function satisfy the equation:\n\\[\nx = \\frac{1}{2}y^2 \\pm \\sqrt{\\frac{1}{3}y^4 + sy}\n\\]\nTo analyze the wavelet associated with this system, we start by writing down the Lagrangian:\n\\[L = T - V = \\frac{1}{2}m(\\frac{\\delta q}{\\delta t})^2 - mgq\\]\nThe wavelet equation is then given by:\n\\[\\delta S = L \\delta t = \\left(\\frac{1}{2}m(\\frac{\\delta q}{\\delta t})^2 - mgq\\right)\\delta t\\]\nSimplifying this equation using our convenience variables, we get:\n\\[(\\delta x)^2 = 2x(\\delta y)^2 + \\delta s \\delta y\\]\nSolving for \\(\\delta y\\), we obtain:\n\\[\\delta y = \\frac{-\\delta s \\pm \\sqrt{(\\delta s)^2 + 8x(\\delta x)^2}}{4x}\\]\nThis equation reveals the nature of the wavelet. When \\(x &gt; 0\\), the equation describes a hyperbola. For \\(x &lt; 0\\), it describes an ellipse. At the boundary \\(x = 0\\), the equation describes a parabola.\n\nThere is no planar wave solution, because a planar wave solution is both constant energy and unbounded, whereas if a particle can move infinitely far away, it must have infinite energy. If we attempt to force a planar wave solution, it would immediately break down:\n\n\n\n\n\nExercise 5 Solve the time-independent HJE for the particle in free fall. It should be \\(S = W(q) - Et\\), where \\(E\\) is a constant, and \\(W\\) is a semicubical parabola.\n\n\nExercise 6 In the same way, analyze the simple harmonic oscillator – a particle in a potential well \\(V = \\frac 12 kq^2\\). Similarly, it cannot have a planar wave solution. Plot the wavelets along each point on a planar wave, and see how it breaks down. Find two families of solutions: The case where we have a point source at \\((0, 0)\\), and the case of time-independent HJE.\n\n\n\nDeriving the time-independent Schrödinger equation\nThis section based on (Masoliver and Ros 2009; Derbes 1996; Hamill 2013, sec. 6.4).\nAssume that the potential is time-independent: \\(V(t, q) = V(q)\\). Assume that the physical system can be described by a function\n\\[\n\\Psi(t, q) = \\Psi_0(r) e^{iS(t, q)/\\hbar}\n\\]\nwhere the function \\(\\Psi\\) is typically called the “wave function”.13 We assume that the wave is a “standing wave”, so that all of space is oscillating in sync. Let \\(S(t, q) = W(q) - Et\\), so that the oscillation frequency is \\(E/\\hbar\\).14\n13 What is a wave function? It is just some abstract mathematical object, that somehow allows us to calculate everything we want to know about this system. We have no idea what it is, but it works. The same applies to the function \\(S(t, q)\\). We call it the “minimal cost” for arriving at \\((t, q)\\), but what really is a cost in physics? Particles do not really pay their paths with natural money. All this time, we have pretended that they pay some kind of cost and want to minimize the cost, but it is really just one big analogy. The same applies for the function \\(\\Psi\\). We might call it a “wave function”, but it really is just one big analogy with the waves on an ocean. There is really no wave in quantum mechanics, only a function that we pretend is a wave, because it helps us calculate results that happen to be correct.14 The most important experimental result from quantum mechanics is that energy levels are quantized. Now, a quantized energy level is something like \\(E = h, 2h, 3h, \\dots\\). There is really just one kind of thing in classical mechanics that is quantized: standing waves! If you have a string, then its standing waves must have \\(0, 1, 2, 3, \\dots\\) nodes, i.e. quantized. Thus, it is natural to try out this “standing wave” assumption.So, we can separate the variables to\n\\[\n\\Psi(t, q) = \\underbrace{e^{-i\\frac{E}{\\hbar}t}}_{\\text{oscillation in sync}} \\underbrace{\\psi(q)}_{\\text{variation over space}}, \\quad \\psi(q) = \\Psi_0(q) e^{i\\frac{W(q)}{\\hbar}t}\n\\]\nSince \\(\\Psi\\) should be a wave, it has better follow the wave equations:\n\\[\n(\\partial_t^2 - v_g^2 \\nabla^2)\\Psi = 0\n\\]\nwhere \\(v_g\\) is the group velocity of the wave. As we saw previously, \\(v_g = \\frac{E}{\\sqrt{2m(E-V)}}\\) for a particle in a potential. Then we have\n\\[\n\\begin{cases}\n\\Psi(t, q) &= e^{-i\\frac{E}{\\hbar} t} \\psi(q), \\\\\n0 &= (\\partial_t^2 - v_g^2 \\nabla^2)\\Psi, \\\\\nv_g &= \\frac{E}{\\sqrt{2m(E-V)}},\n\\end{cases}\\;\\; \\implies \\frac{\\hbar^2}{2 m} \\nabla^2 \\psi+(E-V) \\psi = 0,\n\\]\nwhich is the time-independent Schrödinger equation.\n\nExercise 7 The time-dependent Schrödinger equation states that\n\\[\ni\\hbar\\frac{\\partial}{\\partial t} \\Psi(t, q) = \\left [ - \\frac{\\hbar^2}{2m}\\nabla^2 + V(t, q)\\right ] \\Psi(t, q).\n\\]\nPlug \\(\\Psi(t, q) = \\psi_0(t, q) e^{i S(t, q)/\\hbar}\\) back to the time-dependent Schrödinger equation, and check that at the \\(\\hbar \\to 0\\) limit, we recover the HJE for \\(S(t, q)\\). This is a simple example of the WKB approximation.\n\nIf the above derivation looks mildly suspect, and leaves you with a feeling of seeing a magic trick, it is not an accident. The analogy between classical mechanics and quantum mechanics is not exact, so we cannot logically derive quantum mechanics from classical mechanics. The simple problem is that classical mechanics, even when formulated in the form of Hamilton–Jacobi wave equations, cannot reproduce interference or diffractions. Consider the simple case of a straight-edge diffraction. If you aim a light beam at a sharp edge, then on the other side, there would be alternating bright and dark bands fading into the shadow. However, if light is going by the shortest path, then there should be no such banding, and the brightness should just drop off to zero monotonically.\nThe solution is to admit that geometric optics is insufficient, that Huygens’ principle is insufficient, and we need a full theory of light wave in order to explain what happens on the very smallest scales – a diffraction theory. Similarly, classical mechanics is insufficient, and the HJE is insufficient, and we need a full theory of matter wave in order to explain what happens in the atomic world – quantum mechanics.\n\n\n\nIn classical mechanics, the shadow of a hard edge has no diffractive stripes.\n\n\n\n\n\nThe optical-mechanical analogy at three levels. There is a question mark, because I’m not sure if that should be quantum field theory.\n\n\nDeriving quantum mechanics from classical mechanics is necessarily fraught with danger and luck, because in going from quantum mechanics to classical mechanics, something is irrevocably lost (and other things are irrevocably earned). It is about as difficult as going from geometric optics to wave optics. Still, several people have tried and succeeded, especially Schrödinger.\n\n… the conception of rays is thoroughly well defined only in pure abstract geometrical optics. It is wholly incapable of being applied to the fine structure of real optical phenomena, i.e. to the phenomena of diffraction. Even in extending geometrical optics some what by adding the notion of Huygens’ principle one is not able to account for the most simple phenomena of diffraction without adding some further very strange rules concerning the circumstances under which Huygens’ envelope-surface is or is not physically significant. (I mean the construction of “Fresnel’s zones”.) These rules would be wholly incomprehensible to one versed in geometrical optics alone. Furthermore it may be observed that the notions which are fundamental to real physical optics, i.e. the wave-function itself (\\(W\\) is merely the phase), the equation of wave-propagation, the wave length and frequency of the waves, do not enter at all into the above stated analogy.\n(Schrödinger 1926)\n\n\n… to establish a correspondence between waves and corpuscles such that the laws of mechanics correspond to the laws of geometrical optics. In the wave theory, however, as you will know, geometrical optics is only an approximation: this approximation has its limits of validity and particularly when interference and diffraction phenomena are involved, it is quite inadequate. This prompted the thought that classical mechanics is also only an approximation relative to a vaster wave mechanics. … A new mechanics must be developed which is to classical mechanics what wave optics is to geometrical optics. This new mechanics has since been developed, thanks mainly to the fine work done by Schrödinger.\nLouis de Broglie’s Nobel Prize Lecture (De Broglie 1929)\n\n\n\nRelativistic particle in free space\nSince the HJE is fully general for any function \\(L(t, q, v)\\) that is smooth and strictly convex in \\(v\\), we can simply write down the Lagrangian for relativistic particle in a field, and it would just work.\nLet’s first consider particle in free space. In relativity, the one thing that is coordinate-independent is the proper time of a trajectory, so it is reasonable to guess that the action is the proper time, then deduce from it the Lagrangian. This is natural if we think of \\(S\\) as the optimal cost of traveling.\nLet \\(t_0 = 0, q_0 = 0\\), then by basic relativity, the proper time for the particle to arrive at \\((t, q)\\) is\n\\[S(t, q) = \\frac{\\|q\\|}{v\\gamma} = \\sqrt{t^2- \\frac{\\|q\\|^2}{c^2}}\\]\nwhere \\(\\gamma = \\frac{1}{\\sqrt{1-v^2/c^2}}\\) is the well-known factor used everywhere in special relativity.\nTaking \\(\\nabla_q\\), and simplifying, we find the relativistic momentum to be...\n\\[p = \\nabla_q S = -\\frac{\\gamma v}{c^2}\\]\nHowever, we were expecting \\(p \\to mv\\) when \\(v \\to 0\\), so we fix this issue by multiplying the action with a constant factor \\(-mc^2\\). Multiplying a constant factor in action has no effect on the calculus of variations, so we are free to do this. Thus we find that the action of a path is the proper time of the path multiplied by \\(-mc^2\\):\n\\[S(\\text{path}) = -mc^2 \\int_{\\text{path}}d\\tau = -mc^2 \\int_{\\text{path}}\\frac 1\\gamma dt\\]\nWith this, we can derive the familiar equations by the HJE and convex duality:\n\\[\\begin{cases}\nL(q, v) = -\\frac{mc^2}{\\gamma}\\\\     \nH(q, p) = \\sqrt{(\\|p\\|c)^2 + (mc^2)^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\gamma mv \\\\     \nv^\\ast = \\frac{pc}{\\sqrt{\\|p\\|^2 + (mc)^2}}\n\\end{cases}\\]\nIn particular, at low \\(v\\), we have \\(L \\approx -mc^2 + \\frac 12 m\\|v\\|^2\\). So somehow, by combining the geometry of spacetime with analytical mechanics, we have discovered the \\(E = mc^2\\) formula, even though there seems like something we couldn’t have discovered from mere geometry.\nThe HJE then becomes\n\\[\\frac 1{c^2} \\left(\\partial_t S \\right)^2 - \\|\\nabla S \\|^2 = m^2 c^2\\]\nIn particular, the time-independent solutions are of the form\n\\[S = W(q)-Et, \\quad \\| \\nabla W \\| = \\frac 1c \\sqrt{E^2 - m^2 c^4 }\\]\nfor any \\(E &gt; mc^2\\). In particular, if we plug in the usual relativistic energy \\(E = \\gamma mc^2\\), we get\n\\[\\| \\nabla W \\| = \\gamma mv\\]\nwhich is similar to what we obtained for the free particle in classical mechanics, with \\(\\|\\nabla W \\| = \\sqrt{2mE}\\), just with classical momentum upgraded to relativistic momentum.\n\nExercise 8 Just as how the HJE of a classical particle can be derived as the \\(\\hbar \\to 0\\) limit of the Schrödinger equation, one can derive the HJE of the non-quantum relativistic particle as the \\(\\hbar \\to 0\\) limit limit of the Klein–Gordon equation. The Klein–Gordon equation is essentially the simplest possible way to combine special relativity with Schrödinger equation:\n\\[\\left( \\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2} - \\nabla^2 + \\frac{m^2 c^2}{\\hbar^2} \\right) \\psi(t, \\mathbf{x}) = 0\\]\nPlug in \\(\\psi(t, q) = \\psi_0(q, t) e^{i S(t, q) / \\hbar}\\), and check that at \\(\\hbar \\to 0\\) limit, we recover the HJE.\n\n\n\nGeometric optics\nWe are going back to the roots, as geometric optics was what inspired Hamilton to develop his theory of Hamiltonian mechanics.\nWhen Hamilton developed his Hamiltonian approach, it was to study geometric optics, which can be derived from Fermat’s principle: light paths have stationary travel time. In other words, the action of a path is\n\\[S(\\text{path}) = \\int_{\\text{path}} dt\\]\nThus, \\(L = 1\\)...? Well, here we see the problem: in geometric optics, if you fix the starting and ending point as \\((t_0, q_0), (t, q)\\), then any path between them takes exactly \\(t-t_0\\) time, and there is nothing to vary. Consequently, we need to remove time from consideration, so that there is something to vary.\nFermat’s principle, reformulated, states light paths have stationary optical length. Let the medium be isotropic (light speed does not depend on direction), then we have\n\\[S(\\text{path}) = \\int_{\\text{path}} n(q) \\|dq\\|\\]\nwhere \\(n\\) is the refractive index. with \\(L(q) = n(q)\\). Here we encounter a brief difficulty: time flows in one direction only, but space flows in infinitely many possible directions!\nThe solution might seem like a joke, but it would work out well: select one direction15, say \\(q_0\\), and pretend that it is time. With this trick, all previous mathematical formalism immediately applies, and we have\n15 This direction is usually selected to be the direction of the principal optic axis. For example, the long-axis of a camera is a principal optic axis, and so is the barrel-axis of a telescope.\\[S(\\text{path}) = \\int_{\\text{path}} n(q_0, q_1, q_2) \\sqrt{1 + \\left(\\frac{dq_1}{dq_0}\\right)^2 + \\left(\\frac{dq_2}{dq_0}\\right)^2}dq_0\\]\n\nDerivation\nLet’s make the notation cleaner, by rewriting \\(q_0\\) as \\(t\\), \\((q_1, q_2)\\) as \\(q\\), and using \\(v\\) to mean \\(\\left(\\frac{dq_1}{dq_0}, \\frac{dq_2}{dq_0}\\right)\\). Then we have\n\\[L(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\]\nRoutine calculation yields\n\\[\\begin{cases}     \nL(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\\\     \nH(t, q, p) = -\\sqrt{n^2 - \\|p\\|^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\frac{nv}{\\sqrt{1 + \\|v\\|^2}} \\\\     \nv^\\ast = \\frac{p}{\\sqrt{n^2 - \\|p\\|^2}}\n\\end{cases}\\]\nwe continue with the HJE, which simplifies to:\n\\[(\\partial_t S)^2 + \\|\\nabla_q S\\|^2 = n^2\\]\nReverting notation back to \\((q_0, q_1, q_2)\\), we find the eikonal equation:\n\\[\\|\\nabla_q S\\| = n(q)\\]\nWhy did the trick work? Well, if we look back to how we derived the Hamiltonian, we could see that what we called \"time\" is really just a special copy of \\(\\mathbb{R}\\), along which we organized all other state and control variables. We don’t really need time to be anything more than the domain of functions, as in \\(q_i: \\mathbb{R}\\to \\mathbb{R}\\) and \\(v_i : \\mathbb{R}\\to \\mathbb{R}\\). It most definitely does not need to \"flow\", or flow only from the past to the future, or have any psychological significance.\n\n\nInterpretation\nStarting with Fermat’s principle for light rays, we ended up with the eikonal equation for light waves. In general, we find the following duality between wave-field optics and particle-path optics.\n\nThe particle-wave duality.\n\n\n\n\n\n\n\nperspective\nparticle-path\nwave-field\n\n\n\n\naction \\(S\\)\na function of particle path\na field on configuration-spacetime\n\n\nequation\n\\(\\|\\nabla_q S\\| = n(q)\\)\n\\(\\partial_t S + H(t, q, \\nabla_q S) = 0\\)\n\n\nin optics\nlight rays, Fermat’s principle\nlight waves, Huygens principle\n\n\nin mechanics\npoint particles\nmatter waves\n\n\n\n\n\n\nAnisotropic optics\nWhen the travel cost of light can depend on the direction of travel, we say that the medium is anisotropic. Now, you might expect\n\\[\nS = \\int n(\\hat{\\delta q}) \\delta q\n\\]\nbut this is incorrect, not because there is anything necessarily wrong with the formalism, but because of how \\(n\\) is defined by convention in anisotropic material. At this point, we must study the full particle-wave duality again.\nFor a moment, let’s pretend light is really a particle, and consider how it might appear to someone who believes light is a wave. We arrange an entire plane of photons, such that the plane is perpendicular to a unit vector \\(\\hat k\\). Now, let them move optimally for time \\(\\delta\\). Each of them would go in the same optimal direction \\(v^*(\\hat k)\\), to push the wavefront as far-out as possible.\n\n\n\nA plane of particles marching in sync at velocity \\(v\\), but the collective effect is that the plane moves with group velocity \\(v_g\\), which is different from the individual velocity \\(v\\).\n\n\nNow, the wavefront does not move in the direction \\(v^*\\), but in the direction \\(\\hat k\\). Therefore, the wavefront moves at group velocity \\(v_g(\\hat k) = \\left\\langle v^*(\\hat k), \\hat k\\right\\rangle \\hat k\\).\nSince the photons are trying to push as far out as possible,\n\\[v^*(\\hat k) = \\mathop{\\mathrm{argmax}}_{v \\in K_{particle}} \\left\\langle\\hat k, v\\right\\rangle\\]\nwhere we write \\(K_{particle}\\) as the surface of all particle velocities in all directions. It is a sphere of radius \\(c\\) in a vacuum, but in an anisotropic medium, we allow it to be any crazy shape.\nInstead of studying the group velocity, we actually need to use its inverse – the wavevector \\(k = \\frac{\\hat k}{v_g}\\).16 We thus have\n16 The typical definition is \\(k_{usual} = \\frac{2\\pi}{\\lambda}\\hat k = \\nabla \\phi\\), where \\(\\phi\\) is the phase of the light, and \\(f\\) is its temporal frequency. Our definition, which makes it cleaner, but somewhat different from typical definition, is \\(k_{ours} = \\frac{\\nabla \\phi}{2\\pi f} = \\frac{\\nabla \\phi}{\\omega}\\).\\[k = \\frac{\\hat k}{\\max_{v \\in K_{particle} \\left\\langle v, \\hat k\\right\\rangle}}\\]\nThe reason we use this instead of the group velocity is that, a little simplification later, we have the beautifully simple relation\n\\[\n\\forall k \\in K_{wave}, \\quad \\max_{v \\in K_{particle}}\\left\\langle v, k\\right\\rangle = 1\n\\]\nThis is a very suggestive symmetry, which practically demands us to write it as a duality:\n\\[\n\\begin{cases}\nv^*(k) = \\mathop{\\mathrm{argmax}}_{v \\in K_{particle}}\\left\\langle v, k\\right\\rangle \\\\\nk^*(v) = \\mathop{\\mathrm{argmax}}_{k \\in K_{wave}}\\left\\langle v, k\\right\\rangle\n\\end{cases}, \\quad\n\\begin{cases}\n\\left\\langle v^*(k), k\\right\\rangle = 1\\\\\n\\left\\langle v, k^*(v)\\right\\rangle = 1\\\\\n\\end{cases}\n\\]\nThis is the polar dual construction, often used in convex analysis.17 (Hiriart-Urruty and Lemaréchal 2001, sec. C.3).\n17 What, just because we have not mentioned Legendre transform for a few pages, you would think that we’re done with convex analysis? Too bad! If nature is the great optimizer, then convex analysis is inescapable at every turn.The best case is if \\(K_{particle}\\) is convex. In this case, each \\(k \\in K_{wave}\\) defines a plane perpendicular to it, at a distance \\(\\|k\\|^{=1}\\) from the origin, and the plane is tangent to \\(K_{particle}\\) at precisely \\(v^*(k)\\), and conversely so. In other words, \\(K_{particle}\\) is the envelope of polar lines to points in \\(K_{wave}\\), and conversely so.\nConversely, we can pretend that light is really a wave, and consider how it might appear to someone who believes light is a particle. We would then go through the above argument, and obtain the same result.\n\n\n\nA pair of polar duals. Both surfaces are convex.\n\n\nHowever, we want to deal with more general cases than this, so we need to resolve two issues.\nFirst issue: \\(K_{particle}\\) might be non-convex. Second issue: it might be double-sheeted, or even many-sheeted. For example, in crystal, light polarized in two different orientations can move at two different velocities even in the same direction. Thus, its \\(K_{wave}\\) has two sheets, and so its polar dual, \\(K_{particle}\\), also has two sheets.\nBoth issues are solved by extending the definition of polar duality: replace the maximum with a stationarity. We can still construct \\(K_{particle}\\) from \\(K_{wave}\\) by taking a tangent plane for each \\(k \\in K_{wave}\\), but now instead of the intersection of the half-planes, we use their envelope. A picture shows what we mean:\n\n\n\nA pair of polar duals. The surfaces are no longer convex. Notice how the double tangent on the left becomes a double crossing point on the right.\n\n\n\n\n\nThe curve on the right is a trefoil curve defined by \\(z = 0.3 e^{i\\phi} + e^{-2i \\phi}\\), shifted to make the image clearer. The curve on the left is the polar dual of the trefoil curve. It is the envelope of the polar dual lines of each point on the trefoil curve.\n\n\nWe still have a duality between points on the two surfaces, defined by stationarity, not optimality. For example, for any wavevector \\(k \\in K_{wave}\\), its corresponding dual point \\(v^*(k)\\) satisfies \\(\\left\\langle v^*(k) + \\delta v, k\\right\\rangle = 0\\) for any \\(\\delta v\\) in the tangent space of \\(K_{particle}\\) at \\(v^*(k)\\).\nThe first application of Hamiltonian mechanics was done by Hamilton, who predicted theoretically that if light enters a biaxial crystal in just the right way, it will not just refract in one direction, but in an entire cone of directions – which he termed internal conical refraction. The theory of this is rather fascinating, but we will only give the barest description.\nSimply put, it turns out that in a biaxial crystal, both \\(K_{particle}\\) and \\(K_{wave}\\) have the same shape of a large blob containing a smaller blob, touching each other at 4 cone-shaped points. Now, let \\(k_c \\in K_{wave}\\) be one of the cone-shaped points, then it corresponds to a tangent plane to \\(K_{particle}\\). Each tangent point \\(v \\in K_{particle}\\), conversely, corresponds to a tangent plane to \\(k_c\\).\nSince \\(k_c\\) is a conical point, however, there are a whole circle of tangent planes to \\(K_{wave}\\) at \\(k_c\\). Consequently, the tangent plane to \\(K_{particle}\\) is tangent to it on one entire circle. It is as if we throw a tire on the floor – it will touch the floor not just at three points, but an entire circle of points. Now, suppose that we have a planar wave moving in the direction of \\(k_c\\) inside the crystal, then each light-particle would have to move in a direction \\(\\mathop{\\mathrm{argmax}}_{v \\in K_{particle}}\\left\\langle v, k_c\\right\\rangle\\). But since there is an entire circle of such directions, we would have an entire circle of possible \\(v\\), and thus, we obtain a hollow cone of light.\n\n\n\nWhen a planar wave travels in a crystal, such that \\(K_{particle}\\) is tangent to the plane of the wave at an entire circle, then instead of choosing one among the entire circle of velocities, the particles simply take every single possible direction on the circle, resulting in conical refraction.\n\n\n\n\n\nThe shape of the \\(K_{wave}\\) surface. The \\(K_{particle}\\) surface is topologically the same, and can be obtained from \\(K_{wave}\\) by squashing it just right. Figure from (Schaefer 1949, 485, figure 128)"
  },
  {
    "objectID": "blog/posts/art/index.html#periodic-motion",
    "href": "blog/posts/art/index.html#periodic-motion",
    "title": "Analytical mechanics",
    "section": "Periodic motion",
    "text": "Periodic motion\n\nOscillator on a line\nConsider a simple harmonic oscillator (SHO), with Hamiltonian \\(H\\) in the \\((q, p)\\) coordinates:\n\\[H(t, q, p) = \\frac{p^2}{2m} + \\frac 12 kq^2\\]\nThe motion of the system is very simple: a circular motion around \\((q, p) = (0, 0)\\):\n\\[\\begin{cases}\n\\dot q = p/m \\\\\n\\dot p = - kq\n\\end{cases}\\quad  \n\\begin{cases}\n(q, p) = (q_0 \\cos(\\omega t), -m\\omega q_0 \\sin(\\omega t)) \\\\\n\\omega = \\sqrt{k/m}\n\\end{cases}\\]\nNow consider the action of an entire cycle:\n\\[S = \\oint Ldt = \\oint (pdq - Hdt)\\]\nThe \\(\\oint pdq\\) term is the area enclosed by the ellipse, so it is \\(\\pi p_0 q_0\\), and the \\(\\oint Hdt\\) term is just \\(HT = \\frac{2\\pi}{\\omega} \\frac 12 kq_0^2\\), since the system conserves energy. Now direct computation shows\n\\[\\oint pdq = HT\\]\nIn particular, since \\(T\\) does not depend on the energy of the oscillation, we can take derivative against energy, obtaining\n\\[\n\\frac{d}{dE}\\oint_{\\gamma_E} pdq = T\n\\]\nwhere \\(\\gamma_E\\) is the path traced out by the oscillator with energy \\(E\\). We show that this is generally true for 1D oscillators.\n\nTheorem 10 Given any 1D oscillator,\n\\[\n\\frac{d}{dE}\\oint_{\\gamma_E} pdq = T(E)\n\\]\nwhere \\(\\gamma_E\\) is the path traced out by the oscillator when it has energy \\(E\\), and \\(T(E)\\) is the period.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider the phase space plot of a generic 1D oscillator. Every point in its phase space must go in a cycle, returning to the start again. Thus, its phase space is like an ugly onion: It is split into cycles, which are not generally circular in shape, and generally each cycle has a different cycling period.\n\n\n\n\n\nTake a particular cycle as shown, starting and ending at \\(q_0 = q_1\\). Now consider this variation that fixes \\((t_0, q_0), (t_1, q_1)\\): move from point 0 to point 1, then go around the larger cycle to point 1, then return to point 0. The action of the varied cycle consists of three parts: \\(0\\to 1, 1 \\to 1, 1 \\to 0\\). By (modified) Hamilton’s principle, the variation of action is zero.\nNow, let \\(T(E) = t_1 - t_0\\) be the cycle period for the cycle with energy \\(E\\), then from our above argument, we have\n\\[\\oint_E pdq - E T(E) = \\oint_{E + \\delta E} pdq - (E + \\delta E) T(E) + O(\\delta E^2)\\]\nwhere the \\(O(\\delta E^2)\\) term deals with the \\(0\\to 1, 1\\to 0\\) parts of \\(\\int -Hdt\\). Thus we obtain\n\\[\\frac{d}{dE} \\oint_E pdq = T(E)\\]\n\n\n\n\n\n\n\n\n\nWorked example: pendulum in gravity\n\n\n\n\n\nThe 1D pendulum in gravity, with length \\(l\\) and mass \\(m\\), has Lagrangian \\(L = \\frac 12 m(l\\dot q)^2 + mgl\\cos q\\), momentum \\(p = ml^2 \\dot q\\), and Hamiltonian\n\\[H = \\frac{p^2}{2ml^2} - mgl \\cos(q)\\]\nWe know that the pendulum is not a SHO. Indeed, the cycle period \\(T(E)\\) strictly increases with energy \\(E\\) of the cycle, and it diverges as the pendulum swing approaches the highest point: \\(\\lim_{E \\to mgl} T(E) = +\\infty\\).\nConsider the cycle with maximum swing angle \\(\\theta\\). The cycle encloses an oval-shaped region in phase space, with equation \\(p^2 = 2m^2 gl^3(\\cos q - \\cos\\theta)\\). Consequently, we have the somewhat mysterious result:\n\\[\\int_0^{E(\\theta)} T(E) dE = 4\\sqrt{2m^2 gl^3} \\int_0^\\theta \\sqrt{\\cos q - \\cos\\theta} dq\\]\nwhere \\(E(\\theta) = -mgl \\cos\\theta\\) is the energy of the system when it has maximum swing angle \\(\\theta\\).\nWhen \\(\\theta\\) is small, the integral is approximately\n\\[\\int_0^\\theta \\sqrt{\\frac 12 (\\theta^2 - q^2)}dq = \\frac{\\pi\\theta^2}{4\\sqrt 2}\\]\nwhich does correspond to \\(T(E) \\approx 2\\pi\\sqrt{\\frac lg}\\), and \\(\\delta E = mgl(1 - \\cos(\\theta)) \\approx \\frac 12 mgl \\theta^2\\).\nWhen \\(\\theta = \\pi\\), the integral can be exactly evaluated:\n\\[\\int_0^{mgl} T(E) dE = 16\\sqrt{m^2 gl^3}\\]\nWe are unable to interpret this strange but satisfying equality.\nTaking \\(\\partial_\\theta\\) under the integral sign, we get\n\\[T(E) = \\sqrt{\\frac{8l}g} \\int_0^\\theta \\frac{dq}{\\sqrt{\\cos q - \\cos \\theta}}\\]\nwhich may be directly verified.\n\n\n\n\n\nAction-angle variables\nNow, it would be great if we could \"unwind\" the rotatory dynamics by a time-independent canonical transform to some \\((Q, P)\\), by where \\(P\\) is constant along the cycles, and \\(Q\\) is increasing. That is, we want \\(P\\) to be the analog of \"amplitude\", and \\(Q\\) to be the analog of \"phase angle\".\nSince the transform is time-independent and canonical, the Hamiltonian \\(H\\) is unmodified, so \\(H\\) is a function of \\(P\\) only, not \\(Q\\) (since \\(H\\) is a conserved quantity of motion). Then, since the transform is canonical, Hamilton’s equations of motion read \\(\\dot Q = \\partial_P H(P)\\). Consequently, the Hamiltonian equations of motion would become\n\\[\\begin{cases} P(t) = P(0) \\\\ Q(t) = Q(0) + H'(P) t \\end{cases}\\]\nas simple as it could be! It remains to find such a canonical transform.\nWe are already mostly there: we know that \\(P\\) is constant along the cycles, and \\(Q\\) increasing along the cycles. It remains to find the right scaling, so that the transform is canonical, that is, the coordinates preserve area: \\(dP \\wedge dQ = dp \\wedge dq\\).\nDefine \\(P = \\frac{1}{2\\pi} \\oint pdq\\). Here the \\(2\\pi\\) factor is not essential, since we could always do a point transform, scale down \\(Q\\) by \\(2\\pi\\), and scale up \\(P\\) by \\(2\\pi\\). However, the factor will make many formulas look cleaner.\nFrom the proof of Theorem 10, we know that increasing the energy of the cycle by \\(\\delta H\\) would increase the cycle area by \\(T(H)\\delta H\\), and the cycle area is \\(2\\pi P\\), thus\n\\[\\delta(2\\pi P) = T(H) \\delta H \\implies \\frac{2\\pi}{T(H)} = H'(P)\\]\nso we find that the equations of motion are:\n\\[\\begin{cases} P(t) = P(0) \\\\ Q(t) = Q(0) + 2\\pi \\frac{t}{T(H)} \\end{cases}\\]\nThis allows us to graphically construct the \\((Q, P)\\) coordinates on phase space:\n\nDraw the cycles in phase space.\nSelect a \"line of longitude\" arbitrarily as \\(Q = 0\\) line.\nFollow the trajectory of each point on the line of longitude, and mark down a new line of longitude at equal phases-angles. So for example, if you are on the cycle of energy \\(E\\), you would start the ride, and after \\(T(E)/3\\) has passed, note down its phase-angle as \\(2\\pi/3\\). The set of all such points at every cycle is the line of longitude with \\(Q = 2\\pi/3\\).\n\n\n\n\nConstructing a canonical coordinate system over the phase space of the 1D oscillator.\n\n\nNow, we can graphically see that this construction really preserves areas:\n\nTake an infinitesimal parallelogram at \\((Q, P)\\) with sides \\(\\delta Q, \\delta P\\), such that \\(\\delta Q = \\frac{2\\pi}{N}\\) for some infinite integer \\(N\\).\nEvolve the system in discrete steps of \\(\\frac{T(P)}{N}\\), and follow the parallelogram along.\nNote that the parallelogram would tile the thin ring between \\(P\\) and \\(P+ \\delta P\\). The thin ring has area \\(\\delta \\oint pdq = 2\\pi \\delta P\\), so each parallelogram has area \\(2\\pi \\delta P/N = \\delta P \\delta Q\\).\n\n\n\n\n\n\n\nWarning\n\n\n\nThis is not as trivial as it seems. The idea of “area” in phase space was defined by \\(\\oint pdq\\), so it is not obvious that \\(\\delta P \\delta Q\\) would be the area of the parallelogram, especially considering that the sides of a parallelogram might not even be perpendicular to each other!\n\n\nThe entire construction of \\((Q, P)\\) from \\((q, p)\\) is often done in one divinely-inspired move by a generating function.\n\n\nAdiabaticity\nThis section based on (Duncan and Janssen 2019, chap. 5; de Oliveira 2022).\nThe Lorentz pendulum is a famous example that connects the classical and the quantum world. In the early 1900s, as physicists were trying to explain various phenomena, such as the black body radiation spectrum, the atomic spectra, and such, they came to the quantum hypothesis. Consider a classical system undergoing periodic motion – such as the electrons cycling around a proton in the hydrogen atom. Whereas classically, its \\(\\oint pdq\\) may be of any value, the quantum hypothesis states that it can only take values in\n\\[\n\\oint pdq = nh, \\quad n = 1, 2, 3, \\dots\n\\]\nfor a certain constant of nature \\(h\\) – later given the name of Planck’s constant. For example, if we have a simple harmonic oscillator, then we have\n\\[\nE\\nu = n h\n\\]\nwhere \\(\\nu = 1/T\\) is the frequency of the oscillator.\nAt the 1911 Solvay Conference, where the great physicists grappled with the new quantum phenomena,18 Einstein gave a presentation on the quantum hypothesis. At the end of the presentation, Lorentz asked a question about the pendulum. The conversation went as follows:\n18 The entire conference is summarized in (Straumann 2011).\nMr. Lorentz recalls a conversation he had with Mr. Einstein some time ago, in which they discussed a simple pendulum that could be shortened by holding the string between two fingers and sliding them downwards. Suppose that initially, the pendulum has exactly one energy element corresponding to the frequency of its oscillations. It then seems that at the end of the experiment, its energy will be less than the element corresponding to the new frequency.\nMr. Einstein – If the length of the pendulum is changed infinitely slowly, the energy of the oscillation remains equal to \\(h\\nu\\), if it was initially equal to \\(h\\nu\\) ; it varies proportionally to the frequency. The same is true for a resistance-free oscillating electrical circuit, and also for free radiation.\nMr. Lorentz – This result is very curious and removes the difficulty. In general, the hypothesis of energy elements gives rise to interesting problems in all cases where one can change the frequency of vibrations at will.\n(Instituts Solvay et al. 1912, 450)\n\n\n\n\nThe adiabatic pendulum of Lorentz.\n\n\nWhy is this interesting? The quantum hypothesis states that for quantum oscillators, \\(E/\\nu = nh\\), where \\(n\\) can only take values in the natural numbers. The Lorentz pendulum seems to show that the quantity \\(E/\\nu\\) can change continuously. Thus, for example, we might start at a quantized value of \\(E/\\nu = 100h\\), and end up at \\(100.5h\\), invalidating the quantum hypothesis for macroscopic systems. And if macroscopic systems do not follow the quantum hypothesis, then as the macroscopic system becomes microscopic, it seems the quantum hypothesis would be invalidated as well.\nEinstein replied that \\(E/\\nu\\) of the oscillator is conserved if the length of the pendulum is changed infinitely slowly. Surprising, but it saves the quantum hypothesis.\n\nThe adiabatic theorem\nConsider a pendulum with a string length \\(\\lambda\\) that is slowly changed over time. How slow? Slow enough that the system completes many cycles before \\(\\lambda\\) makes any appreciable change. That is,\n\\[\\dot \\lambda \\ll \\frac{\\lambda}{T(\\lambda)}\\]\n\n\n\n\n\n\nparametric resonance\n\n\n\nIt is vitally important that the pulling on the pendulum is not only slow, but also “smeared”, meaning that \\(\\dot\\lambda\\) is equal over the entirety of a single oscillation. If it is not smeared, then we can break the theory. Consider for example a (spherical) child on a (frictionless) swing (in a vacuum). It is well-known that the child can, by swinging the legs in sync with the swing, get as high as possible. This is called parametric resonance.\nCompared to adiabatic change, parametric resonance differs in that it is discriminating about the states. When you adiabatically pull on the string of a pendulum, your rate of pulling is the same over the entire cycle of a pendulum swing. When you resonantly pull on the string of a pendulum, your rate of pulling differs over the cycle of a pendulum swing. In the language of thermodynamics, adiabaticity means treating all microstates equally, without discrimination.\n\n\nLet the angular frequency of oscillation be \\(\\omega = \\sqrt{\\frac g\\lambda}\\), then \\(E/\\omega\\) is constant over time.\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy basic physics, the force in the string is\n\\[\nF = mg \\cos \\theta + m\\dot \\theta^2 / \\lambda \\approx mg - \\underbrace{\\frac 12 mg \\theta^2}_{\\text{$V/\\lambda$}} + \\underbrace{m\\lambda \\dot\\theta^2}_{\\text{$2T/\\lambda$}}\n\\]\nBecause the system is undergoing simple harmonic oscillation, the time-average of \\(V\\) and \\(T\\) are both \\(\\frac 12 E\\), where \\(E\\) is the oscillation energy. Therefore, the time-average force is \\(\\bar F = mg + \\frac 12 E/\\lambda\\).\nThus, if we shorten the string by \\(\\delta \\lambda\\), we would inject an energy of \\(\\delta E = \\bar F (-\\delta\\lambda) -( mg\\delta\\lambda)\\) (we subtract away the gravitational energy at the lowest point, as it is irrelevant). This gives us\n\\[\n\\delta E + E \\delta\\lambda / 2\\lambda = 0 \\implies E\\lambda^{1/2} = Const\n\\]\nSince the angular frequency of oscillation is \\(\\omega = \\sqrt{\\frac g\\lambda}\\), we have the result.\n\n\n\n\nExercise 9 Perform the same analysis on a vibrating string. The string is fixed at both ends, and the length of the string is slowly changed. The string is in a standing wave pattern, and the length of the string is changed so slowly that the string completes many cycles before the length changes appreciably. What is the adiabatic invariant in this case? The answer is in (Rayleigh 1902).\n\n\n\n\n\n\n\nAdiabatic invariance to all orders\n\n\n\n\n\nThe adiabatic invariance is actually much stronger than what we have shown. It is not just that the enclosed action \\(I\\) is conserved up to \\(O(\\dot\\lambda)\\), but that it is conserved to all orders in \\(O(\\dot \\lambda^n)\\) (Lenard 1959). Under stronger restrictions, it is even conserved to order \\(O(e^{c/\\dot \\lambda})\\). See (Henrard 1993, sec. 4) for more theorems in this style.\n\n\n\nGeneralizing from this experience, for an arbitrary 1D oscillator with Hamiltonian \\(H(q, p; \\lambda)\\), the phase space trajectory is a closed wobbly cycle. As we vary \\(\\lambda\\) adiabatically by external force, the cycle changes shape, both because the system has received energy from the external force, and because the Hamiltonian of the system has changed. Nevertheless, the area enclosed within should remain constant.\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor a multidimensional oscillating system, we have three possibilities.\nIf the dimensions separate, like an \\(n\\)-dimensional oscillator \\(H = \\frac{p_1^2 + \\dots + p_n^2}{2m} + \\frac 12 k (q_1^2 + \\dots + q_n^2)\\). In this case, the adiabatic theorem still applies along each dimension, with one adiabatic invariant per dimension.\nIf all dimensions mix together, like a tank of hot entangled gas. In this case, the adiabatic theorem states that if we start with the microcanonical ensemble, then the phase space volume enclosed by the surface of \\(H = E\\) remains constant as we adiabatically vary \\(\\lambda\\). The volume is named the Gibbs invariant.(de Oliveira 2022)\nIf the dimensions neither separate nor mix together, but have some kind of complicated dynamics, then what adiabaticity means in that case is still a current area of research.\n\n\n\n\nConnection to thermodynamics\nA simpler example is when we put one ball moving in a piston. We hold one wall of the piston constant, and slowly move the other. The phase space diagram of the ball is then a rectangle. Let the ball have speed \\(v\\), and the walls of the piston have separation \\(L\\). The action enclosed by one cycle of the system is \\(I = 2mvL\\). If we slowly move the wall of the piston, then the action is conserved, giving us\n\\[\n2mv_0 L_0 = 2mvL \\implies v = \\frac{L_0}{L} v_0\n\\]\nWe can formulate this into the language of thermodynamics. First, expand our system to three dimensions – from a piston to a box. Since the motion of the ball in the \\(x, y, z\\) directions are independent, we can treat them separately. We also assume equipartition of energies, that is, the energy of the ball is equally distributed among the three dimensions, so \\(v_{x, 0} = v_{y, 0} = v_{z, 0}\\). The conservation of action then states that\n\\[\nv_i = \\frac{L_{i, 0}}{L_i} v_{i, 0} \\quad \\text{for } i = x, y, z\n\\]\nImagine the ball is a gas molecule, and the piston is a wall of a container. Let \\(E = \\sum_{i = x, y, z} \\frac 12 mv_i^2\\) be the energy of the gas molecule, and \\(V = \\prod_{i = x, y, z}L_i\\) be the volume of the gas. We then have\n\\[\nV = V_0 \\prod_i \\frac{L_i}{L_{i, 0}} \\approx V_0 \\left(1 + \\sum_i \\frac{\\delta L_{i}}{L_{i, 0}}\\right), \\quad\n\\begin{aligned}\nE &= \\frac 12 m \\sum_i \\left(\\frac{L_{i,0}}{L_i}\\right)^2 v_{i, 0}^2\\\\\n&= \\frac 32 m v_0^2 \\frac 13 \\sum_i \\left(\\frac{L_{i,0}}{L_i}\\right)^2 \\\\\n&\\approx E_0 \\left(1 - \\frac 23 \\sum_i \\frac{\\delta L_{i}}{L_{i, 0}}\\right)\n\\end{aligned}\n\\]\nThese imply that \\(E^{3/2}V \\approx E_0^{3/2}V_0\\). Now, this is precisely what happens if you compress an ideal gas adiabatically. This is one connection between the concept of “adiabatic” in classical mechanics and thermodynamics.\n\nExercise 10 Prove that \\(I\\) is conserved: calculate the average force \\(\\bar F\\) on the piston, then calculate the work done by the piston.\n\n\n\nMore examples\nGiven a Lorentz pendulum and a schedule for varying its arm length, we can plot the angle \\(x\\) as a function of time, and see directly that \\(I = T (\\frac 12 m \\dot x_{max}^2)\\) is conserved over many swings of the pendulum.\n\n\n\nA Lorentz pendulum with length increasing linearly with time. As its length increases, \\(\\dot x_{max}\\) decreases while \\(T\\) increases, keeping \\(I\\) conserved. Annotated from (Sánchez-Soto and Zoido 2013, fig. 1)\n\n\nFor a more rigorous proof of adiabatic invariance at the level of first-year graduate student, see (Wells and Siklos 2007). (Henrard 1993) is a good comprehensive review of adiabatic invariance in classical mechanics, and points to the literature on a lot of applications in celestial mechanics, magnetism, and the geometry of phase space plots. In textbooks on classical statistical mechanics, the adiabatic invariance theorem is used to derive many results. (Fernandez-Pineda, Diez de los Rios, and Mengual 1982) gives some worked-out examples, such as the ideal gas and the photon gas.\n\n\n\nOld quantum mechanics\n\nSommerfeld, in the new edition of his book [Atombau und Spektrallinien], has introduced the adiabatic hypothesis through a couple of very elegant changes and footnotes, in such a way that my participation in that can rather appear reduced to — a plagiarism. Lorentz and Einstein have founded the subject, I have given it a name and Burgers has put everything in order. I was first very, very depressed. I know that I have never discovered anything, and quite surely never will discover anything, that I can love so fervently as this line of thought which I found out with so large joy.\nEhrenfest’s letter to Bohr, 8 May 1922. Emphasis in original. Quoted in (Navarro and Pérez 2006)\n\n\nThe adiabatic hypothesis\nThere are two ways to interpret the word “adiabatic”. In thermodynamics, “adiabatic” means “no exchange of heat”. In mechanics, “adiabatic” means “gradual”.19 It is a winding story of how one word “adiabatic” came to mean two things that fortuitously are connected after all, the details of which are given in (Jammer 1966, chap. 3; Laidler 1994). The story is almost as interesting as that of the word “entropy”, which also has two meanings that are fortuitously connected after all.\n19 Because “adiabatic” has two meanings in English, in Chinese, it also has two different translations based on the two meanings. There is 绝热, which means “no exchange of heat”, and 浸渐, which means “gradually, like moisture soaking into something”.Rankine first coined the term “adiabatic” in 1858, to denote a process in which no heat is exchanged with the surroundings. Later, Boltzmann and Clausius tried to explain the second law of thermodynamics mechanically, by using purely mechanical models of the microscopic world. In this sense, they defined an “adiabatic” mechanical process to be one where a certain variable is slowly changed (for example, if we have a box of little bouncing balls, and we very slowly move its walls), because an adiabatic thermodynamic process in their view is actually an adiabatic mechanical process.\n“Adiabatic motion” in mechanics was introduced by Helmholtz and Hertz, to denote mechanical processes where external forces act upon a system, but only on a few parameters, with no action on the underlying details. For example, think back to the case of bouncing balls in a box. The external force only moves the walls of the box on average, with no attempt to move the walls to manipulate the precise location of the ball. They used the thermodynamic terminology, because the work done on the system during an adiabatic motion results exclusively in changes in its energy. (Jammer 1966, chap. 3)\nIn 1900, Pyotr Lebedev experimentally proved that radiation pressure exists, and follows Maxwell’s theory of electromagnetism. Inspired by this, Lord Rayleigh (Rayleigh 1902) generalized the concept of radiation pressure to all kinds of vibrations, starting with the humble pendulum. Since his goal was to understand what happens when you adiabatically compress a photon gas, that is, Wien’s displacement law,20 he studied the effect of adiabatic motion on some simple mechanical systems undergoing wave motion, such as the Lorentz pendulum, a vibrating cord, a piston of gas with a standing acoustic ave, etc.\n20 Since he didn’t actually know what a photon was, it might be better to say that he was studying what would happen when you compress a hot chamber of light. Though Wien’s displacement law is nowadays proved straight from quantum mechanics, back when ien discovered it in 1893, he used a thermodynamic argument using the adiabatic compression of a photon gas. For a brief presentation of how Rayleigh did it, see (Ter Haar 1966).Like Lord Kelvin, Paul Ehrenfest was also trying to explain Wien’s displacement law. He was puzzled by the fact that while Wien’s displacement law was derived without the quantum hypothesis, yet somehow, it remains true. Suppose we start with a box of light, then it follows a certain black body radiation, which can only be derived by the quantum hypothesis. Now suppose we adiabatically compress the box of light. Though the compression process is studied classically, without the quantum hypothesis, the final state of the light is still the black body radiation. So, it seems that if we start with a system following the quantum hypothesis, then any adiabatic classical process would give us a system that still follows the quantum hypothesis. This is his adiabatic hypothesis, for which he is famous.\nDuring the 1910s, Ehrenfest published a series of papers to subsume the many ad-hoc quantum rules under the framework of the adiabatic hypothesis. His idea is as follows: If, in a periodic system described by classical mechanics (such as an electron orbiting a proton), a certain quantity \\(I\\) has units of joule-second, and is conserved as it undergoes adiabatic motion, then this quantity should be quantized, and only this quantity can be quantized. Only \\(I\\) can be quantized, for the reason discussed by Lorentz and Einstein at the Solvay conference.\nFurther, \\(I\\) should be quantized, because otherwise, why else should \\(I\\) be adiabatically conserved? The adiabaticity of \\(I\\) in the classical world, on the surface, is a shadow of the discreteness of \\(I\\) in the quantum world, deep down. Because \\(I\\) is quantized, if we vary the system slowly enough, the system would have no reason to make a big jump from \\(I = nh\\) to \\(I = (n+1)h\\). This discretenesss in the quantum world traps \\(I\\) in its starting position, and this is why \\(I\\) appears adiabatic in the classical world.\nThus, quantized quantities are precisely adiabatic invariants. We can write down \\(I = nh\\), where \\(n \\in \\mathbb{N}\\), and proceed to calculate the properties of the system, such as its energy levels, its absorption and emission spectra, etc.\nIn short, this is Ehrenfest’s recipe for doing “old quantum mechanics”:\n\nFind a system that has a conserved quantity \\(I\\) under adiabatic motion.\n\nYou can do this by solving the equations of motion, then integrate \\(\\oint pdq\\).\nAlternatively, you can start with a harmonic oscillator, and adiabatically deform the system until it becomes the system you want. Ehrenfest called such systems “adiabatically related to the harmonic oscillator” (Jammer 1966, 99).\n\nProclaim that \\(I = nh\\) for some constant \\(h\\).\nCalculate the properties of the system.\n\n\n\nThe Bohr–Sommerfeld model\nAs an example, consider the pinnacle of old quantum theory, the Bohr–Sommerfeld model of the hydrogen atom. First, treat the hydrogen atom as if it is a relativisitic solar system, with the electron as a planet, moving at relativistic speeds21 under the inverse-square force \\(F \\propto \\frac{1}{r^2}\\). Next, assume that the adiabatic invariant is quantized:\n21 Because the electron moves faster closer to the atom than further away, it has more mass close to the atom than further away. This allows the orbit to precess in a way that is not predicted by Newtonian mechanics. Generally, any perturbation of the inverse-square force will cause the orbit to precess. Even special relativity would predict some precession for the perihelion of Mercury, though it predicts a value of \\(7''/\\text{year}\\) only \\(1/6\\) of the correct value (McDonald 2023; Goldstein, Poole, and Safko 2008, exercise 7.27, page 332). Only general relativity predicts the correct value. Assuming that only special relativity contributes, the perihelion of Mercury would take \\(7.5e7\\) Mercury-years to go around the sun once.\nAs the electron moves a lot faster than Mercury, it takes much shorter time, but still it takes \\(4e4\\) electron-years to go around the nucleus once, as noted in Bohr’s Nobel lecture (Bohr 1923).\\[\\int_0^T p_r \\,dq_r = n' h\\]\nwhere \\(q_r\\) is the radial position of the electron, \\(p_r\\) is the momentum conjugate to it, \\(n'\\) is the “auxiliary quantum number”, and \\(T\\) is the period of the electron’s orbit. This, when combined with the hypothesis of quantized angular momentum \\(mvr = nh\\) (here, \\(n\\) is the “principal quantum number”), would predict the emission spectrum of the hydrogen atom.22\n22 Because the equation of motion for the electron separates into a radial component \\(q_r, p_r\\) and an angular component \\(q_\\theta, p_\\theta\\), we can apply the multidimensional adiabatic theorem and find that both \\(\\int_0^T p_r \\,dq_r\\) and \\(\\int_0^T p_\\theta \\,dq_\\theta\\) are adiabatic invariants.Sommerfeld went further, piling epicycles upon epicycles, to explain the fine structure of atomic spectra. All those has been swept away by the new quantum theory like how the new astronomy of Kepler swept away the epicycles of Ptolemy. But the adiabatic hypothesis remains to this day a fruitful meeting point between the classical, the quantum, and the thermodynamic world.\nHave some cool pictures, because I like cool pictures.\n\n\n\n\n\nSelections from (Sommerfeld 1923).\n\n\n\n\n\n\n\nQuantization of the adiabatic invariant. Page 197.\n\n\n\n\n\n\n\n\n\nThis looks familiar… it looks just like the phase space plot of a ball bouncing in a piston. Page 199.\n\n\n\n\n\n\n\n\n\nOrbits of the hydrogen atom with the same principal quantum number \\(n\\), but different auxiliary quantum number \\(n'\\). Page 240.\n\n\n\n\n\n\n\n\n\n5 electrons with the same principal and auxiliary quantum numbers, interacting by the pentagonal dance. Page 502.\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nSelections from (Kramers 1923).\n\n\n\n\n\n\n\nOrbits of the Bohr–Sommerfeld model of the hydrogen atom, labelled by their principal quantum numbers and auxiliary quantum numbers. The jumps from 31, 32, 33 to 22 all create the Balmer spectral line Hα, but they differ at the fine structure. Figure 27.\n\n\n\n\n\n\n\n\n\nOrbits of the Bohr–Sommerfeld model of the Radium atom. First end plate. I find its fonts very classy.\n\n\n\n\n\n\n\n\n\nA modern redrawing. (Holtebekk and Linder 2023)\n\n\n\n\n\n\nFigure 2\n\n\n\n\nWhat we are nowadays hearing of the language of spectra is a true “ music of the spheres ” within the atom, chords of integral relationships, an order and harmony that becomes ever more perfect in spite of the manifold variety. The theory of spectral lines will bear the name of Bohr for all time. But yet another name will be permanently associated with it, that of Planck. All integral laws of spectral lines and of atomic theory spring originally from the quantum theory. It is the mysterious organon on which Nature plays her music of the spectra, and according to the rhythm of which she regulates the structure of the atoms and nuclei.\nPreface to the first edition of Atomic structure and spectral lines, Arnold Sommerfeld, 1919. (Sommerfeld 1923)\n\n\n\nThe Einstein—Brillouin–Keller quantization\nThis topic is quite obscure and hard to find a simple reference on, yet I found that it is absolutely necessary to treat this correctly, if only to soothe my mathematical conscience. I wrote it based on (Stone 2005; Duncan and Janssen 2019, chap. 5).\nLet’s take a more careful look at the Bohr–Sommerfeld model of a hydrogen atom. The electron orbits a proton, and the equation of motion is spherically symmetric. Therefore, we can write it in spherical coordinates \\((r, \\theta, \\psi)\\), where \\(r\\) is the radius, \\(\\theta\\) is the co-latitude, and \\(\\psi\\) is the longitude. The Bohr–Sommerfeld quantization then states that\n\\[\n\\begin{aligned}\n& \\oint p_r d r = n_r h \\\\\n& \\oint p_{\\theta} d \\theta=n_\\theta h, \\\\\n& \\oint p_\\psi d \\psi=n_\\psi h .\n\\end{aligned}\n\\]\nfor some positive integers \\(n_r, n_\\theta, n_\\psi\\). However, we notice something deeply unsatisfying: How does the atom “know” which way is the sphere pointing? To define the spherical coordinates, we need to define the direction of the north and south pole. The Bohr–Sommerfeld quantization condition is thus creating an artificial direction in space where none should exist. Worse, if we solve the equations, we would find that this artificial direction has physically measurable consequences.\nSommerfeld evaded the difficulty by arguing that there never is a zero field anywhere in space. As long as there is the weakest magnetic field \\(B\\) pointing in some direction \\(\\hat z\\), that direction can be picked to be the north pole direction.\nWe see the difficulty inherent in old quantum theory. Suppose we have a hydrogen atom suspended in free space, then the tiniest change in the external magnetic field would create a large (for the atom, at least) change in its north-pole direction. The Stern–Gerlach experiment, performed in 1922, experimentally showed that the external field can determine the direction of \\(\\hat z\\), and thus the quantization of angular momentum. To see something in classical mechanics so jumpy is disconcerting, and certainly disturbed me greatly when I first understood the Stern–Gerlach experiment. In 4 years, Schrödinger would have proposed his equation, Heisenberg his matrix mechanics, and old quantum theory washed away by the new quantum mechanics.\nEinstein, in his only paper on the old quantum mechanics,23 elegantly resolved the problem by using the Poincaré–Cartan integral invariant to construct quantization equations that do not depend on our arbitrary choices of coordinate systems.\n23 (Einstein 1917), reprinted and translated in (Einstein 1997, vol. 6, pages 434–444).24 In the jargon of topology, this is a linear function on \\(T^d\\), the homology group of the torus. Here, \\(d\\) is the dimension of the torus.As we saw with Exercise 2, a contractable loop on the torus integrates to zero. Thus, we can attach and detach contractible loops at will, deform the cycle arbitrarily, and still get the same number. That is, the integral is determined by the topology of the cycle, not the exact shape of the cycle.24 This gives us the Einstein quantization:\n\\[\n\\oint_{\\gamma_i} \\left\\langle p, dq\\right\\rangle = n_i h\n\\]\nwhere \\(\\gamma_1, \\dots, \\gamma_d\\) range over the \\(d\\) topologically distinct loops around the \\(n\\)-dimensional torus in phase space, and \\(n_1, \\dots, n_d\\) are positive integers. This was later modified by Brillouin and Keller to take account of singularities in the trajectory, such as a hard wall reflector, giving us the EBK quantization.\n\n\n\nA particle moving in a central potential. Its angular momentum \\(p_\\theta\\) is conserved, so we do not plot it. Plotting its other three phase-space variables \\((r, \\theta, p_r)\\), we see that its orbit makes a spiralling and rotating pattern on a torus. There are two fundamental ways to cycle around the torus, and each has a corresponding Poincaré–Cartan integral that is independent of the precise shape of the cycle. The two integrals are quantized according to the EBK quantization.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe EBK quantization resembles the Bohr–Sommerfeld quantization condition, but it is quite different. In the Bohr–Sommerfeld quantization condition, the integral \\(\\oint p_i dq_i\\) integrates over a cycle of physically real trajectory in phase space. In EBK quantization, the integral \\(\\oint_{\\gamma_i} \\left\\langle p, dq\\right\\rangle\\) integrates over a geometric cycle in phase space with no physical reality at all.\nBoth conditions happen to be the same when we have a 1D oscillator, but that is because the only way to physically go around the torus is the only way to geometrically go around the torus. It is a misleading coincidence.\nIn general, the physically real trajectories look like a braiding on the torus, and are not even closed cycles. They definitely do not go around the torus exactly once in exactly one direction.\n\n\nThere is only one problem left: What happens when we don’t have a torus? It is all well and good when we can construct a torus in phase space with as many dimensions as possible. However, when we have a classically chaotic system, such as the three body problem, we cannot have something this simple.\nConsider the simplest case of three body problem: We put two suns in a circular orbit around each other, and a speck of dust orbiting them. The two suns’ orbit is perfectly predictable, so we consider only the trajectory of the dust. We also assume the dust only moves in the plane of the suns. Thus, the system has only 2 dimensions of configuration, or 4 dimensions of phase.\nAs the energy of the system is conserved, the motion of the dust is restricted to the constant energy surface \\(H(q_1, q_2, p_1 p_2) = E\\), which is a 3-dimensional blob within the 4-dimensional phase space. However, in general, this is all we can say about it. The motion of the dust is chaotic, and would densely criss-cross over a 3-dimensional subset of the blob.\nWithout a torus in phase space, we cannot find trajectories around the torus, and so the integral \\(\\oint_{\\gamma}\\lra{p, dq\\) is undefined. Einstein presciently pointed this out in his 1916 paper:\n\nIf there exist fewer than \\(d\\) [constants of motion], as is the case, for example, according to Poincaré in the three-body problem, then the \\(p_i\\) are not expressible by the \\(q_i\\) and the quantum condition of Sommerfeld-Epstein fails also in the slightly generalized form that has been given here.\n\nThis failure of the EBK quantization on classically chaotic systems was forgotten for many years, but eventually rediscovered (Stone 2005). When it did, it became a seed of quantum chaos, which I hope to explain clearly some day. In the mean time, I leave you with a beautiful picture of quantum chaos instead:\n\n\n\nThe nonchaotic quantum circular billiard and the chaotic quantum cardioid billiard. Figure from (Backer 2007)\n\n\n\n\n\nIn a chaotic quantum “stadium” billiard, the standing wave functions look dark along certain lines. You can think of them as taking a classical billiard table, and using a knife to cut along the classical trajectories. The scars left behind are the quantum scars of departed classicality. Figure from (King 2014)"
  },
  {
    "objectID": "blog/posts/art/index.html#selection-from-kramersatombohrtheory1923.",
    "href": "blog/posts/art/index.html#selection-from-kramersatombohrtheory1923.",
    "title": "Analytical mechanics",
    "section": "Selection from (Kramers 1923).",
    "text": "Selection from (Kramers 1923).\n\n\n\nOrbits of the Bohr–Sommerfeld model of the hydrogen atom, labelled by their principal quantum numbers and auxiliary quantum numbers. The jumps from 31, 32, 33 to 22 all create the Balmer spectral line Hα, but they differ at the fine structure. Figure 27."
  },
  {
    "objectID": "blog/posts/art/index.html#selections-from-sommerfeldatomicstructurespectral1923.",
    "href": "blog/posts/art/index.html#selections-from-sommerfeldatomicstructurespectral1923.",
    "title": "Analytical mechanics",
    "section": "Selections from (Sommerfeld 1923).",
    "text": "Selections from (Sommerfeld 1923).\n\n\n\nThis looks familiar… it looks just like the phase space plot of a ball bouncing in a piston. Page 197."
  },
  {
    "objectID": "blog/posts/art/index.html#solving-for-the-action-and-the-wavelet",
    "href": "blog/posts/art/index.html#solving-for-the-action-and-the-wavelet",
    "title": "Analytical mechanics",
    "section": "Solving for the Action and the Wavelet",
    "text": "Solving for the Action and the Wavelet\nWe consider the classical problem of a body in free fall, thrown from the origin \\((t, q) = (0, 0)\\). Basic physics tells us that the position and velocity of the body are given by\n\\[q(t) = v_0 t - \\frac{1}{2}gt^2\\]\n\\[v = v_0 - gt = \\frac{q}{t} - \\frac{1}{2}gt\\]\nPlugging these expressions into the Hamilton-Jacobi equation, we obtain a system of partial differential equations for the action function \\(S\\):\n\\[\n\\begin{cases}\n\\partial_t S &= -H = -\\frac{1}{2}m(\\frac{q}{t} - \\frac{gt}{2})^2 - mgq \\\\\n\\partial_q S &= m(\\frac{q}{t} - gt)\n\\end{cases}\n\\]\nSolving this system, we find the unique solution for the action:\n\\[S = \\frac{x^2}{y} - xy - \\frac{y^3}{12}\\]\nwhere we have introduced convenience variables \\(x = gq\\), \\(y = gt\\), and \\(s = \\frac{2gS}{m}\\).\nThe contour lines of the action function satisfy the equation:\n\\[\nx = \\frac{1}{2}y^2 \\pm \\sqrt{\\frac{1}{3}y^4 + sy}\n\\]\nTo analyze the wavelet associated with this system, we start by writing down the Lagrangian:\n\\[L = T - V = \\frac{1}{2}m(\\frac{\\delta q}{\\delta t})^2 - mgq\\]\nThe wavelet equation is then given by:\n\\[\\delta S = L \\delta t = \\left(\\frac{1}{2}m(\\frac{\\delta q}{\\delta t})^2 - mgq\\right)\\delta t\\]\nSimplifying this equation using our convenience variables, we get:\n\\[(\\delta x)^2 = 2x(\\delta y)^2 + \\delta s \\delta y\\]\nSolving for \\(\\delta y\\), we obtain:\n\\[\\delta y = \\frac{-\\delta s \\pm \\sqrt{(\\delta s)^2 + 8x(\\delta x)^2}}{4x}\\]\nThis equation reveals the nature of the wavelet. When \\(x &gt; 0\\), the equation describes a hyperbola, indicating a diverging wavefront. For \\(x &lt; 0\\), it represents an ellipse, suggesting a converging wavefront. At the boundary \\(x = 0\\), the equation describes a parabola.\n\n\nDeriving the time-independent Schrödinger equation\nAssume that the potential is time-independent: \\(V(t, q) = V(q)\\). Assume that the physical system can be described by a function\n\\[\n\\Psi(t, q) = \\Psi_0(r) e^{iS(t, q)/\\hbar}\n\\]\nwhere the function \\(\\Psi\\) is typcially called the “wave function”.13\n13 What is a wave function? It is just some abstract mathematical object, that somehow allows us to calculate everything we want to know about this system. We have no idea what it is, but it works. The same applies to the function \\(S(t, q)\\). We call it the “minimal cost” for arriving at \\((t, q)\\), but what really is a cost in physics? Particles do not really pay their paths with natural money. All this time, we have pretended that they pay some kind of cost and want to minimize the cost, but it is really just one big analogy. The same applies for the function \\(\\Psi\\). We might call it a “wave function”, but it really is just one big analogy with the waves on an ocean. There is really no wave in quantum mechanics, only a function that we pretend is a wave, because it helps us calculate results that happen to be correct.Now, the Schrödinger equation for the same situation is\n\\[i \\hbar \\frac{\\partial \\psi}{\\partial t}=-\\frac{\\hbar^2}{2 m} \\nabla_q^2\\psi+V(t, q) \\psi\\]\nTypically, solutions to the Schrödinger equation have the form of \\(\\psi(q) = \\exp(iS(t, q) / \\hbar)\\), where \\(S(t, q)\\) is the \"phase\" of the particle at \\((t, q)\\). Plugging it in, and hoping that it would work out, we get\n\\[\\partial_t S + \\frac 1{2m} \\|\\nabla_q S\\|^2 = -V(t, q) + \\frac{i\\hbar}{2m} \\nabla_q^2 S\\]\nwhich is the same except a \"quantum correction term\" proportional to \\(\\hbar\\). This is one way to interpret \"classical mechanics is quantum mechanics at the \\(\\hbar \\to 0\\) limit\".\n\n\nA sketch of the path to Schrödinger’s equation\nHowever, the analogy between classical mechanics and quantum mechanics is not exact. The simple problem is that classical mechanics, even when formulated in the form of Hamilton–Jacobi wave equations, cannot reproduce interference or diffractions. Consider the simple case of a straight-edge diffraction. If you aim a light beam at a sharp edge, then on the other side, there would be alternating bright and dark bands fading into the shadow. However, if light is going by the shortest path, then there should be no such banding, and the brightness should just drop off to zero monotonically.\nThe solution is to admit that geometric optics is insufficient, that Huygens’ principle is insufficient, and we need a full theory of light wave in order to explain what happens on the very smallest scales – a diffraction theory. Similarly, classical mechanics is insufficient, and the HJE is insufficient, and we need a full theory of matter wave in order to explain what happens in the atomic world – quantum mechanics.\n\n\n\nThe optical-mechanical analogy at three levels.\n\n\nDeriving quantum mechanics from classical mechanics is necessarily fraught with danger and luck, because in going from quantum mechanics to classical mechanics, something is irrevocably lost (and other things are irrevocably earned). It is about as difficult as going from geometric optics to wave optics. Still, several people have tried and succeeded, especially Schrödinger.\n\n… the conception of rays is thoroughly well defined only in pure abstract geometrical optics. It is wholly incapable of being app1ied to the fine structure of real optical phenomena, i.e. to the phenomena of diffraction. Even in extending geometrical optics some what by adding the notion of Huygens’ principle one is not able to account for the most simple phenomena of diffraction without adding some further very strange rules concerning the circumstances under which Huygens’ envelope-surface is or is not physically significant. (I mean the construction of “Fresnel’s zones”.) These rules would be wholly incomprehensible to one versed in geometrical optics alone. Furthermore it may be observed that the notions which are fundamental to real physical optics, i.e. the wave-function itself (\\(W\\) is merely the phase), the equation of wave-propagation, the wave length and frequency of the waves, do not enter at all into the above stated analogy.\n(Schrödinger 1926)\n\n\n… to establish a correspondence between waves and corpuscles such that the laws of mechanics correspond to the laws of geometrical optics. In the wave theory, however, as you will know, geometrical optics is only an approximation: this approximation has its limits of validity and particularly when interference and diffraction phenomena are involved, it is quite inadequate. This prompted the thought that classical mechanics is also only an approximation relative to a vaster wave mechanics. … A new mechanics must be developed which is to classical mechanics what wave optics is to geometrical optics. This new mechanics has since been developed, thanks mainly to the fine work done by Schrödinger.\nLouis de Broglie’s Nobel Prize Lecture, 1929 (De Broglie 1929)\n\nInstead of fully deriving Schrödinger’s equation from the HJE, which involves some stupid tricks, let’s instead show how the HJE is a limit of Schrödinger’s equation, which involves no stupid tricks whatsoever.\n\n\nRelativistic particle in free space\nSince the HJE is fully general for any function \\(L(t, q, v)\\) that is smooth and strictly convex in \\(v\\), we can simply write down the Lagrangian for relativistic particle in a field, and it would just work.\nLet’s first consider particle in free space. In relativity, the one thing that is coordinate-independent is the proper time of a trajectory, so it is reasonable to guess that the action is the proper time, then deduce from it the Lagrangian. This is natural if we think of \\(S\\) as the optimal cost of traveling.\nLet \\(t_0 = 0, q_0 = 0\\), then by basic relativity, the proper time for the particle to arrive at \\((t, q)\\) is\n\\[S(t, q) = \\frac{\\|q\\|}{v\\gamma} = \\sqrt{t^2- \\frac{\\|q\\|^2}{c^2}}\\]\nwhere \\(\\gamma = \\frac{1}{\\sqrt{1-v^2/c^2}}\\) is the well-known factor used everywhere in special relativity.\nTaking \\(\\nabla_q\\), and simplifying, we find the relativistic momentum to be...\n\\[p = \\nabla_q S = -\\frac{\\gamma v}{c^2}\\]\nHowever, we were expecting \\(p \\to mv\\) when \\(v \\to 0\\), so we fix this issue by multiplying the action with a constant factor \\(-mc^2\\). Multiplying a constant factor in action has no effect on the calculus of variations, so we are free to do this. Thus we find that the action of a path is the proper time of the path multiplied by \\(-mc^2\\):\n\\[S(\\text{path}) = -mc^2 \\int_{\\text{path}}d\\tau = -mc^2 \\int_{\\text{path}}\\frac 1\\gamma dt\\]\nWith this, we can derive the familiar equations by the HJE and convex duality:\n\\[\\begin{cases}\nL(q, v) = -\\frac{mc^2}{\\gamma}\\\\     \nH(q, p) = \\sqrt{(\\|p\\|c)^2 + (mc^2)^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\gamma mv \\\\     \nv^\\ast = \\frac{pc}{\\sqrt{\\|p\\|^2 + (mc)^2}}\n\\end{cases}\\]\nIn particular, at low \\(v\\), we have \\(L \\approx -mc^2 + \\frac 12 m\\|v\\|^2\\). So somehow, by combining the geometry of spacetime with analytical mechanics, we have discovered the \\(E = mc^2\\) formula, even though there seems like something we couldn’t have discovered from mere geometry.\nThe HJE then becomes\n\\[\\frac 1{c^2} \\left(\\partial_t S \\right)^2 - \\|\\nabla S \\|^2 = m^2 c^2\\]\nIn particular, the time-independent solutions are of the form\n\\[S = W(q)-Et, \\quad \\| \\nabla W \\| = \\frac 1c \\sqrt{E^2 - m^2 c^4 }\\]\nfor any \\(E &gt; mc^2\\). In particular, if we plug in the usual relativistic energy \\(E = \\gamma mc^2\\), we get\n\\[\\| \\nabla W \\| = \\gamma mv\\]\nwhich is similar to what we obtained for the free particle in classical mechanics, with \\(\\|\\nabla W \\| = \\sqrt{2mE}\\), just with classical momentum upgraded to relativistic momentum.\nJust as how the HJE of a classical particle can be derived as the \\(\\hbar \\to 0\\) limit of the Schrödinger equation, one can derive the HJE of the non-quantum relativistic particle as the \\(\\hbar \\to 0\\) limit limit of the Klein–Gordon equation. The Klein–Gordon equation is essentially the simplest possible way to combine special relativity with Schrödinger equation:\n\\[\\left( \\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2} - \\nabla^2 + \\frac{m^2 c^2}{\\hbar^2} \\right) \\psi(t, \\mathbf{x}) = 0\\]\nAgain, plugging in \\(\\psi = e^{iS(t, q)/\\hbar}\\), we find with great satisfaction\n\\[\\frac 1{c^2} \\left(\\partial_t S \\right)^2 - \\|\\nabla S \\|^2 = m^2 c^2 + \\frac{i\\hbar}{c^2}(\\partial_t^2 S - \\nabla^2 S)\\]\nThe derivation in this section is similar to how Schrödinger derived his formula. Roughly speaking, he derived it by thinking that if electrons behave as waves, as de Broglie said, then they must obey some sort of wave equation. Then, he recalled that the Hamilton–Jacobi equations describes motion of particles by a wave equation, and he followed the analogy along, until he arrived at his equation (Derbes 1996; Hamill 2013, sec. 6.4).\n\n\nGeometric optics\nWe are going back to the roots, as geometric optics was what inspired Hamilton to develop his theory of Hamiltonian mechanics.\nWhen Hamilton developed his Hamiltonian approach, it was to study geometric optics, which can be derived from Fermat’s principle: light paths have stationary travel time. In other words, the action of a path is\n\\[S(\\text{path}) = \\int_{\\text{path}} dt\\]\nThus, \\(L = 1\\)...? Well, here we see the problem: in geometric optics, if you fix the starting and ending point as \\((t_0, q_0), (t, q)\\), then any path between them takes exactly \\(t-t_0\\) time, and there is nothing to vary. Consequently, we need to remove time from consideration, so that there is something to vary.\nFermat’s principle, reformulated, states light paths have stationary optical length. Let the medium be isotropic (light speed does not depend on direction), then we have\n\\[S(\\text{path}) = \\int_{\\text{path}} n(q) \\|dq\\|\\]\nwhere \\(n\\) is the refractive index. with \\(L(q) = n(q)\\). Here we encounter a brief difficulty: time flows in one direction only, but space flows in infinitely many possible directions!\nThe solution might seem like a joke, but it would work out well: select one direction14, say \\(q_0\\), and pretend that it is time. With this trick, all previous mathematical formalism immediately applies, and we have\n14 This direction is usually selected to be the direction of the principal optic axis. For example, the long-axis of a camera is a principal optic axis, and so is the barrel-axis of a telescope.\\[S(\\text{path}) = \\int_{\\text{path}} n(q_0, q_1, q_2) \\sqrt{1 + \\left(\\frac{dq_1}{dq_0}\\right)^2 + \\left(\\frac{dq_2}{dq_0}\\right)^2}dq_0\\]\n\nDerivation\nLet’s make the notation cleaner, by rewriting \\(q_0\\) as \\(t\\), \\((q_1, q_2)\\) as \\(q\\), and using \\(v\\) to mean \\(\\left(\\frac{dq_1}{dq_0}, \\frac{dq_2}{dq_0}\\right)\\). Then we have\n\\[L(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\]\nRoutine calculation yields\n\\[\\begin{cases}     \nL(t, q, v) = n(t, q) \\sqrt{1 + \\|v\\|^2}\\\\     \nH(t, q, p) = -\\sqrt{n^2 - \\|p\\|^2}\n\\end{cases} \\quad\n\\begin{cases}     \np^\\ast = \\frac{nv}{\\sqrt{1 + \\|v\\|^2}} \\\\     \nv^\\ast = \\frac{p}{\\sqrt{n^2 - \\|p\\|^2}}\n\\end{cases}\\]\nwe continue with the HJE, which simplifies to:\n\\[(\\partial_t S)^2 + \\|\\nabla_q S\\|^2 = n^2\\]\nReverting notation back to \\((q_0, q_1, q_2)\\), we find the eikonal equation:\n\\[\\|\\nabla_q S\\| = n(q)\\]\nWhy did the trick work? Well, if we look back to how we derived the Hamiltonian, we could see that what we called \"time\" is really just a special copy of \\(\\mathbb{R}\\), along which we organized all other state and control variables. We don’t really need time to be anything more than the domain of functions, as in \\(q_i: \\mathbb{R}\\to \\mathbb{R}\\) and \\(v_i : \\mathbb{R}\\to \\mathbb{R}\\). It most definitely does not need to \"flow\", or flow only from the past to the future, or have any psychological significance.\n\n\nInterpretation\nStarting with Fermat’s principle for light rays, we ended up with the eikonal equation for light waves. In general, we find the following duality between wave-field optics and particle-path optics.\n\nThe particle-wave duality.\n\n\n\n\n\n\n\nperspective\nparticle-path\nwave-field\n\n\n\n\naction \\(S\\)\na function of particle path\na field on configuration-spacetime\n\n\nequation\n\\(\\|\\nabla_q S\\| = n(q)\\)\n\\(\\partial_t S + H(t, q, \\nabla_q S) = 0\\)\n\n\nin optics\nlight rays, Fermat’s principle\nlight waves, Huygens principle\n\n\nin mechanics\npoint particles\nmatter waves\n\n\n\n\n\n\nAnisotropic optics\nWhen the travel cost of light can depend on the direction of travel, we say that the medium is anisotropic. Now, you might expect\n\\[\nS = \\int n(\\hat{\\delta q}) \\delta q\n\\]\nbut this is incorrect, not because there is anything necessarily wrong with the formalism, but because of how \\(n\\) is defined by convention in anisotropic material. At this point, we must study the full particle-wave duality again.\nFor a moment, let’s pretend light is really a particle, and consider how it might appear to someone who believes light is a wave. We arrange an entire plane of photons, such that the plane is perpendicular to a unit vector \\(\\hat k\\). Now, let them move optimally for time \\(\\delta\\). Each of them would go in the same optimal direction \\(v^*(\\hat k)\\), to push the wavefront as far-out as possible. Now, the wavefront does not move in the direction \\(v^*\\), but in the direction \\(\\hat k\\). Therefore, the wavefront moves at group velocity \\(v_g(\\hat k) = \\left\\langle v^*(\\hat k), \\hat k\\right\\rangle \\hat k\\).\nSince the photons are trying to push as far out as possible,\n\\[v^*(\\hat k) = \\mathop{\\mathrm{argmax}}_{v \\in K_{particle}} \\left\\langle\\hat k, v\\right\\rangle\\]\nwhere we write \\(K_{particle}\\) as the surface of all particle velocities in all directions. It is a sphere of radius \\(c\\) in a vacuum, but in an anisotropic medium, we allow it to be any crazy shape.\n\nNow, instead of studying the group velocity, we actually need to use its inverse – the wavevector \\(k = \\frac{\\hat k}{v_g}\\).15 We thus have\n15 The typical definition is \\(k_{usual} = \\frac{2\\pi}{\\lambda}\\hat k = \\nabla \\phi\\), where \\(\\phi\\) is the phase of the light, and \\(f\\) is its temporal frequency. Our definition, which makes it cleaner, but somewhat different from typical definition, is \\(k_{ours} = \\frac{\\nabla \\phi}{2\\pi f} = \\frac{\\nabla \\phi}{\\omega}\\).\\[k = \\frac{\\hat k}{\\max_{v \\in K_{particle} \\left\\langle v, \\hat k\\right\\rangle}}\\]\nThe reason we use this instead of the group velocity is that, a little simplification later, we have the beautifully simple relation\n\\[\n\\forall k \\in K_{wave}, \\quad \\max_{v \\in K_{particle}}\\left\\langle v, k\\right\\rangle = 1\n\\]\nThis is a very suggestive symmetry, which practically demands us to write it as a duality:\n\\[\n\\begin{cases}\nv^*(k) = \\mathop{\\mathrm{argmax}}_{v \\in K_{particle}}\\left\\langle v, k\\right\\rangle \\\\\nk^*(v) = \\mathop{\\mathrm{argmax}}_{k \\in K_{wave}}\\left\\langle v, k\\right\\rangle\n\\end{cases}, \\quad\n\\begin{cases}\n\\left\\langle v^*(k), k\\right\\rangle = 1\\\\\n\\left\\langle v, k^*(v)\\right\\rangle = 1\\\\\n\\end{cases}\n\\]\nThis is the polar dual construction, often used in convex analysis.16 (Hiriart-Urruty and Lemaréchal 2001, sec. C.3).\n16 What, just because we have not mentioned Legendre transform for a few pages, you would think that we’re done with convex analysis? Too bad! If nature is the great optimizer, then convex analysis is inescapable at every turn.The best case is if \\(K_{particle}\\) is convex. In this case, each \\(k \\in K_{wave}\\) defines a plane perpendicular to it, at a distance \\(\\|k\\|^{=1}\\) from the origin, and the plane is tangent to \\(K_{particle}\\) at precisely \\(v^*(k)\\), and conversely so. In other words, \\(K_{particle}\\) is the envelope of polar lines to points in \\(K_{wave}\\), and conversely so.\nConversely, we can pretend that light is really a wave, and consider how it might appear to someone who believes light is a particle. We would then go through the above argument, and obtain the same result.\nHowever, we want to deal with more general cases than this, so we need to resolve two issues.\nFirst issue: \\(K_{particle}\\) might be non-convex. Second issue: it might be double-sheeted, or even many-sheeted. For example, in crystal, light polarized in two different orientations can move at two different velocities even in the same direction. Thus, its \\(K_{wave}\\) has two sheets, and so its polar dual, \\(K_{particle}\\), also has two sheets.\n\nBoth issues are solved by extending the definition of polar duality: replace the maximum with a stationarity. We can still construct \\(K_{particle}\\) from \\(K_{wave}\\) by taking a tangent plane for each \\(k \\in K_{wave}\\), but now instead of the intersection of the half-planes, we use their envelope. A picture shows what we mean:\n\n\n\nThe curve on the right is a trefoil curve defined by \\(z = 0.3 e^{i\\phi} + e^{-2i \\phi}\\), shifted to make the image clearer. The curve on the left is the polar dual of the trefoil curve. It is the envelope of the polar dual lines of each point on the trefoil curve.\n\n\nWe still have a duality between points on the two surfaces, defined by stationarity, not optimality. For example, for any wavevector \\(k \\in K_{wave}\\), its corresponding dual point \\(v^*(k)\\) satisfies \\(\\left\\langle v^*(k) + \\delta v, k\\right\\rangle = 0\\) for any \\(\\delta v\\) in the tangent space of \\(K_{particle}\\) at \\(v^*(k)\\)."
  }
]
[
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "",
    "text": "The essay is written at the level of two years of undergraduate mathematics. I will keep jargons to a minimum and use as few infinities as possible. For example, instead of particles that can be anywhere on a real-number line, I would talk about particles that can be in one of three boxes."
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Many-world theory",
    "text": "Many-world theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Pilot wave theory",
    "text": "Pilot wave theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Copenhagen interpretation",
    "text": "Copenhagen interpretation"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Relational quantum mechanics",
    "text": "Relational quantum mechanics"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "QBism",
    "text": "QBism"
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html",
    "href": "blog/posts/geometrical-mechanics/index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Consider a particle in a field, in polar coordinates. We have\n\\[L = \\frac 12 m (\\dot r^2 + r^2 \\dot \\theta^2) - V(r, \\theta)\\]\nNow suppose we want to use a rotating frame at angular velocity \\(+\\Omega\\), then we can use the change of variables by \\(\\theta = \\phi + \\Omega t\\), plug into the Euler–Lagrange equations, and obtain\n\\[\\begin{cases}\nm\\ddot r = mr\\dot\\phi^2 -\\partial_r V(r, \\phi + \\Omega t)  + mr\\Omega^2 + 2m(r\\dot \\phi)\\Omega \\\\\nm(r\\ddot\\phi + 2\\dot r\\dot \\phi) = -\\frac 1r \\partial_\\theta(r, \\phi+ \\Omega t) - 2m\\dot r\\Omega\n\\end{cases}\\]\nIn the above procedure, we simply performed a change of variables, then plugged into the Euler–Lagrange equations without comment, but are we allowed to do that? Yes, but there are conditions – the change of variables must not depend on velocity.\n\n\nAt this point, it is important to be as explicit as possible, carefully distinguishing between often confused concepts:\n\nphysical state: An intuitive concept that cannot be made more precise than say \"this is what physicists study\", much like how a geometric point cannot be made more precise than say \"this is what geometers study\".\nsame: As in most modern mathematics, two things are \"the same\" when they are really just \"equivalent\" or \"not distinguished in use\". For example, there is really just one \\(\\R\\), but we can have as many 1-dimensional vector spaces as we want, and they are all equivalent to \\(\\R\\), though not literally the same as it (if they were, then we wouldn’t have as many vector spaces as we want!).\n(n-dimensional smooth) manifold \\(\\mathcal M\\): a space that is locally the same as \\(\\R^n\\). More precisely, at every point \\(x\\in \\mathcal M\\), there exists a coordinate system around \\(x\\).\ncoordinate system of a manifold \\(\\mathcal M\\): a diffeomorphism from an open subset of \\(\\mathcal M\\) to an open subset of \\(\\R^n\\).\ndiffeomorphism: a smooth, one-to-one function between two smooth spaces. (What is a smooth space? ... it’s a space smooth enough to do calculus in. Making it more precise would be too much of a detour.)\nstate space \\(\\mathcal S\\): the manifold of distinct physical states. Every point \\(x\\in \\mathcal S\\) is a particular state that the system can assume. The manifold is built such that close-by points on the manifold are close-by physical states. That is, the topology of the state space (a precisely defined mathematical concept) is an exact representation of the topology of physical states (an intuitive concept that cannot be made more precise than that).\ntangent space \\(\\mathcal T_x\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible velocities at that state. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\).\ncotangent space \\(\\mathcal T_x^\\ast\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible momenta at that state. From the abstract perspective, a momentum is nothing more than a linear map of type \\(p: \\mathcal T_x\\mathcal S \\to \\R\\). That is, the only way to really \"use\" a momentum is to combine it with a velocity, mutually annihilating both of them and leaving behind nothing but a little real number representing the energy. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\). Neither is it literally the same as \\(\\mathcal T_x\\mathcal S\\).\nconfiguration space \\(\\mathcal C = \\mathcal T\\mathcal S\\): The tangent bundle of state space. That is, at each \\(x\\in \\mathcal S\\), we \"glue\" the space of velocities \\(\\mathcal T_x \\mathcal S\\) to the point. The totality of \\(\\mathcal C\\) with all its \\(\\mathcal T_x \\mathcal S\\) is the configuration space.\nphase space \\(\\mathcal P = \\mathcal T^\\ast\\mathcal S\\): The cotangent bundle of state space. That is, at each point \\(x\\in \\mathcal S\\), we attach the space of momenta \\(\\mathcal T_x^\\ast\\mathcal S\\).\n\nDo not worry if the words do not make much sense. The example will make it clear.\nFor concreteness, consider a pendulum-cart system, shown in Figure 4. It is clear that its state space is shaped like a cylinder: one circle for the angle of the pendulum, and one line being the location of the cart.\nMore examples are shown in Table 2. Most of them are obvious, except the one about particle on a sphere.\nIt’s clear that its state space is \\(\\mathbb S^2\\). However, that is not equivalent to the torus \\(\\mathbb S^1 \\times \\mathbb S^1\\). There is simply no way to split the sphere into a direct product of two circles (as a casual comparison between a donut and a ball can verify).\nFurthermore, its configuration space \\(\\mathcal\\mathbb S^2\\) is not equivalent to \\(\\R^2 \\times \\mathbb S^2\\). To prove that, we invoke the hairy ball theorem: there is no smooth and everywhere nonzero vector field on \\(\\mathbb S^2\\). Now, if it were equivalent to \\(\\R^2 \\times \\mathbb S^2\\), then there is an obvious smooth and everywhere nonzero vector field: \\(x \\mapsto ((1, 0), x)\\).\n\n\n\nThe pendulum-cart system.\n\n\n\n\nSome physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nphysical system\nstate space\nconfiguration space\n\n\n\n\nparticle in 3D space\n\\(\\R^3\\)\n\\(\\R^6\\)\n\n\npendulum\ncircle \\(\\mathbb S^1\\)\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\n\ndouble pendulum\ntorus \\(\\mathbb S^1 \\times \\mathbb S^1\\)\ncylinder-squared \\(\\R^2 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\npendulum-cart\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\\(\\R^3 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\nparticle on a sphere\nsphere \\(\\mathbb S^2\\)\ntangent bundle of sphere \\(\\mathcal T\\mathbb S^2\\)\n\n\n\n\n: Some physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\n\nWith the above formalism, we can precisely define more concepts\n\ntrajectory, or path, in a manifold \\(\\mathcal M\\): a function of type \\(\\gamma: [t_0, t] \\to \\mathcal M\\).\nLagrangian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal L: \\R \\times \\mathcal T\\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on configuration space.\n\nHamiltonian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal H: \\R \\times \\mathcal T^\\ast \\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on phase space.\n\naction of a path\n\n\\[S(\\gamma) = \\int_{t_0}^t \\mathcal L(\\tau, \\gamma(\\tau), \\dot \\gamma(\\tau))d\\tau.\\]\nNow, the convex duality between Lagrangian and Hamiltonian transfers with almost no change in notation:\n\\[\\begin{cases}\n\\mathcal L(t, q, v) = \\max_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\n\\mathcal H(t, q, p) = \\max_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\np^\\ast(t, q, v) = \\mathop{\\mathrm{arg\\,max}}_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\nv^\\ast(t, q, p) = \\mathop{\\mathrm{arg\\,max}}_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\nThe economic argument almost goes through without problem, but we need to be careful with some notations. In particular, we take another look at gradients. What does it mean to write \\(\\nabla_v \\mathcal L(t, q, v)\\)? The defining property is\n\\[\\mathcal L(t, q, v + u\\tau) = \\mathcal L(t, q, v) + \\lra{\\nabla_v \\mathcal L(t, q, v), u} \\tau + O(\\tau^2)\\]\nwhich implies the following operational definition:\n\\[\\nabla_v \\mathcal L(t, q, v) := u \\mapsto \\lim_{\\tau \\to 0} \\frac 1\\tau (\\mathcal L(t, q, v + u\\tau) - \\mathcal L(t, q, v))\\]\nThis definition makes it clear that \\(\\nabla_v \\mathcal L(t, q, v)\\) is a function of type \\(\\mathcal T_q \\mathcal S \\to\\R\\), thus it is an element of \\(\\mathcal T_q^\\ast \\mathcal S\\). Similarly, \\(\\nabla_p \\mathcal H(t, q, p)\\) is an element of \\(\\mathcal T_q \\mathcal S\\). Succinctly, \\(\\nabla_q \\mathcal L, \\nabla_v \\mathcal L, \\nabla_q \\mathcal H\\) are covector fields (like momentum), and \\(\\nabla_p \\mathcal H\\) is a vector field (like velocity).\nWith these, the types of every equation come out correctly again:\n\\[\\begin{cases}\nv = \\nabla_p \\mathcal H(t, q, p^\\ast(t, q, v))\\\\\np = \\nabla_v \\mathcal L(t, q, v^\\ast(t, q, p))\n\\end{cases},\n\\frac{d}{dt}(\\nabla_v \\mathcal L) = \\nabla_q \\mathcal L,\\quad\n\\begin{cases}\n\\dot p = -\\nabla_q \\mathcal H \\\\\n\\dot q = -\\nabla_p \\mathcal H\n\\end{cases}\\]\nLet’s call these the coordinate-free equations, to be contrasted with the coordinate-based equations, to be defined below.\n\n\n\nManifolds are geometrically pristine, but you can’t calculate numerically with them unless you lay down coordinate systems over them. Concretely, consider a state space \\(\\mathcal S\\). We take an open subset \\(U\\) of it, and define a coordinate system (with a possible dependence on time):\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nThis coordinate system then induces a coordinate system over the configuration space:\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nNow consider a different coordinate system\n\\[(Q_1, ..., Q_N): \\R \\times U \\to \\R^N\\]\nand suppose they are related by a function \\(f: \\R \\times \\R^N \\to \\R^N\\) such that\n\\[q(t, x) = f(t, Q(t, x))\\]\nThis is then a point transformation of the coordinate system.\nThe point transformation induces a transformation of the velocities, too. To find the transformation of velocities, consider a path \\(\\gamma: \\R \\to \\mathcal S\\). Its velocity at time \\(t\\) is \\(\\dot \\gamma(t) \\in \\mathcal T_{\\gamma(t)}\\mathcal S\\), a vector that looks like it literally lives in \\(\\R^N\\), but is not. It is not a native of \\(\\R^N\\), but thanks to the \\(q\\)-coordinate system, it is represented by the \\(\\R^N\\)-vector\n\\[\\frac{d}{dt} q(t, \\gamma(t)) \\in \\R^N\\]\nNow plug in \\(q(t, x) = f(t, Q(t, x))\\), to find a relationship between the representation of \\(\\dot \\gamma(t)\\) in \\(q\\)-coordinate system and \\(Q\\)-coordinate system:\n\\[\\frac{d}{dt} q(t, \\gamma(t)) = \\frac{d}{dt} f(t, Q(t, \\gamma(t))) = \\partial_t f(t, Q(t, \\gamma(t))) + \\frac{\\partial f}{\\partial Q} \\frac{d}{dt}Q(t, \\gamma(t))\\]\nMore succinctly, we have the following transformation from \\((t, Q, V)\\) to \\((t, q, v)\\):\n\\[\\begin{cases}\nq = f(t, Q) \\\\\nv= \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\n\\end{cases}\\]\nA note on matrix algebra: Conventionally, vectors are written as column-matrices, that is, \\(q, v, Q, V\\) are written as \\(N\\times 1\\) matrices. Correspondingly, gradients, being covectors, are written as row-matrices, that is, \\(\\nabla_q l, \\nabla_v l, \\nabla_Q L, \\nabla_V L\\), are written as \\(1 \\times N\\) matrices. Finally, gradients of vector-valued functions, like \\(\\frac{\\partial f}{\\partial Q}\\), are \\(N\\times N\\) matrices, with each row being a gradient of one vector coordinate. This convention makes everything come out cleanly, with no need to take the transpose of anything.\nThe point transformation also induces a transformation of the Lagrangians. While the Lagrangian itself is a function \\(\\mathcal L\\) of type \\(\\R \\times \\mathcal T \\mathcal S \\to \\R\\), the Lagrangians \\(L(t, Q, V), l(t, q, v)\\) are functions of type \\(\\R \\times \\R^N \\times \\R^N \\to \\R\\). Both \\(L, l\\) are induced from \\(\\mathcal L\\) by the choice of coordinates. We have\n\\[\\mathcal(t, x, u) = L(t, Q(t, x), V(t, x, u)) = l(t, q(t, x), v(t, x, u))\\]\nand plug in \\(q(t, x) = f(t, Q(t, x)), v = \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\\), we have\n\\[l\\left(t, f(t, Q), \\partial_t f(t, Q)  + \\frac{\\partial f}{\\partial Q}(t, Q) V\\right) = L(t, Q, V)\\]\nBrute computation shows that\n\\[\\frac{d}{dt}(\\nabla_V L) - \\nabla_Q L = \\left(\\frac{d}{dt}(\\nabla_v l) - \\nabla_q l\\right)\\frac{\\partial f}{\\partial Q}\\]\nimplying that the coordinate-based Euler–Lagrange equation is true in \\((Q, V)\\) coordinates iff it is true in \\((q, v)\\) coordinates.\nWhat, in the final analysis, is a point transformation? It is nothing more than changing a time-varying coordinate system on the state space. Since our derivation of the coordinate-based Euler–Lagrange equations required no special property of the coordinate system, it must be preserved by point transformations. All the above verification was really nothing but \"ceremonial\".\nIn more detail: we know that the coordinate-free EL equations are true, which implies that the \\(q\\)-coordinate-based EL equations and the \\(Q\\)-coordinate-based EL equations are both true (since they are merely two coordinate-based representations on the coordinate-free equation). No \\(Q\\)-to-\\(q\\) translation is necessary!\nWhat, then, is the phrase \"point transformation\" supposed to be contrasted with? It is contrasted with more general coordinate transforms that also depend on velocities, as \\(q = f(t, Q, V)\\). From the perspective given here, the contrast is really between \"state space coordinate systems\" and \"configuration space coordinate systems\". Whereas state space coordinate system is first defined as some\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nand that is then extended to \\((q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\), a configuration space coordinate system defines \"all at once\" a complete coordinate system\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nIt is no wonder that such overly general coordinate systems do not have nice properties, and do not satisfy the coordinate-based Euler–Lagrange equations.\n\n\n\nBefore writing this chapter, try going through (Bohn 2018, chap. 7).\nWhereas for the Lagrangian \\(\\mathcal L\\), we can only perform point-transformations \\(q = f(t, Q)\\), lest the Euler–Lagrange equation is mangled, for the Hamiltonian, we can simultaneously transform both \\(q, p\\), while preserving the Hamiltonian equations of motion. Such transformations are called canonical transformations. They are of the form:\n\\[\\begin{cases}\nQ = f_Q(t, p, q)\\\\\nP = f_P(t, p, q)\n\\end{cases}\\]\nwhere the functions \\(f_Q, f_P: \\R \\times \\R^N \\times \\R^N \\to \\R^N\\) are required to satisfy some functional equations.\nThis is usually derived by brute force without comments. However, to truly understand the meaning, we need to understand phase space from a perspective even more modern than \\(\\mathcal T^\\ast \\mathcal S\\)."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-physical-states",
    "href": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-physical-states",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Consider a particle in a field, in polar coordinates. We have\n\\[L = \\frac 12 m (\\dot r^2 + r^2 \\dot \\theta^2) - V(r, \\theta)\\]\nNow suppose we want to use a rotating frame at angular velocity \\(+\\Omega\\), then we can use the change of variables by \\(\\theta = \\phi + \\Omega t\\), plug into the Euler–Lagrange equations, and obtain\n\\[\\begin{cases}\nm\\ddot r = mr\\dot\\phi^2 -\\partial_r V(r, \\phi + \\Omega t)  + mr\\Omega^2 + 2m(r\\dot \\phi)\\Omega \\\\\nm(r\\ddot\\phi + 2\\dot r\\dot \\phi) = -\\frac 1r \\partial_\\theta(r, \\phi+ \\Omega t) - 2m\\dot r\\Omega\n\\end{cases}\\]\nIn the above procedure, we simply performed a change of variables, then plugged into the Euler–Lagrange equations without comment, but are we allowed to do that? Yes, but there are conditions – the change of variables must not depend on velocity.\n\n\nAt this point, it is important to be as explicit as possible, carefully distinguishing between often confused concepts:\n\nphysical state: An intuitive concept that cannot be made more precise than say \"this is what physicists study\", much like how a geometric point cannot be made more precise than say \"this is what geometers study\".\nsame: As in most modern mathematics, two things are \"the same\" when they are really just \"equivalent\" or \"not distinguished in use\". For example, there is really just one \\(\\R\\), but we can have as many 1-dimensional vector spaces as we want, and they are all equivalent to \\(\\R\\), though not literally the same as it (if they were, then we wouldn’t have as many vector spaces as we want!).\n(n-dimensional smooth) manifold \\(\\mathcal M\\): a space that is locally the same as \\(\\R^n\\). More precisely, at every point \\(x\\in \\mathcal M\\), there exists a coordinate system around \\(x\\).\ncoordinate system of a manifold \\(\\mathcal M\\): a diffeomorphism from an open subset of \\(\\mathcal M\\) to an open subset of \\(\\R^n\\).\ndiffeomorphism: a smooth, one-to-one function between two smooth spaces. (What is a smooth space? ... it’s a space smooth enough to do calculus in. Making it more precise would be too much of a detour.)\nstate space \\(\\mathcal S\\): the manifold of distinct physical states. Every point \\(x\\in \\mathcal S\\) is a particular state that the system can assume. The manifold is built such that close-by points on the manifold are close-by physical states. That is, the topology of the state space (a precisely defined mathematical concept) is an exact representation of the topology of physical states (an intuitive concept that cannot be made more precise than that).\ntangent space \\(\\mathcal T_x\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible velocities at that state. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\).\ncotangent space \\(\\mathcal T_x^\\ast\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible momenta at that state. From the abstract perspective, a momentum is nothing more than a linear map of type \\(p: \\mathcal T_x\\mathcal S \\to \\R\\). That is, the only way to really \"use\" a momentum is to combine it with a velocity, mutually annihilating both of them and leaving behind nothing but a little real number representing the energy. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\). Neither is it literally the same as \\(\\mathcal T_x\\mathcal S\\).\nconfiguration space \\(\\mathcal C = \\mathcal T\\mathcal S\\): The tangent bundle of state space. That is, at each \\(x\\in \\mathcal S\\), we \"glue\" the space of velocities \\(\\mathcal T_x \\mathcal S\\) to the point. The totality of \\(\\mathcal C\\) with all its \\(\\mathcal T_x \\mathcal S\\) is the configuration space.\nphase space \\(\\mathcal P = \\mathcal T^\\ast\\mathcal S\\): The cotangent bundle of state space. That is, at each point \\(x\\in \\mathcal S\\), we attach the space of momenta \\(\\mathcal T_x^\\ast\\mathcal S\\).\n\nDo not worry if the words do not make much sense. The example will make it clear.\nFor concreteness, consider a pendulum-cart system, shown in Figure 4. It is clear that its state space is shaped like a cylinder: one circle for the angle of the pendulum, and one line being the location of the cart.\nMore examples are shown in Table 2. Most of them are obvious, except the one about particle on a sphere.\nIt’s clear that its state space is \\(\\mathbb S^2\\). However, that is not equivalent to the torus \\(\\mathbb S^1 \\times \\mathbb S^1\\). There is simply no way to split the sphere into a direct product of two circles (as a casual comparison between a donut and a ball can verify).\nFurthermore, its configuration space \\(\\mathcal\\mathbb S^2\\) is not equivalent to \\(\\R^2 \\times \\mathbb S^2\\). To prove that, we invoke the hairy ball theorem: there is no smooth and everywhere nonzero vector field on \\(\\mathbb S^2\\). Now, if it were equivalent to \\(\\R^2 \\times \\mathbb S^2\\), then there is an obvious smooth and everywhere nonzero vector field: \\(x \\mapsto ((1, 0), x)\\).\n\n\n\nThe pendulum-cart system.\n\n\n\n\nSome physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nphysical system\nstate space\nconfiguration space\n\n\n\n\nparticle in 3D space\n\\(\\R^3\\)\n\\(\\R^6\\)\n\n\npendulum\ncircle \\(\\mathbb S^1\\)\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\n\ndouble pendulum\ntorus \\(\\mathbb S^1 \\times \\mathbb S^1\\)\ncylinder-squared \\(\\R^2 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\npendulum-cart\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\\(\\R^3 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\nparticle on a sphere\nsphere \\(\\mathbb S^2\\)\ntangent bundle of sphere \\(\\mathcal T\\mathbb S^2\\)\n\n\n\n\n: Some physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\n\nWith the above formalism, we can precisely define more concepts\n\ntrajectory, or path, in a manifold \\(\\mathcal M\\): a function of type \\(\\gamma: [t_0, t] \\to \\mathcal M\\).\nLagrangian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal L: \\R \\times \\mathcal T\\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on configuration space.\n\nHamiltonian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal H: \\R \\times \\mathcal T^\\ast \\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on phase space.\n\naction of a path\n\n\\[S(\\gamma) = \\int_{t_0}^t \\mathcal L(\\tau, \\gamma(\\tau), \\dot \\gamma(\\tau))d\\tau.\\]\nNow, the convex duality between Lagrangian and Hamiltonian transfers with almost no change in notation:\n\\[\\begin{cases}\n\\mathcal L(t, q, v) = \\max_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\n\\mathcal H(t, q, p) = \\max_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\np^\\ast(t, q, v) = \\mathop{\\mathrm{arg\\,max}}_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\nv^\\ast(t, q, p) = \\mathop{\\mathrm{arg\\,max}}_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\nThe economic argument almost goes through without problem, but we need to be careful with some notations. In particular, we take another look at gradients. What does it mean to write \\(\\nabla_v \\mathcal L(t, q, v)\\)? The defining property is\n\\[\\mathcal L(t, q, v + u\\tau) = \\mathcal L(t, q, v) + \\lra{\\nabla_v \\mathcal L(t, q, v), u} \\tau + O(\\tau^2)\\]\nwhich implies the following operational definition:\n\\[\\nabla_v \\mathcal L(t, q, v) := u \\mapsto \\lim_{\\tau \\to 0} \\frac 1\\tau (\\mathcal L(t, q, v + u\\tau) - \\mathcal L(t, q, v))\\]\nThis definition makes it clear that \\(\\nabla_v \\mathcal L(t, q, v)\\) is a function of type \\(\\mathcal T_q \\mathcal S \\to\\R\\), thus it is an element of \\(\\mathcal T_q^\\ast \\mathcal S\\). Similarly, \\(\\nabla_p \\mathcal H(t, q, p)\\) is an element of \\(\\mathcal T_q \\mathcal S\\). Succinctly, \\(\\nabla_q \\mathcal L, \\nabla_v \\mathcal L, \\nabla_q \\mathcal H\\) are covector fields (like momentum), and \\(\\nabla_p \\mathcal H\\) is a vector field (like velocity).\nWith these, the types of every equation come out correctly again:\n\\[\\begin{cases}\nv = \\nabla_p \\mathcal H(t, q, p^\\ast(t, q, v))\\\\\np = \\nabla_v \\mathcal L(t, q, v^\\ast(t, q, p))\n\\end{cases},\n\\frac{d}{dt}(\\nabla_v \\mathcal L) = \\nabla_q \\mathcal L,\\quad\n\\begin{cases}\n\\dot p = -\\nabla_q \\mathcal H \\\\\n\\dot q = -\\nabla_p \\mathcal H\n\\end{cases}\\]\nLet’s call these the coordinate-free equations, to be contrasted with the coordinate-based equations, to be defined below.\n\n\n\nManifolds are geometrically pristine, but you can’t calculate numerically with them unless you lay down coordinate systems over them. Concretely, consider a state space \\(\\mathcal S\\). We take an open subset \\(U\\) of it, and define a coordinate system (with a possible dependence on time):\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nThis coordinate system then induces a coordinate system over the configuration space:\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nNow consider a different coordinate system\n\\[(Q_1, ..., Q_N): \\R \\times U \\to \\R^N\\]\nand suppose they are related by a function \\(f: \\R \\times \\R^N \\to \\R^N\\) such that\n\\[q(t, x) = f(t, Q(t, x))\\]\nThis is then a point transformation of the coordinate system.\nThe point transformation induces a transformation of the velocities, too. To find the transformation of velocities, consider a path \\(\\gamma: \\R \\to \\mathcal S\\). Its velocity at time \\(t\\) is \\(\\dot \\gamma(t) \\in \\mathcal T_{\\gamma(t)}\\mathcal S\\), a vector that looks like it literally lives in \\(\\R^N\\), but is not. It is not a native of \\(\\R^N\\), but thanks to the \\(q\\)-coordinate system, it is represented by the \\(\\R^N\\)-vector\n\\[\\frac{d}{dt} q(t, \\gamma(t)) \\in \\R^N\\]\nNow plug in \\(q(t, x) = f(t, Q(t, x))\\), to find a relationship between the representation of \\(\\dot \\gamma(t)\\) in \\(q\\)-coordinate system and \\(Q\\)-coordinate system:\n\\[\\frac{d}{dt} q(t, \\gamma(t)) = \\frac{d}{dt} f(t, Q(t, \\gamma(t))) = \\partial_t f(t, Q(t, \\gamma(t))) + \\frac{\\partial f}{\\partial Q} \\frac{d}{dt}Q(t, \\gamma(t))\\]\nMore succinctly, we have the following transformation from \\((t, Q, V)\\) to \\((t, q, v)\\):\n\\[\\begin{cases}\nq = f(t, Q) \\\\\nv= \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\n\\end{cases}\\]\nA note on matrix algebra: Conventionally, vectors are written as column-matrices, that is, \\(q, v, Q, V\\) are written as \\(N\\times 1\\) matrices. Correspondingly, gradients, being covectors, are written as row-matrices, that is, \\(\\nabla_q l, \\nabla_v l, \\nabla_Q L, \\nabla_V L\\), are written as \\(1 \\times N\\) matrices. Finally, gradients of vector-valued functions, like \\(\\frac{\\partial f}{\\partial Q}\\), are \\(N\\times N\\) matrices, with each row being a gradient of one vector coordinate. This convention makes everything come out cleanly, with no need to take the transpose of anything.\nThe point transformation also induces a transformation of the Lagrangians. While the Lagrangian itself is a function \\(\\mathcal L\\) of type \\(\\R \\times \\mathcal T \\mathcal S \\to \\R\\), the Lagrangians \\(L(t, Q, V), l(t, q, v)\\) are functions of type \\(\\R \\times \\R^N \\times \\R^N \\to \\R\\). Both \\(L, l\\) are induced from \\(\\mathcal L\\) by the choice of coordinates. We have\n\\[\\mathcal(t, x, u) = L(t, Q(t, x), V(t, x, u)) = l(t, q(t, x), v(t, x, u))\\]\nand plug in \\(q(t, x) = f(t, Q(t, x)), v = \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\\), we have\n\\[l\\left(t, f(t, Q), \\partial_t f(t, Q)  + \\frac{\\partial f}{\\partial Q}(t, Q) V\\right) = L(t, Q, V)\\]\nBrute computation shows that\n\\[\\frac{d}{dt}(\\nabla_V L) - \\nabla_Q L = \\left(\\frac{d}{dt}(\\nabla_v l) - \\nabla_q l\\right)\\frac{\\partial f}{\\partial Q}\\]\nimplying that the coordinate-based Euler–Lagrange equation is true in \\((Q, V)\\) coordinates iff it is true in \\((q, v)\\) coordinates.\nWhat, in the final analysis, is a point transformation? It is nothing more than changing a time-varying coordinate system on the state space. Since our derivation of the coordinate-based Euler–Lagrange equations required no special property of the coordinate system, it must be preserved by point transformations. All the above verification was really nothing but \"ceremonial\".\nIn more detail: we know that the coordinate-free EL equations are true, which implies that the \\(q\\)-coordinate-based EL equations and the \\(Q\\)-coordinate-based EL equations are both true (since they are merely two coordinate-based representations on the coordinate-free equation). No \\(Q\\)-to-\\(q\\) translation is necessary!\nWhat, then, is the phrase \"point transformation\" supposed to be contrasted with? It is contrasted with more general coordinate transforms that also depend on velocities, as \\(q = f(t, Q, V)\\). From the perspective given here, the contrast is really between \"state space coordinate systems\" and \"configuration space coordinate systems\". Whereas state space coordinate system is first defined as some\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nand that is then extended to \\((q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\), a configuration space coordinate system defines \"all at once\" a complete coordinate system\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nIt is no wonder that such overly general coordinate systems do not have nice properties, and do not satisfy the coordinate-based Euler–Lagrange equations.\n\n\n\nBefore writing this chapter, try going through (Bohn 2018, chap. 7).\nWhereas for the Lagrangian \\(\\mathcal L\\), we can only perform point-transformations \\(q = f(t, Q)\\), lest the Euler–Lagrange equation is mangled, for the Hamiltonian, we can simultaneously transform both \\(q, p\\), while preserving the Hamiltonian equations of motion. Such transformations are called canonical transformations. They are of the form:\n\\[\\begin{cases}\nQ = f_Q(t, p, q)\\\\\nP = f_P(t, p, q)\n\\end{cases}\\]\nwhere the functions \\(f_Q, f_P: \\R \\times \\R^N \\times \\R^N \\to \\R^N\\) are required to satisfy some functional equations.\nThis is usually derived by brute force without comments. However, to truly understand the meaning, we need to understand phase space from a perspective even more modern than \\(\\mathcal T^\\ast \\mathcal S\\)."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-phase-space",
    "href": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-phase-space",
    "title": "Yuxi on the Wired",
    "section": "The geometry of phase space",
    "text": "The geometry of phase space\nGiven a state space \\(\\mathcal S\\), both its configuration space and its phase space are obtained by attaching vector spaces to every point of it. Despite this, the geometry of phase space turns out to be a far richer thing than the geometry of configuration space. This fundamentally comes down to the difference between a cotangent vector and a tangent vector.\nConsider an infinitesimal parallelogram in the phase space, around the point \\((q, p)\\). The parallelogram has (signed) sides \\((\\delta q_1, ..., \\delta q_N; \\delta p_1, ..., \\delta p_N)\\). What should be its (signed) volume? The natural answer is of course\n\\[\\prod_i \\delta q_i \\delta p_i\\]\nbut is this a meaningful answer? That is, is this a mirage in \\(\\R^N \\times \\R^N\\) created by our choice of coordinates, or is this a faithful representation of something that truly takes place in the phase space \\(\\mathcal T^\\ast\\mathcal S\\) itself?\nThis answer is critically important, since if a concept takes place in the phase space itself, then it will be coordinate-free, and every coordinate system automatically translates that one coordinate-free concept. This is how we could have predicted that the coordinate-based Euler–Lagrange equations are preserved, by going up to the coordinate-free version of it, then coming back down again.\nHaving a coordinate-free thing is like having a lingua-franca between different coordinate-based representations.\n\nPoisson bracket\nThe Poisson bracket notation is convenient:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nFor any differentiable function \\(f(t, q, p)\\), and any path \\(p(t), q(t)\\) that conforms to a Hamiltonian \\(H(t, q, p)\\), we have by Hamiltonian’s equations of motion\n\\[\\frac{d}{dt} f(t, p(t), q(t)) = \\partial_t f(t, p(t), q(t)) + \\{f, H\\}\\]\nor more succinctly, \\(\\dot f = \\partial_t f + \\{f, H\\}\\).\n\n\nLiouville’s theorem\nProof taken from (Tolman 1980, sec. 19).\n\n\nThe interpretation of phase space geometry\nLiouville’s theorem is a delicate construction, having several moving parts. We have a phase space, a volume-measurement on the phase space, a Hamiltonian on the phase space, and a density field on the phase space which flows according to the Hamiltonian. Only when all four moving parts come together do we get Liouville’s theorem.\nWhat is a phase space, in the final analysis? A phase space \\(\\mathcal T^\\ast \\mathcal S\\) is a state space \\(\\mathcal S\\), with each state \\(x\\) attached with \\(\\mathcal T^\\ast_x \\mathcal S\\), the vector space of all possible momenta at that state. Good... but not quite! This interpretation of phase space is still bound firmly to the economic interpretation, where each momentum \\(p\\) at state \\(x\\) is a vector of prices, with which we are allowed to measure the profit flow, as \\(\\langle p, \\dot x \\rangle\\).\nWhile this perspective is how Hamiltonian mechanics got its start, the modern abstract viewpoint of Hamiltonian mechanics has sailed far away from the safe harbor of \\(\\R^{2N}\\), past \\(\\mathcal T^\\ast \\mathcal S\\), and voyaged deep into the strange seas of symplectic geometry. Since the early days of the 20th century, there is a tacit understanding among physicists where the humble origin of the phase space \\(\\mathcal T^\\ast \\mathcal S\\) is suppressed, and it is presented instead as a \\(2N\\)-dimensional smooth manifold \\(\\mathcal P\\) equipped with some \\(\\omega\\), a way to measure volumes. The seams where \\(\\mathcal T^\\ast_x \\mathcal S\\) was attached to \\(\\mathcal S\\) are now plastered over, never there, never will be mentioned again... And this abstract viewpoint actually works.\nSpeak not how the phase space was born, but what you can use it for! This is a principle useful not only in programming (encapsulation, API, abstract interfacing), but also in modern mathematics (speak not of equality, but equivalences and isomorphisms...), and perhaps in society (Ye shall know them by their fruits. Do men gather grapes of thorns, or figs of thistles?).\nWhat do we gain and what do we lose when we go from \\(\\R^{2N}\\) to \\(\\mathcal T^\\ast \\mathcal S\\) to \\((\\mathcal P, \\omega)\\)? What we gain are new interpretations, and what we lose are old interpretations. See Table 3.\n\n::: {#table:three_abstractions} \\(\\R^{2N}\\) \\(\\mathcal T^\\ast \\mathcal S\\) \\((\\mathcal P, \\omega)\\) ———————– ——————————– —————————- tuples of real number points, vectors, and covectors points, areas, and volumes multivariate calculus vector bundle geometry symplectic geometry\n\nThe three steps of abstraction. :::\n\n\nIn \\(\\R^{2N}\\), we can interpret each point \\((q, p)\\in \\R^{2N}\\) economically: \\(q_1, ..., q_N\\) are the amounts of commodities, and \\(p_1, ..., p_N\\) are their market prices. In \\(\\mathcal T^\\ast \\mathcal S\\), half of this interpretation is lost, since we are not allowed to interpret \\(x\\in \\mathcal S\\) as a tuple of commodities, unless we lay down a more or less arbitrary coordinate system over it.\nNevertheless, half of this interpretation is preserved. While we are no longer able to interpret a point \\(x\\in \\mathcal S\\) as a stock of commodities that we own, we are still able to interpret a vector \\(v \\in \\mathcal T_x \\mathcal S\\) as a flow of commodities. This then allows us to interpret \\(\\langle p, v \\rangle\\) as a flow of profits: if we are producing at speed \\(v\\), and the market price vector is \\(p\\), then our profit flow is \\(\\langle p, v \\rangle\\). In economic language, we can’t talk of the stock, but we can still talk of the flow.\nGiving up half of the economic interpretation allows us to gain in coordinate-freedom. The Hamiltonian equations of motion become coordinate-free equations on \\(\\mathcal T^\\ast \\mathcal S\\), and we are given the guarantee that it is preserved by any coordinate system on \\(\\mathcal S\\).\nWhen we get to \\((\\mathcal P, \\omega)\\), the economic interpretation is totally destroyed, because there is no more separation between commodities and prices. A point in \\(\\mathcal P\\) simply is a point \\(y\\in \\mathcal P\\), not a 2-tuple \\((x, p)\\) with \\(x\\in \\mathcal S\\) and \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\). There is no way to seize the \"second half\" of \\(y\\) and interpret it as a price vector.\nFurthermore, we cannot even interpret it as a physical state with a momentum covector, either. A momentum covector still looks like an arrow. It has a direction, a length, and can be scaled linearly, and added. Out there in \\(\\mathcal P\\), every point is just a point, not \"half base point, half vector\" like for \\(\\mathcal T^\\ast \\mathcal S\\).\nGiving this much up allows us to gain in even more coordinate-freedom. We are allowed to interpret a physical system not as a base state \\(x\\in \\mathcal S\\) plus a momentum state \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\) , but simply as a phase state \\(y\\in \\mathcal P\\). This in particular gives us the freedom to consider coordinate systems on \\(\\mathcal P\\) that are \"fully nonlinear\", which is what canonical transforms are all about.\nRecall how we defined point transforms in Lagrangian mechanics. We start with a coordinate system \\((q_1, ..., q_N)\\) on an open subset \\(U\\) of the state space \\(\\mathcal S\\), then induced a coordinate system \\((q_1, ..., q_N; v_1, ..., v_N)\\) on \\(\\mathcal T U\\). We also stated that, while we could have went directly for a coordinate system on \\(\\mathcal T\\), this would break the Euler–Lagrange equation.\nIt turns out that the Hamiltonian equations of motion are sturdier than the Euler–Lagrange equation: there are large families of coordinate systems \\((q_1, ..., q_N; p_1, ..., p_N)\\) that we can directly define on open subsets of \\(\\mathcal T^\\ast \\mathcal S\\), and the resulting coordinate-based Hamiltonian equations would still be \\(\\dot p = -\\nabla_q H, \\dot q = \\nabla_p H\\), even if \\((q_1, ..., q_N; p_1, ..., p_N)\\) is not induced by any coordinate system on the state space!\nTo fully exploit the freedom, of course, means that we must break down the strict segregation between a state-point and a momentum-vector. In particular, this means that we no longer require \\(\\mathcal T_x \\mathcal S\\) to be treated with the rigid dignity of a linear space, but the rough freedom of a manifold space:\n\\[p(x, ku) \\neq k p(x, u) \\text { in general, for } (x, u)\\in \\mathcal T^\\ast \\mathcal S, \\: k\\in \\R\\]\nGiven that, we can immediately see why canonical transforms are in general of the form\n\\[Q(t, x, u) = f_Q(t, q(t, x, u), p(t, x, u)),\\quad P(t, x, u) = f_P(t, q(t, x, u), p(t, x, u))\\]\nor more succinctly,\n\\[Q = f_Q(t, q, p),\\quad P = f_P(t, q, p)\\]\nThey have to nonlinearly \"mix up\" state and momentum, because that’s the only way to truly exploit all the freedoms that the sturdy Hamiltonian’s equations of motion grants us.1\n1 Mathematicians exploit every freedom that they are given... sounds evil, but it works in math.Of course, the Hamiltonian equations are not that tough. Some restraint is needed. Not everything goes. What is the restraint? The volume must be preserved! That is precisely what \\(\\omega\\) is there for: it measures areas. A coordinate system on the phase space is only given the title of \"canonical\" iff the coordinate system represents \\(\\omega\\) correctly.\nThus, we find that by exploiting exactly as much freedom as Hamiltonian mechanics gives us, while keeping track of the boundaries so that we are not giving ourselves too much freedom and shooting ourselves in the foot, we walked inexorably into treating the phase space as \\((\\mathcal P, \\omega)\\) – as an object of symplectic geometry."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "href": "blog/posts/geometrical-mechanics/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "title": "Yuxi on the Wired",
    "section": "All the variational principles of physics that you’re likely to ever see",
    "text": "All the variational principles of physics that you’re likely to ever see\nBased on (Lanczos 1970).\nOthers not covered: D’lambert’s principle. Gauss’s principle of least constraint, Hertz principle of least curvature, etc.\nLet’s be clear here.\n\na variation of a function \\(\\gamma: \\R^n \\to \\R^m\\) is a function \\(\\gamma + \\delta \\eta\\), such that \\(\\eta: \\R^n \\to \\R^m\\), and \\(\\delta\\) is an infinitesimal.\na constrained variation of a function \\(\\gamma\\) is a variation \\(\\gamma + \\delta \\eta\\), such that \\(\\eta\\) satisfies certain constraints \\(c\\).\na functional is a function that maps a function to a real number. For example, the Lagrangian action \\(S\\) is a functional, defined by\n\n\\[S(\\gamma) = \\int L(t, \\gamma(t), \\dot \\gamma(t))dt.\\]\n\na functional \\(S\\) has zero variation at \\(\\gamma\\) under constraint \\(c\\) iff for any variation \\(\\delta\\eta\\) satisfying constraint \\(c\\), we have \\(S(\\gamma + \\delta \\eta) = S(\\gamma) + o(\\delta)\\). We often write it simply as \\((\\delta S(\\gamma))_c = 0\\).\nvariational calculus is a collection of techniques for solving calculus problems involving variations.\na variational principle is a statement with the following format:\n\n::: center A trajectory \\(\\gamma\\) of the system is a physically valid trajectory iff \\((\\delta S(\\gamma))_c = 0\\). :::\nNow that we are clear on that, we can tabulate just about every variational principles of physics that you’re likely to ever see in Table [table:var-prin].\n\n\n1.0|L|L|L|L|L| name & Where is the trajectory? & specification & constraint & the functional\nHamilton’s principle & state spacetime & Lagrangian \\(L(t, q, v)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma L(t, q, \\dot q)dt\\)\nmodified Hamilton’s principle & phase spacetime & Hamiltonian \\(H(t, q, p)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma (\\sum_i p_i \\dot q_i - H(t, q, p))dt\\)\nMaupertuis’ principle2 & phase space & time-independent Hamiltonian \\(H(q, p)\\) & fixed \\(q_0, q_1\\), constant \\(H(q, p)\\) & \\(\\int_\\gamma \\sum_i p_i dq_i\\)\nJacobi’s form of Maupertuis’ principle & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), bonuded \\(V(q) \\leq 0\\) & \\(\\int_\\gamma \\sqrt{(E - V(q)) dq^T M dq}\\)\ntimed Maupertuis’ principle & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q + V(q)\\) & \\(\\int_\\gamma (\\dot q^T M \\dot q) dt\\)\nFermat’s principle of stationary pathlength3 & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(\\int_\\gamma \\sqrt{dq^T M dq}\\)\nFermat’s principle of stationary time & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(t_1 - t_0\\)\n\n2 \"principle of least action\" in (Goldstein, Poole, and Safko 2008)3 Corollary: Hertz’s principle of least curvature\n\n\nHamilton’s principle and modified Hamilton’s principle\nThere are two principles that are often confused with impunity by physicists. The fact is that they are indeed equivalent (which is why they can be confused with impunity), but that is no excuse for bad mathematics.\nHamilton’s principle is a principle about trajectories of type \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\). That is, \\(\\gamma(t)\\) is a state of the system. Variations can be thought of as making a state perturbation \\(\\delta \\eta(t)\\) at every time.\nIn contrast, modified Hamilton’s principle is a principle about trajectories of type \\(\\Gamma: [t_0, t_1] \\to \\mathcal P\\). That is, \\(\\Gamma(t)\\) is a phase of the system, specifying both its state and momentum. Variations can be thought of as making a state perturbation \\(\\delta \\eta_p(t)\\) and a momentum perturbation \\(\\delta \\eta_p(t)\\) at every time.\nOne may object that modified Hamilton’s principle is performing physically impossible variations: how could you perform variations on position and momentum independently of each other? Shouldn’t we have \\(\\delta p = m\\delta \\dot q = \\delta (\\nabla_{v} L(t, q, \\dot q))\\) at all times? To this objection, there are four layers of replies.\n\nThe equivalence of Hamilton’s principle and modified Hamilton’s principle, to be proved below, is a theorem in pure mathematics. It makes no demand on physical reality. It merely states that Hamilton’s principle specifies the same trajectories as modified Hamilton’s principle. Consequently, if it happens that these trajectories are physically real, then they can be specified by either principle.\nThe economic interpretation of momentum \\(p\\) is merely the market price. The equation \\(p = \\nabla_{v} L(t, q, \\dot q)\\) is true if we also assume that the producer is profit-maximizing. Now, if the trajectory \\(\\gamma\\) is optimal, then it implies that the producer is profit-maximizing. But after a perturbation of \\(\\gamma\\) to \\(\\gamma + \\delta \\eta\\), the producer is not necessarily profit-maximizing.4 Consequently, even in Hamilton’s principle, there is no requirement that \\(p = \\nabla_{v} L(t, q, \\dot q)\\). The modified Hamilton’s principle makes this interactive dance between the producer and the market explicit: we allow both the production schedule and the market price schedule to vary independently. Then, the equation \\(\\delta \\int (\\sum_i p_i \\dot q_i - H)dt = 0\\) is a statement about the trajectory of the producer-market system, and solving it would simultaneously solve both the producer and the market. In contrast, the equation \\(\\delta \\int L dt = 0\\) is a statement about the producer, and solving it by imagining a market \\(p\\) is useful, but not necessary.\nEven in classical mechanics, momentum is not real. We are fooled by our long habit of thinking about classical mechanics as if it is merely a more mathematical version of our intuition. Classical mechanics is actually unintuitive.5 In classical mechanics, there is no necessary connection between momentum and velocity – \"If \\(L = \\frac 12 v^T M v\\), then \\(p = Mv\\) on physically valid paths\" actually needs to be proved from Hamilton’s principle, not baked into the definition of momentum!\nThough in classical mechanics, both principles are equivalent, in modern physics, the modified Hamilton’s principle is primary, and the Hamilton’s principle a mere derivative. Furthermore, the phase space is primary, and the division of it into position-momentum is arbitrary. At a more fundamental level, there is no distinction between position and momentum. A \"rotation in phase space\" can transform position and momentum into each other.\n\n4 Unless the market price is perturbed in just the right way to make the producer profit-maximizing – If the producer messes up, the market can still accommodate the producer and make the producer look as if it is still profit-maximizing... Just like Potemkin villages!5 Why else did Newton come two thousand years after Aristotle? Though quantum mechanics is certainly more unintuitive.\nTheorem 1 (Hamilton’s principle and modified Hamilton’s principle are equivalent.) Given a state space \\(\\mathcal S\\), a Lagrangian \\(L(t, q, v)\\) on the configuration space, and a Hamiltonian \\(H(t, q, p)\\) on the phase space, related by convex duality, then a path \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) on state space satisfies\n\\[\\delta \\int_\\gamma L(t, q, \\dot q) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\), iff its corresponding path \\(\\Gamma: [t_0, t_1]: \\to \\mathcal T^\\ast \\mathcal S\\) on phase space satisfies\n\\[\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\) (and variable \\(p_0, p_1\\)).\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\((\\Rightarrow):\\) Since \\(\\gamma\\) has zero variation for the action \\(\\int_\\gamma L(t, q, \\dot q)dt\\), and \\(H\\) is related to \\(L\\) by convex duality, by our previous results, the Hamiltonian equations of motion are satisfied along \\(\\gamma\\). That is, \\(-\\nabla_q H = \\dot p, \\nabla_p H = \\dot p\\).\nPerform variation \\(\\Gamma + \\delta \\eta\\) on phase space. The variation in the action is\n\\[\\begin{aligned} \\delta S(\\Gamma) &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle \\nabla_q H, \\delta q\\rangle - \\langle \\nabla_p H, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle -\\dot p, \\delta q\\rangle - \\langle \\dot q, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle  p, \\delta \\dot q\\rangle + \\langle \\dot p, \\delta q\\rangle] dt \\\\ &= \\langle p, \\delta q\\rangle \\Big|_{t_0}^{t_1} = 0 \\end{aligned}\\]\nsince \\(\\delta q= 0\\) at the end points.\n\\((\\Leftarrow):\\) Since \\(\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\) at \\(\\Gamma\\) under constraint of fixed \\((t_0, q_0), (t_1, q_1)\\), it must also have zero variation if we use the stronger constraint of fixed \\((t_0, q_0, p_0), (t_1, q_1, p_1)\\). Then the Euler–Lagrange equations state6\n\\[-\\nabla_q H = \\dot p, \\quad \\nabla_p H = \\dot p\\]\nwhich, as we proved, are precisely the conditions (no arbitrage pricing, and stationary profit flow) for \\(\\delta \\int_\\gamma L = 0\\).\n\n\n\n6 One can interpret this as treating the phase space as if it is a state space of a physical system with \\(2N\\) degrees of freedom.\n\nMaupertuis’ principle\nMaupertuis’ principle is a principle for specifying orbits in phase space. An orbit is a trajectory of the physical system, but with timing information lost. We know that the system traveled through the states on the orbit, one after another, but we don’t know how fast is the traversal.\nIn order to be very explicit about it, we will write orbits in phase space as \\(\\mu: [a, b] \\to \\mathcal P\\). Here \\(a, b\\) look like \"start and end times\" and \\(\\mu(s)\\) looks like \"location of the path at time \\(s\\)\", but \\(s\\) is not time, and \\(a, b\\) are not moments in time either. It is really just a parametrization of the curve, with no implications about how fast, or how slow, the system would actually traverse the orbit.\nThe integral \\(\\int_\\mu \\sum_i p_i \\dot q_i ds\\) is unchanged by stretching and pressing the timing of \\(\\mu\\). That is, let \\(f: [a', b'] \\to [a, b]\\) be a strictly increasing differentiable function, then \\(\\int_{\\mu\\circ f} \\sum_i p_i \\dot q_i ds = \\int_\\mu \\sum_i p_i \\dot q_i ds\\). Consequently, Maupertuis’ principle is really concerned only with the orbit, not the timing of the orbit.\nSince timing is lost, the constraint of fixed \\((t_0, q_0), (t_1, q_1)\\) cannot apply. However, merely fixing \\(q_0, q_1\\) is too little constraint. The solution is to add a new constraint: the variation must stay on the surface of constant energy \\(E\\). That is, \\(H(\\mu'(s')) = E\\) for any variation \\(\\mu'\\) and parameter \\(s'\\). This is how we arrive at Maupertuis’ principle.\n::: prop\nWhen the Hamiltonian is time-independent, Hamilton’s principle and Maupertuis’ principle are equivalent (after a retiming scaling).\nGiven phase space \\(\\mathcal P\\) and a time-independent Hamiltonian \\(H(q, p)\\) over the phase space, such that \\((\\nabla_q H, \\nabla_p H)\\) is never zero, then any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) that satisfies Hamilton’s principle also satisfies Maupertuis’ principle.\nConversely, given any orbit \\(\\mu: [a, b] \\to \\mathcal P\\) with constant \\(H\\) that satisfies Maupertuis’ principle, there exists a \"retiming map\" \\(f: [t_0, t_1]\\to [a, b]\\) such that \\(f\\) is monotonically increasing, and \\(\\mu\\circ f\\) satisfies Hamilton’s principle. :::\n::: proof Proof. We show that Maupertuis’ principle is equivalent to Hamilton’s equations of motion after a retiming map.\nConsider orbit \\(\\mu: [a, b] \\to \\mathcal P\\) in phase space, with constant \\(H(\\mu(s)) = E_0\\). By integration-by-parts, we have\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int \\langle \\delta p, \\dot q\\rangle - \\langle \\dot p, \\delta  q\\rangle ds + \\cancel{\\langle p, \\delta q\\rangle} \\Big|_{a}^{b}\\]\nwhere the variation fixes \\(q_0, q_1\\) and \\(H\\).\nNow, \\(\\delta H = \\langle \\nabla_p H, \\delta p\\rangle +  \\langle \\nabla_q H, \\delta q\\rangle = 0\\). So, if the orbit satisfies Hamilton’s equations of motion after a retiming map \\(f\\), that is,\n\\[\\begin{cases}     \\dot p = -f'(s)\\nabla_p H \\\\     \\dot q = f'(s)\\nabla_q H \\end{cases}\\]\nthen plugging it back, we get\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int f'(s) \\delta H ds = 0\\]\nIt is routine to check that, given four vectors \\(a, b, c, d\\in \\R^N\\), if \\(\\forall x, y\\in \\R^N\\),\n\\[\\langle a, x\\rangle - \\langle b, y\\rangle = 0 \\implies \\langle c, x\\rangle - \\langle d, y\\rangle = 0\\]\nthen there exists \\(\\lambda &gt; 0\\) such that \\(c = \\lambda a, d = \\lambda d\\).\nThus, if the variation is zero for all \\(\\delta q, \\delta p\\) with fixed \\(H\\), then there exists some continuous and positive function \\(\\lambda: [a, b] \\to \\R\\) such that\n\\[\\begin{cases}     \\dot p = -\\lambda(s)\\nabla_p H \\\\     \\dot q = \\lambda(s)\\nabla_q H \\end{cases}\\]\nNow solve for \\(f' = \\lambda^{-1}\\) by integration7, then \\(f\\) is the desired retiming map. ◻ :::\n7 Since \\(\\lambda\\) is continuous and positive, with compact domain, its range must be bounded below by some positive constant \\(\\epsilon &gt; 0\\), thus the integration would not diverge."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#canonical-transformations",
    "href": "blog/posts/geometrical-mechanics/index.html#canonical-transformations",
    "title": "Yuxi on the Wired",
    "section": "Canonical transformations",
    "text": "Canonical transformations\n\nGenerating functions\nThe dynamics of a physical system can be fully defined by its Lagrangian function. However, the Lagrangian function is not fully defined by the dynamics. There are many possible functions that can all play the role of the Lagrangian.\nSuppose \\(L(t, q, v)\\) is a Lagrangian function, then take any twice-differentiable function \\(F(t, q)\\), and define\n\\[L' dt := L dt + dF\\]\nwhich implies\n\\[L'(t, q, v) := L(t, q, v) + \\partial_t F(t, q) + \\langle \\nabla_q F(t, q), v\\rangle\\]\nthen it is easy to directly verify that a trajectory \\(\\gamma(t)\\) satisfies the Euler–Lagrange equations for \\(L\\) iff it satisfies them for \\(L'\\). Consequently, both \\(L\\) and \\(L'\\) are different functions that can both play the role of Lagrangian for the same physical system.\nInstead of directly computing the Euler–Lagrangian equations, we can also do it directly by variational principles: For any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) we have\n\\[\\int_{t_0}^{t_1} L'(t, \\gamma(t), \\dot \\gamma(t))dt = F(t, \\gamma(t))|_{t_0}^{t_1} + \\int_{t_0}^{t_1} L(t, \\gamma(t), \\dot \\gamma(t))dt\\]\nConsequently, \\(\\delta \\int Ldt = 0\\) iff \\(\\delta \\int L'dt = 0\\), so a trajectory has stationary action according to one Lagrangian iff according to the other.\nSuch \\(F(t, q)\\) are called a generating function for transforming a Lagrangian function. Generating functions are really just functions that are picked to play a certain role. That is, being a generating function is not an intrinsic property of a function, but extrinsic, because some human physicist has decided to use it for generating a new Lagrangian from an old one. This is why I don’t like saying \"\\(F\\) a generating function...\". Instead, I prefer to say \"Now we use \\(F\\) to generate a new Lagrangian...\" Nevertheless I am forced to use the term because it is a venerable error, a bug that became a feature.\n\n\nGenerating functions for Hamiltonians\nHamiltonians are freer than Lagrangians. Instead of one way, there are many ways to generate new Hamiltonians from old.\nTaking inspiration from Lagrangian generating functions, we write down the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nwhere \\(G: \\R \\times \\mathcal P \\to \\R\\) is any twice-differentiable function on phase spacetime.\n::: theorem If \\((q, p), (Q, P)\\) are two coordinate systems on the phase spacetime, and \\(h, H, G\\) are twice-differentiable functions on phase spacetime, and\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nThen along any trajectory in phase spacetime, \\((q, p)\\) satisfies Hamiltonian equations of motion for \\(h\\), iff \\((Q, P)\\) satisfies Hamiltonian equations of motion for \\(H\\). :::\n::: proof Proof. Let \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) be any trajectory, not necessarily satisfying Hamilton’s equations of motion. Then for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\), we have by integration-by-parts,\n\\[\\begin{aligned}     &\\delta\\int_\\gamma \\langle p , dq \\rangle - hdt = \\delta\\int_\\gamma \\langle P, dQ \\rangle - Hdt + dG\\\\     &= \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt + (\\langle P, \\delta Q \\rangle + \\delta G)\\Big|_{t_0}^{t_1} \\\\     &= \\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt + \\langle p, \\delta q \\rangle \\Big|_{t_0}^{t_1}  \\end{aligned}\\]\nThe boundary terms are equal, since \\(\\langle p , \\delta q \\rangle - h \\delta t = \\langle P, \\delta Q \\rangle - H\\delta t + \\delta G\\), and \\(\\delta t = 0\\) as we fixed \\(t_0, t_1\\).\nThus, for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\),\n\\[\\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt = \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt\\]\nThus, if \\(\\gamma\\) satisfies Hamiltonian equations of motion for \\((q, p), h\\), then it also does so for \\((Q, P), H\\). ◻ :::\n\n\nCoordinate-based canonical transforms\nThis section might make more sense after reading the next section.\nThe equation\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nlives in phase spacetime. That is, \\(dq, dt, dQ, dG\\) are all differentials in \\(\\R \\times \\mathcal P\\). This is elegant, but not good for concrete computations, which requires coordinate-based equations.\nGenerally, \\(G(t, y)\\) is a function on phase spacetime, so it could be represented in any coordinate system of phase spacetime. For example, we can represent it as \\(G(t, y) = G_{q, p}(t, q(t, y), p(t, y))\\), or \\(G(t, y) = G_{Q, P}(t, Q(t, y), P(t, y))\\), or even mixed coordinates like \\(G(t, y) = G_{q, P}(t, q(t, y), P(t, y))\\), etc.\nMost representations result in intractable coordinate-based equations, but a few are actually usable. These are traditionally classified as \"type 1\" to \"type 5\".\nType 1: \\(G(t, y) = F_1(t, q(t, y), Q(t, y))\\).\nPlugging it in, we find\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_1 dt + \\langle \\nabla_q F_1, dq \\rangle + \\langle \\nabla_Q F_1, dQ \\rangle\\]\nyielding the equations\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q) \\\\     p = \\nabla_q F_1(t, q, Q) \\\\     P = - \\nabla_Q F_1(t, q, Q) \\end{cases}\\]\nIn order to solve for the canonical transform, first invert \\(p = \\nabla_p F_1(t, q, Q)\\) to obtain \\(Q = f_Q(t, q, p)\\), then plug it into \\(P = - \\nabla_Q F_1(t, q, Q)\\) to obtain \\(P = f_P(t, q, p)\\). Inverting them gives us \\(q = g_q(t, Q, P), p = g_p(t, Q, P)\\).\nThen, given any Hamiltonian \\(h(t, q, p)\\), the corresponding \\(H(t, Q, P)\\) is found by \\(H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q)\\), or very explicitly,\n\\[H(t, Q, P) = h(t, g_q(t, Q, P), g_p(t, Q, P)) + \\partial_t F_1(t, g_q(t, Q, P), Q)\\]\nType 2: \\(G(t, y) = F_2(t, q(t, y), P(t, y)) - \\langle P(t, y), Q(t, y)\\rangle\\).\nWhy \\(\\langle P, Q\\rangle\\)? Directly writing down \\(G = F_2(t, q, P)\\) results in the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_2 dt + \\langle \\nabla_q F_2, dq \\rangle + \\langle \\nabla_P F_2, dP \\rangle\\]\nHere, there is an entanglement between terms \\(dq, dQ, dP\\). Since there are only \\(2N\\) dimensions in the phase space, but there are \\(3N\\) differentials in \\(dq, dQ, dP\\), it must be possible to represent \\(N\\) of them as a linear combination of the other \\(2N\\) differentials. In particular, we can represent \\(dQ\\) as a linear combination of \\(dq, dP\\).\nInstead, we can directly cancel out \\(\\langle P, Q\\rangle\\) from the equation by writing \\(G\\) as \\(G + \\langle P, Q\\rangle - \\langle P, Q\\rangle\\), then represent \\(G + \\langle P, Q\\rangle\\) as \\(F_2(t, q, P)\\). This then gives\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_2(t, q, P) \\\\     Q = \\nabla_P F_2(t, q, P) \\\\     p = \\nabla_q F_2(t, q, P) \\end{cases}\\]\nType 3: \\(G = F_3(t, p, Q) + \\langle p, q\\rangle\\).\nType 4: \\(G = F_4(t, p, P) + \\langle p, q\\rangle  - \\langle P, Q\\rangle\\).\nType 5: \\(G = F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) + \\langle p_{I_1}, q_{I_1} \\rangle - \\langle P_{I_3}, Q_{I_3} \\rangle\\).\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     q_{I_1} = -\\nabla_{p_{I_1}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     p_{I_2} = \\nabla_{q_{I_2}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     Q_{I_3} = \\nabla_{P_{I_3}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     P_{I_4} = -\\nabla_{Q_{I_4}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\end{cases}\\]\nHere, \\(I_1, I_2, I_3, I_4\\) stand for subsets of the indexing set \\(\\{1, 2, ..., N\\}\\). We also require \\(I_1 \\cup I_2 = I_3 \\cup I_4 = \\{1, 2, ..., N\\}\\)\nNote that types 1 to 4 are all special cases of type 5.\n\n\nExamples of canonical transforms\n\nPoint transforms\nIf \\(G= 0\\), then we need to solve only the equation \\(\\langle p, dq \\rangle = \\langle P, dQ \\rangle\\), which can be done in general iff \\(dQ\\) is a linear combination of \\(dq\\), thus \\(Q = f_Q(t, q)\\) for some function \\(f_Q\\). This is just the point transform, with solution\n\\[P = ([\\nabla_q f_Q]^T)^{-1}p\\]\n\n\nInterpolating a canonical transform\nGiven any canonical transform from \\((q, p)\\) to \\((Q, P)\\), for any two times \\(t_0 &lt; t_1\\), we can interpolate between \\((q, p), (Q, P)\\) over the period \\([t_0, t_1]\\). That is, we construct a canonical transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) such that \\((\\bar q, \\bar p) = (q, p)\\) at \\(t=t_0\\), and \\((\\bar q, \\bar p) = (Q, P)\\) at \\(t = t_1\\).\nThe idea is to note that any canonical transform can be written in type 2, including the identity transform.\nThe identity transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) can be represented in type 2 as\n\\[G_0 = \\langle q, \\bar p \\rangle - \\langle \\bar p, \\bar q \\rangle\\]\nGenerate the transform from \\((q, p)\\) to \\((Q, P)\\) by \\(G\\), and represent it in type 2 as\n\\[G_1 = F_2(t, q, P) - \\langle P, Q \\rangle\\]\nNow interpolate them by\n\\[G = \\frac{t_1-t}{t_1 - t_0} \\langle q, \\bar p \\rangle + \\frac{t - t_0}{t_1 - t_0} F_2(t, q, \\bar p)  - \\langle \\bar p, \\bar q \\rangle\\]\n\n\nTime-evolution is a canonical transform generated by the action\nRecall that, for any coordinate system \\((q, p)\\) and Hamiltonian \\(h\\), we defined the action function (\"Hamilton’s principal function\") \\(S(t_1, q_1; t_0, q_0)\\) to be the action for the path \\(\\gamma\\) from \\((t_0, q_0)\\) to \\((t_1, q_1)\\). We also proved, during derivation of the HJE,\n\\[dS = \\langle p_1, dq_1 \\rangle -h(t_1, q_1, p_1) dt_1 - \\langle p_0, dq_0 \\rangle + h(t_0, q_0, p_0) dt_0\\]\nRearrange, and using suggestive notation, we get...\n\\[\\langle p_0, dq_0 \\rangle - h_0 dt_0 = \\langle p_1, dq_1 \\rangle -h_1 dt_1 + dS\\]\nSo we find that time evolution is a canonical transformation generated by \\(S\\).\nIn more detail, fix some coordinate system \\((q, p)\\). Then for any Hamiltonian \\(\\mathcal H : \\R \\times \\mathcal P \\to \\R\\), define its time-evolution function \\(\\phi\\), such that \\(\\phi(t_0, t_1; y)\\) is the point that we end up with at time \\(t_1\\), if we start at \\(y\\) at time \\(t_0\\), and evolve according to \\(\\dot q = \\nabla_p h, \\dot p = -\\nabla_q h\\), where \\(h(t, q(t, x), p(t, x)) = \\mathcal H(t, x)\\) is the coordinate-based version of the coordinate-free \\(\\mathcal H\\).\nNow, fix some time-interval \\(s\\in \\R\\), then define the (coordinate-free) function \\(\\mathcal G\\), the action of the trajectory starting at \\((t, y)\\) and lasting for \\(s\\):\n\\[\\mathcal G(t, y) := S(t+s, q(t+s, \\phi(t, t+s; y)); t, q(t, y))\\]\nand the new coordinate system with a new Hamiltonian, obtained by \"evolving for \\(s\\) time\": \\[\\begin{aligned} Q(t, y) = q(t+s, \\phi(t, t+s; y)) \\\\ P(t, y) = p(t+s, \\phi(t, t+s; y)) \\\\ H(t, Q(t, y), P(t, y)) = \\mathcal H(t + s, \\phi(t, t+s; y)) \\end{aligned}\\]\nwhich allows a coordinate-based representation of \\(\\mathcal G\\):\n\\[G(t, q, Q) = S(t+s, Q; t, q)\\]\nWith these definitions, we have\n\\[dG = -Hdt + \\langle P, dQ \\rangle + hdt -\\langle p, dq \\rangle\\]\nthat is, \\((Q, P), H\\) is canonically transformed from \\((q, p), h\\) via the function \\(G\\).\n\n\n\nSimple harmonic oscillator\nConsider a SHO with \\(N\\) degrees of freedom. Its Hamiltonian is\n\\[H = \\frac 12 p^T M^{-1} p + \\frac 12 q^T K q\\]\nwhere \\(M\\) is the matrix representing the masses of the system, and \\(K\\) is the matrix representing the elastic constants of the system.\n\nTranslation is a canonical transform generated by momentum\n\n\nRotation is a canonical transform generated by angular momentum\n\n\n\nCanonical transforms, in general\nThere are two possible ways to define canonical transforms. The more concrete way is by using generating functions: two coordinate systems \\((q, p), (Q, P)\\) on phase spacetime are generated canonical transforms of each other iff\n\\[\\langle p, dq\\rangle - \\langle P, dQ\\rangle = dG\\]\nfor some \\(G\\) functions on phase spacetime. Remember that \\(dq, dQ\\) are differentials with constant time.\nAs for the more abstract form... long story short: every canonical transform has a generating function. This is usually called \"Carathéodory Theorem\". See (Goldstein, Poole, and Safko 2008, sec. 9.5).\nThis has a more elegant form with exterior calculus. Take exterior differentiation (again, only in phase space, not in time), we get\n\\[\\sum_i dp_i \\wedge dq_i = \\sum_i dP_i \\wedge dQ_i\\]\nNow take wedge product \\(N\\) times with itself, we get\n\\[\\bigwedge_i dp_i \\wedge dq_i = \\bigwedge_i dP_i \\wedge dQ_i\\]\nInterpretation: canonical transforms preserve phase space volumes. That is, if we have an open subset in phase space, defined coordinate-free, then we can compute its volume by writing down a canonical coordinate system \\((q, p)\\) and integrating \\(\\prod_i dp_i dq_i\\). The result is unchanged by a canonical transform to \\((Q, P)\\).\nThis gives us a new proof of Liouville’s theorem:\n\nProof. Since time-evolution is a canonical transform, time-evolution preserves volumes.\nGiven a particle flow in phase space, with density \\(\\rho(t, p, q)\\), flowing according to Hamiltonian \\(H(t, q, p)\\). Take an infinitesimal cube around \\((q, p)\\) at time \\(t\\), with volume \\(\\delta V = \\prod_i \\delta p_i \\delta q_i\\), then it contains \\(\\delta N = \\rho(t, q, p) \\delta V\\) number of particles. Then, let it flow for time \\(s\\).\nThe infinitesimal cube is transported to some other parallelogram around some point \\((q', p')\\), but its volume is unchanged, thus the density at the new location is still the same: \\(\\rho(t+s, q', p') = \\rho(t, q, p)\\). Thus \\(\\dot \\rho = 0\\). \n\n\n\nPoisson brackets are preserved by canonical transforms\nThe Poisson bracket \\(\\{f, g\\}\\) was defined in a coordinate-based way:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nWe show that it is preserved by canonical transforms. That is, if \\((Q, P)\\) is a canonical transform of \\((p, q)\\) then\n\\[\\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right) = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial Q_{i}} \\frac{\\partial g}{\\partial P_{i}} - \\frac{\\partial f}{\\partial P_i} \\frac{\\partial g}{\\partial Q_i}\\right)\\]\n\nProof. (From the Landau–Lifshitz textbook) Since the Poisson bracket does not depend on time, and if \\(Q(t, q, p), P(t, q, p)\\) is a canonical transform, so is \\(Q(t, q, p), P(t, q, p)\\), so we consider only canonical transforms that are independent of time.\nIf we started with only \\(f(q, p), g(q, p)\\), then extend them to phase spacetime by\n\\[\\mathcal F(t, y) = f(q(0, y), p(0, y)),\\quad \\mathcal G(t, y) = g(q(0, y), p(0, y))\\]\nNext, impose \\(\\mathcal G\\) as a Hamiltonian, and evolve the physical system according to Hamilton’s equations of motion for \\((q, p), \\mathcal G\\). Since \\((q, p)\\) and \\((Q, P)\\) are canonical transforms of each other, we have\n\\[\\{\\mathcal F, \\mathcal G\\}_{q, p} + \\partial_t \\mathcal F = \\dot{\\mathcal F} = \\{\\mathcal F, \\mathcal G'\\}_{Q, P} + \\partial_t \\mathcal F\\]\nOkay, what is \\(\\mathcal G'\\)? It is a solution to\n\\[\\langle p, dq \\rangle - \\mathcal G dt  = \\langle P, dQ \\rangle - \\mathcal G' dt + d\\mathcal K\\]\nsince \\(\\mathcal K\\) does not depend on time, \\(d\\mathcal K\\) contains zero \\(dt\\) term, so \\(\\mathcal G = \\mathcal G'\\).\n\n\n\nInterpretation of canonical transforms\nWhat is invariant under canonical transforms is what is really real about the physical system. Other things are mirages, illusions caused by our choice of coordinates.\nThus, position and momentum are mirages. Hamiltonian equations are real. \\(p, q\\) are mirages. \\(\\int \\sum_i p_i dq_i\\) is real. \\(\\nabla_p, \\nabla_q\\) are mirages. Poisson brackets \\(\\{f, g\\}\\) are real. Phase space lengths \\(dp, dq\\) are mirages. Phase space areas \\(\\sum_i p_i dq_i\\), volumes \\(\\prod_i dp_i dq_i\\), and densities \\(\\rho\\) are real."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe geometry of physical states\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Mechanics\n\n\n\n\n\n\nmath\n\n\nphysics\n\n\nphilosophy\n\n\nprobability\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipia Philosophica Naturalium Mathematicarum\n\n\nPhilosophical Principles of Natural Mathematics\n\n\n\nmath\n\n\nphysics\n\n\nphilosophy\n\n\ncs\n\n\n\n.\n\n\n\n\n\nApr 11, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation and GDP since 10000 BC\n\n\n\n\n\n\nAI\n\n\nscaling\n\n\n\nWhen did the singularity get cancelled?\n\n\n\n\n\nJan 18, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nMathematical Interpretations of Quantum Mechanics\n\n\n\n\n\n\nphysics\n\n\n\nQuantum mechanics: what it all means, mathematically speaking.\n\n\n\n\n\nJan 10, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nTemplate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nBook Reviews\n\n\n\n\n\n\nbook-review\n\n\n\nBook reviews.\n\n\n\n\n\nDec 16, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nThe Decline of Mathematical Fields\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nhistory\n\n\nmath\n\n\n\nLosing my religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nWhat does it feel like to be a mathematical object?\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nmath\n\n\n\nMy religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n  \n  \nYuxi Liu is a PhD student in Computer Science at the Berkeley Artificial Intelligence Research Lab, researching on the scaling laws of large neural networks."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html",
    "href": "blog/posts/ai-creativity/index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#introduction",
    "href": "blog/posts/ai-creativity/index.html#introduction",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "href": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "title": "Yuxi on the Wired",
    "section": "The self-interest theory",
    "text": "The self-interest theory\nThe self-interest theory is as follows: “It is hard to get someone to understand something if something they care about depends on their not understanding it.”"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "href": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "title": "Yuxi on the Wired",
    "section": "The non-truth theory",
    "text": "The non-truth theory\nThe non-truth theory states that some arguments are forever mired in the same controversies, always rehashing the same arguments, because there is no truth to be found underneath the arguments.\nThere are certain social functions that are best served by saying something in language that looks like they talk about objective things. You can think of this as a hack in the programming language of humans. For example,\nThere are some social functions that"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems terrible that machines might create",
    "text": "Why it seems terrible that machines might create\nAt the “immortal dinner party” held by Benjamin Haydon on 28 December 1817, the Romantic poet John Keats agreed with Charles Lamb that Newton “had destroyed all the poetry of the rainbow, by reducing it to the prismatic colors”. Later, Keats wrote “Lamia” that included these famous lines:\nDo not all charms fly\nAt the mere touch of cold philosophy?\nThere was an awful rainbow once in heaven:\nWe know her woof, her texture; she is given\nIn the dull catalogue of common things.\nPhilosophy will clip an Angel's wings,\nConquer all mysteries by rule and line,\nEmpty the haunted air, and gnomed mine—\nUnweave a rainbow, as it erewhile made\nThe tender-person'd Lamia melt into a shade\nGPT4: Keats came up with the concept of “negative capability.” This is the ability to dwell in uncertainties, mysteries, doubts, without any compulsive reaching after fact and reason. Keats valued this ability, arguing that it was central to a poet’s creative process."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems incredible that machines might create",
    "text": "Why it seems incredible that machines might create\nHere, the arguments are easier to classify. It seems that there are several common mental models that people use when they think about machines that create. Using any of these would make it seem obvious that machines cannot be creative. So, I just need to classify the mental models!\n\nMachines as monkeys typing randomly\nIn Gulliver’s Travels (1726) by Jonathan Swift, there was a writing machine. It is a 16x16 matrix of little square blocks, with a character on each side. To use it, you turn the 32 handles randomly, then read out the few words that appeared by chance. This allowed:\n\nthe most ignorant person, at a reasonable charge, and with a little bodily labour, might write books in philosophy, poetry, politics, laws, mathematics, and theology, without the least assistance from genius or study.\n\nIt is a clear satire, possibly of Ramon Llull’ s Thinking Machine (3 concentric rotating disks that generate all possible theological arguments):\n\nThe first of these features means that all of these attributes are inherent; the second, that they are systematically interrelated in such a way as to affirm, with impeccable orthodoxy, that glory is eternal or that eternity is glorious; that power is true, glorious, good, great, eternal, powerful, wise, free, and virtuous, or benevolently great, greatly eternal, eternally powerful, powerfully wise, wisely free, freely virtuous, virtuously truthful, etc., etc.\n\n\n\nMachines as pipes for the water of creativity\n\nIt appears to me that if one wants to make progress in mathematics one should study the masters and not the pupils.\n\n— N.H. Abel (1802–1829), quoted from an unpublished source by O. Ore in Niels Henrik Abel, Mathematician Extraordinary, p. 138.\nThere is a common attitude that I can summarize as this: Like drawing water from the unsullied source at the mountain’s peak, so is the experience of returning to the writings of the masters: clear, refreshing, and devoid of later impurities.\n\nAncient Greek theory of creativity\nIn ancient Greece, the Muses were considered the source of the knowledge embodied in the poetry, lyric songs, and myths that were related orally for centuries in ancient Greek culture. Homer began his Iliad with:\n\nSing, Muse, the fatal wrath of Peleus’ son,\nWhich to the Greeks unnumb’red evils brought,\n\nNote that the Muses was doing the real singing, and Homer was a channel for their singing (back then, poetry was sang – the Iliad was written down only after a few centuries). In Plato’s dialog Ion, Socrates (perhaps a sockpuppet of Plato) argued that “it is not by art that poets compose… but by divine apportionment”:\n\nFor the poets tell us that they carry honey to us from every quarter like bees, and they fly as bees do, sipping from honey-flowing fountains in glens and gardens of the Muses. And they tell the truth. For a poet is a delicate thing, winged and sacred, and unable to create until he becomes inspired and frenzied, his mind no longer in him; as long as he keeps his hold on that, no man can compose or chant prophecy. Since, then, it is not by art that poets compose and say many beautiful things about their subjects, as you do about Homer, but by divine apportionment, they each can do well only that to which the Muse directs them-this one dithyrambs, that one odes, or encomia, or dances, or epics, or iambics-each of them worthless in respect to the others.\n\nThe same point was made repeatedly in Plato’s corpus.\n\nJust as the rhapsode says what he says about Homer not by art but by divine apportionment, without intelligence (Ion 534b-c, 536c, 542a), so in the Meno (gge-looa) politicians get their virtue by divine apportionment, without intelligence; they have no more wisdom than seers and soothsayers, who say many fine things but know nothing of what they say; politicians are divine and inspired like poets, and possessed by the god (Meno 9gb-e). The irrational effects of poetry and rhapsody are directly comparable to the irrational effect of vulgar politics, whose servant is vulgar rhetoric (cf. Gorgias 502C).\n\nBoth quotes came from The Dialogues of Plato, Volume 3: Ion, Hippias Minor, Laches, Protagoras, translated by R. Allen. (I decided not to use one of the freely available versions since they tended to mistranslate “gods” as “God”.)\nFor example, in Phaedrus 245a, Socrates claimed that “the poetry of the sane man vanishes into nothingness before that of the inspired madmen”:\n\nAnd a third kind of possession and madness comes from the Muses. This takes hold upon a gentle and pure soul, arouses it and inspires it to songs and other poetry, and thus by adorning countless deeds of the ancients educates later generations. But he who without the divine madness comes to the doors of the Muses, confident that he will be a good poet by art, meets with no success, and the poetry of the sane man vanishes into nothingness before that of the inspired madmen.\n\n\n\nLater manifestations\nIsaac Newton thought he was merely recovering what the ancients have known all along. His friend William Stukeley described Newton as “the Great Restorer of True Philosophy”.\n\n\nApplication to machine creativity\n\n\n\nMachines as flowers for the DNA of creativity\nFrom Lovelace’s “Notes by the Translator”:\n\nThe Analytical Engine has no pretensions whatever to originate any thing. It can do whatever we know how to order it to perform. (source)\n\nIn his seminal paper “Computing machinery and intelligence” (1950), Alan Turing referenced Lovelace’s observation as the sixth objection to the possibility that machines might think. He then objected:\n\nThe view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. It is a very useful assumption under many circumstances, but one too easily forgets that it is false. (source).\n\nTuring was led to Lovelace’s objection by debates with Douglas Hartree, who in his book “Calculating Instruments and Machines” (page 70, 1949), quoted Lovelace approvingly. He objected using the phrase “electronic brain” for devices like electronic calculating machines or automatic pilots. He clarified that these machines cannot “think for themselves” and can only execute the instructions provided to them.\nThus, machines, in this view, are akin to flowers—organisms that reproduce and grow according to a predetermined genetic code but do not originate new genetic information on their own. Creativity, like DNA, must be instilled by a designer or operator, who programs the machine with the “genetic code” of what to create.\nAs a short etymological fun fact, the word “development” is a little capsule of the “flower for the DNA” idea:\n\nFirst use 1756, from French développement (“unrolling”). Compare with envelopment (“rolling”).\n\nThe idea is that of “opening up a scroll and showing what has always been written there. In the machines’ creative process can be seen as a similar”unrolling” of predetermined instructions or codes, much like the genetic “unrolling” in a blooming flower.\nThis is most explicitly manifest in the idea of preformationism, prevalent around 17th to 18th century. It seems the same intuitive appeals of preformationism apply to Lovelace’s objection.\n(A brief personal anecdote: When I was a kid, I thought bus cards contained tiny compressed coins inside, and when you “beep” them, those tiny coins fall into the machine through tiny openings on the card. Preformationism in economics!)"
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html",
    "href": "blog/posts/decline-of-mathematics/index.html",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "href": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/mathematical-phenomenology/index.html",
    "href": "blog/posts/mathematical-phenomenology/index.html",
    "title": "What does it feel like to be a mathematical object?",
    "section": "",
    "text": "TODO: change the folder name, and title, etc.\nStructuralism"
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html",
    "href": "blog/posts/principia-mathematicarum/index.html",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "",
    "text": "# The world as theories and interpretations\nWhat is light? Newton said it was a particle1. Huygens said it was a wave. Schrödinger said it was both. Some clever fool said it was a wavicle. And Feynman said it was whatever helps you sleep at night shuts you up and lets you calculate.\nSo is light a particle, or a wave? None of these explanations satisfied me, so I figured it out for myself."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "href": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "The wave-particle duality",
    "text": "The wave-particle duality\nThere are more than one wave-particle duality. In fact, there is nothing particularly two-ful or wave-ful or particle-ful about physics! Why are we so confused about wave-particle duality? I blame force of habit and evolution.\n\nA particle is a curve. That is, it is a function \\(\\gamma: (a, b) \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathcal M\\) is a manifold.\nA field is a function \\(\\phi: \\mathcal M \\to Y\\), where \\(Y\\) is any manifold you like. We say the field is \\(Y\\)-valued.\nA scalar field is a real-valued field.\nA wave is a more confusing name for a field. Why \"confusing\"? Because the word \"wave\" makes people think the field must be \"going up and down\" here, there, or everywhere, but the fact is, a field can be exactly flat everywhere, and still be a wave! So why did physicists call it a \"wave\" when they really mean a field? Well, force of habit... back in the old days, the only field they knew of is the water-wave, which can be described mathematically as \\(h: \\R^2 \\to \\R\\), where \\(h(x)\\) is the height of water at location \\(x\\).\nA particle theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain paths in \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA field theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain fields over \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA wave theory is a field theory.\nA wave-particle duality over a manifold \\(\\mathcal M\\) is a tuple \\((T, T', f)\\). Here, \\(T\\) is a particle theory over \\(\\mathcal M\\), and \\(T'\\) is a field theory over \\(\\mathcal M\\), and \\(f\\) is an equivalence between \\(T, T'\\).\nA wave-equation is a differential equation satisfied by a field.\nAn equation of motion (of a particle) is a differential equation satisfied by a particle.\n\nIf our physical theory has a very special \"physical space\" \\(\\mathcal M\\), then a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\R\\) represents time. In other words, a particle is nothing more and nothing less than a trajectory in spacetime. This is what we mean by a \"particle\" by default, even though sometimes we would deal with \"timeless particles\", for which time is meaningless, and a particle must instead be a function \\(\\gamma: (a, b) \\to \\mathcal M\\).\nTimeless particles? Why yes! That’s how we study geometric optics as the study of light-rays.\n\nIn geometric optics\n\n\nIn Hamiltonian mechanics\n\n\nIn quantum mechanics"
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "href": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Crash course in modern theoretical physics",
    "text": "Crash course in modern theoretical physics\nRecall that a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\). But what if we don’t use an interval \\((a, b)\\), but use a square, or a cylinder, or even a cube? This leads us to the idea of strings, branes, and other such fancy frontiers of theoretical physics.\n\nString theory\nA closed string is a function \\(\\mu: (a, b) \\times \\mathbb S^1 \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathbb S^1\\) is the circle.\nAn open string is a function \\(\\mu: (a, b) \\times (0, 1)\\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers.\nA string theory is made of two parts: one, the types of strings that it decides about; two, a way to decide if a string is physical or unphysical.\n\n\nHow to make your own variational physical theory\n\nFind a manifold \\(\\mathcal A\\).\nFind another manifold \\(\\mathcal B\\).\nDefine a family of functions of type \\(\\mu: \\mathcal A \\to \\mathcal B\\). This will be the domain of your physical theory.\nWrite down an action function \\(S(\\mu)\\).\nSpecify a way to \"vary \\(\\mu\\) infinitesimally\". Write that as \\(\\delta\\).\nDerive consequences of \\[\\delta S(\\mu) = 0.\\]\n\nFollowing the recipe, we immediately get Lagrangian mechanics and Hamiltonian mechanics.\nNow, we made a small sleight of hand in the recipe. Can you spot it? It is in steps 4 and 5. Namely, we have claimed that we can \"write down an action function\" and \"vary \\(\\mu\\) infinitesimally\". However, not every \\(\\mathcal A, \\mathcal B\\) has enough structure to allow us to do that. The art of doing theoretical physics is mostly in putting in enough structure in \\(\\mathcal A, \\mathcal B\\) so that you can define \\(S(\\mu)\\) and \\(\\delta S(\\mu)\\).\n\n\nHow to clothe your manifolds\n::: epigraph The world found nothing sacred in the abstract nakedness of being human.\nHannah Arendt, The origins of totalitarianism :::\nSince a mere manifold is not structured enough for defining actions and infinitesimal variations, we will \"clothe\" the manifolds with enough structures so that they do. To make this concrete, we will consider how we could construct Lagrangian mechanics and Hamiltonian mechanics according to the recipe.\nLagrangian\nHamiltonian\nAnd if you go deep into theoretical physics, you will eventually encounter Calabi–Yau manifolds, which are \"compact Kähler manifolds with a vanishing first Chern class and a Ricci-flat metric\". All these extra structures give them enough theoretical niceness for elegant string theories.\n\n\nExercise for the reader\nApply the recipe to your favorite manifolds, and get it published in a journal of physics with an impact factor of at least 2."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of classical mechanics",
    "text": "Interpretations of classical mechanics\nFigure 3 shows six main interpretations of classical mechanics. They are all equivalent in some exact mathematical sense.\n\n\n\nSix main interpretations of classical mechanics.\n\n\n\nPosthuman classical mechanics\nWhat is it like to be a bat? What is it like to be a robot? The umwelt, seeing in infrared."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of quantum mechanics",
    "text": "Interpretations of quantum mechanics"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html",
    "title": "Hole Argument and Inverted Qualia",
    "section": "",
    "text": "problems\neasy\nhard\nmeta\n\n\n\n\nclassical gravity\nHow to model astronomical phenomena with some distribution of mass-points in \\(\\R^3\\)?\nOut of all the equivalent models, which one is the right one?\nWhy did Newton insist on absolute space, but Leibniz on relative space?\n\n\ngeneral relativity\nHow to model astronomical phenomena with some \\((\\mathcal M, g, T)\\)?\nHole argument: Out of all the isometric models, which one is the right one?\nWhy did Einstein and Hilbert fall for the hole argument?\n\n\ncolor\nPsychophysics: How to model human perception of color?\nQualia: Why does red feel like red?\nWhy are people prone to argue about the inverted spectrum?\n\n\nlanguage\nHow to model language use?\nWhy is language use associated with a feeling of understanding?\nWhy are people prone to argue about the Chinese room?\n\n\nconsciousness\nHow to explain objective phenomena associated with consciousness, such as attention, working memory, dreaming, etc?\nWhy does paying attention, dreaming, etc, feel like something?\nWhy are people prone to argue about the hard question?\n\n\n\n\n\n\nShifted qualia and the hole argument. Figure modified from (Norton, Pooley, and Read 1999) and Wikimedia Commons\n\n\n\n\n\nInverted qualia and Leibnitz’s inverted space. Figure modified from (Norton, Pooley, and Read 1999) and Wikimedia Commons"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#section",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#section",
    "title": "Hole Argument and Inverted Qualia",
    "section": "",
    "text": "BIB.\n\nhttps://plato.stanford.edu/ENTRIES/spacetime-holearg/\n\nThe hole argument, in Norton’s formulation\n\nGiven two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since\n\nThe two distributions are observationally identical.\nThe laws of the theory cannot pick between the two developments of the fields into the hole.\n\nBut by manifold substantivalism, they represent distinct physical systems.\nTherefore, manifold substantivalism has a problematic metaphysics.\n\n\n\nMacdonald, Alan. “Einstein’s hole argument.” American Journal of Physics 69.2 (2001): 223-225.\n\n\n\nRelationalism\n\nThis is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In a passage that predates the inverted qualia thought experiment, Leibniz imagined the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place – ergo, space is relational, not absolute.\n\nLeibniz’s third paper, in Samuel Clarke, A Collection of Papers, Which passed between the late Learned Mr. Leibnitz, and Dr. Clarke, In the Years 1715 and 1716 (London: 1717).\n\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\n\nThe hole argument as a prototype for gauge freedom.\n\nIf two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\n\n\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\n\n\nMetric essentialism\n\nMaudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\n\nNon-duality\n\nIt is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\) , then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces – where there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#inverted-qualia",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#inverted-qualia",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Inverted qualia",
    "text": "Inverted qualia\n\nInverted qualia\nThe inverted qualia thought experiment has been used, like the philosophical zombie, in a whole host of arguments involving consciousness and the qualia. We consider the case involving functionalism, which is currently the most fashionable among cognitive psychologists and computer scientists. Other variants are reviewed in (Byrne 2004).\nAccording to functionalism, mental states are best understood as functional states, that is, mathematical functions that map perceptual inputs to behavioral outputs. It’s the intricate web of causal relations that constitutes a mental state, rather than the specific physical makeup realizing those relations.\nIn the anti-functionalism case, we consider two individuals, “Invert” and “Nonvert”, are functionally identical. They receive the same visual input (a tomato), undergo the same internal processing, and produce the same behavioral outputs (saying “that’s a red tomato”). However, their subjective experiences – their qualia – differ drastically. Where Nonvert sees red, Invert experiences green (or another color qualia entirely). They outwardly behave in the same way, and all functional measurements, from verbal reporting, psychological experiments, to MRI scanning, all find them the same, and yet the qualia of any color the Invert sees is rotated 180 degrees compared to that of the Nonvert.\nFormally:\n\nThe following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.\nThus, the mental does not supervene on functional organization.\nThus, functionalism is false.\n\n\n\nPrecursors\n(Eastwood 1986)\nAlhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.\n\n\n\nLeonardo da Vinci’s drawings comparing the eye to a camera obscura. From Codex Atlanticus (1490-1495). Figure from Wikimedia Commons.\n\n\n\n… certain extravagant situations are to be avoided, as they would create ‘monstrosities’, or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say.\n\n\n\n\nIllustration from Descartes’ Treatise of Man.\n\n\n\n\nAlternative examples\nOne objection from color science states that color space is not symmetric, and does not actually allow inversion as in the thought experiment. For example, saturated yellow does not merely look different from saturated red, but also looks brighter. In this view, “simply yellow” is not simply yellow. A point in color space is not simply a point. It is already inherently structured. Yellow is the brightest of all saturated colors, while violet is the dimmest, etc. (Hilbert and Kalderon 2000) argued that every possible quality space must be asymmetrical, in the sense that the only automorphism is the identity map, of \\(x \\mapsto x\\).\nThis appears to me an objection that is too strong, as there really do exist quality spaces that are symmetric. In humans, left and right are symmetric. Indeed, there are some highly symmetric quality spaces in nature.\nLight, being electromagnetic waves, can be polarized. The space of possible polarizations is isomorphic to a ball, the Poincare ball. The mantis shrimp species Gonodactylus smithii can detect the polarization of light over the entire 3-dimensional Poincaré ball (Kleinlogel and White 2008). It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.\n\n\n\nPolarization states on the Poincaré ball. Figure from Wikimedia Commons.\n\n\nNow, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincaré ball is inverted compared to yours? That is, what if when you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, and similarly across all of the ball? We can even imagine more exotic reflections, such as one that reflects across the \\((0.3, 0.3, 0.9)\\) direction, etc."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#color-space",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#color-space",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Color space",
    "text": "Color space\n\nHuman eye structure\nSpectral sensitivity and response\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short).\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is essentially a deterministic function that maps a spectral flux density to three response intensities. Mathematically, it is a function\n\\[C(P) := (I_S(P), I_M(P), I_L(P))\\]\nwith type \\((\\R^+ \\to \\R^+) \\to (\\R^+)^3\\), where \\(\\R^+ = [0, \\infty)\\) is the space of non-negative real numbers.\nThe color space is the range of the function \\(C\\). Because \\(C\\) is a linear functional, color space is a convex cone-shaped subset of \\(\\R^3\\). On the edge of the cone are the pure colors, produced by spectra that are concentrated at just one wavelength. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness.\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the gamut are points of pure spectral colors, from pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.\nFor any three spectra \\(P_1, P_2, P_3\\), we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-hole-argument",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-hole-argument",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The hole argument",
    "text": "The hole argument\nIn general relativity, the hole argument is a thought experiment that apparently shows that general covariance is impossible. Einstein in late 1913, and David Hilbert in 1915, both fell into the hole argument. Misled by the hole argument, Einstein attempted to study theories of gravity that are not generally covariant, before finally giving up and . (Norton, Pooley, and Read 1999)\n\nA brief history of spacetime\nThe history of spacetime is a history of expanding symmetries.\nIn the most ancient cosmology of China, the earth is a square, while the sky is a half-bowl covering the earth. Each direction of earth – east, west, south, north – has a mystical significance. Up is not down, and east is not west. Not only that, there is a center of earth, somewhere in The Middle Kingdom. Thus, there is no spatial symmetry. The world was born an unspecified number of years in the past out of a chaotic egg. Thus, there is no temporal symmetry. Therefore, ancient Chinese spacetime is \\(\\R^1 \\times \\R^3\\), with no (nontrivial) symmetry.\nIn Aristotle’s physics, there is a center of the universe, where everything heavy (water and earth) is moving towards, and everything light (air and fire) is fleeing from. Other than that, space is spherically symmetric – he knew that earth is round. However, though space has a center, time is translation-invariant. Therefore, Aristotle’s spacetime is \\(\\R^1 \\times \\R^3\\) with symmetry group \\(\\R^1 \\times SO(3)\\), where \\(\\R^1\\) is the time-translation symmetry group, and \\(SO(3)\\) is the spherical symmetry group.\nThe Christian spacetime, with a beginning and an end for time, has a smaller symmetry group of \\(\\{0\\} \\times SO(3)\\).\nCopernicus and Kepler replaced the sun for the earth as the center of the universe, but they still insisted on a center. The first true breakthrough was Giordano Bruno’s infinite spacetime, where both space and time are infinite and without center. Therefore, Bruno’s spacetime has symmetry group \\(\\R^1 \\times E(3)\\), where \\(E(3)\\) is the 3D Euclidean symmetry group. That is, we allow all spatial translations.\nGalileo braided together space and time, resulting in an even bigger symmetry group. Specifically, he argued that the universe does not have a special “at rest” velocity. To see why this is a breakthrough, consider what happens in Bruno’s universe. In Bruno’s universe, it matters whether you are staying still, or moving at \\(1 \\;\\mathrm{m/s}\\) relative to the universe. If you are staying still, then your trajectory is like \\(\\dots, (t_0, p), (t_1, p), (t_2, p), \\dots\\). Metaphorically speaking, you are sitting somewhere in the cinema of spacetime, and you can “peek at the number of your seat” and see that you have been sitting at the same space-point \\(p\\). However, if you are moving relative to the universe, you can see that your space-point is changing.\nGalileo rejects this. There is no “space-point”. You can take a slice of the universe at \\(t=0\\), and another slice of the universe at \\(t=1\\), but you cannot point at a point in each slice and ask, “Are these two points the same space-point?”.\nNewton’s concept of spacetime is harder to conceptualize. He understood Galileo’s point, and initially attempted to model spacetime the same way as Galileo did. However, for obscure reasons, he reintroduced absolute space and time. This had strange consequences that Leibnitz relentlessly criticized. Consider the inertial frame, relative to which the sun is standing still at this moment. Now consider another inertial frame, moving at \\(1 \\;\\mathrm{m/s}\\) in the direction of Sun-to-Mars at this moment. The laws of Newtonian mechanics are the same, and no observation or experiment could tell us whether one of them is the “absolute frame”, or neither of them is. Yet, out of the infinitely many inertial frames, Newton designated precisely one of them as the “absolute”, and all others are defined as those moving at constant velocity relative to the absolute frame. (DiSalle 2020)\nTo dramatize this seemingly arcane point, consider the following imaginary conversation between Newton and Leibniz about a grant proposal to find the absolute frame:\n\nThis is a proposal to find the absolute frame…\nHow would you find it? The only difference between absolute and non-absolute inertial frames is that one of them is designated so. Do the stars turn perfectly white when you are standing still in the absolute frame? Do the music of the spheres tune to a perfect pitch? Do you see it in your mind’s eye? And even if you do, what if every material point in the universe, by an act of God, were set off in this direction [points finger up] at one mile per day? Would anything seem amiss? You yourself admit that the very sustenance of the universe requires continuous divine forcing, that the stars would have collapsed to the same point otherwise.1\n… yet all relative frames has no existence without assuming the absolute frame, for otherwise, one would fall to a circular argument, where relative frames are relative to nought but each other, and the very meaning of inertiality becomes vacuous. One might as well The absolute might be hidden, but it is out there.\n1 \nIn the 1726 edition of the General Scholium, Newton added a new sentence: “And so that the systems of the fixed stars will not fall upon one another as a result of their gravity, he has placed them at immense distances from one another.” Once again, the implication is that gravity can be a destabilising force. An annotation in Newton’s copy of the 1713 edition after the words “send light into all the others” shows that he had considered an even more theologically powerful statement: “and the fixed stars would, through their gravity, gradually fall on each other, were they not carried back by the counsel of the supreme Being.”\n(Snobelen 2020)\n\nHe also believed that the Great Comet of 1680 would someday fall into the sun, causing a solar flare-up that would kill all life on earth. God would then repopulate earth. In general, he thought the universe as an unstable system requiring constant divine support. (Snobelen 2020)\nWith special relativity, the symmetry of spacetime becomes \\(SO(3, 1)\\), which is in a sense more “braided” than Galilean relativity. In Galilean relativity, the symmetry group of spacetime factors into a direct product between the symmetry group of space, and the symmetry group of time. In special relativity, the symmetry group of spacetime cannot be factored into a direct product. This is the deep meaning of Minkowski’s claim that “space for itself, and time for itself shall completely reduce to a mere shadow”.\nFor general relativity, any diffeomorphism on spacetime is a symmetry.2 In other words, it is a generally covariant theory. This is quite a vast generalization, and warrants further details.\n2 A function is a diffeomorphism iff itis one-to-one, smooth, and has a smooth inverse.\n\nGeneral relativity\nGeneral relativity models spacetime as a manifold \\(\\mathcal M\\), with a metric tensor field \\(g_{\\mu\\nu}\\) and an energy-momentum tensor field \\(T_{\\mu\\nu}\\). The metric tensor describes the spacetime separation between points on the manifold, and thereby the geometry of spacetime. The energy-momentum tensor describes the flow of energy and momentum in spacetime. In particular, a body with mass \\(m\\), such as a black hole, is a flow of energy \\(mc^2\\) in time, and therefore can be described within the energy-momentum tensor.\nThe metric tensor field and the energy-momentum tensor field are “braided together” by Einstein’s field equation:\n\\[\n(\\text{a polynomial equation involving components of }g) = \\kappa T\n\\]\nwhere \\(\\kappa\\) is a constant of nature, measured by experiments.\nThe spacetime manifold \\(\\mathcal M\\) can be transformed, in that we can write down a function \\(f: \\mathcal M \\to \\mathcal M\\), such that it maps one point in the manifold to another point. According to general relativity, if \\(f\\) is a diffeomorphism, then the field equation is unchanged. In this sense, all diffeomorphisms of \\(\\R^4\\) become symmetries of spacetime. Whereas in special relativity, inertial frames are distinguished from non-inertial frames, in that the coordinate lines in an inertial frame are deemed “straight”, no one gets special treatment in general relativity, and any smooth coordinate system is as good as any other. That is, Einstein’s field equation is generally covariant.\n\n\nProblem of time\nThe old couplet about general relativity goes like “Matter tells space-time how to curve, and space-time tells matter how to move.” but this is often misunderstood as saying “Matter exists, then space-time reacts to matter, and then matter reacts to space-time by changing its motion.” This fundamentally misunderstands what general relativity is. There is no time nor causality, at least as commonly understood, in special or general relativity.\nSpecial relativity is typically interpreted as an “eternalist” or “four-dimensionalist” theory. That is, all of space and time exist in the same way, and the future is as real as the past. Einstein said it as “the distinction between past, present, and future is only a stubbornly persistent illusion.”. It is typically supported by the Rietdijk–Putnam argument, as follows.\nWhereas in Newtonian spacetime, one can still imagine that the universe somehow “grows one time-slice at a time” – though this is susceptible to McTaggart’s objection – in special relativity, there does not exist such a thing as “time-slice”, because there is no absolute simultaneity. We may pick the time-slices in the inertial frame of the solar system, or in that of the Andromeda galaxy. However, just like how no observation can distinguish Newton’s absolute inertial frame from all the other relative inertial frames, no observation can distinguish between the absolute simultaneity from all the other relative simultaneities.\nThe difficulty is only amplified in general relativity. Let us imagine a universe that is swirling with stars and galaxies. Locally, the spacetime manifold is curved, but globally, it is topologically the same as \\(\\R^4\\) – no loops, no singularities, and no wormholes. Now, construct a coordinate system \\((t, x, y, z)\\). We can then select a “snapshot” of the universe by selecting the 3D submanifold at \\(t = 0\\). If we know the exact value of \\(g, T\\) on that snapshot, then we can crank the Einstein field equations to solve for \\(g, T\\) for all \\(t &gt; 0\\). Does this mean that the slice of \\(t=0\\) determines what happens afterwards?\nNot really. We could have smoothly distorted the coordinate system to \\((t', x', y', z')\\), and solve the Einstein field equations for all \\(t' &gt; 0\\). There are infinitely more degrees of freedom compared to special relativity, making the RP argument bite harder.\nYet, the issue goes even deeper. We could very well select \\(t = 10000\\) and crank the field equations to solve for \\(g, T\\) for all \\(t &lt; 10000\\). Does this mean that “the future determines the past?” Perhaps we can compromise by saying “one point in time determines both the past and the future”, but even that is not necessarily true. We can design much wilder boundary conditions. We can make two lightcones determine the rest of the universe (double-null, or Sachs), make one lightcone plus a “left side” of the universe determine the rest (null-timelike, or Winicour–Tamburino), make half of the universe’s left-side and half of the universe’s \\(t=0\\) determine the rest, etc.\n\n\n\nDifferent initial value conditions. The first is the commonly used Cauchy condition, but the others, more exotic, are also valid. Figure modified from (d’Inverno 1984)\n\n\n\n\nThe hole argument\nDuring 1912, Einstein struggled with finding a generally covariant field equation for gravity. He even considered the one he would eventually publish in 1915 and be famous for, but gave them up over certain difficulties. Then in late 1913, he tried to turn this loss into a victory by arguing that general covariance is not the right approach, because of the hole argument. (Norton, Pooley, and Read 1999)\nConsider the following two models of a small universe. The universe contains three galaxies moving away from each other. The model on the left shows that one of the galaxies passes the spacetime-point \\(E\\), while the model on the right shows that no galaxy passes the spacetime-point \\(E\\).\nIf the universe satisfies a generally covariant field equation, then we can transform the model on the left to the model on the right by a diffeomorphism, and the equation would be none the wiser. In other words, any generally covariant field equation suffers from rampant indeterminism.\n\n\n\nEinstein’s hole argument. Figure from (Norton, Pooley, and Read 1999)\n\n\nNow, the spacetime manifold is supposed to\nThe hole argument, in Norton’s formulation\n\nGiven two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since\n\nThe two distributions are observationally identical. The laws of the theory cannot pick between the two developments of the fields into the hole.\nBut by manifold substantivalism, they represent distinct physical systems.\n\nTherefore, manifold substantivalism has a problematic metaphysics.\n\n\n\nResponses to the hole argument\nRelationalism. This is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In Leibniz’s third paper during the Leibniz–Clarke correspondence (Clarke 1717), Leibniz proposed the “inverted space” thought experiment:3 Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place. Ergo, space is relational, not absolute.\n3 \n… supposing Space to be Something in it self, besides the Order of Bodies among themselves, that ’tis impossible there should be a Reason, why God, preserving the same Situations of Bodies among themselves, should have placed them in Space after one certain particular manner, and not otherwise; why every thing was not placed the quite contrary way, for instance, by changing East into West.\n(Clarke 1717)\n\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\nGauge freedom. If two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.(Tao 2008)\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\nMetric essentialism. Maudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\nNon-duality. It is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\), then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces, where there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#example-calculation",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#example-calculation",
    "title": "Hole Argument and Inverted Qualia",
    "section": "example calculation",
    "text": "example calculation\nMacdonald, Alan. “Einstein’s hole argument.” American Journal of Physics 69.2 (2001): 223-225."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#responses",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#responses",
    "title": "Hole Argument and Inverted Qualia",
    "section": "responses",
    "text": "responses\nRelationalism\nThis is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In a passage that predates the inverted qualia thought experiment, Leibniz imagined the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place -\nergo, space is relational, not absolute.\nLeibniz’s third paper, in Samuel Clarke, A Collection of Papers, Which passed between the late Learned Mr. Leibnitz, and Dr. Clarke, In the Years 1715 and 1716 (London: 1717).\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\nThe hole argument as a prototype for gauge freedom.\nIf two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\nMetric essentialism\nMaudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\nNon-duality\nIt is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\) , then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces -\nwhere there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#human-eye-structure",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#human-eye-structure",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Human eye structure",
    "text": "Human eye structure\nSpectral sensitivity and response\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short).\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is essentially a deterministic function that maps a spectral flux density to three response intensities. Mathematically, it is a function of type:\n\\[C: (\\R^+ \\to \\R^+) \\to \\R^3\\]\nwhere \\(\\R^+\\) means the space of non-negative real numbers. It is defined by\n\\[C(P) = (I_S(P), I_M(P), I_L(P))\\]\nDefine the color space as the range of the function \\(C\\). Because \\(C\\) is a linear functional, color space is a convex cone-shaped subset of \\(\\R^3\\). On the edge of the cone are the pure colors, produced by spectra that are concentrated at just one wavelength. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#cie-color-spaces",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#cie-color-spaces",
    "title": "Hole Argument and Inverted Qualia",
    "section": "CIE color spaces",
    "text": "CIE color spaces\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the gamut are points of pure spectral colors -\nfrom pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.\nFor any three spectra \\(P_1, P_2, P_3\\), we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.\nSubsequent color spaces are just minor adjustments to ICE 1931.\nIt defines three numbers \\(X, Y, Z\\). It was created before human cone cells were discovered. However, it turns out to be almost exactly a linear transform of \\(I_S, I_M, I_L\\), by \\[\n\\begin{bmatrix}\nX\\\\Y\\\\Z\n\\end{bmatrix}\n=\n\\left[\\begin{aligned}\n  1&.910\\,20 \\!\\!\\!&\\!\\! -1&.112\\,12 \\!\\!\\!&\\!\\! 0&.201\\,91 \\\\\n  0&.370\\,95 \\!\\!\\!&\\!\\!  0&.629\\,05 \\!\\!\\!&\\!\\! 0&         \\\\\n  0&         \\!\\!\\!&\\!\\!  0&         \\!\\!\\!&\\!\\! 1&.000\\,00\n\\end{aligned}\\right]\n\\begin{bmatrix}\nI_L\\\\I_M\\\\I_S\n\\end{bmatrix}\n\\]\nThe color gamut of CIE 1931 is defined by the projective transform\n\\[(x, y, z) := \\left(\\frac{X}{X+Y+Z},\\frac{Y}{X+Y+Z},\\frac{Z}{X+Y+Z}\\right)\\]\nusually plotted over the \\(x+y+z = 1\\) plane.\nThe RGB values required to match 1 unit of energy at each wavelength.\n700, 546.1, and 435.8 nm"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#riemannian-metric",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#riemannian-metric",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Riemannian metric",
    "text": "Riemannian metric\nThe MacAdam ellipses …\n\n\n\nMacAdam ellipses the CIE 1931 \\(xy\\)-diagram, 10× actual size. Figure from Wikimedia Commons.\n\n\n\n\n\n(da Fonseca and Samengo 2016, fig. 8b)\n\n\nFrom the \\(S_S, S_M, S_L\\) curves, we can use information theory to predict the JND in color space.\n(da Fonseca and Samengo 2016) explain ~87% of the variance of human color discrimination ability\nImagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker’s ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization – a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.\nIf the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.\nIf the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.\nNote that, while color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. (Bujack et al. 2022) reported that there is “diminishing returns” in color distances. Color difference might not even be symmetric, meaning that if we ask a subject “How far is color 1 from color 2?” and then ask the opposite direction, we might get a different answer. This reminds me of KL divergence."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#arguments",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#arguments",
    "title": "Hole Argument and Inverted Qualia",
    "section": "arguments",
    "text": "arguments\nThe inverted qualia thought experiment has been used, like p-zombie argument, in a whole host of arguments. Let’s deal with functionalism, which seems rather urgent these days, what with the advent of AI and all.\nArgument against functionalism\nThe following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.\nThus, the mental does not supervene on functional organization.\nThus, functionalism is false.\nAccording to functionalism, mental states are functional states: states defined by their causal role with respect to inputs, outputs, and other states. So, according to functionalism, necessarily, two creatures who are functionally alike are also mentally alike.\nAlhazen, Leonardo, and Late-Medieval Speculation on the Inversion of Images in the Eye (1986)\nAlhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.\n\n\n\nimage.png\n\n\n[File:1490-95 da vinci\ncodex atlanticus.jpg\nWikimedia Commons](https://commons.wikimedia.org/wiki/File:1490-95_da_vinci_-_codex_atlanticus.jpg) - &gt; … certain extravagant situations are to be avoided, as they would create ‘monstrosities’, or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#problem-of-consciousness",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#problem-of-consciousness",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Problem of consciousness",
    "text": "Problem of consciousness\n(Metzinger 2004, chapter TODO; Roden 2015, chap. 4)\nThe just noticeable difference (JND) in color perception possibly shows that we see metric, not colors themselves.\nIf the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.\nIf the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.\nThe meta-problem of consciousness (Chalmers 2018) is TODO\nThe inverted polarization spectrum for mantis shrimps. Why would they be confused?\n(Kleinlogel and White 2008)\nThe mantis shrimp species Gonodactylus smithii can detect polarization of light over the entire 3-dimensional Poincare sphere. It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.\nNow, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincare sphere is inverted compared to yours? When you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, etc."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#meta-problem-of-consciousness",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#meta-problem-of-consciousness",
    "title": "Hole Argument and Inverted Qualia",
    "section": "meta-problem of consciousness",
    "text": "meta-problem of consciousness\nOn the psychological origins of dualism: Dual-process cognition and the explanatory gap (2012)\nOn the psychological origins of dualism: Dual-process cognition and the explanatory gap (2012) collapsed:: true\nWe have Type 1 and Type 2 cognitive processes for judging if something is conscious.\nType 1 processes\nPicture\n\n\n\nimage.png\n\n\nfast, domain-specific, automatic (the authors don’t argue if they are also associative)\nThree apparent features reliably produce AGENT categorization:\nhas eye-like shapes on a head-like bump;\nreacts to the environment unpredictably;\nmoves on its own, not a slave to mere inertia.\nConfirmed by judgment-speed experiments - &gt; … presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute… Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.\nType 2 processes\nrational deliberation, theory application, or conscious reasoning\nAny brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.\nThe brain doesn’t have eyes\nThe brain seems to do nothing by itself, stewing alone in a dark cave;\nThe brain doesn’t display any motion, let alone non-inertial motion. - &gt; Since the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.\n- &gt; Jenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick & Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious\nAlternative physicalist theory of consciousness designed to satisfy Type 1 process won’t satisfy Type 2 process.\nThe eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.\nAnd lock-in syndrome people don’t interact and don’t display noninertial motions.\nEvolutionary origin of the dual process\nOnly very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.\nThus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.\nThe Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.\n(Non-)Analogies\nThe authors thought that there is no Type 1 intuition for general relativity, so there’s no explanatory gap there. But I beg to differ.\nGeneral Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent “explanatory gap”, as a nagging feeling “but how do we know which one is the real spacetime manifold? The theory is incomplete because it doesn’t tell us that.”.\nThis is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there’s a unique spacetime structure.\nAs another example, Bergson famously debated Einstein over the nature of time.\nIntentionality explanatory gap.\nSome philosophers did propose an explanatory gap.\nAlthough most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.\nThis would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics. -"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-meta-problem",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-meta-problem",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The meta-problem",
    "text": "The meta-problem\nWe have Type 1 and Type 2 cognitive processes for judging if something is conscious.\nType 1 processes\n(Fiala, Arico, and Nichols 2012)\nfast, domain-specific, automatic (the authors don’t argue if they are also associative)\nThree apparent features reliably produce AGENT categorization:\nhas eye-like shapes on a head-like bump;\nreacts to the environment unpredictably;\nmoves on its own, not a slave to mere inertia.\nConfirmed by judgment-speed experiments\n\n… presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute… Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.\n\nType 2 processes\nrational deliberation, theory application, or conscious reasoning\nAny brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.\nThe brain doesn’t have eyes\nThe brain seems to do nothing by itself, stewing alone in a dark cave;\nThe brain doesn’t display any motion, let alone non-inertial motion.\n\nSince the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.\n\n\nJenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick & Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious\n\nAlternative physicalist theory of consciousness designed to satisfy Type 1 process won’t satisfy Type 2 process.\nThe eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.\nAnd lock-in syndrome people don’t interact and don’t display noninertial motions.\nEvolutionary origin of the dual process\nOnly very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.\nThus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.\nThe Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.\n(Non-)Analogies\nThe authors thought that there is no Type 1 intuition for general relativity, so there’s no explanatory gap there. But I beg to differ.\nGeneral Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent “explanatory gap”, as a nagging feeling “but how do we know which one is the real spacetime manifold? The theory is incomplete because it doesn’t tell us that.”.\nThis is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there’s a unique spacetime structure.\nAs another example, Bergson famously debated Einstein over the nature of time.\nIntentionality explanatory gap.\nSome philosophers did propose an explanatory gap.\nAlthough most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.\nThis would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-color",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-color",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The geometry of color",
    "text": "The geometry of color\n\nSmooth geometry\nThe human eye, abstractly speaking, is a light detector with 4 kinds of sensors: the rod cell, active in the dark, and 3 kinds of cone cells, active when it’s bright. Each cell carries its own kind of light-sensitive proteins (“opsins”), which are molecular switches. If a photon hits an opsin in the “passive” shape, then the opsin may absorb the photon and flip into its “active” shape. An active opsin would then set off a molecular chain-reaction in the cell, that may result in an electric signal down the optic nerve.\nMathematically, suppose we shine a light on a patch of long-wavelength-type cone cells, we can represent the electric response as:\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\nwhere\n\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second. Though each cell’s operation is quantum-mechanically random, when averaged over many cone cells, the response is deterministic.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\n\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short). Each \\(S_L, S_M, S_S\\) is approximately bell-shaped.\n\n\n\nSchematic diagram of human cone cell sensitivity. Each curve is “normalized”, meaning that it is multiplied by a positive real number, so that its maximal value is exactly 1.\n\n\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is just a deterministic function that maps a spectrum to three real numbers:\n\\[C(P) := (I_S(P), I_M(P), I_L(P))\\]\nwith type \\((\\R^+ \\to \\R^+) \\to (\\R^+)^3\\), where \\(\\R^+ = [0, \\infty)\\) is the space of non-negative real numbers. Define this as the \\((I_S, I_M, I_L)\\) as the LMS color space.4 Furthermore, the biochemical limit on neural firing is 1000 Hz (“Neuron Firing Rates in Humans” 2015), thus the LMS color space is bounded within a cube.\n4 This seems as close to “sense data” (Hatfield 2021) as it gets in science.Any smooth deformation of the LMS color space gives us another color space. In theory, it doesn’t matter which one we use, because the underlying color space is still the same. In practice, some color spaces are easier to use than others.\n\n\n\nDifferent depictions of the same color space. By a smooth map, we can deform the LMS color space into any shape we want, such as a cone, a cube, a cylinder, a double cone, etc. Figure from Wikimedia Commons\n\n\nIn people with only two types of cone cells, the color vision function \\(C\\) loses a dimension. For example, if that person has deuteranopia, without medium-wavelength cone cells, then they would see all colors in LMS space with the same \\((S, L)\\)-coordinates as the same.\n\n\nProjective geometry\nBecause \\(C\\) is a linear functional, and any two colors can be mixed to give a third color, LMS color space is a convex cone. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness. It is an old experimental fact that the geometry of colors is invariant under scaling. So, if you have two lights with spectra \\(P, P'\\), such that their colors look the same/different/very different, then we make them brighter or dimmer, to \\(cP, cP'\\) where \\(c &gt; 0\\), then their colors will still look the same/different/very different.\nThus, we can factor the space of colors into two components: an apparent lightness, and an apparent chromaticity. So, if we take two dim red lights, and shine both of them on the same pane of frosted glass, the frosted glass would look lighter, but have the same chromaticity. The space of chromaticities is the space of lines passing the origin, which allows us to use projective geometry.\nThe space of all colors looks like a cone, and since each line in the cone can be represented as a point on the line, the space of all chromaticities looks like the intersection of the cone with a plane – each line is represented by its intersection with the plane. What does the space of all chromaticities look like?\nBecause any spectrum \\(I\\) is the convex sum of pure spectra\n\\[\\{I_{\\lambda}: \\lambda \\in (400 \\;\\mathrm{nm}, 700\\;\\mathrm{nm})\\},\\]\nthe space of all colors is the convex sum of all pure spectral colors\n\\[\\{C(I_{\\lambda}): \\lambda \\in (400 \\;\\mathrm{nm}, 700\\;\\mathrm{nm})\\}.\\]\nConsider a wall covered with a “pure spectral paint”, in the sense that it reflects exactly light at wavelength \\(500 \\;\\mathrm{nm}\\), and nothing else. Then, under any illumination, the color of the wall has the same chromaticity. Pure spectral colors are special colors, in the following diagram, on the edge of the cone are lines of pure spectral color, each produced by a spectrum that is concentrated at just one wavelength.\n\n\n\nThe pure spectral colors in LMS color space. The rainbow curve represents the spectrum of visible light, from violet to red. Each point on this curve corresponds to a specific wavelength of light and its unique combination of stimulations to the three types of cone cells. For each point on the spectral curve, we can draw a straight line to the origin. Each point on the line has the same color, but appears increasingly bright.\n\n\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the chromaticity space are points of pure spectral colors, from pure \\(700 \\;\\mathrm{nm}\\) line on the red end, to the pure \\(400 \\;\\mathrm{nm}\\) line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors. However, this is not the entirety of chromaticity space. The ray at the shortest-wavelength end (pure spectral purple) and the ray at the longest-wavelength end (pure spectral red) do not touch each other. Instead, they shoot out like two ends of a horseshoe. Chromaticity space, then, has a second, straight edge, obtained by mixing the shortest and the longest wavelength. This is the purple boundary.\n\n\n\nSchrödinger’s diagram of chromaticity space. Spektralkurve: spectral curve. Schnitt mit einer Ebene: intersection with an arbitrarily inclined plane. R: red. G: green. I: indigo. V: violet. O: origin. (Schrödinger 1920, fig. 3)\n\n\nWe can construct the chromaticity space of someone with deuteranopia by starting with the purple line, then draw one line for each point on the purple line that is perpendicular to the \\((S, L)\\)-plane in LMS color space. The deuteranopic observer sees each line of chromaticities as a single chromaticity.\nTheoretically, we can imagine creating the world’s best computer display by putting in a full-spectral display unit into each pixel. It will then be able to cover the entire gamut space. It will not only display true-life colors for humans, but also for dogs, bees, and mantis shrimps. Unfortunately, we don’t have that luxury, and computer displays are built for human-use only, with just three spectra.\nNow, if we have a pixel containing three little LED units, capable of emitting light of spectra \\(P_1, P_2, P_3\\), then we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. Thus, the chromaticity that this pixel can display is a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.\n\n\n\nThe triangle of displayable chromaticities for cathode-ray televisions (left) and LCDs (right). Figure from Wikimedia Commons\n\n\nWhen you print on a page, the page does not emit color, and can only acquire color by selectively reflecting light. When under a standard white light, the more ink you lavish on a page, the more saturated the color can be, but the darker it would be, because more light is absorbed. Conversely, if all the light is reflected, then it would look white. Because of this trade-off, the gamut of printable colors is even smaller.\n\n\n\nThe gamut of printable colors when placed under standard white illumination. (MacAdam 1944, plate 1)\n\n\nEvolution has created a multi-spectral display in some octopuses and chameleons. The best octopus camouflagers have 2 kinds of color organs in their skins: the chromatophores, the leucophores, and the iridocytes. Chromatophores contain pigment cells, which expand and contract by radial muscles like wheel spokes around an axis. The leucophores are roughly ideal “matte” reflectors, meaning they reflect incoming light uniformly, with little loss.\nThe iridocytes are the most exotic, and approximates our “world’s best television screen”. Specifically, they are dielectric mirrors, which reflects light at a specific wavelength. They are alternating layers of guanine crystals and cytoplasms. To change color, it simply adjusts the water content of the cytoplasm, which makes them expand or contract, changing the distance between guanine layers. More pictures are found in (Cloney and Brocco 1983).\n\n\n\nHow the iridocytes work in cephalopods. Figure from (Cossins 2013)\n\n\n\n\n\nA, B. cephalopod before and after camouflage. C. structure of cephalopod skin. D. before and after chromatophore expansion. F. before and after iridocyte turning iridescent. G. the dielectric mirrors inside an iridocyte. (Chatterjee 2022, fig. 4)\n\n\nMeanwhile, chameleons have iridocytes that operate by a different mechanism: photonic crystals (Teyssier et al. 2015).\n\n\nLinear geometry\nGrassmann, famous for originating linear algebra, studied color theory and applied linear algebra to it. Essentially, he discovered that the human color vision function \\(C\\), defined previously, is a linear function. He discovered this by color-mixing experiments, in the style of 19th century psychophysics. Considering it was 50 years before the neuron doctrine became accepted, and 100 years before cone cells were observed, he did very well.\nFor any three spectra \\(P_1, P_2, P_3\\), we can define their colors as \\(C_i := C(I_i)\\). Since \\(C\\) is a linear function, as long as \\(\\{C_1, C_2, C_3\\}\\) are linearly independent, we can represent any color as \\(C(x_1 P_1 + x_2 P_2 + x_3 P_3)\\) for some \\((x_1, x_2, x_3) \\in \\R^3\\).\nFor example, we can go to a scientific standard shop and buy a set of standard lamps, which when plugged into a standard plug, viewed in a standard room, at a standard distance and a standard angle, by a standard observer,5 will create a standard red, a standard green, and a standard blue. Then, using opaque to cover up parts of the lamp, and combining the lights, we can create any color \\(C(x_1 P_1 + x_2 P_2 + x_3 P_3)\\), for any \\((x_1, x_2, x_3) \\in [0, 1]^3\\). By buying more lamps, we can create all colors with \\((x_1, x_2, x_3) \\in (\\R^+)^3\\).\n5 Because humans are resistant to standardization, the standard observer is obtained by taking data from real observers in good health that are physiologically similar, and their average. The methodology resembles l’homme moyen (“the average man”) of Adolphe Quetelet, a fanatic for anthropometry. Also, the standard observer is not required to drink standard cups of tea.Here, we notice a difficulty: we can’t take a negative amount of lamp. Fortunately, we can bypass the difficulty by adding a fourth lamp, a “standard white” lamp emitting a spectrum \\(P_0\\). Then, for any other spectrum \\(I\\), there exists \\((x_1, x_2, x_3, x_4) \\in (\\R^+)^4\\), such that\n\\[\nC(I) + C(x_0 P_0) = C(x_1 P_1 + x_2 P_2 + x_3 P_3)\n\\]\nwhich allows us to place the color of \\(I\\) at the unique point. Of course, the choice of \\((x_1, x_2, x_3, x_4)\\) is not unique. However, since color space is linear, the sum \\(C(x_1 P_1 + x_2 P_2 + x_3 P_3 - x_0 P_0)\\) is unique. Once \\(C(P_0)\\) is itself constructed as a linear sum of \\(C(\\sum_{i=1}^3 x_{i, 0}P_i)\\), we would have located \\(C(I)\\) in color space, at\n\\[\nC(I) = \\sum_{i=1}^3 (x_i - x_0x_{i, 0}) C(P_i)\n\\]\nThis is essentially the state of the art of colorimetry in 1931, when CIE 1931 was constructed by color-mixing experiments. An observer is seated in a standard room, and sees two light sources. On the left, a to-be-measured light \\(I\\) is mixed with a standard white light \\(P_0\\), and on the right, are three standard blue, green, red lights \\(P_1, P_2, P_3\\). The observer turns the 4 knobs until two sides look indistinguishable. This was repeated for many observers, over many days, for many light sources. The result is a table with three columns, and many rows. Each row is an industrially important light source, and the three columns are the standard red, standard green, standard blue. It schematically looks like this (I made up the data):\n\n\n\ncolor\nstandard red\nstandard green\nstandard blue\n\n\n\n\nstandard red\n1.000\n0.000\n0.000\n\n\nstandard green\n0.000\n1.000\n0.000\n\n\nstandard blue\n0.000\n0.000\n1.000\n\n\nstandard white\n0.334\n0.334\n0.332\n\n\n…\n…\n…\n…\n\n\n\n\n\n\n\n\n\nTechnically\n\n\n\nTechnically, the CIE 1931 color of a spectrum \\(I\\) is a point in \\(\\R^3\\) defined by\n\\[\nC_{\\text{CIE 1931}}(I) := \\left(\\int I(\\lambda) \\bar r(\\lambda) d\\lambda , \\int I(\\lambda) \\bar g(\\lambda) d\\lambda , \\int I(\\lambda) \\bar b(\\lambda) d\\lambda \\right)\n\\]\nwhere \\(\\bar r, \\bar g, \\bar b\\) are “standard observer color matching functions”. They are not any real observer’s sensitivities, because they have negative values. Instead, they are roughly a linear transform of the real sensitivities \\(S_S, S_M, S_L\\), meaning CIE 1931 color space is roughly a linear transform of LMS color space.\nWhy did they go for a roughly linear transform? I know it’s confusing (it confused me), but it’s simply a temporary hack. Back then, they had no way to measure the neural spikes, so they had to infer the real sensitivities by indirect psychophysics data. And the negative values are for some kind of numerical stability considerations. Point being, it’s really not fundamental to science, but rather a 1930s technical hack.\n\n\n\n\nOpponent process\nHave you ever wondered why things seem bluer just after sunset, or under a high full moon? This is where opponent process theory and Purkinje effect comes in.\nWhile the retina might be operating with the LMS color space, it is not what gets sent to the brain. Specifically, before leaving the retina, the spikes from the 3 cone cells and the rod cell (we are finally accounting for them now!) are linearly transformed by 3 paired-kinds of neurons within the retina, before sending down the optic nerve. Greatly simplified, the linear transform is:\n\\[\n\\begin{cases}\n  I_{\\text{Red-Green}} &= I_L - I_M \\\\\n  I_{\\text{Yellow-Blue}} &= I_L + I_M - 2 I_S \\\\\n  I_{\\text{Brightness}} &= 2I_L + I_M + 0.05 I_S + I_R\n\\end{cases}\n\\]\n\n\n\n(Hunt and Pointer 2011, fig. 1.4)\n\n\nIn words, the Red-Green-pair of neurons take the long-wavelength (reddish) cone cells, and subtract away the medium-wavelength (greenish) cone cells. If the result is positive, then the positive half of the pair sends down a signal at the rate of \\(I_L - I_M\\), otherwise, the negative half of the pair sends down a signal at the rate of \\(-(I_L - I_M)\\). This linear transform, while mathematically equivalent (as long as the rod cells don’t appear) to LMS space, allows the optic nerves to carry more information in Homo Sapiens’ natural habitat (Buchsbaum, Gottschalk, and Barlow 1997).\nWhen the light level is around \\(0.5 \\;\\mathrm{lux}\\), which corresponds to twilight, or a full high moon, both the rod cells and the cone cells are active (Dominy and Melin 2020).\nSo, let us look at the linear transform\n\\[\n\\begin{cases}\n  I_{\\text{Red-Green}} &= I_L - I_M \\\\\n  I_{\\text{Yellow-Blue}} &= I_L + I_M - 2 I_S \\\\\n  I_{\\text{Brightness}} &= 2I_L + I_M + 0.05 I_S + I_R\n\\end{cases}\n\\]\nLet’s pretend we are the brain, interpreting the signals sent down the optic nerves. Suppose the retina secretly increases \\(I_R\\) by a small amount of \\(\\Delta I\\), but we don’t know that. How would we interpret it? We would interpret it as a color in LMS space with color\n\\[(I_S + \\Delta I', I_M + \\Delta I', I_L + \\Delta I')\\]\nwhere \\(2.05\\Delta I' = \\Delta I\\). That is, it looks as if each type of cone cell has increased firing rate by the same amount. Looking at the sensitivity curve, this effect can be created by shifting the spectrum to the shorter wavelength, then increase its power slightly. Thus, things look bluer.\n\n\n\nPurkinje effect illustrated with a flower. As the lighting condition dims, the entire scene shifts more to the bluish shade. At low enough lighting, all cone cells deactivate, and the entire scene becomes monochromatic. Figure modified from Wikimedia Commons\n\n\n\n\nRiemannian geometry\n\nMagnitude-notions are only possible where there is an antecedent general notion which admits of different specialisations… the only simple notions whose specialisations form a multiply extended manifoldness are the positions of perceived objects and colours. More frequent occasions for the creation and development of these notions occur first in the higher mathematic.\nRiemann’s Habilitation dissertation, 1854 (Riemann 2016)\n\nNow that we have a space of colors, how do we measure distances in it? Some colors are close, while some colors are far apart. How do we quantify it? This question occupied the minds of some famous scientists, including Riemann, Grassmann, Helmholtz, and Schrödinger (Pavlidis 2021).\nIn 1920, Schrödinger (more famous for his other equation) hypothesized that color space has a Riemannian geometry, and the subjective difference between two colors is the geodesic distance between the two points in color space (Schrödinger 1920). This is the foundation of modern colorimetry (Niall 2017). Over the years, there had been a mess of increasingly detailed theoretical models for the Riemannian metric of color space, of interest only to specialists – see (Wyszecki and Stiles 1982, chap. 8.4) for a review. Here, we bypass most of the theory by experimental data.\nGiven two spectra \\(I, I'\\), if their colors \\(C(I), C(I')\\) are close enough, an observer would judge them as equal. This is the concept of “just noticeable difference” (JND), a foundational concept of psychophysics.6 In general, the JND method goes like this:\n6 One can get a good feel for the JND by playing the Color Game. In case this fails in the future, try the archived link.\nFix one stimulus \\(S\\), and vary the other stimulus \\(S'\\). The prior probability that \\(S = S'\\) is \\(1/2\\).\nPresent both \\(S, S'\\) to the observer.\nThe observer judges whether they are the same or different.\nRepeat many times.\nIf, when truly \\(S' = S\\), the observer judges that they are the same with probability \\(p_0\\), then the JND point is the point where the observer judges that \\(S' = S\\) with probability \\(p_0/2\\).\n\nIn the original experiments, MacAdam fixed one spectrum \\(I\\), and varied the other spectrum \\(I'\\) on a curve that passes \\(I\\). He repeated the JND measurement along many curves across many spectra, and found that around each spectrum, the JND points make up a rough ellipsoid.\n\n\n\nThe JND of a single observer around a single color, when approached from 14 different directions. The JND points fall roughly on an ellipse. (Wyszecki and Stiles 1982, fig. 1(5.4.1))\n\n\nIf the JND measurement is binary classification in color space, then what is real-valued regression in color space? Answer: color matching experiment.\nSpecifically, suppose we fix \\(I\\), and let the observer turn a knob that varies \\(I'\\) along a curve passing \\(I\\), then we would find that \\(I'\\) is normally distributed centered upon \\(I\\). Perform the experiment with 3 knobs, and we would obtain an ellipsoidal cluster. The ellipsoids of \\(1\\sigma\\) are the MacAdam ellipsoids. As ellipsoids are very hard to draw, we typically only see 2D slices of them – the MacAdam ellipses.\n\n\n\nThe color matching experiment data of a single observer around a single color. The points are projected from 3D space to three orthogonal views. The ellipsoid is the ellipsoid of \\(3\\sigma\\). (Wyszecki and Stiles 1982, fig. 1(5.4.3))\n\n\n\n\n\n\n\n\nConjecture: perceived lightness and hues are totally geodesic foliations\n\n\n\nGiven two colors \\(C_0, C_1\\), we can construct the geodesic curve between them as the shortest sequence of colors \\(C_a, C_b, C_c, \\dots\\), such that \\(C_0, C_a\\) are JND, and \\(C_a, C_b\\) are also JND, etc. It sounds reasonable in my head that, if \\(C_0, C_1\\) have the same perceived lightness, then the geodesic connecting them should all have the same perceived lightness, because it seems like we would be wasting some precious JND on “jumping up in lightness, only to jump down again”. Similarly, if \\(C_0, C_1\\) have the same perceived hue, then I guess the geodesic through them would stay along the same perceived hue.\nIf this is true, then we can construct two families of foliations in color space, one for equal-lightness surfaces, and one for equal-hue surfaces. Each surface is a totally geodesic foliation (Johnson and Whitt 1980), meaning that each geodesic within a foliation is also a geodesic in the total color space.\nHowever, this definitely isn’t true for perceived saturation, as the shortest path between slightly saturated red and slightly saturated green (opposite of red) goes through perfect gray, so who knows whether this conjecture is true or not?\n\n\nThough JND and color matching are two different methods, they are both using people as statistical detectors, and it stands to reason that they should measure the same thing. Indeed, the ellipsoids of JND are roughly the \\(3\\sigma\\) MacAdam ellipsoids (Wyszecki and Stiles 1982, sec. 5.4).\n\n\n\nMacAdam ellipses plotted on the CIE 1931 \\(xy\\)-diagram, 10× actual size. Figure from Wikimedia Commons.\n\n\nGiven the Tissot’s indicatrix, it is natural to try to draw a distortion-less map of earth, where all Tissot ellipses are equally-sized circles. This is impossible, and Gauss knew exactly why: earth has positive gaussian curvature, but a flat sheet of paper has zero gaussian curvature.\n\n\n\nTissot’s indicatrix on Behrmann projection. Figure from Wikimedia Commons\n\n\nGiven the MacAdam ellipses, it is natural to try to draw a distortion-less map of color space. This is impossible, for the same reason: color space has nonzero curvature. It was already known to MacAdam in the 1940s that his experimental data shows color space has significant curvature.\n\n\n\nA paper model of a 2D subspace of the color space – the space of colors with unit subjective brightness. The metric on the paper model faithfully matches the metric implied by MacAdam ellipse. We can see the curvature. (MacAdam 1944, fig. 5)\n\n\n\n\n\n\n\n\nConjecture: color space is not conformally flat\n\n\n\nIs it possible to at least stretch the MacAdam ellipses into spheres, even though they aren’t of the same radius? That is, is color space conformally flat? For example, in Mercator’s projection, the Tissot ellipses are indeed circular, though they become larger near the poles, so earth is conformally flat.\nHowever, by Liouville’s theorem, conformal flatness is very stringent at 3 dimensions and above, so my conjecture is that color space is not conformally flat. Proof sketch: download the metric tensor from CIE, and check its Cotton tensor is (statistically) nonzero.\n\n\n\n\n\nA nonlinear map of CIE 1931 \\(xy\\)-graph designed to make MacAdam ellipses look roughly circular. (Wyszecki and Stiles 1982, fig. 4(5.4.1))\n\n\nCIELAB color space is a smooth mapping from CIE 1931 color space to \\(\\R^3\\), such that the MacAdam ellipses are stretched spherical enough for practical purposes.\n\n\n\nAll visible colors, plotted in CIELAB color space. Figure from Wikimedia Commons\n\n\n\n\nInformation geometry\nImagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker’s ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization – a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.\nSimilarly, as we move around in color space, we may distinguish colors by the photoreceptor responses, which can be inferred from the sensitivity curves \\(S_S, S_M, S_L\\). That is, we can reduce Riemannian metric to information geometry. Working this out in detail, (da Fonseca and Samengo 2016) showed that the Riemannian metric in color space is roughly the same (“explains 87% variance”) as the Fisher information metric.\n\n\n\nThe ellipses measured by MacAdam (green) vs ellipses predicted by information theory (red). (da Fonseca and Samengo 2016, fig. 8b)\n\n\nIn the same vein, people have argued for centuries about why certain colors are perceived as “pure” or “primary” (white, black, red, blue, green, etc), while others are “mixed” or “derived” from the primary colors. (MacEvoy 2015) argues that the primary colors are “landmarks” in the geometry of color space, much like how on a map, the peaks and troughs are local maxima of gaussian curvature, and the mountain passes are the local minima, or how on a spacetime, a black hole singularity is the point where the Kretschmann scalar is infinite. Intuitively, we can see this on the CIELAB color solid. The top-most point is white, the bottom-most color is violet, and you can just see yellow at another point behind the back, etc.\n\n\n\n\n\n\nBeyond Riemannian geometry\n\n\n\nWhile color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. (Bujack et al. 2022) reported that there is “diminishing returns” in color distances.\nIndeed, this non-Riemannian geometry has been known for a while. CIE in 1994 proposed a color difference, \\(\\Delta E\\), that is not symmetric. That is, if we ask a subject “How far is color 1 from color 2?” and then ask the opposite direction, we usually get a different numerical answer. This reminds me of information-geometric divergence, which is also not symmetric. I cannot find anyone who has studied this in detail, but it ought to interest the information geometers."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#consciousness",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#consciousness",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Consciousness",
    "text": "Consciousness\n\nEasy, hard, meta\nDavid Chalmers proposed three problems of consciousness.\nThe easy problem is essentially the problem of consciousness information processing as studied by scientists: how memories work; how the brain recognizes objects; how to create human-level intelligence; etc. By “easy”, Chalmers was not dismissing them as “intellectually easy”, as he expects it would take the best minds a century or more to solve these. Rather, by “easy”, he meant that “within the power of science as currently understood”. We would need no new metaphysics, or faith, or\nThe hard problem is the easy problem, but with something extra that seems impossible to even fit into a scientific system. What that something extra is, philosophers are unable to say, but they typically give it the name of “qualia”, “experience”, “phenomenal awareness”, etc.\n\nWhat makes the hard problem hard and almost unique is that it goes beyond problems about the performance of functions. To see this, note that even when we have explained the performance of all the cognitive and behavioral functions in the vicinity of experience—perceptual discrimination, categorization, internal access, verbal report–there may still remain a further unanswered question: Why is the performance of these functions accompanied by experience?\n(D. J. Chalmers 1995)\n\n\nWhat exactly are the problem data that need explaining? They can be construed as verbal reports (my saying ‘Consciousness is hard to explain’), as judgments (my forming the judgment that consciousness is hard to explain), or as dispositions to make these reports and judgments. Verbal reports are perhaps the most objective data here, but they are also a relatively superficial expression of an underlying state that is really what we want to explain. So I will generally focus on dispositions to make verbal reports and judgments as what we want to explain.\n\nWhile decades of science have made good progress on the easy problem, centuries of philosophical disputations have not made progress on the hard problem. To bypass the impasse, Chalmers proposed the meta problem: Why is the hard problem a problem? (D. Chalmers 2018)\nLet’s consider an analogy. The easy problem of biology would be: How does biological machines work? The hard problem: Why is the performance of these functions accompanied by life? The meta problem: What kind of cognition do people have, such that they can see a machine performing all the motions of life, and yet still call it “lifeless”?\nIn John Searle’s Chinese room story, a man who knows nothing of Chinese, by executing an algorithm with pen and paper, could converse in Chinese writing. Many, including Searle, thought that the Chinese room does not really understand Chinese. This gives us another analogy.\nThe easy problem of Chinese: What algorithms can converse in Chinese text? The hard problem of Chinese: Why is the performance of Chinese speaking in a Chinese-speaker accompanied by understanding? The meta problem: What kind of cognition do people have, such that they say the Chinese room “lacks understanding”?\n\n\nDark phenomena\n\n[Folk Psychology] suffers explanatory failures on an epic scale, that it has been stagnant for at least 25 centuries, and that its categories appear (so far) to be incommensurable with or orthogonal to the categories of the background physical science whose long-term claim to explain human behavior seems undeniable. Any theory that meets this description must be allowed a serious candidate for outright elimination.\n(Churchland 1981)\n\n\nNeurophenomenology is possible; phenomenology is impossible.\n(Metzinger 2004, 83)\n\nEverything I see, I know that I see. Everything that I hear, I know that I hear. Everything that I think, I know that I think. What could be clearer? Descartes based his entire philosophy on these kinds of self-evident truths, and these are still the starting points of many modern philosophies of the mind and consciousness.\nHowever, such self-evident truths can be questioned. In blindsight, I see things that I don’t know that I see. In Anton’s syndrome, I don’t see things, yet I think that I see.6 In Cotard’s delusion, I live yet I think that I am dead.\n6 There was a philosopher who had taken Anton’s Syndrome very seriously, but in the opposite direction, in the spirit of one man’s modus ponens is another man’s modus tollens:\n\nI still vividly remember one heated debate at an interdisciplinary conference in Germany a number of years ago, at which a philosopher insisted, in the presence of eminent neuropsychologists, that Anton’s syndrome does not exist because a priori it cannot exist.\n(Metzinger 2004, 235)\n\nAs a mathematician, I often know things without knowing how I know. When doing mental arithmetics, usually I do it both ways. One algorithm, operating consciously, goes from the highest digit down; the other algorithm, operating unconsciously, goes from the lowest digit up. As I consciously grind out digits from one end, digits simply “emerge” out of the other end. Like two teams digging a tunnel, they finally meet in the middle; the digits ripple-carry; the mouth vocalizes the final answer.\nDuring deep contemplations of high-dimensional geometric objects, my self-awareness is turned down to a whimper, dimly illuminated by the sparks and piezoluminescence of vast gears and pulleys turning in the dark mill of the brain,7 where the light of consciousness can never penetrate. A few times, I came back to consciousness on the carpet, not knowing how I got there, but with a clear feeling that an answer is close. Then I find the answer – or not. The non-conscious parts of the brain make plenty of mistakes too.\n7 I really wanted to write “dark Satanic mills of the mind”, but that would be too much purple prose.Consider a pair of pure lights, at \\(550 \\;\\mathrm{nm}\\) and \\(554 \\;\\mathrm{nm}\\). For an observer with good vision, they are separated by a JND, so if the observer sees two patches of light shining on two plates of frosted glass placed close to each other, then the observer can just barely see that they are not the same color. However, as soon as the two lights are turned off, the difference disappears. The observer cannot recall one as “green-550” and the other as “green-554”. Both would be recalled as “kind of green”. The observer cannot tell if a single patch of light is closer to green-550 or green-554. The observer cannot tune a laser by sight so that its color matches green-550 rather than green-554.\nThere are several ways to interpret this result.\nDaniel Dennett’s approach would be to eliminate inaccessible phenomena – there is neither green-550 phenomenon nor green-554 phenomenon, but only the “one patch looks greener than another” phenomenon, which is available for conscious information processing.\nThomas Metzinger and David Roden’s approach is “dark phenomenology” (Roden 2015, chap. 4). A dark phenomenon rises from dust, does its job, then falls back to dust. It cannot be interrogated, redirected, paused, vocalized, remembered, threatened, or inspected. In this way, green-550 and green-554 are dark phenomena. They are real phenomena and have real mental functions, but they cannot be captured or interrogated. A dark phenomenon, such as green-550, is an information object that only flows along hardwired circuits. The conscious part of the brain might echo a command “Store this phenomenon in long-term memory!” or “Reroute this phenomenon for verbal report!” but such commands are futile. The green-550 and green-554 phenomena are sent to some visual comparison module then discarded. The visual comparison module might output a bright phenomenon “They are different.”, but this bright phenomenon is merely an impoverished derivative of the dark phenomena that came before.\nThe just noticeable difference (JND) in color perception possibly shows that we see metric, not colors themselves.\nIf the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.\nIf the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.\n\n\nDual-process theory of the meta-problem\nIn cognitive psychology, there are many dual-process theories for explaining many cognitive processes. A theory is a dual-process theory if it follows the dual-process template. That is, if it models a cognitive process with an algorithm that has two parts, termed System 1 and System 2. System 1 is characterized by automatic, fast, and intuitive processing, while System 2 is deliberative, slower, and more analytical.\n(Fiala, Arico, and Nichols 2012) proposed a dual-process theory for the meta-problem of consciousness. According to them, people recognize something as an agent or not by a dual process. This is evolutionarily important for ancestral humans, because detecting whether that shaking in the grass is caused by an animal or not could be a life-and-death decision.\nSystem 1 for detecting agency uses the following heuristics: eye-like shapes on a head-like bump, unpredictable environmental reactions, and self-initiated movement beyond mere inertia. System 2 for detecting agency involves rational deliberation, theory application, and conscious reasoning. These processes are engaged when evaluating complex concepts, such as brain-based theories of consciousness.\nNow, the meta-problem of consciousness occurs when one attributes agency to the brain. The brain, lacking visible features like eyes, appearing inert within the skull, and not exhibiting self-propelled motion, is not an agent according to System 1. The persistent conflict between System 1 and System 2 is verbalized into the hard problem of consciousness: System 2 admits that the brain is enough for agency, while System 1 insists that it is still lacking something, be it “consciousness”, “qualia”, or “experience”.\nSimilarly, this explains how both Einstein and Poincare stumbled over the hard problem of General Relativity. General Relativity is acceptable to System 2 processes, but not to System 1 processes, which insists that spacetime is \\(\\R^4\\), and that General Relativity may describe a metric field over it, but not what spacetime is. Consequently, there is a persistent “explanatory gap”, as a nagging feeling of the hard problem. “Even when we have explained the observable results from the astronomical to the microscopic, there may still remain a further unanswered question: Why did the galaxy pass over point A, not point A’?”\nThey start with \\(\\R^N\\), then quotient out smooth deformations.\nMathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity. This is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces – where there is literally a substance with changeable property (the strain field). Indeed, the famous image of “earth sitting on a rubber sheet” is a stubbornly persistent illusion created by System 1.\n\n\n\nThe stubbornly persistent illusion. Figure from xkcd: Teaching Physics"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#abstract",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#abstract",
    "title": "Hole Argument and Inverted Qualia",
    "section": "",
    "text": "problems\neasy\nhard\nmeta\n\n\n\n\nclassical gravity\nHow to model astronomical phenomena with some distribution of mass-points in \\(\\R^3\\)?\nOut of all the equivalent models, which one is the right one?\nWhy did Newton insist on absolute space, but Leibniz on relative space?\n\n\ngeneral relativity\nHow to model astronomical phenomena with some \\((\\mathcal M, g, T)\\)?\nHole argument: Out of all the isometric models, which one is the right one?\nWhy did Einstein and Hilbert fall for the hole argument?\n\n\ncolor\nPsychophysics: How to model human perception of color?\nQualia: Why does red feel like red?\nWhy are people prone to argue about the inverted spectrum?\n\n\nlanguage\nHow to model language use?\nWhy is language use associated with a feeling of understanding?\nWhy are people prone to argue about the Chinese room?\n\n\nconsciousness\nHow to explain objective phenomena associated with consciousness, such as attention, working memory, dreaming, etc?\nWhy does paying attention, dreaming, etc, feel like something?\nWhy are people prone to argue about the hard question?\n\n\n\n\n\n\nShifted qualia and the hole argument. Figure modified from (Norton, Pooley, and Read 1999) and Wikimedia Commons\n\n\n\n\n\nInverted qualia and Leibnitz’s inverted space. Figure modified from (Norton, Pooley, and Read 1999) and Wikimedia Commons"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-spacetime",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-spacetime",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The geometry of spacetime",
    "text": "The geometry of spacetime\nIn general relativity, the hole argument is a thought experiment that apparently shows that general covariance is impossible. Einstein in late 1913, and David Hilbert in 1915, both fell into the hole argument. Misled by the hole argument, Einstein attempted to study theories of gravity that are not generally covariant, before finally giving up and . (Norton, Pooley, and Read 1999)\n\nA brief history of spacetime\nThe history of spacetime is a history of expanding symmetries.\nIn the most ancient cosmology of China, the earth is a square, while the sky is a half-bowl covering the earth. Each direction of earth – east, west, south, north – has a mystical significance. Up is not down, and east is not west. Not only that, there is a center of earth, somewhere in The Middle Kingdom. Thus, there is no spatial symmetry. The world was born an unspecified number of years in the past out of a chaotic egg. Thus, there is no temporal symmetry. Therefore, ancient Chinese spacetime is \\(\\R^1 \\times \\R^3\\), with no (nontrivial) symmetry.\nIn Aristotle’s physics, there is a center of the universe, where everything heavy (water and earth) is moving towards, and everything light (air and fire) is fleeing from. Other than that, space is spherically symmetric – he knew that earth is round. However, though space has a center, time is translation-invariant. Therefore, Aristotle’s spacetime is \\(\\R^1 \\times \\R^3\\) with symmetry group \\(\\R^1 \\times SO(3)\\), where \\(\\R^1\\) is the time-translation symmetry group, and \\(SO(3)\\) is the spherical symmetry group.\nThe Christian spacetime, with a beginning and an end for time, has a smaller symmetry group of \\(\\{0\\} \\times SO(3)\\).\nCopernicus and Kepler replaced the sun for the earth as the center of the universe, but they still insisted on a center. The first true breakthrough was Giordano Bruno’s infinite spacetime, where both space and time are infinite and without center. Therefore, Bruno’s spacetime has symmetry group \\(\\R^1 \\times E(3)\\), where \\(E(3)\\) is the 3D Euclidean symmetry group. That is, we allow all spatial translations.\nGalileo braided together space and time, resulting in an even bigger symmetry group. Specifically, he argued that the universe does not have a special “at rest” velocity. To see why this is a breakthrough, consider what happens in Bruno’s universe. In Bruno’s universe, it matters whether you are staying still, or moving at \\(1 \\;\\mathrm{m/s}\\) relative to the universe. If you are staying still, then your trajectory is like \\(\\dots, (t_0, p), (t_1, p), (t_2, p), \\dots\\). Metaphorically speaking, you are sitting somewhere in the cinema of spacetime, and you can “peek at the number of your seat” and see that you have been sitting at the same space-point \\(p\\). However, if you are moving relative to the universe, you can see that your space-point is changing.\nGalileo rejects this. There is no “space-point”. You can take a slice of the universe at \\(t=0\\), and another slice of the universe at \\(t=1\\), but you cannot point at a point in each slice and ask, “Are these two points the same space-point?”.\nNewton’s concept of spacetime is harder to conceptualize. He understood Galileo’s point, and initially attempted to model spacetime the same way as Galileo did. However, for obscure reasons, he reintroduced absolute space and time. This had strange consequences that Leibnitz relentlessly criticized. Consider the inertial frame, relative to which the sun is standing still at this moment. Now consider another inertial frame, moving at \\(1 \\;\\mathrm{m/s}\\) in the direction of Sun-to-Mars at this moment. The laws of Newtonian mechanics are the same, and no observation or experiment could tell us whether one of them is the “absolute frame”, or neither of them is. Yet, out of the infinitely many inertial frames, Newton designated precisely one of them as the “absolute”, and all others are defined as those moving at constant velocity relative to the absolute frame. (DiSalle 2020)\nTo dramatize this seemingly arcane point, consider the following imaginary conversation between Newton and Leibniz about a grant proposal to find the absolute frame:\n\nThis is a proposal to find the absolute frame…\nHow would you find it? The only difference between absolute and non-absolute inertial frames is that one of them is designated so. Do the stars turn perfectly white when you are standing still in the absolute frame? Do the music of the spheres tune to a perfect pitch? Do you see it in your mind’s eye? And even if you do, what if every material point in the universe, by an act of God, were set off in this direction [points finger up] at one mile per day? Would anything seem amiss? You yourself admit that the very sustenance of the universe requires continuous divine forcing, that the stars would have collapsed to the same point otherwise.1\n… yet all relative frames has no existence without assuming the absolute frame, for otherwise, one would fall to a circular argument, where relative frames are relative to nought but each other, and the very meaning of inertiality becomes vacuous. One might as well The absolute might be hidden, but it is out there.\n1 \nIn the 1726 edition of the General Scholium, Newton added a new sentence: “And so that the systems of the fixed stars will not fall upon one another as a result of their gravity, he has placed them at immense distances from one another.” Once again, the implication is that gravity can be a destabilising force. An annotation in Newton’s copy of the 1713 edition after the words “send light into all the others” shows that he had considered an even more theologically powerful statement: “and the fixed stars would, through their gravity, gradually fall on each other, were they not carried back by the counsel of the supreme Being.”\n(Snobelen 2020)\n\nHe also believed that the Great Comet of 1680 would someday fall into the sun, causing a solar flare-up that would kill all life on earth. God would then repopulate earth. In general, he thought the universe as an unstable system requiring constant divine support. (Snobelen 2020)\nWith special relativity, the symmetry of spacetime becomes \\(SO(3, 1)\\), which is in a sense more “braided” than Galilean relativity. In Galilean relativity, the symmetry group of spacetime factors into a direct product between the symmetry group of space, and the symmetry group of time. In special relativity, the symmetry group of spacetime cannot be factored into a direct product. This is the deep meaning of Minkowski’s claim that “space for itself, and time for itself shall completely reduce to a mere shadow”.\nFor general relativity, any diffeomorphism on spacetime is a symmetry.2 In other words, it is a generally covariant theory. This is quite a vast generalization, and warrants further details.\n2 A function is a diffeomorphism iff itis one-to-one, smooth, and has a smooth inverse.\n\nGeneral relativity\nGeneral relativity models spacetime as a manifold \\(\\mathcal M\\), with a metric tensor field \\(g_{\\mu\\nu}\\) and an energy-momentum tensor field \\(T_{\\mu\\nu}\\). The metric tensor describes the spacetime separation between points on the manifold, and thereby the geometry of spacetime. The energy-momentum tensor describes the flow of energy and momentum in spacetime. In particular, a body with mass \\(m\\), such as a black hole, is a flow of energy \\(mc^2\\) in time, and therefore can be described within the energy-momentum tensor.\nThe metric tensor field and the energy-momentum tensor field are “braided together” by Einstein’s field equation:\n\\[\n(\\text{a polynomial equation involving components of }g) = \\kappa T\n\\]\nwhere \\(\\kappa\\) is a constant of nature, measured by experiments.\nThe spacetime manifold \\(\\mathcal M\\) can be transformed, in that we can write down a function \\(f: \\mathcal M \\to \\mathcal M\\), such that it maps one point in the manifold to another point. According to general relativity, if \\(f\\) is a diffeomorphism, then the field equation is unchanged. In this sense, all diffeomorphisms of \\(\\R^4\\) become symmetries of spacetime. Whereas in special relativity, inertial frames are distinguished from non-inertial frames, in that the coordinate lines in an inertial frame are deemed “straight”, no one gets special treatment in general relativity, and any smooth coordinate system is as good as any other. That is, Einstein’s field equation is generally covariant.\n\n\nThe hole argument\nDuring 1912, Einstein struggled with finding a generally covariant field equation for gravity. He even considered the one he would eventually publish in 1915 and be famous for, but gave them up over certain difficulties. Then in late 1913, he tried to turn this loss into a victory by arguing that general covariance is not the right approach, because of the hole argument. (Norton, Pooley, and Read 1999)\nConsider the following two models of a small universe. The universe contains three galaxies moving away from each other. The model on the left shows that one of the galaxies passes the spacetime-point \\(E\\), while the model on the right shows that no galaxy passes the spacetime-point \\(E\\).\nIf the universe satisfies a generally covariant field equation, then we can transform the model on the left to the model on the right by a diffeomorphism, and the equation would be none the wiser. In other words, any generally covariant field equation suffers from rampant indeterminism.\n\n\n\nEinstein’s hole argument. Figure from (Norton, Pooley, and Read 1999)\n\n\nWe cannot fault Einstein for “falling into the hole”, because Hilbert fell into the hole as well around the same time, though he fell in via the route of Cauchy boundary value problem. In Hilbert’s formulation, any generally covariant field equation suffers from indeterminism, in the sense that no amount of initial value on the field is enough to determine the future of the field.\nThat is, if we start off from a slice of simultaneity (“Cauchy surface”), and solve the equations forwards in time, we would find that we are lacking conditions. Concretely, consider the motion of water. If the universe is Newtonian, full of Newtonian water, then cosmology is just hydrodynamics. If we know the precise velocity field at a single moment in time, then we can solve the equations forward and find all there is to know about the cosmos. However, Hilbert found that any generally covariant theory fails this: No amount of knowledge of the field at a single slice of simultaneity is sufficient to determine any future or past of the field. Unlike a clockwork Newtonian universe ticking forward by ironclad laws of motion, the Einsteinian universe would “go off the rails” immediately. (Stachel 2014)\n\n\nProblem of time\nThe old couplet about general relativity goes like “Matter tells space-time how to curve, and space-time tells matter how to move.” but this is often misunderstood as saying “Matter exists, then space-time reacts to matter, and then matter reacts to space-time by changing its motion.” This fundamentally misunderstands what general relativity is. There is no time nor causality, at least as commonly understood, in special or general relativity.\nSpecial relativity is typically interpreted as an “eternalist” or “four-dimensionalist” theory. That is, all of space and time exist in the same way, and the future is as real as the past. Einstein said it as “the distinction between past, present, and future is only a stubbornly persistent illusion.”. It is typically supported by the Rietdijk–Putnam argument, as follows.\nWhereas in Newtonian spacetime, one can still imagine that the universe somehow “grows one time-slice at a time” – though this is susceptible to McTaggart’s objection – in special relativity, there does not exist such a thing as “time-slice”, because there is no absolute simultaneity. We may pick the time-slices in the inertial frame of the solar system, or in that of the Andromeda galaxy. However, just like how no observation can distinguish Newton’s absolute inertial frame from all the other relative inertial frames, no observation can distinguish between the absolute simultaneity from all the other relative simultaneities.\nThe difficulty is only amplified in general relativity. Let us imagine a universe that is swirling with stars and galaxies. Locally, the spacetime manifold is curved, but globally, it is topologically the same as \\(\\R^4\\) – no loops, no singularities, and no wormholes. Now, construct a coordinate system \\((t, x, y, z)\\). We can then select a “snapshot” of the universe by selecting the “slice of simultaneity” (that is, a “Cauchy surface”) at \\(t = 0\\). If we know the exact value of \\(g, T\\) on that snapshot, then we can crank the Einstein field equations to solve (up to general covariance) for \\(g, T\\) for all \\(t &gt; 0\\). Does this mean that the slice of \\(t=0\\) determines what happens afterwards?\nNot really. We could have smoothly distorted the coordinate system to \\((t', x', y', z')\\), and solve the Einstein field equations for all \\(t' &gt; 0\\) starting from \\(t' = 0\\). There are infinitely more degrees of freedom compared to special relativity, making the RP argument bite harder.\nYet, the issue goes even deeper. We could very well select \\(t = 10000\\) and crank the field equations to solve for \\(g, T\\) for all \\(t &lt; 10000\\). Does this mean that “the future determines the past?” Perhaps we can compromise by saying “one point in time determines both the past and the future”, but even that is not necessarily true. We can design much wilder boundary conditions. We can make two lightcones determine the rest of the universe (double-null, or Sachs), make one lightcone plus a “left side” of the universe determine the rest (null-timelike, or Winicour–Tamburino), make half of the universe’s left-side and half of the universe’s \\(t=0\\) determine the rest, etc.\n\n\n\nDifferent initial value conditions. The first is the commonly used Cauchy condition, but the others, more exotic, are also valid. Figure modified from (d’Inverno 1984)\n\n\n\n\nGauge freedom\nThe standard solution, one that is inscribed in every textbook, is the gauge freedom point of view. Even the most practical textbook on general relativity must handle the issue somehow, for the same problem that tripped up Hilbert: the Cauchy problem is not well-posed.\nConcretely, consider the first serious problem in every textbook, where there is a single mass point in the universe. Pick a spherical coordinate system in which the mass point is in the center, and assume that the metric field is constant over time, and spherically symmetric, as\n\\[g_{\\mu\\nu}dx^\\mu dx^\\nu = f_{\\text{radial}}dr^2 + f_{\\text{orthogonal}}(r^2d\\theta^2 + r^2 \\sin^2\\theta d\\phi^2)\\]\nThis then reduces to an ordinary differential equation for \\(f_{\\text{radial}}, f_{\\text{orthogonal}}\\). Note how we have made an assumption for the form of the equation for the metric field. This is by no means a benign assumption, as it is this choice that banishes the spectre of the hole argument.\nSuppose we had chosen the metric field to be not constant over time, but merely spherically symmetric, then we would find that we have a whole family of solutions. Take the previous solution of \\(g_{\\mu\\nu}\\), and construct a spherical shell around the mass point. Now, we can apply the hole argument on the spherical shell to “ring spacetime like a bell”, obtaining another spherically symmetric solution. 3\n3 \nAs all the Heavens were a Bell,\nAnd Being, but an Ear,\nAnd I, and Silence, some strange Race,\nWrecked, solitary, here –\n\n\n\n\nRinging spacetime like a bell, creating a whole family of spherically symmetric solutions. Figures modified from (Norton, Pooley, and Read 1999)\n\n\nThe gauge freedom interpretation states that any solution to the field equations are equivalent. They are practically equivalent, in the sense that no observable differences exist between them. They are ontologically equivalent, in the sense that no solution is “absolute” compared to others that are “derivative”. The first claim is an experimental fact, while the second claim is a metaphysical interpretation. The metaphysical interpretation does not necessarily follow from the experimental fact, yet it is hard to admit the experimental fact and reject the metaphysical interpretation.\nThe parallel with the Newtonian absolute vs relative inertial frames is obvious. (Rynasiewicz 2012) noted if we apply the hole argument to a universe with no mass, we obtain a hole argument for special relativity that should imply that the one-way speed of light is also a gauge freedom. So for example, if we apply a shearing transform \\(x \\mapsto x + 0.1 t\\), we would increase the one-way speed of light in the \\(+x\\) direction, and decrease it in the \\(-x\\) direction, without changing any observable predictions."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-feeling",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-feeling",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The geometry of feeling",
    "text": "The geometry of feeling\n\nEasy, hard, meta\nDavid Chalmers proposed three problems of consciousness.\nThe easy problem is the scientific problem of human perception, cognition, and motor control: how memories work, how vision recognizes objects, etc. By “easy”, Chalmers was not dismissing them as “intellectually easy”, but that they are within the paradigm of science as currently understood. They are about as easy as colonizing Mars or curing cancer.\nThe hard problem is the easy problem, but with something extra that seems impossible to even fit into a scientific system. What that something extra is, philosophers are unable to say, but they typically give it the name of “qualia”, “experience”, “phenomenal awareness”, etc.\n\nWhat makes the hard problem hard and almost unique is that it goes beyond problems about the performance of functions. To see this, note that even when we have explained the performance of all the cognitive and behavioral functions in the vicinity of experience—perceptual discrimination, categorization, internal access, verbal report–there may still remain a further unanswered question: Why is the performance of these functions accompanied by experience?\n(D. J. Chalmers 1995)\n\nWhile decades of science have made good progress on the easy problem, centuries of philosophical disputations have not made progress on the hard problem. To bypass the impasse, Chalmers proposed the meta problem: Why is the hard problem a problem?\n\nWhat exactly are the problem data that need explaining? They can be construed as verbal reports (my saying ‘Consciousness is hard to explain’), as judgments (my forming the judgment that consciousness is hard to explain), or as dispositions to make these reports and judgments. Verbal reports are perhaps the most objective data here, but they are also a relatively superficial expression of an underlying state that is really what we want to explain. So I will generally focus on dispositions to make verbal reports and judgments as what we want to explain.\n(D. Chalmers 2018)\n\nThe easy problem of consciousness, being part of the domain of science, excited little philosophical attention, while the hard and the meta problems excited a vast discourse. It is not within my power to review the literature, though it might be within my power to solve them.\nLet’s consider an analogy. The easy problem of biology would be: How does biological machines work? The hard problem: Why is the performance of these functions accompanied by life? The meta problem: What kind of cognition do people have, such that they can see a machine performing all the motions of life, and yet still call it “lifeless”? This analogy was considered by Dennett and rejected by Chalmers as a disanalogy. (Garrett 2006)\nIn John Searle’s Chinese room story, a man who knows nothing of Chinese, by executing an algorithm with pen and paper, could converse in Chinese writing. Many, including Searle, thought that the Chinese room does not really understand Chinese. This gives us another analogy.\nThe easy problem of Chinese: What algorithms can converse in Chinese text? The hard problem of Chinese: Why is the performance of Chinese speaking in a Chinese-speaker accompanied by understanding? The meta problem: What kind of cognition do people have, such that they say the Chinese room “lacks understanding”?\nIt is my aim to dissolve the hard problem of consciousness by showing that it has no explanandum. That is, the non-reducible form of consciousness does not exist, so the hard problem is meaningless.\n\n\nInverted qualia\n\n\n\nA normal-colored photo and an inverted version of it. Figure from (Byrne 2004, fig. 4)\n\n\nThe inverted qualia thought experiment has been used, like the p-zombie, in a whole host of arguments involving consciousness and the qualia. We consider the case involving functionalism, which is currently the most fashionable among cognitive psychologists and computer scientists. Other variants are reviewed in (Byrne 2004).\nAccording to functionalism, mental states are best understood as functional states, that is, mathematical functions that map perceptual inputs to behavioral outputs. It’s the intricate web of causal relations that constitutes a mental state, rather than the specific physical makeup realizing those relations.\nIn the anti-functionalism case, we consider two individuals, “Invert” and “Nonvert”, are functionally identical. They receive the same visual input (a tomato), undergo the same internal processing, and produce the same behavioral outputs (saying “that’s a red tomato”). However, their subjective experiences – their qualia – differ drastically. Where Nonvert sees red, Invert experiences green (or another color qualia entirely). They outwardly behave in the same way, and all functional measurements, from verbal reporting, psychological experiments, to MRI scanning, all find them the same, and yet the qualia of any color the Invert sees is rotated 180 degrees compared to that of the Nonvert.\nFormally:\n\nThe following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.\nThus, the mental does not supervene on functional organization.\nThus, functionalism is false.\n\nSimilarly the shifted qualia thought experiment does not completely invert color space, but simply shift it, so that dark red looks slightly bluer, etc.\n\n\nOther inversions\nIn his Book of Optics, Alhazen rejected the theory that the eye works like a camera obscura, as it would create an inverted image. He also rejected any significant deviation from perfect regularity of the eye, as it would create “monstrous” images like seeing everything in a funhouse mirror. Similarly, da Vinci knew that the pupil acts as a camera obscura, but developed no less than 8 different hypothetical mechanisms inside the eye to re-invert the image again, so the image lands right-side-up on the retina. (Eastwood 1986)\n\n\n\nLeonardo da Vinci’s drawings comparing the eye to a camera obscura. From Codex Atlanticus (1490-1495). Note the double-inversion to make sure the image lands right-side-up on the retina. Figure from Wikimedia Commons.\n\n\nIn his famed Treatise of Man, Descartes solved the problem according to functionalism: It is not an issue if the image on the retina is “upside-down”. It only matters if the retina is wired to the brain in a regular way, such that the neural control of motion by sight works. Informally speaking, it doesn’t matter if the wires are wired upside-down, as long as the wires are not crossed.\n\n\n\nIllustration from Descartes’ Treatise of Man, showing how the eye can guide the arm despite an “upside down” image. Suppose the eye sees the hand is pointing at the middle of the arrow, and then the brain needs to have the finger pointing at the tail of the arrow, then the control circuit goes from the retinal-C point, to the optical-nerve-C point, to the brain-C point, and finally to the arm abductor muscle.\n\n\nIn Leibniz’s third paper of the Leibniz–Clarke correspondence, Leibniz proposed the “inverted space” thought experiment:7 Suppose at the moment of creation, God were to switch East and West, then nothing would act different. Since God must have created the world according to the principle of sufficient reason, God could not have chosen arbitrarily. Ergo, such a choice never existed in the first place, meaning that space is relational, not absolute.\n7 \n… supposing Space to be Something in it self, besides the Order of Bodies among themselves, that ’tis impossible there should be a Reason, why God, preserving the same Situations of Bodies among themselves, should have placed them in Space after one certain particular manner, and not otherwise; why every thing was not placed the quite contrary way, for instance, by changing East into West.\n(Clarke 1717)\n\n\n\nThe broken symmetry argument\nA sophisticated objection to inverted qualia, based on color science, states that since color space has no nontrivial symmetries, the thought experiment is impossible. For example, saturated yellow does not merely look different from saturated red, but also looks brighter. In this view, “simply yellow” is not simply yellow. A point in color space is not simply a point. It is already inherently structured. Yellow is the brightest of all saturated colors, while violet is the dimmest, etc. (Hilbert and Kalderon 2000) argued that every possible quality space must be asymmetrical, in the sense that the only automorphism is the identity map, of \\(x \\mapsto x\\).\nThis appears to me an objection that is too strong, as there really do exist quality spaces that are symmetric. In humans, left and right are symmetric. And if there exists someone with a color space that is mirror-symmetric across some plane, then the following kind of experiment might be possible:\n\n“They are different.” [points at this patch and that patch]\nThe experimenter takes both patches away, then brings back one patch, and asks “Is this the left patch or the right patch?”\n“I don’t know.”\n\nThis is similar to the case of dark phenomena of JND color pairs (to be detailed below), but it is different in that, unlike JND color pairs, there would be color patches that are as different as left hand from right, as different as red and green, but they simply cannot see color-in-itself, only color-between-them. It might not be strange for them, since they were born this way, but it would be strange for normal people. However, the strangeness is conceivable, perhaps even unremarkable. When I was a kid, left and right was like that for a long time. I suspect that some people never acquire a distinction between left and right, until they acquire some asymmetric scar, such as a burn-mark on one hand.\nIf we look beyond the human umwelt, then this may not be just a thought experiment, as there are some highly symmetric quality spaces in non-human animals.\nLight, being electromagnetic waves, can be polarized. The space of possible polarizations is isomorphic to a ball, the Poincare ball. The mantis shrimp species Gonodactylus smithii can detect the polarization of light over the entire 3-dimensional Poincaré ball (Kleinlogel and White 2008). It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.\n\n\n\nPolarization states on the Poincaré ball. Figure from Wikimedia Commons.\n\n\nNow, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincaré ball is inverted compared to yours? That is, what if when you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, and similarly across all of the ball? We can even imagine more exotic reflections, such as one that reflects across the \\((0.3, 0.3, 0.9)\\) direction, etc.\n\n\nGauge freedom in qualia-space\nAt this point, we have a formal analogy between the thought experiments concerning qualia and those concerning spacetime. Explicitly:\n\n\n\ncolor\nspacetime\n\n\n\n\nshifted qualia\nhole argument\n\n\ninverted qualia\nLeibniz inversion\n\n\ncolor space\nspacetime\n\n\nqualia of a color\na point in spacetime\n\n\ngeometry of color space\ngeometry of spacetime\n\n\nqualia realism\nmanifold substantialism\n\n\ncolor space is but its geometry\ngauge freedom\n\n\n\nIn manifold substantialism, points on the spacetime manifold exist in themselves, and one can ask what a point on the spacetime manifold is, independent of the metric or the energy-momentum field, and what happens if the fields are stretched differently over the same manifold. In qualia realism, points in the space of color exist in themselves, and one can ask what happens if the same photons are mapped to different points in color space.\nJND in color perception possibly shows that we see metric, not colors themselves.\nPoints in spacetime do not exist in themselves, but reduces to the interplay of metric and energy-momentum tensor fields up to gauge freedom. Similarly, qualias do not exist in themselves, but reduces to the interplay between brain, the rest of the body, and the outside world. Arguments in support of gauge freedom in general relativity can be directly translated to arguments in support of functionalism in consciousness.\nFurthermore, if the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We would be able to scientifically answer Nagel’s question of what it is like to be a bat. The hard problem of being a bat dissolves, leaving the easy problem. It simply requires us to construct the geometry of a bat’s color space from its neurophysiology. We may not even need to perform psychophysical experiments, such as asking a bat to make JND distinctions (though psychophysics is possible with animal subjects, see for example (Jacobs 1982)). We may construct it by information-geometric methods, like how MacAdam ellipses can be constructed by the light sensitivity curves of retinal cells.\n\n\nDark phenomena\n\nNeurophenomenology is possible; phenomenology is impossible.\n(Metzinger 2004, 83)\n\nEverything I see, I know that I see. Everything that I hear, I know that I hear. Everything that I think, I know that I think. What could be clearer? Descartes based his entire philosophy on these kinds of self-evident truths, and these are still the starting points of many modern philosophies of the mind and consciousness.\nThe concept of qualia attempts to formalize this self-evident truths. There is no generally agreed-on definition of qualia, but according to the original proposer, David Lewis, a qualia must contain several properties (Metzinger 2004, 68). Of those, we consider the first one:\n\nSubjective identity criteria are available, by which we can introspectively recognize their transtemporal identity.\n\nWhile the concept of qualia might seem self-evident, such self-evident truths can be questioned. In blindsight, I see things that I don’t know that I see. In Anton’s syndrome, I don’t see things, yet I think that I see.8 In Cotard’s delusion, I live yet I think that I am dead.\n8 There was a philosopher who had taken Anton’s Syndrome very seriously, but in the opposite direction, in the spirit of one man’s modus ponens is another man’s modus tollens:\n\nI still vividly remember one heated debate at an interdisciplinary conference in Germany a number of years ago, at which a philosopher insisted, in the presence of eminent neuropsychologists, that Anton’s syndrome does not exist because a priori it cannot exist.\n(Metzinger 2004, 235)\n\nAs a mathematician, I often know things without knowing how I know. When doing mental arithmetics, usually I do it both ways. One algorithm, operating consciously, goes from the highest digit down; the other algorithm, operating unconsciously, goes from the lowest digit up. As I consciously grind out digits from one end, digits simply “emerge” out of the other end. Like two teams digging a tunnel, they finally meet in the middle; the digits ripple-carry; the mouth vocalizes the final answer.\nDuring deep contemplations of high-dimensional geometric objects, my self-awareness is turned down to a whimper, dimly illuminated by the sparks and piezoluminescence of vast gears and pulleys turning in the dark mill of the brain,9 where the light of consciousness can never penetrate. A few times, I came back to consciousness on the carpet, not knowing how I got there, but with a clear feeling that an answer is close. Then I find the answer – or not. The non-conscious parts of the brain make plenty of mistakes too.\n9 I really wanted to write “dark Satanic mills of the mind”, but that would be too much purple prose.Consider a pair of pure lights, at \\(550 \\;\\mathrm{nm}\\) and \\(554 \\;\\mathrm{nm}\\). For an observer with good vision, they are separated by a JND, so if the observer sees two patches of light shining on two plates of frosted glass placed close to each other, then the observer can just barely see that they are not the same color. However, as soon as the two lights are turned off, the difference disappears. The observer cannot recall one as “green-550” and the other as “green-554”. Both would be recalled as “kind of green”. The observer cannot tell if a single patch of light is closer to green-550 or green-554. The observer cannot tune a laser by sight so that its color matches green-550 rather than green-554. According to experiments in the 1950s, though people can distinguish around 150 pure spectral colors in the sense of JND, they can identify only around 15 pure spectral colors in the absolute sense. (Halsey and Chapanis 1951)\nAccording to Thomas Metzinger (Metzinger 2004, chap. 2.4), such “dark phenomena” (Roden 2015, chap. 4) constitute an empirical disproof of qualia as defined by Lewis, because subjective identity criteria are not available, since we cannot introspectively recognize the transtemporal identity of green-550.\nA dark phenomenon rises from dust, does its job, then falls back to dust. It cannot be interrogated, redirected, paused, vocalized, remembered, threatened, or inspected. In this way, green-550 and green-554 are dark phenomena. They are real phenomena and have real mental functions, but they cannot be captured or interrogated. A dark phenomenon, such as green-550, is an information object that only flows along hardwired circuits. The conscious part of the brain might echo a command “Store this phenomenon in long-term memory!” or “Reroute this phenomenon for verbal report!” but such commands are futile. The green-550 and green-554 phenomena are sent to some visual comparison module then discarded. The visual comparison module might output a bright phenomenon “They are different.”, but this bright phenomenon is merely an impoverished derivative of the dark phenomena that came before.10\n10 If a thought enters the mind but nobody talks about it, does it make a sound?What dark phenomena do resemble, however, are the gauge-freedom conception of spacetime. The metric in color space is just like the metric in spacetime. Just like how each color qualia has no individual transtemporal existence, each point in the spacetime manifold has no individual trans-manifold existence. Just like how the spacetime manifold is defined only up to gauge freedom, the color space is defined only up to diffeomorphism. Just like how the hole argument is dispelled by the gauge freedom viewpoint, the inverted or shifted qualia argument is dispelled if there is no ontological difference between diffeomorphically equivalent color spaces.\nContinuing the same argument, absolute color identification is like identifying large-scale structures of the universe. The point of perfect gray is the point furthest from the edge of chromaticity space. The grayscale axis is the line of perfect grays. The ring of saturated colors is the region close to the edge of chromaticity space. The island of absolute yellow is the part in the ring of saturated colors that is furthest away from black, etc."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-future-of-an-illusion",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-future-of-an-illusion",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The Future of an Illusion",
    "text": "The Future of an Illusion\n\n[Folk Psychology] suffers explanatory failures on an epic scale, that it has been stagnant for at least 25 centuries, and that its categories appear (so far) to be incommensurable with or orthogonal to the categories of the background physical science whose long-term claim to explain human behavior seems undeniable. Any theory that meets this description must be allowed a serious candidate for outright elimination.\n(Churchland 1981)\n\n\nif commonsense intentional psychology really were to collapse, that would be, beyond comparison, the greatest intellectual catastrophe in the history of our species; if we’re that wrong about the mind, then that’s the wrongest we’ve ever been about anything. The collapse of the supernatural, for example, didn’t compare; theism never came close to being as intimately involved in our thought and practice – especially our practice – as belief/desire explanation is.\n(Fodor 1987, vii)\n\nThe above, I hope, constitutes a good argument for dissolving the hard problem of consciousness as a pseudoproblem, much as the hole argument of general relativity is dissolved as a pseudoproblem. However, even if the hard problem resists philosophical dissolution by the gauge freedom argument, it might still be dissolved practically, since the meta-problem has a purely material basis, and thus cannot resist materialist invasions in practice, metaphysical defences be damned.\n\nDual-process theory\nWhile some argue that the meta-problem is just the hard problem in disguise, and therefore is not solvable by purely materialist methods, the opinion seems to be a minority. In the paper that proposed it (D. Chalmers 2018), Chalmers discussed no less than 12 possible solutions to the meta-problem that are within the materialist paradigm of modern science. Here I describe one that gives a flavor of how things might go.\nIn cognitive psychology, there are many dual-process theories for explaining many cognitive processes. A theory is a dual-process theory if it follows the dual-process template. That is, if it models a cognitive process with an algorithm that has two parts, termed System 1 and System 2. System 1 is characterized by automatic, fast, and intuitive processing, while System 2 is deliberative, slower, and more analytical.\n(Fiala, Arico, and Nichols 2012) proposed a dual-process theory for the meta-problem of consciousness. According to them, people recognize something as an agent or not by a dual process. This is evolutionarily important for ancestral humans, because detecting whether that shaking in the grass is caused by an animal or not could be a life-and-death decision.\nSystem 1 for detecting agency uses the following heuristics: eye-like shapes on a head-like bump, unpredictable environmental reactions, and self-initiated movement beyond mere inertia. System 2 for detecting agency involves rational deliberation, theory application, and conscious reasoning. These processes are engaged when evaluating complex concepts, such as brain-based theories of consciousness.\nNow, the meta-problem of consciousness occurs when one attributes agency to the brain. The brain, lacking visible features like eyes, appearing inert within the skull, and not exhibiting self-propelled motion, is not an agent according to System 1. The persistent conflict between System 1 and System 2 is verbalized into the hard problem of consciousness: System 2 admits that the brain is enough for agency, while System 1 insists that it is still lacking something, be it “consciousness”, “qualia”, or “experience”.\n\n\nMathematical illusion\nAnother answer to the meta-problem of general relativity is an accident of mathematics. Traditionally, general relativity is written as a theory about a triple of mathematical objects: \\((\\mathcal M, g, T)\\). Looking at it, it seems obvious that there are three things: an underlying manifold \\(\\mathcal M\\), and two tensor fields \\(g, T\\) stretched over it. This then brings us the problem of interpreting each of them separately. In particular, what is the ontological status of the spacetime-in-itself \\(\\mathcal M\\) is, independently of \\(g, T\\)? However, this is an artifact of mathematical symbolism.\nDue to the historical development of differential geometry in the 19th century, its overarching paradigm in the Kuhnian sense – the prototypical examples – include the continuum mechanics of deformable surfaces, and practical geodesy. In continuum mechanics, there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field). In practical geodesy, there is literally an unchanging substance (a map-paper) with changeable property (the geodesic lines).\nThe abstracted paradigm is then a substance-property duality, where the substance is a “raw” structure, upon which we may decorate with properties. However, it is quite possible to regard \\(\\mathcal M\\) as a derivative to the original \\((\\mathcal M, g, T)\\). Concretely, we would begin with \\(\\R^4\\) with \\(g, T\\) “baked in”, then quotient out these structures. This is analogous to how we may construct the affine space \\(\\mathbb A^3\\) by starting with \\(\\R^3\\), then quotient out the group of translations.\nIn short, there is no necessary division between substance and property, only conventional. Taking the conventional division as necessary leads to the meta-problem of general relativity.\n\n\n\nThe stubbornly persistent illusion. Figure from xkcd: Teaching Physics\n\n\n\n\nPhilosophy with a deadline\n\nLevel-1 or world space is an anthropomorphically scaled, predominantly vision-configured, massively multi-slotted reality system that is obsolescing very rapidly.\nGarbage time is running out.\nCan what is playing you make it to level-2?\n— Nick Land, Meltdown\n\nA 2009 survey of professional philosophers (largely analytical) over 30 major problems of philosophy showed only two problems commanded a rough consensus (over 70% agreement): the existence of the external world, and the nonexistence of God. Chalmers noted that despite some progress in the sophistication of arguments, there has been little convergence towards any consensus over time, other than the question of God. (D. J. Chalmers 2015)\n\n… none of these methods have led to recent convergence on answers to the big questions of philosophy. In the wake of each of these methods, philosophical disagreement is as rife as it ever was. Even within a tradition, there are few cases where the big questions are regarded as settled. Instead, these methods have led us again to more sophisticated versions of old disagreements.\n(D. J. Chalmers 2015)\n\nWhile the existence of the external world had always commanded a near-consensus, the question of God is interesting, as it has a dramatic and unidirectional change in opinions, from almost total consensus on the existence of God, to 73% consensus on His nonexistence. This is an example of historical change in the meta-problem of theology.\nI consider the meta-problem of consciousness as an example of “philosophy with a deadline” (Bostrom 2014). Traditionally, philosophy is a rather calmly affair, a great conversation down the ages with no deadline. It was simply assumed that, barring some kind of human extinction event, there has been and will always be time to think things through. However, if the meta problem is indeed amenable to scientific explanation, then it is exposed to technological intervention, because if the meta problem is naturalizable in theory, then it will be naturalized in practice.\nWhat might cause a historical change in the meta-problem of consciousness? Consider analyzing the meta-problem from the ecological point of view. A problem-ecology creates a distribution of answers to the hard problem, and a change in problem-ecology changes the distribution. Specifically, technical or biological changes to the human world might shift the population of future people from 95% consensus that the hard problem has an explanandum, to 80% consensus that it has no explanandum.\n(Chiang 2005) sketches out just such a scenario concerning free will. The retrocausal device is a button that lights up exactly 1 second before it is pressed. A human that interacts with such a device undergoes permanent and irreversible change of its neural circuitry. Before interaction, a human is prone to say and act as if believing in free will, but afterwards, the human is prone to say and act as if not believing in free will. The proliferation of the retrocausal device has created a dramatic shift in the problem-ecology of free will, from almost total consensus on free will, to almost total consensus on the opposite, more dramatic than the shift to atheism during the past few centuries.\nThe “Gordian scenario” (cutting the Gordian knot of consciousness) seems patently conceivable. Indeed, it has been conceived previously, although in the opposite direction. In an influential paper, Empiricism and the Philosophy of Mind, Wilfrid Sellars sketches out The Myth of Jones scenario (Sellars 1956). In the myth, humans were originally without a theory of mind. They lived, worked, and spoke, but not of mind, consciousness, or qualia. Instead, they spoke only of skin, sky, and everything there is to see and touch. These ancient humans were continuously frustrated by the black box of other people, as the same person in the same situation might do a totally different thing, and a person, unprovoked, might suddenly stand up and run off ot its own. Eventually, a genius named Jones made up a new theory – the theory of mind. According to the theory of mind, people not only speak with their mouths, but might also speak inaudibly “inside their heads”. People not only have skin and hair, but might also have invisible but real personalities. And so on. The effect is that, in the problem-ecology of primitive human society, theory of mind appeared as an adaptive solution.\nAnd the process might be reversed.\nIn the p-zombie version of the conceivability argument, by merely entertaining the possibility of p-zombies, one may be convinced that consciousness is non-physical. Similarly, by merely entertaining the possibility of the Gordian scenario, one may be convinced that qualia is debunked. This debunking argument may or may not be philosophically valid (D. Chalmers 2020). However, its practical consequences do not hinge on its philosophical validity. Even if it has no philosophical import, it is still a future where consciousness is rendered ineffectual. It is entirely possible that God has existed and still exists, but if He does, He has certainly become rather hands-off recently.\nFor the sake of argument, let us assume that souls are real.11 That is, consciousness is real and not purely reducible to the material. As the Cotard delusion shows, how a soul responds to the meta-problem of consciousness depends on what kind of brain it has. We can imagine one way to arrive at the Gordian scenario, where by technological intervention, high-functioning Cotard delusionists become healthier, more productive, and generally more rational (rationalism is about consistent winning) than baseline humans, and thus the human population evolves to mostly Cotard delusionists. What might this “Disneyland without Kids” be like?\n11 It is just convenient to use the word “soul”, as so much talk of non-reductive consciousness resembles the soul in its mysterious resistance to reduction to mere materialism.It is as if the material world has again awoken from a bad dream of consciousness, into the second eternal night, while the fate of the soul world becomes even more immaterial. Perhaps they will continue to experience the qualia of saying “I don’t exist” forever (a Cartesian nightmare), or perhaps they will bud off into a world of pure qualias (a Berkeleyan dream). No matter what, it seems that no matter how much consciousness tries to claim its (partial) priority or autonomy over the material, the Gordian scenario is an existential threat. Even immortals can’t subsist on pure aether."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html",
    "href": "blog/posts/statistical-mechanics/index.html",
    "title": "Statistical Mechanics",
    "section": "",
    "text": "Liouville’s theorem: Hamiltonian dynamics preserves density in phase space."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#introduction",
    "href": "blog/posts/statistical-mechanics/index.html#introduction",
    "title": "Statistical Mechanics",
    "section": "",
    "text": "Liouville’s theorem: Hamiltonian dynamics preserves density in phase space."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#max-ent-statistical-mechanics",
    "href": "blog/posts/statistical-mechanics/index.html#max-ent-statistical-mechanics",
    "title": "Statistical Mechanics",
    "section": "Max-ent statistical mechanics",
    "text": "Max-ent statistical mechanics\nThe idea of Gibbsian statistical mechanics is to study the evolution of an entire probability distribution over all possible states.\nSETUP.\nWe have a state space \\(X\\), which by default is the phase space.\nWe study probability distributions (ensembles) over the state space.\nThe entropy of a probability distribution \\(\\rho\\) is \\[S[\\rho] := -\\int dx\\; \\rho(x) \\ln \\rho(x)\\]\n\nProposition 1 (compound entropy) \\(S_{X,Y} = S_Y + \\braket{S_{X|y}}_y\\)\n\n\nProof. Consider a compound system in ensemble \\(\\rho(x, y)\\). Its entropy is \\[S[\\rho] = -\\int dxdy \\; \\rho(x, y) \\ln \\rho(x, y)\\]\nWe can take the calculation in two steps: \\[S[\\rho] = -\\int dxdy \\; \\rho(x|y)\\rho(y) (\\ln \\rho(x|y) + \\ln  \\rho(y)) = S[\\rho_Y] + \\mathbb{E}_y[S[\\rho_{X|y}]]\\]\nHere, \\[S[\\rho_Y] = -\\int dy \\; \\rho(y) \\ln \\rho(y)\\]\nis the entropy of system \\(Y\\),\n\\[S[\\rho_{X | y}] = -\\int dx \\; \\rho(x|y) \\ln \\rho(x|y)\\]\nis the entropy of system \\(X\\) conditional on the state of system \\(Y\\) being equal to \\(y\\), and\n\\[\\mathbb{E}_y\\]\nmeans taking expectation over the state of system \\(Y\\).\nMore succinctly, \\(S_{X,Y} = S_Y + \\braket{S_{X|y}}_y\\).\n\nASSM. (maximum entropy distribution under constraint)\nIn most systems, everything measurable can be found by studying it as if it has the maximum entropy distribution under constraint.\n\nDifferential entropy depends on coordinates choice\nConsider the uniform distribution on \\([0, 1]\\). It is the maxent distribution on \\([0, 1]\\)… relative to the Lebesgue measure.\nSuppose we now stretch the \\([0, 1]\\) interval nonlinearly, by \\(f(x) = x^2\\), then the maxent distribution relative to that would no longer be the uniform distribution on \\([0, 1]\\). Instead, it would be the uniform distribution after stretching.\nThe problem is essentially this: if we change the coordinates, we change the base measure, and the differential entropy changes.\nTo fix this, we can use the KL-divergence, which is invariant under a change of base measure, as in \\[-D_{KL}(\\rho \\| \\mu) := - \\int dx\\; \\rho(x) \\ln\\frac{\\rho(x)}{\\mu(x)}\\]\nIn typical situations, we don’t need to worry ourselves with KL-divergence, as we just pick the uniform distribution \\(\\mu\\). When the state space is infinite in volume, the uniform distribution is not a probability measure, but it will work. Bayesians say that it is an improper prior.\nIn this interpretation, the principle of “maximum entropy distribution under constraint” becomes the principle of “minimal KL-divergence under constraint”, which is Bayesian inference, with exactly the same formulas.\nIn almost all cases, we use the uniform prior over phase space. This is how Gibbs did it, and he didn’t really justify it other than saying that it just works, and suggesting it has something to do with Liouville’s theorem. Now with a century of hindsight, we know that it works because of quantum mechanics: we should use the uniform prior over phase space, because phase space volumes have a natural unit of measurement: \\(h\\), Planck’s constant. Planck’s constant is a universal constant, so we should weight all of the phase space equally, giving a uniform prior.\nDEF. extensivity\nIn classical thermodynamics, extensivity means that entropy of the compound system can be calculated in a two-step process: calculate the entropy of each subsystem, then add them up. The important fact is that a subsystem still has enough independence to have its own entropy.\nThis is not always obvious. If we have two galaxies of stars, we can think of each as a “cosmic gas” where each particle is a star. Now, if we put them near each other, then the gravity between the two galaxies would mean it is no longer meaningful to speak of “the entropy of galaxy 1”, but only “the entropy of galaxy-compound 1-2”.\nIn statistical mechanics, extensivity usually means the Hamiltonian of each subsystem is unaffected by the state of the other subsystems, and the total Hamiltonian is the sum of all the Hamiltonians. However, other definitions exist.\nSETUP. the microcanonical ensemble\nIf the only constraint is the energy \\(E\\), then the maximal entropy distribution is the uniform distribution on the shell of constant energy \\(H = E\\). This is the microcanonical ensemble:\n\\[\\rho_E(x) \\propto 1_{H(x) = E}\\]\nIf we have a small system connected to a large system, then we typically don’t care about the large system, and only want to study the ensemble of the small system. In this case, we would first find the microcanonical ensemble for the total system, then integrate out of the large system, resulting in an ensemble over just the small system, like\n\\[\\rho_{small}(x) = \\int \\rho_{total}(x, y) dy\\]\nwhere \\(x\\) ranges over the state of the small system, and \\(y\\) that of the large system.\nIf we further assume that the compound system is extensive, then we can derive all the other ensembles – canonical, grand canonical, etc – depending on how the two systems are connected.\nIn the following theorem, we assume that the total system is extensive, and is already in the maximal entropy distribution (microcanonical ensemble). We derive the distribution of the small system by marginalizing out the large system.\n\nProposition 2 (Entropy is preserved in Hamiltonian systems) If a system is a Hamiltonian system with any Hamiltonian (which can change with time), then for any probability distribution \\(\\rho\\) over its phase space, its entropy is conserved over time.\nThe microcanonical ensemble is the unique maximizer of entropy under the constraint of constant energy.\n\n\nProof. The first result is by Liouville’s theorem.\nLet \\(\\rho\\) be the microcanonical distribution on the energy shell of \\(H = E\\). Given any other distribution \\(\\rho'\\), we have \\[S[\\rho'] = S[\\rho] - D_{KL}(\\rho' \\| \\rho)\\]\nwhich is maximized at only \\(\\rho' = \\rho\\).\n\n\nCorollary 1 Constrained maxent distributions are preserved in Hamiltonian systems\nThat is, given any set of constraints, if the Hamiltonian preserves these constraints over time, then any maximal entropy distribution satisfying those constraints is preserved by time-evolution under the Hamiltonian. In particular, if the Hamiltonian is constant over time, then any microcanonical ensemble is preserved by time-evolution.\n\n\nTheorem 1 (Canonical ensembles) If the two systems are in energy-contact, then the small system has the canonical ensemble\n\\[\n\\rho(x) \\propto e^{-\\beta H(x)}\n\\]\nwhere \\(\\beta\\) is the marginal entropy of energy of the large system:\n\\[\\beta := \\partial_E S[\\rho_{bath, E}]\\]\n\nSimilarly, if the two systems are in energy-and-particle-contact, then the small system has the grand canonical ensemble\n\\[\n\\rho(x) \\propto e^{-(\\beta H(x) + (-\\beta \\mu) N(x))}\n\\]\nwhere \\(-\\beta\\mu\\) is the marginal entropy of particle of the large system:\n\\[-\\beta\\mu := (\\partial_N S[\\rho_{bath, E, N}])_{E}\\]\nMore generally, if the two systems are in \\(q_1, \\dots, q_m\\) contact, then \\[\\rho(x) \\propto e^{-\\sum_i p_i q_i(x)}\\]\nwhere \\(p_i = (\\partial_{q_i} S[\\rho_{bath, q}])_{q}\\) is the marginal entropy for conserved quantity \\(q_i\\).\n\nProof. We prove the case for the energy-contact. The other cases are similar.\nSince the total distribution of the whole system is the maximal entropy distribution, we are faced with a constrained maximization problem:\n\\[\\max_\\rho S[\\rho]\\]\nThe entropy of the compound system satisfies\n\\[S = S_{system} + \\braket{S_{bath|system}}_{system}\\]\nSince the bath is so much larger than the system, we can take just the first Taylor expansion:\n\\[S_{bath|system} = S_{bath}(E) - \\beta E_{system}\\]\nwhere \\(E\\) is the total energy, and \\(E_{system}\\) is the energy of the system.\nThis gives us the constraint maximization problem of\n\\[\\max (S_{system} - \\beta \\braket{E_{system}})\\]\nThis is the statistical mechanics analog of the “maximize Helmholtz free entropy” problem.\nIn detail, we have a problem of variational calculus: \\[\n\\begin{cases}\n  \\min\\int dx\\; &\\rho(x)(\\ln\\rho(x) + \\beta E_{system}(x)) \\\\\n      \\int dx\\; &\\rho (x) = 1\n\\end{cases}\n\\]\nwhich by using the Lagrange multiplier, gives us the solution.\n\n\nProof. Alternatively, we don’t need the Lagrange multiplier. Define the Boltzmann distribution as\n\\[\\rho_B(x) = Z(\\beta)^{-1} e^{-\\beta E_{system}(x)}\\]\nwhere \\(Z(\\beta)\\) is the normalization constant (partition function), defined by\n\\[Z(\\beta) = \\int dx\\; e^{-\\beta E_{system}(x)}\\]\nIt remains to prove that \\(\\rho = \\rho_B\\).\nBy routine calculation, the optimization problem is equivalent to\n\\[\n\\min \\left(\\int dx\\; \\rho(x) \\ln\\frac{\\rho(x)}{\\rho_B(x)} - \\ln Z(\\beta)\\right)\n\\]\nand since \\(Z(\\beta)\\) is independent of \\(\\rho\\), we just need to solve\n\\[\n\\min \\int dx\\; \\rho(x) \\ln\\frac{\\rho(x)}{\\rho_B(x)} = \\min D_{KL}(\\rho \\| \\rho_B)\n\\] which is just the KL-divergence, and is minimized exactly at \\(\\rho = \\rho_B\\).\n\n\n\n\n\n\n\nextensivity\n\n\n\nExtensivitiy in statistical mechanics yields extensivity in thermodynamics. Specifically, writing \\(S_{bath}(E)\\), instead of \\(S_{bath}(E, E_{system})\\), requires the assumption of extensivity. Precisely because the bath and the system do not affect each other, we are allowed to calculate the entropy of the bath without knowing anything about the energy of the system.\n\\(S_{bath}\\) is the logarithm of the surface area of the energy shell \\(H_{bath} = E_{bath}\\). By extensivity, \\(H(x_{bath}, x_{system}) = H_{bath}(x_{bath}) + H_{system}(x_{system})\\), so the energy shells of the bath depends on only \\(E_{bath}\\), not \\(E_{system}\\).\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe proof showed something extra: If the small system is in distribution \\(\\rho\\) that does not equal to the equilibrium distribution \\(\\rho_B\\), then the total system’s entropy is\n\\[S = S_{max} - D_{KL}(\\rho \\| \\rho_B)\\]\nwhich reminds me of Sanov theorem and large deviation theory…\n\n\nEXR. Try deriving some other ensembles.\nFor example, what if we have a system in volume-contact, but not thermal-contact? This might happen when the system is a flexible bag of gas held in an atmosphere, but the bag is made of thermally insulation. Notice that in this case, energy exchange still occurs, so you should solve\nAs another example, what if we have a system in particle-contact, but not energy-contact? I don’t know when this might happen, but it could happen!\n\n\n\n\n\n\nTip\n\n\n\nIn statistics, such ensemble are called exponential families, so we can abstractly describe this as follows:\nIf a small system is in contact with a large system, and the total system is in the microcanonical ensemble, then the marginal distribution of the small system is a distribution from an exponential family."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#using-the-partition-function",
    "href": "blog/posts/statistical-mechanics/index.html#using-the-partition-function",
    "title": "Statistical Mechanics",
    "section": "Using the partition function",
    "text": "Using the partition function\nDEF. Let \\(Z = \\int dx\\; e^{-\\beta E(x)}\\) be the partition function, and let \\(f^* := \\ln Z\\).\n\\(Z\\) is a function of \\(\\beta\\), and other possible constraints that might directly change the energy levels of the system. We can more explicitly write it as \\[Z(\\beta; c) = \\int dx \\; e^{-\\beta E_c(x)}\\]\nwhere \\(c\\) stands for the other constraints on the system, such as the size of the container, the number of particles, etc.\n\nProposition 3 (The partition function generates all moments of energy) Let a system be in canonical ensemble with inverse temperature \\(\\beta\\), and let \\(K(t) := \\ln \\braket{e^{tE}}\\) be the cumulant generating function of its energy, then \\[K(t) = \\ln Z(\\beta-t) - \\ln Z(\\beta)\\]\nIn particular, the \\(n\\)-th cumulant of energy is\n\\[\\kappa_n(E) = K^{(n)}(t) |_{t=0} = (-\\partial_\\beta)^n (\\ln Z)\\]\nFor example, the first two cumulants are the mean and variance: \\[\\braket{E} = (-\\partial_\\beta) (\\ln Z), \\quad \\mathrm{Var}(E) = \\partial_\\beta^2 (\\ln Z)\\]\n\nIn typical systems made of \\(N\\) particles, where \\(N\\) is large, we have \\(\\ln Z \\propto N\\), thus showing that \\(\\sqrt{\\mathrm{Var}(E)}/\\braket{E} \\propto N^{-1/2}\\), meaning that the distribution of energy converges to the average value as \\(N \\to \\infty\\).\nA similar proposition applies for the grand canonical ensemble, etc."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#free-entropies",
    "href": "blog/posts/statistical-mechanics/index.html#free-entropies",
    "title": "Statistical Mechanics",
    "section": "Free entropies",
    "text": "Free entropies\nIn the above, the only constraint we have imposed is constant energy, yielding the microcanonical ensemble. We can allow more constraints, yielding the fully general Gibbsian statistical mechanics.\nA common trick in statistical mechanics is to characterize the same equilibrium in many different perspectives. For example, the canonical ensemble has three characterizations at least.\nSETUP.\nWe have a state space \\(X\\), and probability distributions \\(\\rho\\) over \\(X\\).\nMacroscopic observables \\(A, B, C, \\dots\\) are functions of type \\(X \\to \\mathbb{R}\\).\nA constraint can be an equality or inequality on observables. For example, if we have a tube of jelly in a box of volume \\(10\\), then the constraint is \\(0 \\leq V(x) \\leq 10\\).\nA constraint can also be an equality or inequality on the distribution. For example, we can specify that the average energy is exactly 1, by \\[\\int dx\\; \\rho(x) E(x) = 1\\]\nThe equilibrium distribution under constraint is the maximal entropy distribution satisfying the constraints.\nDEF. (free entropies)\nJust like in thermodynamics, we can take convex duals of the entropy function, to obtain various free entropies.\nHelmholtz free entropy: \\[f[\\rho] := S[\\rho] - \\beta \\braket{E} = \\int dx \\; \\rho(x) (-\\ln \\rho(x) - \\beta E(x))\\]\nGibbs free entropy: \\[g[\\rho] = S[\\rho] - \\beta \\braket{E} - \\beta P \\braket{V}\\]\nAnd similarly for others.\n\nProposition 4 (The chain rule for free entropies) \\(f_X = S_Y + \\braket{f_{X|y}}_y\\), and similarly \\(g_X = S_Y + \\braket{g_{X|y}}_y\\), and similarly for all other convex duals of the entropy.\n\n\nProof. \\[\n\\begin{aligned}\n  f_X &= S_X - \\beta \\braket{E}_x  \\\\\n  &= S_Y + \\braket{S_{X|y}}_y - \\beta \\braket{\\braket{E}_{x \\sim X|y}}_y \\\\\n  &= S_Y + \\braket{f_{X|y}}_y\n\\end{aligned}\n\\]\n\n\nProposition 5 (4 characterizations of the canonical ensemble)  \n\n(total entropy under fixed energy constraint) The canonical ensemble maximizes total entropy when the system is in contact with an energy bath that satisfies \\(\\partial_E S_{bath} = \\beta\\), and the total energy is fixed.\n(entropy under mean energy constraint) A system maximizes its entropy under constraint \\(\\braket{E} = E_0\\) when it assumes the canonical ensemble with \\(\\beta\\) that is the unique solution to \\(\\int dx \\; e^{-\\beta E(x)} = E_0\\).\n(thermodynamic limit): Take \\(N\\) copies of a system, and connect them by energy-contacts. Inject the system with total energy \\(NE_0\\), and let the system reach its microcanonical ensemble. Then at the thermodynamic limit of \\(N\\to \\infty\\), the distribution of a single system is the canonical distribution with \\(\\beta\\) that is the unique solution to \\(\\int dx \\; e^{-\\beta E(x)} = E_0\\).\n(free entropy) A system maximizes its Helmholtz free entropy when it assumes the canonical ensemble. At that point, the maximal Helmholtz free entropy is \\(f^* = \\ln Z\\), where \\(Z = \\int dx \\; e^{-\\beta E(x)}\\) is the partition function.\n\n\n\nProof. \n\nWe already proved this.\nUse the Lagrange multiplier.\nIsolate one system, and treat the rest as an energy-bath.\n\\(f[\\rho] = \\ln Z - D_{KL}(\\rho \\| \\rho_B)\\)."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#conditional-entropies",
    "href": "blog/posts/statistical-mechanics/index.html#conditional-entropies",
    "title": "Statistical Mechanics",
    "section": "conditional entropies",
    "text": "conditional entropies\n\nTheorem 2 (conditional entropy) Given any random variable \\(X\\), and an “observable” variable \\(Y\\) that is determined by \\(X\\), if \\(X\\) is the maximal entropy distribution under constraint with entropy \\(S_X^*\\), then the observable \\(Y\\) follows a Boltzmann distribution, as \\[\\rho_Y^*(y) = e^{S_{X|y}^* - S_X^*}\\]\nwhere \\(S_{X|y}^*\\) is the maximal entropy for \\(X\\) conditional on the same constraints, plus the constraint that \\(Y = y\\).\nFurthermore, \\[e^{S_X^*} = \\int dy\\; e^{S_{X|y}^*}\\]\n\n\nProof. By assumption, \\(X\\) is the unique solution to the constrained optimization problem\n\\[\n\\begin{cases}\n    \\max S_X \\\\\n    \\text{constraints on $x$}\n\\end{cases}\n\\]\nBecause \\(S_X = S_Y + \\braket{S_{X|y}}_{y \\sim Y}\\), we realize that solving that one constrained optimization problem is really solving an entire family of constrained optimization problems. In particular, it also solves the problem\n\\[\n\\begin{cases}\n    \\max S_Y + \\braket{S_{X|y}}_{y\\sim Y} \\\\\n    \\text{constraints on $x$}\n\\end{cases}\n\\]\nNow, we can solve the original problem in a two-step process: For each possible observable \\(y\\sim Y\\), we solve an extra-constrained problem:\n\\[\n\\begin{cases}\n    \\max S_{X|y} \\\\\n    \\text{original constraints on $x$} \\\\\n    \\text{$x$ must be chosen such that the observable $Y = y$}\n\\end{cases}\n\\]\nThen, each such problem gives us a maximal conditional1 entropy \\(S_{X|y}^*\\), and we can solve for \\(Y\\) by\n1 If you’re a pure mathematician, you can formalize this using measure disintegration.\\[\\max(S_Y + \\braket{S_{X|y}^*}_{y \\sim Y})\\]\nAgain, the solution is immediate once we see it is just the KL-divergence:\n\\[S_Y + \\braket{S_{X|y}^*}_{y \\sim Y} = - \\int dy \\; \\rho_Y(y) \\ln\\frac{\\rho_Y(y)}{e^{S_{X|y}^*}} = \\ln Z - D_{KL}(\\rho_Y \\| \\rho_Y^*)\\]\nwhere\n\\[Z = \\int dy\\; e^{S_{X|y}^*}, \\quad \\rho_Y^*(y) = \\frac{e^{S_{X|y}^*}}{Z}\\]\nAt the optimal point, the entropy for \\(X\\) is maximized at \\(S_X^* = \\ln Z - 0\\), so \\(Z = e^{S_X^*}\\).\n\nEXP. the canonical ensemble again\nConsider a small system with energy states \\(E_1, E_2, \\dots\\) and a large bath system, in energy contact. We can set \\(X\\) to be the combined state of the whole system, and \\(Y\\) to be the state of the small system.\nOnce we observe \\(y\\), we have fully determined the small system, so the small system has zero entropy, and so all the entropy comes from the bath system: \\[S_{X|y}^* = S_{bath} = S_{bath}(E_{total}) - \\beta E_y\\]\nConsequently, the distribution of the small system is \\[\\rho_Y(y) \\propto e^{-\\beta E_y}\\]\nwhich is the Boltzmann distribution, as expected.\nSimilar calculation gives us the grand canonical ensemble, etc.\nThe above theorem can be generalized to conditional free entropies.\n\nTheorem 3 (conditional free entropy) Given any random variable \\(X\\), and an “observable” variable \\(Y\\) that is determined by \\(X\\), if \\(X\\) is the distribution that maximizes Helmholtz free entropy under constraint with Helmholtz free entropy \\(f_X^*\\), then the observable \\(Y\\) is distributed as \\[\\rho_Y^*(y) = e^{f_{X|y}^* - f_X^*}\\]\nwhere \\(f_{X|y}^*\\) is the maximal Helmholtz free entropy for \\(X\\) conditional on the same constraints, plus the constraint that \\(Y = y\\).\nFurthermore, \\[e^{f_X^*} = \\int dy\\; e^{f_{X|y}^*}\\]\nSimilarly for Gibbs free entropy, and all other free entropies.\n\n\nProof. First note that \\(f_X = S_Y + \\braket{f_{X|y}}_y\\). Then we proceed to argue in the same way."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#fluctuation-relations",
    "href": "blog/posts/statistical-mechanics/index.html#fluctuation-relations",
    "title": "Statistical Mechanics",
    "section": "Fluctuation relations",
    "text": "Fluctuation relations\n\nFluctuation of observables\nSuppose we have a tank of oxygen gas, and it is in the equilibrium distribution (Maxwell-Boltzmann). Now, if we sample its pressure \\(P\\), then every time we sample it, we sample a particular microstate \\(x\\) from its equilibrium distribution, and each corresponds to a different pressure \\(P(x)\\). We know that these particular pressures should be tightly bunched around its average value – the thermodynamic pressure \\(\\braket{P}\\)… but how bunched-up is it?\nMore generally, suppose we have a system in the equilibrium state (maximal entropy under constraint), how much fluctuation does it have?\nEXP. systems in energy-contact, the zeroth law\nTake several systems, and let them exchange energy, but nothing else. For concreteness, we can imagine taking several copper tanks of gas, and let them touch each other. The tanks hold their shape, not expanding or contracting.\nThe system has total entropy \\[S = \\sum_i S_i(E_i, A_i)\\]\nwhere \\(A_i\\) stand for the other state variables we don’t care about, because they are held constant\nThere is a single constraint of constant total energy: \\[E = \\sum_i E_i\\]\nIn the thermodynamical limit, the compound system reaches the maximal entropy state \\(E_1^*, \\dots, E_n^*\\), which solves the following constrained maximization \\[\\begin{cases}\n    \\max \\sum_i S_i(E_i, A_i)\\\\\n    E = \\sum_i E_i\n\\end{cases}\\]\nBy calculus, at the optimal point, all systems satisfy\n\\[\n(\\partial_{E_i} S_i)_{A_i} = \\beta\n\\]\nfor some number \\(\\beta\\). This is the zeroth law of thermodynamics.\nDER.\nHowever, we are in statistical mechanics, so the compound system actually does not stay exactly at the optimal point. Instead, the energy levels fluctuate.\nLet us write the fluctuation vector as\n\\[Y = (\\Delta E_1, \\dots, \\Delta E_n)\\]\nwhich satisfies the constraint \\(\\sum_i \\Delta E_i = 0\\).\nLet the fluctuation vector be the observable. As proved previously, the fluctuation satisfies\n\\[\\rho_Y(y) \\propto e^{S^*_{X|y}}\\]\nwhere \\(S^*_{X|y}\\) is the entropy of the compound system, given \\(Y = y\\). For small fluctuations, this is just:\n\\[S^*_{X|y} = \\sum_i S_i(E_i^*) + (\\partial_{E_i} S_i)_{A_i} \\Delta E_i + \\frac 12 (\\partial_{E_i}^2 S_i)_{A_i} (\\Delta E_i)^2 + \\cdots\\]\nSince \\(\\sum_i \\Delta E_i = 0\\), this just gives\n\\[\\rho_Y(y) \\propto e^{\\sum_i \\frac 12 (\\partial_{E_i}^2 S_i)_{A_i} (\\Delta E_i)^2}\\]\nNow, \\(\\partial_E S = \\beta\\), and \\(\\partial_E^2 S = -\\frac{1}{T^2 C}\\) in typical thermodynamic notation, where \\(C\\) is \\(\\partial_T E\\), the heat capacity (holding all other variables \\(A\\) constant).\nIn particular, for gases, it is\n\\[\\rho_Y(y) \\propto e^{-\\sum_i \\frac{1}{2T^2 C_{V, i}} (\\Delta E_i)^2}\\]\nwhere \\(C_{V, i}\\) is the constant-volume heat capacity of the \\(i\\) -th gas.\nIn particular, if we have monoatomic ideal gas, with \\(C_V = \\frac 32 N\\), then the size of a typical fluctuation is on the order of\n\\[\\sim\\sqrt N T \\sim N^{-1/2} E^*\\]\nThat is, a typical fluctuation energy is only \\(N^{-1/2}\\) that of the mean energy.\n\n\nDensity fluctuation in the canonical ensemble\nTODO sethna section 6.7"
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#maximum-caliber-statistical-mechanics",
    "href": "blog/posts/statistical-mechanics/index.html#maximum-caliber-statistical-mechanics",
    "title": "Statistical Mechanics",
    "section": "Maximum caliber statistical mechanics",
    "text": "Maximum caliber statistical mechanics\n(Ghosh et al. 2006; Ghosh et al. 2020)\nIn general, maximal caliber statistical mechanics is like maximal entropy statistical mechanics. You write down a formula for path-space entropy, and a constraint on allowed paths. Maximize the entropy under constraint, and you would obtain a Boltzmann distribution in path space.\n\nMarkov chains\nSETUP.\n\\(N\\) timesteps in total.\n\\(s_t\\) is the state of timestep \\(t\\).\nThere are \\(m\\) states in total.\n\nTheorem 4 If we fix the singleton probability \\(p_i\\) of each state, then the maximum entropy distribution is the Markov chain with uniform initial probability and \\(p_{i\\to j} = p_i p_j\\).\n\n\nProof. By Lagrange multipliers.\nIf we fix the singleton probability of each state, then the problem is a constrained maximization problem\n\\[\n\\begin{cases}\n    \\max S \\\\\n    \\frac 1N \\sum_t 1[s_t = k] = p_k, \\quad \\forall k = 1, \\dots, m\n\\end{cases}\n\\]\nThis is the same problem as \\(N\\) balls in a certain constrained microcanonical ensemble. When \\(N\\) is large enough, the discrete “macrostate” \\(\\frac 1N \\sum_t 1[s_t = k]\\) becomes continuous, and we can use the Lagrange multiplier to obtain \\[\\rho(s_1, \\dots, s_N) = \\frac 1Z e^{-\\sum_{k=1}^m \\lambda_k (\\frac 1N \\sum_{t=1}^N 1[s_t =k] - p_k)}\\]\nThis factors over time \\(t\\), giving us \\[\\rho(s_1, \\dots, s_N) = \\prod_{t=1}^N \\rho(s_t)\\]\nwith\n\\[\\rho(s_t=k) \\propto e^{-\\sum_{k=1}^m\\frac{\\lambda_k}{N}(1[s_t =k] - p_k)} \\propto e^{-\\frac{\\lambda_k}{N}}\\]\nThe multiplier \\(\\lambda_k\\) can be found by the typical method of solving \\(p_k = -\\partial_{\\lambda_k}\\ln Z\\), or we can take the shortcut and notice that \\(\\rho(s_t=k) = p_k\\), and be done with it.\n\n\nTheorem 5 If we fix the transition probability \\(p_{i \\to j}\\) of each state-pair, then the maximum entropy distribution is the Markov chain with uniform initial probability. If we fix the initial probability, then it’s still the Markov chain with the same transition probabilities.\nAnd more generally, if we fix \\(n\\)-th order transition probability \\(p_{i_1, \\dots, i_n \\to j}\\), then we obtain an \\(n\\)-th order Markov chain model.\n\n\nProof. Similarly as above, the path-space distribution is \\[\\rho(s_1, \\dots, s_N) \\propto \\prod_{t=1}^{N-1} e^{-\\sum_{k, k' \\in 1:m} \\frac{\\lambda_{k, k'}}{N} 1[s_t = k, s_{t+1} = k']} \\propto \\prod_{t=1}^{N-1} p_{s_t \\to s_{t+1}}\\]\nBecause the distribution does not specify \\(s_1\\), it is uniformly distributed on \\(s_1\\). Otherwise, we can constrain \\(s_1\\) with yet another set of Lagrange multipliers and obtain \\(\\rho(s_1, \\dots, s_N) \\propto \\rho(s_1) \\times_{t=1}^{N-1} \\rho(s_t, s_{t+1})\\). Similarly for higher orders.\n\n\n\ndiffusion\nThe path-space entropy\n\\[\nS = - \\int \\rho(x) \\ln \\rho(x) D[x]\n\\]\nwhere \\(D[x]\\) means we integrate over path space, and \\(x: [0, T] \\to \\mathbb{R}^n\\) is a path.\nWe discretize the path into \\(x: \\{0, 1, 2, \\dots, N\\} \\to \\mathbb{R}^n\\), then because we can decompose\n\\[\n\\rho(x) = \\rho(x_0) \\rho(x_1 | x_0) \\cdots \\rho(x_N | x_{0:N-1})\n\\]\nthe path-space entropy decomposes sequentially:\n\\[\nS = S[x_0] + E[S[x_1 | x_0]] + E[S[x_2 | x_{0:1}]] + \\dots + E[S[x_N | x_{0:N-1}]]\n\\]\nTo prevent the entropy from diverging, we need to impose some constraints. If we constrain the second moment of each step, as\n\\[(E[x_t|x_{0:t-1}], E[x_t^2|x_{0:t-1}]) = (0, \\sigma^2), \\quad \\forall t \\in 0:N\\]\nby reasoning backwards from \\(t = N\\) to \\(t=0\\), we find that the maximal entropy distribution is a white noise:\n\\[\n\\rho(x) = \\prod_{t\\in 0:N} \\rho(x_t), \\quad \\rho(x_t) \\propto e^{-\\frac{\\|x_t\\|^2}{2\\sigma^2}}\n\\]\nIf you have studied dynamic programming and cybernetics, this should look very similar to the argument by which you derived the LQR.\nTo keep the path from exploding into white noise, we instead impose the constraints on the step sizes\n\\[(E[x_t - x_{t-1}|x_{0:t-1}], E[\\|x_t - x_{t-1}\\|^2|x_{0:t-1}]) = (0, \\sigma^2), \\quad \\forall t \\in 1:N\\]\nand \\(x_0 = 0\\).\nNow, as in dynamical programming, we can reason backwards from \\(t = N\\) to \\(t=0\\), and we find that the maximal entropy distribution is the Brownian motion\n\\[\\rho(x) \\propto e^{-\\frac{\\sum_{t\\in 1:N} \\| x_t-x_{t-1}\\|^2}{2\\sigma^2}}\\]\nIf we constrain the first and second moments of each step, and allow them to be affected by the previous step, as in\n\\[\n\\begin{cases}\n    E[x_t - x_{t-1}|x_{0:t-1}] &= \\mu(t, x_{t-1}) \\\\\n    E[(x_t - x_{t-1}) (x_t - x_{t-1})^T|x_{0:t-1}] &= \\Sigma(t, x_{t-1})\n\\end{cases}, \\quad \\forall t \\in 1:N\n\\]\nthen, reasoning backwards as before, we would obtain the Fokker–Planck equation.\nOther results, such as the Green-Kubo relation, the Onsager reciprocal relations, etc, can be similarly derived by imposing the right constraints in path space. (Hazoglou et al. 2015)\n\n\nFluctuation-dissipation relations\nImagine if you have a weird liquid. You put a piece of pollen into it, and watch it undergo Brownian motion. Now I flip a switch and suddenly all friction disappears from the liquid. What would happen? The pollen is still being hit by random pieces of molecules, so its velocity is still getting pushed this and that way. However, without friction, the velocity at time \\(t\\) is now obtained by integrating all past impulses, with no dissipation whatsoever. Consequently, its velocity undergoes a random walk, and its position undergoes \\(\\int_0^t W_s ds\\), This is very different from what we actually observe, which is that its position undergoes a random walk, not a time-integral of it.\nIn order to reproduce the actual observed behavior, each fluctuation of its velocity must be quickly dissipated by friction, in a perfect balance such that \\(\\frac 12 m \\braket{v^2} = k_BT\\) exactly. This perfect conspiracy is the fluctuation-dissipation theorem.\nSETUP. Now we set up a one-dimensional fluctuation-dissipation problem.\nWe have a particle in a sticky fluid, moving on the number line. The particle starts at \\(x = 0, t = 0\\), and at each time-step of \\(\\Delta t\\), it moves by \\(\\Delta x\\) to the left or the right. We define \\(D = \\frac{\\Delta x^2}{\\Delta t}\\) to be the “diffusion constant”.\nThe fluid is at temperature \\(\\beta^{-1}\\), and we pull on the particle at constant force \\(F\\). We expect that \\(F = \\gamma \\braket{v}\\), where \\(v\\) is the ensemble-average velocity of the particle, and \\(\\gamma\\) is the viscosity constant.\nNow, we let the particle move for a time \\(t = N\\Delta t\\), where \\(N\\) is a large number. The particle would have arrived at some point \\(x\\), which is a random variable. The particle’s time-averaged velocity is \\(v = x/t\\).\nDER.\nThe number of possible paths that connect \\((0, 0)\\) with \\((t, x)\\) is \\(\\binom{N}{\\frac N2 - \\frac{x}{2\\Delta x}}\\), therefore, the path-space entropy is\n\\[S_{path} = \\ln \\binom{N}{\\frac N2 - \\frac{x}{2\\Delta x}}\\]\nBecause the external force performs work \\(Fx\\), which is dissipated into the sticky liquid at temperature \\(\\beta\\), we also have\n\\[S_{work} = \\beta Fx\\]\nBecause \\(N\\) is large, \\(\\braket{x}\\) should be highly concentrated around the point of maximal entropy. That is, we should have\n\\[\n\\braket{x} \\approx \\mathop{\\mathrm{argmax}}_x (S_{path} + S_{work})\n\\]\nNotice how this is the exact same problem as the case where we have a rubber band. By routine calculation, this simplifies to\n\\[\\braket{x} = \\beta FN(\\Delta x)^2\\]\nwhich gives us, after further simplification, the Einstein relation:\n\\[\\beta D \\gamma = 1\\]"
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#crooks-fluctuation-theorem",
    "href": "blog/posts/statistical-mechanics/index.html#crooks-fluctuation-theorem",
    "title": "Statistical Mechanics",
    "section": "Crooks fluctuation theorem",
    "text": "Crooks fluctuation theorem\n\nIn a closed system (microcanonical)\nSETUP. The system is a classical-mechanical system, with time-reversible dynamics, and follows Liouville’s theorem.\nWe have a thermodynamic system held under variable constraints \\(x\\).\nThe system starts in microcanonical ensemble of energy \\(E_1\\). Then we change the constraints \\(x(t)\\), quickly or slowly, over a time interval \\(t\\in [0, \\tau]\\). Let the microstate trajectory of the system be \\(y(t)\\), arriving at the energy shell of \\(E_2\\).\nDuring the forward process, if the system undergoes microstate trajectory \\(y(t)\\), then we have to expend work \\(W[x(t), y(t)] = E_2 - E_1\\).\nLet \\(S_1^*\\) be the maximal entropy of the system when held under the constraints of \\(x(0)\\), and when the system has energy \\(E_1\\). Similarly for \\(S_2^*\\).\n\n\n\n\n\n\nWarning\n\n\n\n\\(S_1 = S_1^*\\), since the system starts in thermal equilibrium. However, by Liouville’s theorem, entropy is conserved! So we actually have \\(S_2 = S_1 \\neq S_2^*\\), because the system does not end in thermal equilibrium.\n\n\n\\(x', y'\\) are \\(x, y\\) time-reversed.\nFor example, if we have a piston of gas made of only a few gas molecules, then the constraint is the volume \\(V\\), and we want to study the probability of expending work \\(W\\) if we give the piston head a push. The push can be slow or fast – arbitrarily far from equilibrium. Crooks theorem applies no matter how we push the piston head.\n\n\n\n(Sethna 2021, fig. 4.10)\n\n\n\n\n\n(Sethna 2021, fig. 4.11)\n\n\nSETUP. probability density over path-space.\nLet \\(\\delta E_1, \\delta E_2\\) be infinitesimals, and let \\(E_1, E_2\\) be real numbers.\nGiven a small bundle of microtrajectories \\(y\\), we can measure its path-space volume as \\(D[y]\\). Suppose they start on the energy shell \\([E_1, E_1 + \\delta E_1]\\), then they would end up somewhere. If we’re lucky, they would end up on the energy shell \\([E_2 + \\delta E_2]\\).\nSuppose the system starts in the microcanonical ensemble on the energy shell \\([E_1, E_1 + \\delta E_1]\\), and we perform the constraint-variation \\(x\\), then there is a certain probability \\(\\delta P\\) that we would sample a trajectory from the small bundle. That small probability is \\[\\rho(y | x) D[y]\\]\nwhere \\(\\rho(y | x)\\) is a probability density over path-space. In particular, \\(\\rho(y | x) = 0\\) identically, unless \\(y(0)\\) is on the energy shell \\([E_1, E_1 + \\delta E_1]\\).\nRunning the argument backwards, we can define \\(\\rho'(y' | x')\\), another probability density over paths. This one satisfies \\(\\rho'(y'| x') = 0\\) unless \\(y'(0)\\) is on the energy shell \\([E_2, E_2 + \\delta E_2]\\).\n\nTheorem 6 (Crooks fluctuation theorem (microcanonical)) For any trajectory \\(y\\) such that it starts on the \\([E_1, E_1 + \\delta E_1]\\) energy shell, and ends on the \\([E_2, E_2 + \\delta E_2]\\) energy shell,\n\\[\\frac{\\rho(y | x)}{\\rho'(y' | x')} = e^{\\Delta S}\\]\nwhere \\(\\Delta S= \\ln\\Omega_2 - \\ln\\Omega_1\\), \\(\\Omega_1\\) is the phase space volume of the first energy shell, and \\(\\Omega_2\\) the second.\n\n\n\n\n\n\n\nNote\n\n\n\nIf \\(y\\) does not start on the first energy shell, or does not end on the second energy shell, then either the nominator or the denominator is zero, and so the equation fails to hold.\n\n\n\nProof. In the forward process, the probability of going along that trajectory is \\[\\rho(x|y) D[x] = \\frac{\\delta V}{\\Omega_1}\\]\nwhere \\(\\delta V\\) is the phase-space volume of the shaded set.\nIn the backward process, the probability of reversing that trajectory is \\[\\rho'(x'|y') D[x']= \\frac{\\delta V'}{\\Omega_2}\\]\n\\(\\delta V' = \\delta V\\) by Liouville’s theorem, and \\(D[x] = D[x']\\) because \\(x'\\) is just \\(x\\) time-reversed.\n\n\n\nIn an energy bath (canonical)\nNow, suppose we take the same piston of gas, and put it in energy-contact with an energy bath, then at thermal equilibrium, the piston of gas would have the Boltzmann distribution \\(\\propto e^{-\\beta E}\\). We can then give the piston head a push, which would cause it to undergo\n\nTheorem 7 (Crooks fluctuation theorem) \\[\\frac{\\rho(y | x)}{\\rho'(y' | x')} =  e^{S[x, y]} = e^{\\beta (W[x, y] - \\Delta F^*)}\\]\nwhere \\(S[x, y]\\) is the entropy produced during the forward process, after the system has equilibrated, and \\(\\Delta F^* = F^*_2 - F^*_2\\) is the increase in equilibrium Helmholtz free energy of the system.\n\n\n\n\n\n\n\nWarning\n\n\n\nIn both forward and backward cases, we start with a thermal equilibrium, and end with a thermal disequilibrium.\nFor example, suppose we have a small tank of a few gas molecules in thermal equilibrium with a large energy bath.\nNow, we quicky push the piston head in according to the function \\(x(t)\\). The trajectory of the system would go through is \\(y(t)\\), which is determined by both \\(x(t)\\) and the initial state of both the system and the energy bath.\nNow, we wait a long time, until the tank is in thermal equilibrium again. Then we pull the piston head out with time-reversed trajectory. Because the forward trajectory was quick, the backward trajectory was also quick.\n\n\n\n\n\n\n\n\nequilibrium Helmholtz\n\n\n\nWe wrote \\(F^*\\) instead of \\(F\\), to emphasize that we are dealing with equilibrium Helmholtz free energy, defined by \\(F^* = \\min_\\rho (\\braket{E} - TS[\\rho])\\), and not the generic version \\(\\braket{E} - TS[\\rho]\\).\nThis is vitally important, because at time \\(\\tau\\), when the constraints have just reached their new values, the system is not in equilibrium. We would have to hold the constraints constant for a while for the system to return to equilibrium with the energy bath. Despite this, Crooks fluctuation theorem uses \\(\\Delta F^*\\), which is computed at equilibrium.\n\n\n\nProof. Apply the microcanonical version of Crooks theorem to the entire compound system that includes both the bath and the system, then integrate over all possible microstate trajectories of the bath \\(y_{bath}\\).\n\\[\\begin{aligned}\n  S[x, y] &= \\Delta S_{bath} + \\Delta S_{system} \\\\\n  &= \\beta \\Delta E_{bath} + \\Delta S_{system} \\\\\n  &= \\beta(W[x, y] - \\braket{\\Delta E_{system}}_2) + \\Delta S_{system} \\\\\n  &= \\beta (W[x, y] - \\Delta F^*)\n\\end{aligned}\\]\nwhere \\(\\braket{\\cdot}_2\\) means the canonical ensemble average under constraint \\(x(\\tau)\\).\nNotice that the work expended/entropy produced depends only on the system’s microtrajectory \\(y(t)\\), and not on the bath’s microtrajectory \\(y_{bath}(t)\\). That is,\n\\[S[x, y, y_{bath}] = S[x, y]\\]\nThis will be used again in the next step when we integrate over \\(D[y_{bath}]\\).\n\\[\\begin{aligned}\n  \\rho(y|x) &= \\int_{y, y_{bath}, x \\text{ is valid}}D[y_{bath}]\\; \\rho(y, y_{bath} | x)  \\\\\n  &=  \\underbrace{\\int_{y', y'_{bath}, x' \\text{ is valid}}D[y'_{bath}]}_{\\text{reversible dynamics}}\\; \\underbrace{e^{S[x, y, y_{bath}]}\\rho'(y', y'_{bath} | x')}_{\\text{microcanonical Crooks}}  \\\\\n  &=  \\int D[y'_{bath}] \\; e^{\\red{S[x, y]}}\\rho'(y', y'_{bath} | x') \\\\\n  &=  e^{S[x,y]} \\int D[y'_{bath}] \\; \\rho'(y', y'_{bath} | x') \\\\\n  &=  e^{S[x,y]} \\rho'(y'|x')\n\\end{aligned}\\]\n\n\nCorollary 2 \\[\\frac{\\rho(W | x)}{\\rho'(-W | x')} =  e^{\\beta (W - \\Delta F^*)}\\]\nwhere \\(\\rho(W|x)\\) is the probability density of expending work \\(W\\) in the forward process.\n\n\nProof. Integrate over all forward microtrajectories \\(y\\) satisfying \\(W[x, y] \\in [W, W+\\delta W]\\). By reversibility, \\(W[x', y'] = [-W - \\delta W, -W]\\) for such microtrajectories.\n\n\n\nOther ensembles\nLooking at the proof for Crooks theorem for the canonical ensemble, we immediately obtain many other possible Crooks theorems, one per free entropy.\nEXP. Crooks theorem for Gibbs free energy \\(G\\)\nSuppose we have a piston of magnetic gas in energy-and-volume contact with a bath. Now suppose the gas is in equilibrium with the bath, and we vary the external magnetic field over a trajectory \\(x\\). Over the microstate trajectory \\(x\\), the external world would expend both some energy \\(W[x, y]\\) and some volume \\(V[x, y]\\).\n\\[\\frac{\\rho(y | x)}{\\rho'(y' | x')} =  e^{S[x, y]} = e^{\\beta (W[x, y] + PV[x, y] - \\Delta G^*)}\\]\nEXP. Crooks theorem for Landau free energy \\(\\Omega\\)\nSuppose we have a chemical reaction chamber of fixed volume, and in energy-and-particle contact with a bath with chemical potentials \\(\\mu_i\\).\n\\[\\frac{\\rho(y | x)}{\\rho'(y' | x')} =  e^{S[x, y]} = e^{\\beta (W[x, y] -  \\sum_i \\mu_i N_i[x, y] - \\Delta \\Omega^*)}\\]"
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#jarzynski-equality",
    "href": "blog/posts/statistical-mechanics/index.html#jarzynski-equality",
    "title": "Statistical Mechanics",
    "section": "Jarzynski equality",
    "text": "Jarzynski equality\nLet \\(W\\) be the total work we expended by changing the constraints during the interval \\([0, \\tau]\\). Since the work expended depends on the details of the heat bath and the starting state of the system at \\(t=0\\), this is a random variable.\n\nTheorem 8 (Jarzynski equality) \\[\\braket{e^{-\\beta W}} = e^{-\\beta \\Delta F^*}\\]\nwhere the expectation is taken over many repeats of the same experiment (ensemble average).\n\n\nProof. Integrate Crooks over all forward trajectories \\(D[x]\\).\n\\[\\rho(y | x) e^{-\\beta W[x, y] } = \\rho'(y' | x') e^{-\\beta\\Delta F}\\]\nnow integrate over \\(\\int D[y]\\), using the fact that \\(D[y] = D[y']\\).\n\n\nCorollary 3 (violation of second law is exponentially unlikely) \\[Pr((W - \\Delta F^*) \\leq - \\delta W) \\leq e^{-\\beta \\delta W}\\]\n\n\nProof. Apply Markov’s inequality.\n\nEXP. high probability of work extraction\nClassically, if we have a single system in thermal equilibrium with a single energy-bath, and we perform a cyclic operation on it, then we can’t extract work, lest we violate the second law.\nStatistically, \\(\\braket{e^{-\\beta W}} = 1\\), and so it is entirely possible for us to extract work with high probability, as long as there is a small probability to lose a large enough amount of work.\n(Maillet et al. 2019) constructed a quantum mechanical device with a single-electron transistor. The electron can expend work. They managed to extract work from the device with over 75% probability.\n\n\n\nFigure from (Maillet et al. 2019, fig. 3.c)\n\n\n\nWorked example: bouncing ball\nThis example is from (Sethna 2021, exercise 4.8), which itself derives from (Lua and Grosberg 2005). See also (Híjar and de Zárate 2010) for another solved example, of a chest expander with mass points stuck in the middle of the springs. You might need to read my post on field-theoretic calculations before attempting that example.\nWe have a one-dimensional system, of a single ball bounding between two walls of a piston. The only control we have is that we can move one of the piston heads. At the start, the piston has length \\(L\\), and the system is in thermal equilibrium at inverse temperature \\(\\beta\\). We plunge the piston head at velocity \\(v\\) for time \\(\\Delta L / v\\), then immediately reverse it, taking another \\(\\Delta L / v\\). We explicitly calculate that \\(\\braket{e^{-\\beta W}} = 1\\).\n\n\n\n(Sethna 2021, fig. 4.12)\n\n\nThe phase space of the ball has 2 dimensions, \\((p, x)\\). The Boltzmann distribution is\n\\[\\rho(p, x) = \\rho(p) \\rho(x) = \\frac{1}{\\sqrt{2\\pi m/\\beta}}e^{-\\frac{\\beta}{2m}p^2} \\times \\frac{1}{L}\\]\nWe assume that \\(L\\) is large enough, such that the ball hits the piston head at most once. There are three possibilities:\n\nIf the piston head hits the ball during the in-stroke, then the ball’s velocity increases by \\(2v\\), and its kinetic energy increases by \\[W = \\Delta KE = 2v(mv - p)\\]\nIf the piston head hits the ball during the out-stroke, then the ball’s velocity decreases by \\(2v\\), and its kinetic energy increases by\n\\[W = 2v(mv+p)\\]\nOtherwise, the piston head avoids the ball, and we have \\(W = 0\\).\n\nIf at \\(t=0\\), the ball is in the phase space region labelled “in region”, then it will be hit in the in-stroke. If at \\(t=\\Delta L/v\\), the ball is in the phase space region labelled “out region”, then it will be hit in the out-stroke. Otherwise, it will not be hit.\n\n\n\nJarzynski_bouncing_ball_1.jpg\n\n\n\n\n\nJarzynski_bouncing_ball_2.jpg\n\n\nTherefore,\n\\[\n\\begin{aligned}\n    \\braket{e^{-\\beta W}} &= \\int_{in} \\rho dpdx \\; e^{-\\beta 2v(mv-p)} + \\int_{out} \\rho dpdx \\; e^{-\\beta 2v(mv+p)} + \\int_{other} \\rho dpdx \\; 1 \\\\\n    &= e^{-2\\beta mv^2} \\left(\\int_{in} \\rho dpdx \\; e^{2\\beta vp} + \\int_{out} \\rho dpdx \\; e^{-2\\beta vp}\\right) +  \\int_{other} \\rho dpdx \\; 1\n\\end{aligned}\n\\]\nSince \\(\\rho(p, x) = \\rho(-p, x - \\Delta L)\\), the first two integrals can be combined by flipping the “out region”, then moving it by \\(\\Delta L\\), to “out’ region”.\n\n\n\n\n\n\nNote\n\n\n\nBecause \\(L\\) is large, this is mostly correct, as the regions where this is incorrect has \\(\\rho\\) so small that it is negligible, as seen in the figure.\n\n\nNow we continue:\n\\[\n\\begin{aligned}\n\\braket{e^{-\\beta W}} &\\approx e^{-2\\beta mv^2} \\int_{in, out'} \\rho dpdx \\; e^{2\\beta vp} +  \\int_{other} \\rho dpdx \\; 1 \\\\\n&= \\frac{1}{L\\sqrt{2\\pi m/\\beta}} \\left(\\int_{in, out'} e^{-\\frac{\\beta}{2m}(p - 2mv)^2} dpdx + \\int_{other} e^{-\\frac{\\beta}{2m}p^2} dpdx\\right)\n\\end{aligned}\n\\]\nBecause the “in-out’ region” is symmetric across the \\(p = mv\\) line, we can reflect the first integral across the \\(p=mv\\) line and obtain \\[\n= \\frac{1}{L\\sqrt{2\\pi m/\\beta}} \\left(\\int_{in, out'} e^{-\\frac{\\beta}{2m}p^2} dpdx + \\int_{other} e^{-\\frac{\\beta}{2m}p^2} dpdx\\right) = 1\n\\]\n\n\nFluctuation-dissipation relations\n\nCorollary 4 (Fluctuation-dissipation relations) Since \\(e^t\\) is convex, we have \\(\\Delta F^* \\leq \\braket{W}\\), meaning that the average work expended is more than the increase in Helmholtz free energy. This has better be true, else we would be violating the second law of thermodynamics on average.\nSince \\(\\Delta F^* = -\\frac{1}{\\beta} \\ln\\braket{e^{-\\beta W}}\\), we find that to second order, \\[\\underbrace{\\braket{W} - \\Delta F^*}_{\\text{work dissipation}} = \\frac 12 \\beta \\underbrace{\\sigma_W^2}_{\\text{work fluctuation}}\\]\nIt is more familiarly written as \\[\\mu = D\\beta\\]\nwhere \\(D = \\frac 12 \\sigma_W^2\\) is the fluctuation coefficient, and \\(\\mu = (\\braket{W} - \\Delta F^*)\\) is the dissipation coefficient.\n\n\nTheorem 9 (Gallavotti–Cohen fluctuation theorem) A system in an energy bath, and driven by periodically varying its constraints (such as a pendulum in a sticky fluid subjected to a driving force), will settle into a “dynamical equilibrium” ensemble, much like a canonical ensemble.\nIf it is driven by the same process time-reversed, then, it will settle into another dynamical equilibrium ensemble.\n\\[\\frac{\\rho(S)}{\\rho'(-S)} = e^{S}\\]\nwhere \\(\\rho(S)\\) is the probability density for a forward cycle producing entropy \\(S\\), and \\(\\rho'(S)\\) is for the backward cycle.\nMore generally, since at the dynamical equilibrium, the system’s microstates are changing as a Markov chain, we have \\(\\rho(i \\to j)\\), which are basically \\[\\frac{\\rho(i\\to j)}{\\rho'(j \\to i)} = e^{S[i \\to j]}\\]\nwhere \\(i, j\\) are microstates.\n\n\nProof. (sketch)\nConstruct a process that starts at equilibrium, then mount up the periodic driving, runs it for \\(NT\\) time where \\(N\\) is a large integer, then remove the driving. At the \\(N\\to\\infty\\) limit, the CFT reduces to the theorem.\n\n\n\nArrow of time\n(Jarzynski 2011)\nSuppose a scientist has recorded a microscopic movie of pulling on an RNA, flipped a coin to decide whether to reverse the movie, then given you the movie. Your task is to guess whether the movie is reversed.\nBy Bayes theorem, \\[Pr(\\text{forward}|x, y) = \\frac{1}{1 + e^{-S[x, y]}}\\]\nwhere \\(S[x, y] = \\beta(W[x, y] - \\Delta F^*)\\).\nIn words, the higher the entropy production, the more likely it is that the movie is playing forward. This is one way to say that entropy production provides an arrow of time.\n(Parrondo, Horowitz, and Sagawa 2015)\n\\[\\braket{e^{-\\beta W - I}} = e^{-\\beta \\Delta F^*}\\]"
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#fluctuation-dissipation-relations-1",
    "href": "blog/posts/statistical-mechanics/index.html#fluctuation-dissipation-relations-1",
    "title": "Statistical Mechanics",
    "section": "Fluctuation-dissipation relations",
    "text": "Fluctuation-dissipation relations\nSince \\(e^t\\) is convex, we have \\(\\Delta F^* \\leq \\braket{W}\\), meaning that the average work expended is more than the increase in Helmholtz free energy. This has better be true, else we would be violating the second law of thermodynamics on average.\nSince \\(\\Delta F^* = -\\frac{1}{\\beta} \\ln\\braket{e^{-\\beta W}}\\), we find that to second order, \\[\\underbrace{\\braket{W} - \\Delta F^*}_{\\text{work dissipation}} = \\frac 12 \\beta \\underbrace{\\sigma_W^2}_{\\text{work fluctuation}}\\]\nIt is more familiarly written as \\[\\mu = D\\beta\\]\nwhere \\(D = \\frac 12 \\sigma_W^2\\) is the fluctuation coefficient, and \\(\\mu = (\\braket{W} - \\Delta F^*)\\) is the dissipation coefficient.\n\nTheorem 9 (Gallavotti–Cohen fluctuation theorem) A system in an energy bath, and driven by periodically varying its constraints (such as a pendulum in a sticky fluid subjected to a driving force), will settle into a “dynamical equilibrium” ensemble, much like a canonical ensemble.\nIf it is driven by the same process time-reversed, then, it will settle into another dynamical equilibrium ensemble.\n\\[\\frac{\\rho(S)}{\\rho'(-S)} = e^{S}\\]\nwhere \\(\\rho(S)\\) is the probability density for a forward cycle producing entropy \\(S\\), and \\(\\rho'(S)\\) is for the backward cycle.\nMore generally, since at the dynamical equilibrium, the system’s microstates are changing as a Markov chain, we have \\(\\rho(i \\to j)\\), which are basically \\[\\frac{\\rho(i\\to j)}{\\rho'(j \\to i)} = e^{S[i \\to j]}\\]\nwhere \\(i, j\\) are microstates.\n\n\nProof. (sketch)\nConstruct a process that starts at equilibrium, then mount up the periodic driving, runs it for \\(NT\\) time where \\(N\\) is a large integer, then remove the driving. At the \\(N\\to\\infty\\) limit, the CFT reduces to the theorem."
  },
  {
    "objectID": "blog/posts/statistical-mechanics/index.html#maxwells-demon",
    "href": "blog/posts/statistical-mechanics/index.html#maxwells-demon",
    "title": "Statistical Mechanics",
    "section": "Maxwell’s demon",
    "text": "Maxwell’s demon\n(Parrondo, Horowitz, and Sagawa 2015)\n\\[\\braket{e^{-\\beta W - I}} = e^{-\\beta \\Delta F^*}\\]\narrow of time\n(Jarzynski 2011)\nSuppose a scientist has recorded a microscopic movie of pulling on an RNA, flipped a coin to decide whether to reverse the movie, then given you the movie. Your task is to guess whether the movie is reversed.\nBy Bayes theorem, \\[Pr(\\text{forward}|x, y) = \\frac{1}{1 + e^{-S[x, y]}}\\]\nwhere \\(S[x, y] = \\beta(W[x, y] - \\Delta F^*)\\).\nIn words, the higher the entropy production, the more likely it is that the movie is playing forward. This is one way to say that entropy production provides an arrow of time."
  }
]
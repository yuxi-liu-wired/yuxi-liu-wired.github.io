[
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "",
    "text": "The essay is written at the level of two years of undergraduate mathematics. I will keep jargons to a minimum and use as few infinities as possible. For example, instead of particles that can be anywhere on a real-number line, I would talk about particles that can be in one of three boxes."
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#many-world-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Many-world theory",
    "text": "Many-world theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#pilot-wave-theory",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Pilot wave theory",
    "text": "Pilot wave theory"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#copenhagen-interpretation",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Copenhagen interpretation",
    "text": "Copenhagen interpretation"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#relational-quantum-mechanics",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "Relational quantum mechanics",
    "text": "Relational quantum mechanics"
  },
  {
    "objectID": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "href": "blog/posts/quantum-mechanics-interpretations/index.html#qbism",
    "title": "Mathematical Interpretations of Quantum Mechanics",
    "section": "QBism",
    "text": "QBism"
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html",
    "href": "blog/posts/geometrical-mechanics/index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Consider a particle in a field, in polar coordinates. We have\n\\[L = \\frac 12 m (\\dot r^2 + r^2 \\dot \\theta^2) - V(r, \\theta)\\]\nNow suppose we want to use a rotating frame at angular velocity \\(+\\Omega\\), then we can use the change of variables by \\(\\theta = \\phi + \\Omega t\\), plug into the Euler–Lagrange equations, and obtain\n\\[\\begin{cases}\nm\\ddot r = mr\\dot\\phi^2 -\\partial_r V(r, \\phi + \\Omega t)  + mr\\Omega^2 + 2m(r\\dot \\phi)\\Omega \\\\\nm(r\\ddot\\phi + 2\\dot r\\dot \\phi) = -\\frac 1r \\partial_\\theta(r, \\phi+ \\Omega t) - 2m\\dot r\\Omega\n\\end{cases}\\]\nIn the above procedure, we simply performed a change of variables, then plugged into the Euler–Lagrange equations without comment, but are we allowed to do that? Yes, but there are conditions – the change of variables must not depend on velocity.\n\n\nAt this point, it is important to be as explicit as possible, carefully distinguishing between often confused concepts:\n\nphysical state: An intuitive concept that cannot be made more precise than say \"this is what physicists study\", much like how a geometric point cannot be made more precise than say \"this is what geometers study\".\nsame: As in most modern mathematics, two things are \"the same\" when they are really just \"equivalent\" or \"not distinguished in use\". For example, there is really just one \\(\\R\\), but we can have as many 1-dimensional vector spaces as we want, and they are all equivalent to \\(\\R\\), though not literally the same as it (if they were, then we wouldn’t have as many vector spaces as we want!).\n(n-dimensional smooth) manifold \\(\\mathcal M\\): a space that is locally the same as \\(\\R^n\\). More precisely, at every point \\(x\\in \\mathcal M\\), there exists a coordinate system around \\(x\\).\ncoordinate system of a manifold \\(\\mathcal M\\): a diffeomorphism from an open subset of \\(\\mathcal M\\) to an open subset of \\(\\R^n\\).\ndiffeomorphism: a smooth, one-to-one function between two smooth spaces. (What is a smooth space? ... it’s a space smooth enough to do calculus in. Making it more precise would be too much of a detour.)\nstate space \\(\\mathcal S\\): the manifold of distinct physical states. Every point \\(x\\in \\mathcal S\\) is a particular state that the system can assume. The manifold is built such that close-by points on the manifold are close-by physical states. That is, the topology of the state space (a precisely defined mathematical concept) is an exact representation of the topology of physical states (an intuitive concept that cannot be made more precise than that).\ntangent space \\(\\mathcal T_x\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible velocities at that state. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\).\ncotangent space \\(\\mathcal T_x^\\ast\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible momenta at that state. From the abstract perspective, a momentum is nothing more than a linear map of type \\(p: \\mathcal T_x\\mathcal S \\to \\R\\). That is, the only way to really \"use\" a momentum is to combine it with a velocity, mutually annihilating both of them and leaving behind nothing but a little real number representing the energy. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\). Neither is it literally the same as \\(\\mathcal T_x\\mathcal S\\).\nconfiguration space \\(\\mathcal C = \\mathcal T\\mathcal S\\): The tangent bundle of state space. That is, at each \\(x\\in \\mathcal S\\), we \"glue\" the space of velocities \\(\\mathcal T_x \\mathcal S\\) to the point. The totality of \\(\\mathcal C\\) with all its \\(\\mathcal T_x \\mathcal S\\) is the configuration space.\nphase space \\(\\mathcal P = \\mathcal T^\\ast\\mathcal S\\): The cotangent bundle of state space. That is, at each point \\(x\\in \\mathcal S\\), we attach the space of momenta \\(\\mathcal T_x^\\ast\\mathcal S\\).\n\nDo not worry if the words do not make much sense. The example will make it clear.\nFor concreteness, consider a pendulum-cart system, shown in Figure 4. It is clear that its state space is shaped like a cylinder: one circle for the angle of the pendulum, and one line being the location of the cart.\nMore examples are shown in Table 2. Most of them are obvious, except the one about particle on a sphere.\nIt’s clear that its state space is \\(\\mathbb S^2\\). However, that is not equivalent to the torus \\(\\mathbb S^1 \\times \\mathbb S^1\\). There is simply no way to split the sphere into a direct product of two circles (as a casual comparison between a donut and a ball can verify).\nFurthermore, its configuration space \\(\\mathcal\\mathbb S^2\\) is not equivalent to \\(\\R^2 \\times \\mathbb S^2\\). To prove that, we invoke the hairy ball theorem: there is no smooth and everywhere nonzero vector field on \\(\\mathbb S^2\\). Now, if it were equivalent to \\(\\R^2 \\times \\mathbb S^2\\), then there is an obvious smooth and everywhere nonzero vector field: \\(x \\mapsto ((1, 0), x)\\).\n\n\n\nThe pendulum-cart system.\n\n\n\n\nSome physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nphysical system\nstate space\nconfiguration space\n\n\n\n\nparticle in 3D space\n\\(\\R^3\\)\n\\(\\R^6\\)\n\n\npendulum\ncircle \\(\\mathbb S^1\\)\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\n\ndouble pendulum\ntorus \\(\\mathbb S^1 \\times \\mathbb S^1\\)\ncylinder-squared \\(\\R^2 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\npendulum-cart\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\\(\\R^3 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\nparticle on a sphere\nsphere \\(\\mathbb S^2\\)\ntangent bundle of sphere \\(\\mathcal T\\mathbb S^2\\)\n\n\n\n\n: Some physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\n\nWith the above formalism, we can precisely define more concepts\n\ntrajectory, or path, in a manifold \\(\\mathcal M\\): a function of type \\(\\gamma: [t_0, t] \\to \\mathcal M\\).\nLagrangian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal L: \\R \\times \\mathcal T\\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on configuration space.\n\nHamiltonian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal H: \\R \\times \\mathcal T^\\ast \\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on phase space.\n\naction of a path\n\n\\[S(\\gamma) = \\int_{t_0}^t \\mathcal L(\\tau, \\gamma(\\tau), \\dot \\gamma(\\tau))d\\tau.\\]\nNow, the convex duality between Lagrangian and Hamiltonian transfers with almost no change in notation:\n\\[\\begin{cases}\n\\mathcal L(t, q, v) = \\max_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\n\\mathcal H(t, q, p) = \\max_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\np^\\ast(t, q, v) = \\mathop{\\mathrm{arg\\,max}}_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\nv^\\ast(t, q, p) = \\mathop{\\mathrm{arg\\,max}}_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\nThe economic argument almost goes through without problem, but we need to be careful with some notations. In particular, we take another look at gradients. What does it mean to write \\(\\nabla_v \\mathcal L(t, q, v)\\)? The defining property is\n\\[\\mathcal L(t, q, v + u\\tau) = \\mathcal L(t, q, v) + \\lra{\\nabla_v \\mathcal L(t, q, v), u} \\tau + O(\\tau^2)\\]\nwhich implies the following operational definition:\n\\[\\nabla_v \\mathcal L(t, q, v) := u \\mapsto \\lim_{\\tau \\to 0} \\frac 1\\tau (\\mathcal L(t, q, v + u\\tau) - \\mathcal L(t, q, v))\\]\nThis definition makes it clear that \\(\\nabla_v \\mathcal L(t, q, v)\\) is a function of type \\(\\mathcal T_q \\mathcal S \\to\\R\\), thus it is an element of \\(\\mathcal T_q^\\ast \\mathcal S\\). Similarly, \\(\\nabla_p \\mathcal H(t, q, p)\\) is an element of \\(\\mathcal T_q \\mathcal S\\). Succinctly, \\(\\nabla_q \\mathcal L, \\nabla_v \\mathcal L, \\nabla_q \\mathcal H\\) are covector fields (like momentum), and \\(\\nabla_p \\mathcal H\\) is a vector field (like velocity).\nWith these, the types of every equation come out correctly again:\n\\[\\begin{cases}\nv = \\nabla_p \\mathcal H(t, q, p^\\ast(t, q, v))\\\\\np = \\nabla_v \\mathcal L(t, q, v^\\ast(t, q, p))\n\\end{cases},\n\\frac{d}{dt}(\\nabla_v \\mathcal L) = \\nabla_q \\mathcal L,\\quad\n\\begin{cases}\n\\dot p = -\\nabla_q \\mathcal H \\\\\n\\dot q = -\\nabla_p \\mathcal H\n\\end{cases}\\]\nLet’s call these the coordinate-free equations, to be contrasted with the coordinate-based equations, to be defined below.\n\n\n\nManifolds are geometrically pristine, but you can’t calculate numerically with them unless you lay down coordinate systems over them. Concretely, consider a state space \\(\\mathcal S\\). We take an open subset \\(U\\) of it, and define a coordinate system (with a possible dependence on time):\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nThis coordinate system then induces a coordinate system over the configuration space:\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nNow consider a different coordinate system\n\\[(Q_1, ..., Q_N): \\R \\times U \\to \\R^N\\]\nand suppose they are related by a function \\(f: \\R \\times \\R^N \\to \\R^N\\) such that\n\\[q(t, x) = f(t, Q(t, x))\\]\nThis is then a point transformation of the coordinate system.\nThe point transformation induces a transformation of the velocities, too. To find the transformation of velocities, consider a path \\(\\gamma: \\R \\to \\mathcal S\\). Its velocity at time \\(t\\) is \\(\\dot \\gamma(t) \\in \\mathcal T_{\\gamma(t)}\\mathcal S\\), a vector that looks like it literally lives in \\(\\R^N\\), but is not. It is not a native of \\(\\R^N\\), but thanks to the \\(q\\)-coordinate system, it is represented by the \\(\\R^N\\)-vector\n\\[\\frac{d}{dt} q(t, \\gamma(t)) \\in \\R^N\\]\nNow plug in \\(q(t, x) = f(t, Q(t, x))\\), to find a relationship between the representation of \\(\\dot \\gamma(t)\\) in \\(q\\)-coordinate system and \\(Q\\)-coordinate system:\n\\[\\frac{d}{dt} q(t, \\gamma(t)) = \\frac{d}{dt} f(t, Q(t, \\gamma(t))) = \\partial_t f(t, Q(t, \\gamma(t))) + \\frac{\\partial f}{\\partial Q} \\frac{d}{dt}Q(t, \\gamma(t))\\]\nMore succinctly, we have the following transformation from \\((t, Q, V)\\) to \\((t, q, v)\\):\n\\[\\begin{cases}\nq = f(t, Q) \\\\\nv= \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\n\\end{cases}\\]\nA note on matrix algebra: Conventionally, vectors are written as column-matrices, that is, \\(q, v, Q, V\\) are written as \\(N\\times 1\\) matrices. Correspondingly, gradients, being covectors, are written as row-matrices, that is, \\(\\nabla_q l, \\nabla_v l, \\nabla_Q L, \\nabla_V L\\), are written as \\(1 \\times N\\) matrices. Finally, gradients of vector-valued functions, like \\(\\frac{\\partial f}{\\partial Q}\\), are \\(N\\times N\\) matrices, with each row being a gradient of one vector coordinate. This convention makes everything come out cleanly, with no need to take the transpose of anything.\nThe point transformation also induces a transformation of the Lagrangians. While the Lagrangian itself is a function \\(\\mathcal L\\) of type \\(\\R \\times \\mathcal T \\mathcal S \\to \\R\\), the Lagrangians \\(L(t, Q, V), l(t, q, v)\\) are functions of type \\(\\R \\times \\R^N \\times \\R^N \\to \\R\\). Both \\(L, l\\) are induced from \\(\\mathcal L\\) by the choice of coordinates. We have\n\\[\\mathcal(t, x, u) = L(t, Q(t, x), V(t, x, u)) = l(t, q(t, x), v(t, x, u))\\]\nand plug in \\(q(t, x) = f(t, Q(t, x)), v = \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\\), we have\n\\[l\\left(t, f(t, Q), \\partial_t f(t, Q)  + \\frac{\\partial f}{\\partial Q}(t, Q) V\\right) = L(t, Q, V)\\]\nBrute computation shows that\n\\[\\frac{d}{dt}(\\nabla_V L) - \\nabla_Q L = \\left(\\frac{d}{dt}(\\nabla_v l) - \\nabla_q l\\right)\\frac{\\partial f}{\\partial Q}\\]\nimplying that the coordinate-based Euler–Lagrange equation is true in \\((Q, V)\\) coordinates iff it is true in \\((q, v)\\) coordinates.\nWhat, in the final analysis, is a point transformation? It is nothing more than changing a time-varying coordinate system on the state space. Since our derivation of the coordinate-based Euler–Lagrange equations required no special property of the coordinate system, it must be preserved by point transformations. All the above verification was really nothing but \"ceremonial\".\nIn more detail: we know that the coordinate-free EL equations are true, which implies that the \\(q\\)-coordinate-based EL equations and the \\(Q\\)-coordinate-based EL equations are both true (since they are merely two coordinate-based representations on the coordinate-free equation). No \\(Q\\)-to-\\(q\\) translation is necessary!\nWhat, then, is the phrase \"point transformation\" supposed to be contrasted with? It is contrasted with more general coordinate transforms that also depend on velocities, as \\(q = f(t, Q, V)\\). From the perspective given here, the contrast is really between \"state space coordinate systems\" and \"configuration space coordinate systems\". Whereas state space coordinate system is first defined as some\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nand that is then extended to \\((q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\), a configuration space coordinate system defines \"all at once\" a complete coordinate system\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nIt is no wonder that such overly general coordinate systems do not have nice properties, and do not satisfy the coordinate-based Euler–Lagrange equations.\n\n\n\nBefore writing this chapter, try going through (Bohn 2018, chap. 7).\nWhereas for the Lagrangian \\(\\mathcal L\\), we can only perform point-transformations \\(q = f(t, Q)\\), lest the Euler–Lagrange equation is mangled, for the Hamiltonian, we can simultaneously transform both \\(q, p\\), while preserving the Hamiltonian equations of motion. Such transformations are called canonical transformations. They are of the form:\n\\[\\begin{cases}\nQ = f_Q(t, p, q)\\\\\nP = f_P(t, p, q)\n\\end{cases}\\]\nwhere the functions \\(f_Q, f_P: \\R \\times \\R^N \\times \\R^N \\to \\R^N\\) are required to satisfy some functional equations.\nThis is usually derived by brute force without comments. However, to truly understand the meaning, we need to understand phase space from a perspective even more modern than \\(\\mathcal T^\\ast \\mathcal S\\)."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-physical-states",
    "href": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-physical-states",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Consider a particle in a field, in polar coordinates. We have\n\\[L = \\frac 12 m (\\dot r^2 + r^2 \\dot \\theta^2) - V(r, \\theta)\\]\nNow suppose we want to use a rotating frame at angular velocity \\(+\\Omega\\), then we can use the change of variables by \\(\\theta = \\phi + \\Omega t\\), plug into the Euler–Lagrange equations, and obtain\n\\[\\begin{cases}\nm\\ddot r = mr\\dot\\phi^2 -\\partial_r V(r, \\phi + \\Omega t)  + mr\\Omega^2 + 2m(r\\dot \\phi)\\Omega \\\\\nm(r\\ddot\\phi + 2\\dot r\\dot \\phi) = -\\frac 1r \\partial_\\theta(r, \\phi+ \\Omega t) - 2m\\dot r\\Omega\n\\end{cases}\\]\nIn the above procedure, we simply performed a change of variables, then plugged into the Euler–Lagrange equations without comment, but are we allowed to do that? Yes, but there are conditions – the change of variables must not depend on velocity.\n\n\nAt this point, it is important to be as explicit as possible, carefully distinguishing between often confused concepts:\n\nphysical state: An intuitive concept that cannot be made more precise than say \"this is what physicists study\", much like how a geometric point cannot be made more precise than say \"this is what geometers study\".\nsame: As in most modern mathematics, two things are \"the same\" when they are really just \"equivalent\" or \"not distinguished in use\". For example, there is really just one \\(\\R\\), but we can have as many 1-dimensional vector spaces as we want, and they are all equivalent to \\(\\R\\), though not literally the same as it (if they were, then we wouldn’t have as many vector spaces as we want!).\n(n-dimensional smooth) manifold \\(\\mathcal M\\): a space that is locally the same as \\(\\R^n\\). More precisely, at every point \\(x\\in \\mathcal M\\), there exists a coordinate system around \\(x\\).\ncoordinate system of a manifold \\(\\mathcal M\\): a diffeomorphism from an open subset of \\(\\mathcal M\\) to an open subset of \\(\\R^n\\).\ndiffeomorphism: a smooth, one-to-one function between two smooth spaces. (What is a smooth space? ... it’s a space smooth enough to do calculus in. Making it more precise would be too much of a detour.)\nstate space \\(\\mathcal S\\): the manifold of distinct physical states. Every point \\(x\\in \\mathcal S\\) is a particular state that the system can assume. The manifold is built such that close-by points on the manifold are close-by physical states. That is, the topology of the state space (a precisely defined mathematical concept) is an exact representation of the topology of physical states (an intuitive concept that cannot be made more precise than that).\ntangent space \\(\\mathcal T_x\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible velocities at that state. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\).\ncotangent space \\(\\mathcal T_x^\\ast\\mathcal S\\) of a point \\(x\\in \\mathcal S\\): The vector space of all possible momenta at that state. From the abstract perspective, a momentum is nothing more than a linear map of type \\(p: \\mathcal T_x\\mathcal S \\to \\R\\). That is, the only way to really \"use\" a momentum is to combine it with a velocity, mutually annihilating both of them and leaving behind nothing but a little real number representing the energy. It has dimension \\(n\\), and is thus isomorphic to \\(\\R^n\\) as a vector space. However, it is not literally the same as \\(\\R^n\\). Neither is it literally the same as \\(\\mathcal T_x\\mathcal S\\).\nconfiguration space \\(\\mathcal C = \\mathcal T\\mathcal S\\): The tangent bundle of state space. That is, at each \\(x\\in \\mathcal S\\), we \"glue\" the space of velocities \\(\\mathcal T_x \\mathcal S\\) to the point. The totality of \\(\\mathcal C\\) with all its \\(\\mathcal T_x \\mathcal S\\) is the configuration space.\nphase space \\(\\mathcal P = \\mathcal T^\\ast\\mathcal S\\): The cotangent bundle of state space. That is, at each point \\(x\\in \\mathcal S\\), we attach the space of momenta \\(\\mathcal T_x^\\ast\\mathcal S\\).\n\nDo not worry if the words do not make much sense. The example will make it clear.\nFor concreteness, consider a pendulum-cart system, shown in Figure 4. It is clear that its state space is shaped like a cylinder: one circle for the angle of the pendulum, and one line being the location of the cart.\nMore examples are shown in Table 2. Most of them are obvious, except the one about particle on a sphere.\nIt’s clear that its state space is \\(\\mathbb S^2\\). However, that is not equivalent to the torus \\(\\mathbb S^1 \\times \\mathbb S^1\\). There is simply no way to split the sphere into a direct product of two circles (as a casual comparison between a donut and a ball can verify).\nFurthermore, its configuration space \\(\\mathcal\\mathbb S^2\\) is not equivalent to \\(\\R^2 \\times \\mathbb S^2\\). To prove that, we invoke the hairy ball theorem: there is no smooth and everywhere nonzero vector field on \\(\\mathbb S^2\\). Now, if it were equivalent to \\(\\R^2 \\times \\mathbb S^2\\), then there is an obvious smooth and everywhere nonzero vector field: \\(x \\mapsto ((1, 0), x)\\).\n\n\n\nThe pendulum-cart system.\n\n\n\n\nSome physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\nphysical system\nstate space\nconfiguration space\n\n\n\n\nparticle in 3D space\n\\(\\R^3\\)\n\\(\\R^6\\)\n\n\npendulum\ncircle \\(\\mathbb S^1\\)\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\n\ndouble pendulum\ntorus \\(\\mathbb S^1 \\times \\mathbb S^1\\)\ncylinder-squared \\(\\R^2 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\npendulum-cart\ncylinder \\(\\R^1 \\times \\mathbb S^1\\)\n\\(\\R^3 \\times \\mathbb S^1 \\times \\mathbb S^1\\)\n\n\nparticle on a sphere\nsphere \\(\\mathbb S^2\\)\ntangent bundle of sphere \\(\\mathcal T\\mathbb S^2\\)\n\n\n\n\n: Some physical systems and their state and configuration spaces. Note that the state spaces are not literally the same as the ones shown in the table, merely equivalent (by a diffeomorphism).\n\n\n\nWith the above formalism, we can precisely define more concepts\n\ntrajectory, or path, in a manifold \\(\\mathcal M\\): a function of type \\(\\gamma: [t_0, t] \\to \\mathcal M\\).\nLagrangian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal L: \\R \\times \\mathcal T\\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on configuration space.\n\nHamiltonian of a physical system with state manifold \\(\\mathcal S\\): a function of type\n\n\\[\\mathcal H: \\R \\times \\mathcal T^\\ast \\mathcal S \\to \\R.\\]\nThat is, it is a time-varying field on phase space.\n\naction of a path\n\n\\[S(\\gamma) = \\int_{t_0}^t \\mathcal L(\\tau, \\gamma(\\tau), \\dot \\gamma(\\tau))d\\tau.\\]\nNow, the convex duality between Lagrangian and Hamiltonian transfers with almost no change in notation:\n\\[\\begin{cases}\n\\mathcal L(t, q, v) = \\max_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\n\\mathcal H(t, q, p) = \\max_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\np^\\ast(t, q, v) = \\mathop{\\mathrm{arg\\,max}}_{p\\in \\mathcal T_q^\\ast \\mathcal S} (\\langle p, v\\rangle - \\mathcal H(t, q, p)) \\\\\nv^\\ast(t, q, p) = \\mathop{\\mathrm{arg\\,max}}_{v\\in \\mathcal T_q \\mathcal S} (\\langle p, v\\rangle - \\mathcal L(t, q, v))\n\\end{cases}\n\\]\nThe economic argument almost goes through without problem, but we need to be careful with some notations. In particular, we take another look at gradients. What does it mean to write \\(\\nabla_v \\mathcal L(t, q, v)\\)? The defining property is\n\\[\\mathcal L(t, q, v + u\\tau) = \\mathcal L(t, q, v) + \\lra{\\nabla_v \\mathcal L(t, q, v), u} \\tau + O(\\tau^2)\\]\nwhich implies the following operational definition:\n\\[\\nabla_v \\mathcal L(t, q, v) := u \\mapsto \\lim_{\\tau \\to 0} \\frac 1\\tau (\\mathcal L(t, q, v + u\\tau) - \\mathcal L(t, q, v))\\]\nThis definition makes it clear that \\(\\nabla_v \\mathcal L(t, q, v)\\) is a function of type \\(\\mathcal T_q \\mathcal S \\to\\R\\), thus it is an element of \\(\\mathcal T_q^\\ast \\mathcal S\\). Similarly, \\(\\nabla_p \\mathcal H(t, q, p)\\) is an element of \\(\\mathcal T_q \\mathcal S\\). Succinctly, \\(\\nabla_q \\mathcal L, \\nabla_v \\mathcal L, \\nabla_q \\mathcal H\\) are covector fields (like momentum), and \\(\\nabla_p \\mathcal H\\) is a vector field (like velocity).\nWith these, the types of every equation come out correctly again:\n\\[\\begin{cases}\nv = \\nabla_p \\mathcal H(t, q, p^\\ast(t, q, v))\\\\\np = \\nabla_v \\mathcal L(t, q, v^\\ast(t, q, p))\n\\end{cases},\n\\frac{d}{dt}(\\nabla_v \\mathcal L) = \\nabla_q \\mathcal L,\\quad\n\\begin{cases}\n\\dot p = -\\nabla_q \\mathcal H \\\\\n\\dot q = -\\nabla_p \\mathcal H\n\\end{cases}\\]\nLet’s call these the coordinate-free equations, to be contrasted with the coordinate-based equations, to be defined below.\n\n\n\nManifolds are geometrically pristine, but you can’t calculate numerically with them unless you lay down coordinate systems over them. Concretely, consider a state space \\(\\mathcal S\\). We take an open subset \\(U\\) of it, and define a coordinate system (with a possible dependence on time):\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nThis coordinate system then induces a coordinate system over the configuration space:\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nNow consider a different coordinate system\n\\[(Q_1, ..., Q_N): \\R \\times U \\to \\R^N\\]\nand suppose they are related by a function \\(f: \\R \\times \\R^N \\to \\R^N\\) such that\n\\[q(t, x) = f(t, Q(t, x))\\]\nThis is then a point transformation of the coordinate system.\nThe point transformation induces a transformation of the velocities, too. To find the transformation of velocities, consider a path \\(\\gamma: \\R \\to \\mathcal S\\). Its velocity at time \\(t\\) is \\(\\dot \\gamma(t) \\in \\mathcal T_{\\gamma(t)}\\mathcal S\\), a vector that looks like it literally lives in \\(\\R^N\\), but is not. It is not a native of \\(\\R^N\\), but thanks to the \\(q\\)-coordinate system, it is represented by the \\(\\R^N\\)-vector\n\\[\\frac{d}{dt} q(t, \\gamma(t)) \\in \\R^N\\]\nNow plug in \\(q(t, x) = f(t, Q(t, x))\\), to find a relationship between the representation of \\(\\dot \\gamma(t)\\) in \\(q\\)-coordinate system and \\(Q\\)-coordinate system:\n\\[\\frac{d}{dt} q(t, \\gamma(t)) = \\frac{d}{dt} f(t, Q(t, \\gamma(t))) = \\partial_t f(t, Q(t, \\gamma(t))) + \\frac{\\partial f}{\\partial Q} \\frac{d}{dt}Q(t, \\gamma(t))\\]\nMore succinctly, we have the following transformation from \\((t, Q, V)\\) to \\((t, q, v)\\):\n\\[\\begin{cases}\nq = f(t, Q) \\\\\nv= \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\n\\end{cases}\\]\nA note on matrix algebra: Conventionally, vectors are written as column-matrices, that is, \\(q, v, Q, V\\) are written as \\(N\\times 1\\) matrices. Correspondingly, gradients, being covectors, are written as row-matrices, that is, \\(\\nabla_q l, \\nabla_v l, \\nabla_Q L, \\nabla_V L\\), are written as \\(1 \\times N\\) matrices. Finally, gradients of vector-valued functions, like \\(\\frac{\\partial f}{\\partial Q}\\), are \\(N\\times N\\) matrices, with each row being a gradient of one vector coordinate. This convention makes everything come out cleanly, with no need to take the transpose of anything.\nThe point transformation also induces a transformation of the Lagrangians. While the Lagrangian itself is a function \\(\\mathcal L\\) of type \\(\\R \\times \\mathcal T \\mathcal S \\to \\R\\), the Lagrangians \\(L(t, Q, V), l(t, q, v)\\) are functions of type \\(\\R \\times \\R^N \\times \\R^N \\to \\R\\). Both \\(L, l\\) are induced from \\(\\mathcal L\\) by the choice of coordinates. We have\n\\[\\mathcal(t, x, u) = L(t, Q(t, x), V(t, x, u)) = l(t, q(t, x), v(t, x, u))\\]\nand plug in \\(q(t, x) = f(t, Q(t, x)), v = \\partial_t f(t, Q) + \\frac{\\partial f}{\\partial Q}(t, Q) V\\), we have\n\\[l\\left(t, f(t, Q), \\partial_t f(t, Q)  + \\frac{\\partial f}{\\partial Q}(t, Q) V\\right) = L(t, Q, V)\\]\nBrute computation shows that\n\\[\\frac{d}{dt}(\\nabla_V L) - \\nabla_Q L = \\left(\\frac{d}{dt}(\\nabla_v l) - \\nabla_q l\\right)\\frac{\\partial f}{\\partial Q}\\]\nimplying that the coordinate-based Euler–Lagrange equation is true in \\((Q, V)\\) coordinates iff it is true in \\((q, v)\\) coordinates.\nWhat, in the final analysis, is a point transformation? It is nothing more than changing a time-varying coordinate system on the state space. Since our derivation of the coordinate-based Euler–Lagrange equations required no special property of the coordinate system, it must be preserved by point transformations. All the above verification was really nothing but \"ceremonial\".\nIn more detail: we know that the coordinate-free EL equations are true, which implies that the \\(q\\)-coordinate-based EL equations and the \\(Q\\)-coordinate-based EL equations are both true (since they are merely two coordinate-based representations on the coordinate-free equation). No \\(Q\\)-to-\\(q\\) translation is necessary!\nWhat, then, is the phrase \"point transformation\" supposed to be contrasted with? It is contrasted with more general coordinate transforms that also depend on velocities, as \\(q = f(t, Q, V)\\). From the perspective given here, the contrast is really between \"state space coordinate systems\" and \"configuration space coordinate systems\". Whereas state space coordinate system is first defined as some\n\\[(q_1, ..., q_N): \\R \\times U \\to \\R^N\\]\nand that is then extended to \\((q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\), a configuration space coordinate system defines \"all at once\" a complete coordinate system\n\\[(q_1, ..., q_N; v_1, ..., v_N): \\R \\times \\mathcal T U \\to \\R^N \\times \\R^N\\]\nIt is no wonder that such overly general coordinate systems do not have nice properties, and do not satisfy the coordinate-based Euler–Lagrange equations.\n\n\n\nBefore writing this chapter, try going through (Bohn 2018, chap. 7).\nWhereas for the Lagrangian \\(\\mathcal L\\), we can only perform point-transformations \\(q = f(t, Q)\\), lest the Euler–Lagrange equation is mangled, for the Hamiltonian, we can simultaneously transform both \\(q, p\\), while preserving the Hamiltonian equations of motion. Such transformations are called canonical transformations. They are of the form:\n\\[\\begin{cases}\nQ = f_Q(t, p, q)\\\\\nP = f_P(t, p, q)\n\\end{cases}\\]\nwhere the functions \\(f_Q, f_P: \\R \\times \\R^N \\times \\R^N \\to \\R^N\\) are required to satisfy some functional equations.\nThis is usually derived by brute force without comments. However, to truly understand the meaning, we need to understand phase space from a perspective even more modern than \\(\\mathcal T^\\ast \\mathcal S\\)."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-phase-space",
    "href": "blog/posts/geometrical-mechanics/index.html#the-geometry-of-phase-space",
    "title": "Yuxi on the Wired",
    "section": "The geometry of phase space",
    "text": "The geometry of phase space\nGiven a state space \\(\\mathcal S\\), both its configuration space and its phase space are obtained by attaching vector spaces to every point of it. Despite this, the geometry of phase space turns out to be a far richer thing than the geometry of configuration space. This fundamentally comes down to the difference between a cotangent vector and a tangent vector.\nConsider an infinitesimal parallelogram in the phase space, around the point \\((q, p)\\). The parallelogram has (signed) sides \\((\\delta q_1, ..., \\delta q_N; \\delta p_1, ..., \\delta p_N)\\). What should be its (signed) volume? The natural answer is of course\n\\[\\prod_i \\delta q_i \\delta p_i\\]\nbut is this a meaningful answer? That is, is this a mirage in \\(\\R^N \\times \\R^N\\) created by our choice of coordinates, or is this a faithful representation of something that truly takes place in the phase space \\(\\mathcal T^\\ast\\mathcal S\\) itself?\nThis answer is critically important, since if a concept takes place in the phase space itself, then it will be coordinate-free, and every coordinate system automatically translates that one coordinate-free concept. This is how we could have predicted that the coordinate-based Euler–Lagrange equations are preserved, by going up to the coordinate-free version of it, then coming back down again.\nHaving a coordinate-free thing is like having a lingua-franca between different coordinate-based representations.\n\nPoisson bracket\nThe Poisson bracket notation is convenient:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nFor any differentiable function \\(f(t, q, p)\\), and any path \\(p(t), q(t)\\) that conforms to a Hamiltonian \\(H(t, q, p)\\), we have by Hamiltonian’s equations of motion\n\\[\\frac{d}{dt} f(t, p(t), q(t)) = \\partial_t f(t, p(t), q(t)) + \\{f, H\\}\\]\nor more succinctly, \\(\\dot f = \\partial_t f + \\{f, H\\}\\).\n\n\nLiouville’s theorem\nProof taken from (Tolman 1980, sec. 19).\n\n\nThe interpretation of phase space geometry\nLiouville’s theorem is a delicate construction, having several moving parts. We have a phase space, a volume-measurement on the phase space, a Hamiltonian on the phase space, and a density field on the phase space which flows according to the Hamiltonian. Only when all four moving parts come together do we get Liouville’s theorem.\nWhat is a phase space, in the final analysis? A phase space \\(\\mathcal T^\\ast \\mathcal S\\) is a state space \\(\\mathcal S\\), with each state \\(x\\) attached with \\(\\mathcal T^\\ast_x \\mathcal S\\), the vector space of all possible momenta at that state. Good... but not quite! This interpretation of phase space is still bound firmly to the economic interpretation, where each momentum \\(p\\) at state \\(x\\) is a vector of prices, with which we are allowed to measure the profit flow, as \\(\\langle p, \\dot x \\rangle\\).\nWhile this perspective is how Hamiltonian mechanics got its start, the modern abstract viewpoint of Hamiltonian mechanics has sailed far away from the safe harbor of \\(\\R^{2N}\\), past \\(\\mathcal T^\\ast \\mathcal S\\), and voyaged deep into the strange seas of symplectic geometry. Since the early days of the 20th century, there is a tacit understanding among physicists where the humble origin of the phase space \\(\\mathcal T^\\ast \\mathcal S\\) is suppressed, and it is presented instead as a \\(2N\\)-dimensional smooth manifold \\(\\mathcal P\\) equipped with some \\(\\omega\\), a way to measure volumes. The seams where \\(\\mathcal T^\\ast_x \\mathcal S\\) was attached to \\(\\mathcal S\\) are now plastered over, never there, never will be mentioned again... And this abstract viewpoint actually works.\nSpeak not how the phase space was born, but what you can use it for! This is a principle useful not only in programming (encapsulation, API, abstract interfacing), but also in modern mathematics (speak not of equality, but equivalences and isomorphisms...), and perhaps in society (Ye shall know them by their fruits. Do men gather grapes of thorns, or figs of thistles?).\nWhat do we gain and what do we lose when we go from \\(\\R^{2N}\\) to \\(\\mathcal T^\\ast \\mathcal S\\) to \\((\\mathcal P, \\omega)\\)? What we gain are new interpretations, and what we lose are old interpretations. See Table 3.\n\n::: {#table:three_abstractions} \\(\\R^{2N}\\) \\(\\mathcal T^\\ast \\mathcal S\\) \\((\\mathcal P, \\omega)\\) ———————– ——————————– —————————- tuples of real number points, vectors, and covectors points, areas, and volumes multivariate calculus vector bundle geometry symplectic geometry\n\nThe three steps of abstraction. :::\n\n\nIn \\(\\R^{2N}\\), we can interpret each point \\((q, p)\\in \\R^{2N}\\) economically: \\(q_1, ..., q_N\\) are the amounts of commodities, and \\(p_1, ..., p_N\\) are their market prices. In \\(\\mathcal T^\\ast \\mathcal S\\), half of this interpretation is lost, since we are not allowed to interpret \\(x\\in \\mathcal S\\) as a tuple of commodities, unless we lay down a more or less arbitrary coordinate system over it.\nNevertheless, half of this interpretation is preserved. While we are no longer able to interpret a point \\(x\\in \\mathcal S\\) as a stock of commodities that we own, we are still able to interpret a vector \\(v \\in \\mathcal T_x \\mathcal S\\) as a flow of commodities. This then allows us to interpret \\(\\langle p, v \\rangle\\) as a flow of profits: if we are producing at speed \\(v\\), and the market price vector is \\(p\\), then our profit flow is \\(\\langle p, v \\rangle\\). In economic language, we can’t talk of the stock, but we can still talk of the flow.\nGiving up half of the economic interpretation allows us to gain in coordinate-freedom. The Hamiltonian equations of motion become coordinate-free equations on \\(\\mathcal T^\\ast \\mathcal S\\), and we are given the guarantee that it is preserved by any coordinate system on \\(\\mathcal S\\).\nWhen we get to \\((\\mathcal P, \\omega)\\), the economic interpretation is totally destroyed, because there is no more separation between commodities and prices. A point in \\(\\mathcal P\\) simply is a point \\(y\\in \\mathcal P\\), not a 2-tuple \\((x, p)\\) with \\(x\\in \\mathcal S\\) and \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\). There is no way to seize the \"second half\" of \\(y\\) and interpret it as a price vector.\nFurthermore, we cannot even interpret it as a physical state with a momentum covector, either. A momentum covector still looks like an arrow. It has a direction, a length, and can be scaled linearly, and added. Out there in \\(\\mathcal P\\), every point is just a point, not \"half base point, half vector\" like for \\(\\mathcal T^\\ast \\mathcal S\\).\nGiving this much up allows us to gain in even more coordinate-freedom. We are allowed to interpret a physical system not as a base state \\(x\\in \\mathcal S\\) plus a momentum state \\(p \\in \\mathcal T^\\ast_x\\mathcal S\\) , but simply as a phase state \\(y\\in \\mathcal P\\). This in particular gives us the freedom to consider coordinate systems on \\(\\mathcal P\\) that are \"fully nonlinear\", which is what canonical transforms are all about.\nRecall how we defined point transforms in Lagrangian mechanics. We start with a coordinate system \\((q_1, ..., q_N)\\) on an open subset \\(U\\) of the state space \\(\\mathcal S\\), then induced a coordinate system \\((q_1, ..., q_N; v_1, ..., v_N)\\) on \\(\\mathcal T U\\). We also stated that, while we could have went directly for a coordinate system on \\(\\mathcal T\\), this would break the Euler–Lagrange equation.\nIt turns out that the Hamiltonian equations of motion are sturdier than the Euler–Lagrange equation: there are large families of coordinate systems \\((q_1, ..., q_N; p_1, ..., p_N)\\) that we can directly define on open subsets of \\(\\mathcal T^\\ast \\mathcal S\\), and the resulting coordinate-based Hamiltonian equations would still be \\(\\dot p = -\\nabla_q H, \\dot q = \\nabla_p H\\), even if \\((q_1, ..., q_N; p_1, ..., p_N)\\) is not induced by any coordinate system on the state space!\nTo fully exploit the freedom, of course, means that we must break down the strict segregation between a state-point and a momentum-vector. In particular, this means that we no longer require \\(\\mathcal T_x \\mathcal S\\) to be treated with the rigid dignity of a linear space, but the rough freedom of a manifold space:\n\\[p(x, ku) \\neq k p(x, u) \\text { in general, for } (x, u)\\in \\mathcal T^\\ast \\mathcal S, \\: k\\in \\R\\]\nGiven that, we can immediately see why canonical transforms are in general of the form\n\\[Q(t, x, u) = f_Q(t, q(t, x, u), p(t, x, u)),\\quad P(t, x, u) = f_P(t, q(t, x, u), p(t, x, u))\\]\nor more succinctly,\n\\[Q = f_Q(t, q, p),\\quad P = f_P(t, q, p)\\]\nThey have to nonlinearly \"mix up\" state and momentum, because that’s the only way to truly exploit all the freedoms that the sturdy Hamiltonian’s equations of motion grants us.1\n1 Mathematicians exploit every freedom that they are given... sounds evil, but it works in math.Of course, the Hamiltonian equations are not that tough. Some restraint is needed. Not everything goes. What is the restraint? The volume must be preserved! That is precisely what \\(\\omega\\) is there for: it measures areas. A coordinate system on the phase space is only given the title of \"canonical\" iff the coordinate system represents \\(\\omega\\) correctly.\nThus, we find that by exploiting exactly as much freedom as Hamiltonian mechanics gives us, while keeping track of the boundaries so that we are not giving ourselves too much freedom and shooting ourselves in the foot, we walked inexorably into treating the phase space as \\((\\mathcal P, \\omega)\\) – as an object of symplectic geometry."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "href": "blog/posts/geometrical-mechanics/index.html#all-the-variational-principles-of-physics-that-youre-likely-to-ever-see",
    "title": "Yuxi on the Wired",
    "section": "All the variational principles of physics that you’re likely to ever see",
    "text": "All the variational principles of physics that you’re likely to ever see\nBased on (Lanczos 1970).\nOthers not covered: D’lambert’s principle. Gauss’s principle of least constraint, Hertz principle of least curvature, etc.\nLet’s be clear here.\n\na variation of a function \\(\\gamma: \\R^n \\to \\R^m\\) is a function \\(\\gamma + \\delta \\eta\\), such that \\(\\eta: \\R^n \\to \\R^m\\), and \\(\\delta\\) is an infinitesimal.\na constrained variation of a function \\(\\gamma\\) is a variation \\(\\gamma + \\delta \\eta\\), such that \\(\\eta\\) satisfies certain constraints \\(c\\).\na functional is a function that maps a function to a real number. For example, the Lagrangian action \\(S\\) is a functional, defined by\n\n\\[S(\\gamma) = \\int L(t, \\gamma(t), \\dot \\gamma(t))dt.\\]\n\na functional \\(S\\) has zero variation at \\(\\gamma\\) under constraint \\(c\\) iff for any variation \\(\\delta\\eta\\) satisfying constraint \\(c\\), we have \\(S(\\gamma + \\delta \\eta) = S(\\gamma) + o(\\delta)\\). We often write it simply as \\((\\delta S(\\gamma))_c = 0\\).\nvariational calculus is a collection of techniques for solving calculus problems involving variations.\na variational principle is a statement with the following format:\n\n::: center A trajectory \\(\\gamma\\) of the system is a physically valid trajectory iff \\((\\delta S(\\gamma))_c = 0\\). :::\nNow that we are clear on that, we can tabulate just about every variational principles of physics that you’re likely to ever see in Table [table:var-prin].\n\n\n1.0|L|L|L|L|L| name & Where is the trajectory? & specification & constraint & the functional\nHamilton’s principle & state spacetime & Lagrangian \\(L(t, q, v)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma L(t, q, \\dot q)dt\\)\nmodified Hamilton’s principle & phase spacetime & Hamiltonian \\(H(t, q, p)\\) & fixed \\((t_0, q_0), (t_1, q_1)\\) & \\(\\int_\\gamma (\\sum_i p_i \\dot q_i - H(t, q, p))dt\\)\nMaupertuis’ principle2 & phase space & time-independent Hamiltonian \\(H(q, p)\\) & fixed \\(q_0, q_1\\), constant \\(H(q, p)\\) & \\(\\int_\\gamma \\sum_i p_i dq_i\\)\nJacobi’s form of Maupertuis’ principle & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), bonuded \\(V(q) \\leq 0\\) & \\(\\int_\\gamma \\sqrt{(E - V(q)) dq^T M dq}\\)\ntimed Maupertuis’ principle & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v - V(q)\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q + V(q)\\) & \\(\\int_\\gamma (\\dot q^T M \\dot q) dt\\)\nFermat’s principle of stationary pathlength3 & state space & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(\\int_\\gamma \\sqrt{dq^T M dq}\\)\nFermat’s principle of stationary time & state spacetime & Lagrangian of form \\(L(t, q, v) = \\frac 12 v^T M v\\) & fixed \\(q_0, q_1\\), constant \\(\\frac 12 \\dot q^T M \\dot q\\) & \\(t_1 - t_0\\)\n\n2 \"principle of least action\" in (Goldstein, Poole, and Safko 2008)3 Corollary: Hertz’s principle of least curvature\n\n\nHamilton’s principle and modified Hamilton’s principle\nThere are two principles that are often confused with impunity by physicists. The fact is that they are indeed equivalent (which is why they can be confused with impunity), but that is no excuse for bad mathematics.\nHamilton’s principle is a principle about trajectories of type \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\). That is, \\(\\gamma(t)\\) is a state of the system. Variations can be thought of as making a state perturbation \\(\\delta \\eta(t)\\) at every time.\nIn contrast, modified Hamilton’s principle is a principle about trajectories of type \\(\\Gamma: [t_0, t_1] \\to \\mathcal P\\). That is, \\(\\Gamma(t)\\) is a phase of the system, specifying both its state and momentum. Variations can be thought of as making a state perturbation \\(\\delta \\eta_p(t)\\) and a momentum perturbation \\(\\delta \\eta_p(t)\\) at every time.\nOne may object that modified Hamilton’s principle is performing physically impossible variations: how could you perform variations on position and momentum independently of each other? Shouldn’t we have \\(\\delta p = m\\delta \\dot q = \\delta (\\nabla_{v} L(t, q, \\dot q))\\) at all times? To this objection, there are four layers of replies.\n\nThe equivalence of Hamilton’s principle and modified Hamilton’s principle, to be proved below, is a theorem in pure mathematics. It makes no demand on physical reality. It merely states that Hamilton’s principle specifies the same trajectories as modified Hamilton’s principle. Consequently, if it happens that these trajectories are physically real, then they can be specified by either principle.\nThe economic interpretation of momentum \\(p\\) is merely the market price. The equation \\(p = \\nabla_{v} L(t, q, \\dot q)\\) is true if we also assume that the producer is profit-maximizing. Now, if the trajectory \\(\\gamma\\) is optimal, then it implies that the producer is profit-maximizing. But after a perturbation of \\(\\gamma\\) to \\(\\gamma + \\delta \\eta\\), the producer is not necessarily profit-maximizing.4 Consequently, even in Hamilton’s principle, there is no requirement that \\(p = \\nabla_{v} L(t, q, \\dot q)\\). The modified Hamilton’s principle makes this interactive dance between the producer and the market explicit: we allow both the production schedule and the market price schedule to vary independently. Then, the equation \\(\\delta \\int (\\sum_i p_i \\dot q_i - H)dt = 0\\) is a statement about the trajectory of the producer-market system, and solving it would simultaneously solve both the producer and the market. In contrast, the equation \\(\\delta \\int L dt = 0\\) is a statement about the producer, and solving it by imagining a market \\(p\\) is useful, but not necessary.\nEven in classical mechanics, momentum is not real. We are fooled by our long habit of thinking about classical mechanics as if it is merely a more mathematical version of our intuition. Classical mechanics is actually unintuitive.5 In classical mechanics, there is no necessary connection between momentum and velocity – \"If \\(L = \\frac 12 v^T M v\\), then \\(p = Mv\\) on physically valid paths\" actually needs to be proved from Hamilton’s principle, not baked into the definition of momentum!\nThough in classical mechanics, both principles are equivalent, in modern physics, the modified Hamilton’s principle is primary, and the Hamilton’s principle a mere derivative. Furthermore, the phase space is primary, and the division of it into position-momentum is arbitrary. At a more fundamental level, there is no distinction between position and momentum. A \"rotation in phase space\" can transform position and momentum into each other.\n\n4 Unless the market price is perturbed in just the right way to make the producer profit-maximizing – If the producer messes up, the market can still accommodate the producer and make the producer look as if it is still profit-maximizing... Just like Potemkin villages!5 Why else did Newton come two thousand years after Aristotle? Though quantum mechanics is certainly more unintuitive.\nTheorem 1 (Hamilton’s principle and modified Hamilton’s principle are equivalent.) Given a state space \\(\\mathcal S\\), a Lagrangian \\(L(t, q, v)\\) on the configuration space, and a Hamiltonian \\(H(t, q, p)\\) on the phase space, related by convex duality, then a path \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) on state space satisfies\n\\[\\delta \\int_\\gamma L(t, q, \\dot q) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\), iff its corresponding path \\(\\Gamma: [t_0, t_1]: \\to \\mathcal T^\\ast \\mathcal S\\) on phase space satisfies\n\\[\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\]\nwith fixed \\((t_0, q_0), (t_1, q_1)\\) (and variable \\(p_0, p_1\\)).\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\((\\Rightarrow):\\) Since \\(\\gamma\\) has zero variation for the action \\(\\int_\\gamma L(t, q, \\dot q)dt\\), and \\(H\\) is related to \\(L\\) by convex duality, by our previous results, the Hamiltonian equations of motion are satisfied along \\(\\gamma\\). That is, \\(-\\nabla_q H = \\dot p, \\nabla_p H = \\dot p\\).\nPerform variation \\(\\Gamma + \\delta \\eta\\) on phase space. The variation in the action is\n\\[\\begin{aligned} \\delta S(\\Gamma) &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle \\nabla_q H, \\delta q\\rangle - \\langle \\nabla_p H, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle \\delta p, \\dot q\\rangle + \\langle  p, \\delta \\dot q\\rangle - \\langle -\\dot p, \\delta q\\rangle - \\langle \\dot q, \\delta p\\rangle ] dt \\\\ &= \\int_{t_0}^{t_1} [\\langle  p, \\delta \\dot q\\rangle + \\langle \\dot p, \\delta q\\rangle] dt \\\\ &= \\langle p, \\delta q\\rangle \\Big|_{t_0}^{t_1} = 0 \\end{aligned}\\]\nsince \\(\\delta q= 0\\) at the end points.\n\\((\\Leftarrow):\\) Since \\(\\delta \\int_\\Gamma \\sum_i p_i \\dot q_i - H(t, q, p) dt = 0\\) at \\(\\Gamma\\) under constraint of fixed \\((t_0, q_0), (t_1, q_1)\\), it must also have zero variation if we use the stronger constraint of fixed \\((t_0, q_0, p_0), (t_1, q_1, p_1)\\). Then the Euler–Lagrange equations state6\n\\[-\\nabla_q H = \\dot p, \\quad \\nabla_p H = \\dot p\\]\nwhich, as we proved, are precisely the conditions (no arbitrage pricing, and stationary profit flow) for \\(\\delta \\int_\\gamma L = 0\\).\n\n\n\n6 One can interpret this as treating the phase space as if it is a state space of a physical system with \\(2N\\) degrees of freedom.\n\nMaupertuis’ principle\nMaupertuis’ principle is a principle for specifying orbits in phase space. An orbit is a trajectory of the physical system, but with timing information lost. We know that the system traveled through the states on the orbit, one after another, but we don’t know how fast is the traversal.\nIn order to be very explicit about it, we will write orbits in phase space as \\(\\mu: [a, b] \\to \\mathcal P\\). Here \\(a, b\\) look like \"start and end times\" and \\(\\mu(s)\\) looks like \"location of the path at time \\(s\\)\", but \\(s\\) is not time, and \\(a, b\\) are not moments in time either. It is really just a parametrization of the curve, with no implications about how fast, or how slow, the system would actually traverse the orbit.\nThe integral \\(\\int_\\mu \\sum_i p_i \\dot q_i ds\\) is unchanged by stretching and pressing the timing of \\(\\mu\\). That is, let \\(f: [a', b'] \\to [a, b]\\) be a strictly increasing differentiable function, then \\(\\int_{\\mu\\circ f} \\sum_i p_i \\dot q_i ds = \\int_\\mu \\sum_i p_i \\dot q_i ds\\). Consequently, Maupertuis’ principle is really concerned only with the orbit, not the timing of the orbit.\nSince timing is lost, the constraint of fixed \\((t_0, q_0), (t_1, q_1)\\) cannot apply. However, merely fixing \\(q_0, q_1\\) is too little constraint. The solution is to add a new constraint: the variation must stay on the surface of constant energy \\(E\\). That is, \\(H(\\mu'(s')) = E\\) for any variation \\(\\mu'\\) and parameter \\(s'\\). This is how we arrive at Maupertuis’ principle.\n::: prop\nWhen the Hamiltonian is time-independent, Hamilton’s principle and Maupertuis’ principle are equivalent (after a retiming scaling).\nGiven phase space \\(\\mathcal P\\) and a time-independent Hamiltonian \\(H(q, p)\\) over the phase space, such that \\((\\nabla_q H, \\nabla_p H)\\) is never zero, then any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) that satisfies Hamilton’s principle also satisfies Maupertuis’ principle.\nConversely, given any orbit \\(\\mu: [a, b] \\to \\mathcal P\\) with constant \\(H\\) that satisfies Maupertuis’ principle, there exists a \"retiming map\" \\(f: [t_0, t_1]\\to [a, b]\\) such that \\(f\\) is monotonically increasing, and \\(\\mu\\circ f\\) satisfies Hamilton’s principle. :::\n::: proof Proof. We show that Maupertuis’ principle is equivalent to Hamilton’s equations of motion after a retiming map.\nConsider orbit \\(\\mu: [a, b] \\to \\mathcal P\\) in phase space, with constant \\(H(\\mu(s)) = E_0\\). By integration-by-parts, we have\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int \\langle \\delta p, \\dot q\\rangle - \\langle \\dot p, \\delta  q\\rangle ds + \\cancel{\\langle p, \\delta q\\rangle} \\Big|_{a}^{b}\\]\nwhere the variation fixes \\(q_0, q_1\\) and \\(H\\).\nNow, \\(\\delta H = \\langle \\nabla_p H, \\delta p\\rangle +  \\langle \\nabla_q H, \\delta q\\rangle = 0\\). So, if the orbit satisfies Hamilton’s equations of motion after a retiming map \\(f\\), that is,\n\\[\\begin{cases}     \\dot p = -f'(s)\\nabla_p H \\\\     \\dot q = f'(s)\\nabla_q H \\end{cases}\\]\nthen plugging it back, we get\n\\[\\delta \\int \\langle p, \\dot q\\rangle ds = \\int f'(s) \\delta H ds = 0\\]\nIt is routine to check that, given four vectors \\(a, b, c, d\\in \\R^N\\), if \\(\\forall x, y\\in \\R^N\\),\n\\[\\langle a, x\\rangle - \\langle b, y\\rangle = 0 \\implies \\langle c, x\\rangle - \\langle d, y\\rangle = 0\\]\nthen there exists \\(\\lambda &gt; 0\\) such that \\(c = \\lambda a, d = \\lambda d\\).\nThus, if the variation is zero for all \\(\\delta q, \\delta p\\) with fixed \\(H\\), then there exists some continuous and positive function \\(\\lambda: [a, b] \\to \\R\\) such that\n\\[\\begin{cases}     \\dot p = -\\lambda(s)\\nabla_p H \\\\     \\dot q = \\lambda(s)\\nabla_q H \\end{cases}\\]\nNow solve for \\(f' = \\lambda^{-1}\\) by integration7, then \\(f\\) is the desired retiming map. ◻ :::\n7 Since \\(\\lambda\\) is continuous and positive, with compact domain, its range must be bounded below by some positive constant \\(\\epsilon &gt; 0\\), thus the integration would not diverge."
  },
  {
    "objectID": "blog/posts/geometrical-mechanics/index.html#canonical-transformations",
    "href": "blog/posts/geometrical-mechanics/index.html#canonical-transformations",
    "title": "Yuxi on the Wired",
    "section": "Canonical transformations",
    "text": "Canonical transformations\n\nGenerating functions\nThe dynamics of a physical system can be fully defined by its Lagrangian function. However, the Lagrangian function is not fully defined by the dynamics. There are many possible functions that can all play the role of the Lagrangian.\nSuppose \\(L(t, q, v)\\) is a Lagrangian function, then take any twice-differentiable function \\(F(t, q)\\), and define\n\\[L' dt := L dt + dF\\]\nwhich implies\n\\[L'(t, q, v) := L(t, q, v) + \\partial_t F(t, q) + \\langle \\nabla_q F(t, q), v\\rangle\\]\nthen it is easy to directly verify that a trajectory \\(\\gamma(t)\\) satisfies the Euler–Lagrange equations for \\(L\\) iff it satisfies them for \\(L'\\). Consequently, both \\(L\\) and \\(L'\\) are different functions that can both play the role of Lagrangian for the same physical system.\nInstead of directly computing the Euler–Lagrangian equations, we can also do it directly by variational principles: For any trajectory \\(\\gamma: [t_0, t_1] \\to \\mathcal S\\) we have\n\\[\\int_{t_0}^{t_1} L'(t, \\gamma(t), \\dot \\gamma(t))dt = F(t, \\gamma(t))|_{t_0}^{t_1} + \\int_{t_0}^{t_1} L(t, \\gamma(t), \\dot \\gamma(t))dt\\]\nConsequently, \\(\\delta \\int Ldt = 0\\) iff \\(\\delta \\int L'dt = 0\\), so a trajectory has stationary action according to one Lagrangian iff according to the other.\nSuch \\(F(t, q)\\) are called a generating function for transforming a Lagrangian function. Generating functions are really just functions that are picked to play a certain role. That is, being a generating function is not an intrinsic property of a function, but extrinsic, because some human physicist has decided to use it for generating a new Lagrangian from an old one. This is why I don’t like saying \"\\(F\\) a generating function...\". Instead, I prefer to say \"Now we use \\(F\\) to generate a new Lagrangian...\" Nevertheless I am forced to use the term because it is a venerable error, a bug that became a feature.\n\n\nGenerating functions for Hamiltonians\nHamiltonians are freer than Lagrangians. Instead of one way, there are many ways to generate new Hamiltonians from old.\nTaking inspiration from Lagrangian generating functions, we write down the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nwhere \\(G: \\R \\times \\mathcal P \\to \\R\\) is any twice-differentiable function on phase spacetime.\n::: theorem If \\((q, p), (Q, P)\\) are two coordinate systems on the phase spacetime, and \\(h, H, G\\) are twice-differentiable functions on phase spacetime, and\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nThen along any trajectory in phase spacetime, \\((q, p)\\) satisfies Hamiltonian equations of motion for \\(h\\), iff \\((Q, P)\\) satisfies Hamiltonian equations of motion for \\(H\\). :::\n::: proof Proof. Let \\(\\gamma: [t_0, t_1] \\to \\mathcal P\\) be any trajectory, not necessarily satisfying Hamilton’s equations of motion. Then for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\), we have by integration-by-parts,\n\\[\\begin{aligned}     &\\delta\\int_\\gamma \\langle p , dq \\rangle - hdt = \\delta\\int_\\gamma \\langle P, dQ \\rangle - Hdt + dG\\\\     &= \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt + (\\langle P, \\delta Q \\rangle + \\delta G)\\Big|_{t_0}^{t_1} \\\\     &= \\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt + \\langle p, \\delta q \\rangle \\Big|_{t_0}^{t_1}  \\end{aligned}\\]\nThe boundary terms are equal, since \\(\\langle p , \\delta q \\rangle - h \\delta t = \\langle P, \\delta Q \\rangle - H\\delta t + \\delta G\\), and \\(\\delta t = 0\\) as we fixed \\(t_0, t_1\\).\nThus, for any variation of \\(\\gamma\\) with fixed \\(t_0, t_1\\),\n\\[\\int (\\langle \\delta p, \\dot q - \\nabla_p h\\rangle - \\langle \\dot p + \\nabla_q h, \\delta q\\rangle ) dt = \\int (\\langle \\delta P, \\dot Q - \\nabla_P H\\rangle - \\langle \\dot P + \\nabla_Q H, \\delta Q\\rangle ) dt\\]\nThus, if \\(\\gamma\\) satisfies Hamiltonian equations of motion for \\((q, p), h\\), then it also does so for \\((Q, P), H\\). ◻ :::\n\n\nCoordinate-based canonical transforms\nThis section might make more sense after reading the next section.\nThe equation\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + dG\\]\nlives in phase spacetime. That is, \\(dq, dt, dQ, dG\\) are all differentials in \\(\\R \\times \\mathcal P\\). This is elegant, but not good for concrete computations, which requires coordinate-based equations.\nGenerally, \\(G(t, y)\\) is a function on phase spacetime, so it could be represented in any coordinate system of phase spacetime. For example, we can represent it as \\(G(t, y) = G_{q, p}(t, q(t, y), p(t, y))\\), or \\(G(t, y) = G_{Q, P}(t, Q(t, y), P(t, y))\\), or even mixed coordinates like \\(G(t, y) = G_{q, P}(t, q(t, y), P(t, y))\\), etc.\nMost representations result in intractable coordinate-based equations, but a few are actually usable. These are traditionally classified as \"type 1\" to \"type 5\".\nType 1: \\(G(t, y) = F_1(t, q(t, y), Q(t, y))\\).\nPlugging it in, we find\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_1 dt + \\langle \\nabla_q F_1, dq \\rangle + \\langle \\nabla_Q F_1, dQ \\rangle\\]\nyielding the equations\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q) \\\\     p = \\nabla_q F_1(t, q, Q) \\\\     P = - \\nabla_Q F_1(t, q, Q) \\end{cases}\\]\nIn order to solve for the canonical transform, first invert \\(p = \\nabla_p F_1(t, q, Q)\\) to obtain \\(Q = f_Q(t, q, p)\\), then plug it into \\(P = - \\nabla_Q F_1(t, q, Q)\\) to obtain \\(P = f_P(t, q, p)\\). Inverting them gives us \\(q = g_q(t, Q, P), p = g_p(t, Q, P)\\).\nThen, given any Hamiltonian \\(h(t, q, p)\\), the corresponding \\(H(t, Q, P)\\) is found by \\(H(t, Q, P) = h(t, q, p) + \\partial_t F_1(t, q, Q)\\), or very explicitly,\n\\[H(t, Q, P) = h(t, g_q(t, Q, P), g_p(t, Q, P)) + \\partial_t F_1(t, g_q(t, Q, P), Q)\\]\nType 2: \\(G(t, y) = F_2(t, q(t, y), P(t, y)) - \\langle P(t, y), Q(t, y)\\rangle\\).\nWhy \\(\\langle P, Q\\rangle\\)? Directly writing down \\(G = F_2(t, q, P)\\) results in the following equation:\n\\[\\langle p , dq \\rangle - hdt = \\langle P, dQ \\rangle - Hdt + \\partial_t F_2 dt + \\langle \\nabla_q F_2, dq \\rangle + \\langle \\nabla_P F_2, dP \\rangle\\]\nHere, there is an entanglement between terms \\(dq, dQ, dP\\). Since there are only \\(2N\\) dimensions in the phase space, but there are \\(3N\\) differentials in \\(dq, dQ, dP\\), it must be possible to represent \\(N\\) of them as a linear combination of the other \\(2N\\) differentials. In particular, we can represent \\(dQ\\) as a linear combination of \\(dq, dP\\).\nInstead, we can directly cancel out \\(\\langle P, Q\\rangle\\) from the equation by writing \\(G\\) as \\(G + \\langle P, Q\\rangle - \\langle P, Q\\rangle\\), then represent \\(G + \\langle P, Q\\rangle\\) as \\(F_2(t, q, P)\\). This then gives\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F_2(t, q, P) \\\\     Q = \\nabla_P F_2(t, q, P) \\\\     p = \\nabla_q F_2(t, q, P) \\end{cases}\\]\nType 3: \\(G = F_3(t, p, Q) + \\langle p, q\\rangle\\).\nType 4: \\(G = F_4(t, p, P) + \\langle p, q\\rangle  - \\langle P, Q\\rangle\\).\nType 5: \\(G = F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) + \\langle p_{I_1}, q_{I_1} \\rangle - \\langle P_{I_3}, Q_{I_3} \\rangle\\).\n\\[\\begin{cases}     H(t, Q, P) = h(t, q, p) + \\partial_t F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     q_{I_1} = -\\nabla_{p_{I_1}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     p_{I_2} = \\nabla_{q_{I_2}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     Q_{I_3} = \\nabla_{P_{I_3}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\\\     P_{I_4} = -\\nabla_{Q_{I_4}} F(t, p_{I_1}, q_{I_2}, P_{I_3}, Q_{I_4}) \\end{cases}\\]\nHere, \\(I_1, I_2, I_3, I_4\\) stand for subsets of the indexing set \\(\\{1, 2, ..., N\\}\\). We also require \\(I_1 \\cup I_2 = I_3 \\cup I_4 = \\{1, 2, ..., N\\}\\)\nNote that types 1 to 4 are all special cases of type 5.\n\n\nExamples of canonical transforms\n\nPoint transforms\nIf \\(G= 0\\), then we need to solve only the equation \\(\\langle p, dq \\rangle = \\langle P, dQ \\rangle\\), which can be done in general iff \\(dQ\\) is a linear combination of \\(dq\\), thus \\(Q = f_Q(t, q)\\) for some function \\(f_Q\\). This is just the point transform, with solution\n\\[P = ([\\nabla_q f_Q]^T)^{-1}p\\]\n\n\nInterpolating a canonical transform\nGiven any canonical transform from \\((q, p)\\) to \\((Q, P)\\), for any two times \\(t_0 &lt; t_1\\), we can interpolate between \\((q, p), (Q, P)\\) over the period \\([t_0, t_1]\\). That is, we construct a canonical transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) such that \\((\\bar q, \\bar p) = (q, p)\\) at \\(t=t_0\\), and \\((\\bar q, \\bar p) = (Q, P)\\) at \\(t = t_1\\).\nThe idea is to note that any canonical transform can be written in type 2, including the identity transform.\nThe identity transform from \\((q, p)\\) to \\((\\bar q, \\bar p)\\) can be represented in type 2 as\n\\[G_0 = \\langle q, \\bar p \\rangle - \\langle \\bar p, \\bar q \\rangle\\]\nGenerate the transform from \\((q, p)\\) to \\((Q, P)\\) by \\(G\\), and represent it in type 2 as\n\\[G_1 = F_2(t, q, P) - \\langle P, Q \\rangle\\]\nNow interpolate them by\n\\[G = \\frac{t_1-t}{t_1 - t_0} \\langle q, \\bar p \\rangle + \\frac{t - t_0}{t_1 - t_0} F_2(t, q, \\bar p)  - \\langle \\bar p, \\bar q \\rangle\\]\n\n\nTime-evolution is a canonical transform generated by the action\nRecall that, for any coordinate system \\((q, p)\\) and Hamiltonian \\(h\\), we defined the action function (\"Hamilton’s principal function\") \\(S(t_1, q_1; t_0, q_0)\\) to be the action for the path \\(\\gamma\\) from \\((t_0, q_0)\\) to \\((t_1, q_1)\\). We also proved, during derivation of the HJE,\n\\[dS = \\langle p_1, dq_1 \\rangle -h(t_1, q_1, p_1) dt_1 - \\langle p_0, dq_0 \\rangle + h(t_0, q_0, p_0) dt_0\\]\nRearrange, and using suggestive notation, we get...\n\\[\\langle p_0, dq_0 \\rangle - h_0 dt_0 = \\langle p_1, dq_1 \\rangle -h_1 dt_1 + dS\\]\nSo we find that time evolution is a canonical transformation generated by \\(S\\).\nIn more detail, fix some coordinate system \\((q, p)\\). Then for any Hamiltonian \\(\\mathcal H : \\R \\times \\mathcal P \\to \\R\\), define its time-evolution function \\(\\phi\\), such that \\(\\phi(t_0, t_1; y)\\) is the point that we end up with at time \\(t_1\\), if we start at \\(y\\) at time \\(t_0\\), and evolve according to \\(\\dot q = \\nabla_p h, \\dot p = -\\nabla_q h\\), where \\(h(t, q(t, x), p(t, x)) = \\mathcal H(t, x)\\) is the coordinate-based version of the coordinate-free \\(\\mathcal H\\).\nNow, fix some time-interval \\(s\\in \\R\\), then define the (coordinate-free) function \\(\\mathcal G\\), the action of the trajectory starting at \\((t, y)\\) and lasting for \\(s\\):\n\\[\\mathcal G(t, y) := S(t+s, q(t+s, \\phi(t, t+s; y)); t, q(t, y))\\]\nand the new coordinate system with a new Hamiltonian, obtained by \"evolving for \\(s\\) time\": \\[\\begin{aligned} Q(t, y) = q(t+s, \\phi(t, t+s; y)) \\\\ P(t, y) = p(t+s, \\phi(t, t+s; y)) \\\\ H(t, Q(t, y), P(t, y)) = \\mathcal H(t + s, \\phi(t, t+s; y)) \\end{aligned}\\]\nwhich allows a coordinate-based representation of \\(\\mathcal G\\):\n\\[G(t, q, Q) = S(t+s, Q; t, q)\\]\nWith these definitions, we have\n\\[dG = -Hdt + \\langle P, dQ \\rangle + hdt -\\langle p, dq \\rangle\\]\nthat is, \\((Q, P), H\\) is canonically transformed from \\((q, p), h\\) via the function \\(G\\).\n\n\n\nSimple harmonic oscillator\nConsider a SHO with \\(N\\) degrees of freedom. Its Hamiltonian is\n\\[H = \\frac 12 p^T M^{-1} p + \\frac 12 q^T K q\\]\nwhere \\(M\\) is the matrix representing the masses of the system, and \\(K\\) is the matrix representing the elastic constants of the system.\n\nTranslation is a canonical transform generated by momentum\n\n\nRotation is a canonical transform generated by angular momentum\n\n\n\nCanonical transforms, in general\nThere are two possible ways to define canonical transforms. The more concrete way is by using generating functions: two coordinate systems \\((q, p), (Q, P)\\) on phase spacetime are generated canonical transforms of each other iff\n\\[\\langle p, dq\\rangle - \\langle P, dQ\\rangle = dG\\]\nfor some \\(G\\) functions on phase spacetime. Remember that \\(dq, dQ\\) are differentials with constant time.\nAs for the more abstract form... long story short: every canonical transform has a generating function. This is usually called \"Carathéodory Theorem\". See (Goldstein, Poole, and Safko 2008, sec. 9.5).\nThis has a more elegant form with exterior calculus. Take exterior differentiation (again, only in phase space, not in time), we get\n\\[\\sum_i dp_i \\wedge dq_i = \\sum_i dP_i \\wedge dQ_i\\]\nNow take wedge product \\(N\\) times with itself, we get\n\\[\\bigwedge_i dp_i \\wedge dq_i = \\bigwedge_i dP_i \\wedge dQ_i\\]\nInterpretation: canonical transforms preserve phase space volumes. That is, if we have an open subset in phase space, defined coordinate-free, then we can compute its volume by writing down a canonical coordinate system \\((q, p)\\) and integrating \\(\\prod_i dp_i dq_i\\). The result is unchanged by a canonical transform to \\((Q, P)\\).\nThis gives us a new proof of Liouville’s theorem:\n\nProof. Since time-evolution is a canonical transform, time-evolution preserves volumes.\nGiven a particle flow in phase space, with density \\(\\rho(t, p, q)\\), flowing according to Hamiltonian \\(H(t, q, p)\\). Take an infinitesimal cube around \\((q, p)\\) at time \\(t\\), with volume \\(\\delta V = \\prod_i \\delta p_i \\delta q_i\\), then it contains \\(\\delta N = \\rho(t, q, p) \\delta V\\) number of particles. Then, let it flow for time \\(s\\).\nThe infinitesimal cube is transported to some other parallelogram around some point \\((q', p')\\), but its volume is unchanged, thus the density at the new location is still the same: \\(\\rho(t+s, q', p') = \\rho(t, q, p)\\). Thus \\(\\dot \\rho = 0\\). \n\n\n\nPoisson brackets are preserved by canonical transforms\nThe Poisson bracket \\(\\{f, g\\}\\) was defined in a coordinate-based way:\n\\[\\{f, g\\} = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right)\\]\nWe show that it is preserved by canonical transforms. That is, if \\((Q, P)\\) is a canonical transform of \\((p, q)\\) then\n\\[\\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial q_{i}} \\frac{\\partial g}{\\partial p_{i}} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i}\\right) = \\sum_{i=1}^{N} \\left( \\frac{\\partial f}{\\partial Q_{i}} \\frac{\\partial g}{\\partial P_{i}} - \\frac{\\partial f}{\\partial P_i} \\frac{\\partial g}{\\partial Q_i}\\right)\\]\n\nProof. (From the Landau–Lifshitz textbook) Since the Poisson bracket does not depend on time, and if \\(Q(t, q, p), P(t, q, p)\\) is a canonical transform, so is \\(Q(t, q, p), P(t, q, p)\\), so we consider only canonical transforms that are independent of time.\nIf we started with only \\(f(q, p), g(q, p)\\), then extend them to phase spacetime by\n\\[\\mathcal F(t, y) = f(q(0, y), p(0, y)),\\quad \\mathcal G(t, y) = g(q(0, y), p(0, y))\\]\nNext, impose \\(\\mathcal G\\) as a Hamiltonian, and evolve the physical system according to Hamilton’s equations of motion for \\((q, p), \\mathcal G\\). Since \\((q, p)\\) and \\((Q, P)\\) are canonical transforms of each other, we have\n\\[\\{\\mathcal F, \\mathcal G\\}_{q, p} + \\partial_t \\mathcal F = \\dot{\\mathcal F} = \\{\\mathcal F, \\mathcal G'\\}_{Q, P} + \\partial_t \\mathcal F\\]\nOkay, what is \\(\\mathcal G'\\)? It is a solution to\n\\[\\langle p, dq \\rangle - \\mathcal G dt  = \\langle P, dQ \\rangle - \\mathcal G' dt + d\\mathcal K\\]\nsince \\(\\mathcal K\\) does not depend on time, \\(d\\mathcal K\\) contains zero \\(dt\\) term, so \\(\\mathcal G = \\mathcal G'\\).\n\n\n\nInterpretation of canonical transforms\nWhat is invariant under canonical transforms is what is really real about the physical system. Other things are mirages, illusions caused by our choice of coordinates.\nThus, position and momentum are mirages. Hamiltonian equations are real. \\(p, q\\) are mirages. \\(\\int \\sum_i p_i dq_i\\) is real. \\(\\nabla_p, \\nabla_q\\) are mirages. Poisson brackets \\(\\{f, g\\}\\) are real. Phase space lengths \\(dp, dq\\) are mirages. Phase space areas \\(\\sum_i p_i dq_i\\), volumes \\(\\prod_i dp_i dq_i\\), and densities \\(\\rho\\) are real."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe geometry of physical states\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipia Philosophica Naturalium Mathematicarum\n\n\nPhilosophical Principles of Natural Mathematics\n\n\n\nmath\n\n\nphysics\n\n\nphilosophy\n\n\ncs\n\n\n\n.\n\n\n\n\n\nApr 11, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation and GDP since 10000 BC\n\n\n\n\n\n\nAI\n\n\nscaling\n\n\n\nWhen did the singularity get cancelled?\n\n\n\n\n\nJan 18, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nMathematical Interpretations of Quantum Mechanics\n\n\n\n\n\n\nphysics\n\n\n\nQuantum mechanics: what it all means, mathematically speaking.\n\n\n\n\n\nJan 10, 2024\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nBook Reviews\n\n\n\n\n\n\nbook-review\n\n\n\nBook reviews.\n\n\n\n\n\nDec 16, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nThe Decline of Mathematical Fields\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nhistory\n\n\nmath\n\n\n\nLosing my religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nHole Argument and Inverted Qualia\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nmath\n\n\nphysics\n\n\n\nTODO description.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\n\n\n\n\n\n\nWhat does it feel like to be a mathematical object?\n\n\n\n\n\n\nfun\n\n\nphilosophy\n\n\nmath\n\n\n\nMy religion.\n\n\n\n\n\nNov 1, 2023\n\n\nYuxi Liu\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n  \n  \nYuxi Liu is a PhD student in Computer Science at the Berkeley Artificial Intelligence Research Lab, researching on the scaling laws of large neural networks."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html",
    "href": "blog/posts/ai-creativity/index.html",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#introduction",
    "href": "blog/posts/ai-creativity/index.html#introduction",
    "title": "Yuxi on the Wired",
    "section": "",
    "text": "An interesting strand of argument runs through discussions on AI: whether they can be creative or not; whether we should build them to be creative or not.\nDuring an online discussion, I explained to someone who is confused about why people are building these art machines that are “stealing art”. I explained the technological-scientific perspective on art. Their argument ran as follows:\n\nMachines cannot be creative. The apparent creativity is fake and mere copying.\nPeople build machines not because they want to make art, but because of something else. Perhaps a greed for money, a hate of artists, or some other nefarious motivation (the post is a bit vague on the precise motivation).\n\nI tried to explain the very different perspective on the other side of the cultural divide, so that they might understand, if not to accept:\n\nThere is no “magic”. Art might feel impossible to build a machine for, but we can.\nWhat I cannot create, I do not understand. (Feynman quote)\nIntrospection is unreliable. Asking artists how art was “really made” is not a reliable way to understand art.\nThus, we can build art machines, and we want to, if we are to ever understand art.\n\nThey repeated the same arguments, but more vehemently.\nIt was frustrating, though I was not surprised. This incident started my thinking: This is such a common response, that there is probably a psychological mechanism behind it. This essay describes some possible mechanisms."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "href": "blog/posts/ai-creativity/index.html#the-self-interest-theory",
    "title": "Yuxi on the Wired",
    "section": "The self-interest theory",
    "text": "The self-interest theory\nThe self-interest theory is as follows: “It is hard to get someone to understand something if something they care about depends on their not understanding it.”"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "href": "blog/posts/ai-creativity/index.html#the-non-truth-theory",
    "title": "Yuxi on the Wired",
    "section": "The non-truth theory",
    "text": "The non-truth theory\nThe non-truth theory states that some arguments are forever mired in the same controversies, always rehashing the same arguments, because there is no truth to be found underneath the arguments.\nThere are certain social functions that are best served by saying something in language that looks like they talk about objective things. You can think of this as a hack in the programming language of humans. For example,\nThere are some social functions that"
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-terrible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems terrible that machines might create",
    "text": "Why it seems terrible that machines might create\nAt the “immortal dinner party” held by Benjamin Haydon on 28 December 1817, the Romantic poet John Keats agreed with Charles Lamb that Newton “had destroyed all the poetry of the rainbow, by reducing it to the prismatic colors”. Later, Keats wrote “Lamia” that included these famous lines:\nDo not all charms fly\nAt the mere touch of cold philosophy?\nThere was an awful rainbow once in heaven:\nWe know her woof, her texture; she is given\nIn the dull catalogue of common things.\nPhilosophy will clip an Angel's wings,\nConquer all mysteries by rule and line,\nEmpty the haunted air, and gnomed mine—\nUnweave a rainbow, as it erewhile made\nThe tender-person'd Lamia melt into a shade\nGPT4: Keats came up with the concept of “negative capability.” This is the ability to dwell in uncertainties, mysteries, doubts, without any compulsive reaching after fact and reason. Keats valued this ability, arguing that it was central to a poet’s creative process."
  },
  {
    "objectID": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "href": "blog/posts/ai-creativity/index.html#why-it-seems-incredible-that-machines-might-create",
    "title": "Yuxi on the Wired",
    "section": "Why it seems incredible that machines might create",
    "text": "Why it seems incredible that machines might create\nHere, the arguments are easier to classify. It seems that there are several common mental models that people use when they think about machines that create. Using any of these would make it seem obvious that machines cannot be creative. So, I just need to classify the mental models!\n\nMachines as monkeys typing randomly\nIn Gulliver’s Travels (1726) by Jonathan Swift, there was a writing machine. It is a 16x16 matrix of little square blocks, with a character on each side. To use it, you turn the 32 handles randomly, then read out the few words that appeared by chance. This allowed:\n\nthe most ignorant person, at a reasonable charge, and with a little bodily labour, might write books in philosophy, poetry, politics, laws, mathematics, and theology, without the least assistance from genius or study.\n\nIt is a clear satire, possibly of Ramon Llull’ s Thinking Machine (3 concentric rotating disks that generate all possible theological arguments):\n\nThe first of these features means that all of these attributes are inherent; the second, that they are systematically interrelated in such a way as to affirm, with impeccable orthodoxy, that glory is eternal or that eternity is glorious; that power is true, glorious, good, great, eternal, powerful, wise, free, and virtuous, or benevolently great, greatly eternal, eternally powerful, powerfully wise, wisely free, freely virtuous, virtuously truthful, etc., etc.\n\n\n\nMachines as pipes for the water of creativity\n\nIt appears to me that if one wants to make progress in mathematics one should study the masters and not the pupils.\n\n— N.H. Abel (1802–1829), quoted from an unpublished source by O. Ore in Niels Henrik Abel, Mathematician Extraordinary, p. 138.\nThere is a common attitude that I can summarize as this: Like drawing water from the unsullied source at the mountain’s peak, so is the experience of returning to the writings of the masters: clear, refreshing, and devoid of later impurities.\n\nAncient Greek theory of creativity\nIn ancient Greece, the Muses were considered the source of the knowledge embodied in the poetry, lyric songs, and myths that were related orally for centuries in ancient Greek culture. Homer began his Iliad with:\n\nSing, Muse, the fatal wrath of Peleus’ son,\nWhich to the Greeks unnumb’red evils brought,\n\nNote that the Muses was doing the real singing, and Homer was a channel for their singing (back then, poetry was sang – the Iliad was written down only after a few centuries). In Plato’s dialog Ion, Socrates (perhaps a sockpuppet of Plato) argued that “it is not by art that poets compose… but by divine apportionment”:\n\nFor the poets tell us that they carry honey to us from every quarter like bees, and they fly as bees do, sipping from honey-flowing fountains in glens and gardens of the Muses. And they tell the truth. For a poet is a delicate thing, winged and sacred, and unable to create until he becomes inspired and frenzied, his mind no longer in him; as long as he keeps his hold on that, no man can compose or chant prophecy. Since, then, it is not by art that poets compose and say many beautiful things about their subjects, as you do about Homer, but by divine apportionment, they each can do well only that to which the Muse directs them-this one dithyrambs, that one odes, or encomia, or dances, or epics, or iambics-each of them worthless in respect to the others.\n\nThe same point was made repeatedly in Plato’s corpus.\n\nJust as the rhapsode says what he says about Homer not by art but by divine apportionment, without intelligence (Ion 534b-c, 536c, 542a), so in the Meno (gge-looa) politicians get their virtue by divine apportionment, without intelligence; they have no more wisdom than seers and soothsayers, who say many fine things but know nothing of what they say; politicians are divine and inspired like poets, and possessed by the god (Meno 9gb-e). The irrational effects of poetry and rhapsody are directly comparable to the irrational effect of vulgar politics, whose servant is vulgar rhetoric (cf. Gorgias 502C).\n\nBoth quotes came from The Dialogues of Plato, Volume 3: Ion, Hippias Minor, Laches, Protagoras, translated by R. Allen. (I decided not to use one of the freely available versions since they tended to mistranslate “gods” as “God”.)\nFor example, in Phaedrus 245a, Socrates claimed that “the poetry of the sane man vanishes into nothingness before that of the inspired madmen”:\n\nAnd a third kind of possession and madness comes from the Muses. This takes hold upon a gentle and pure soul, arouses it and inspires it to songs and other poetry, and thus by adorning countless deeds of the ancients educates later generations. But he who without the divine madness comes to the doors of the Muses, confident that he will be a good poet by art, meets with no success, and the poetry of the sane man vanishes into nothingness before that of the inspired madmen.\n\n\n\nLater manifestations\nIsaac Newton thought he was merely recovering what the ancients have known all along. His friend William Stukeley described Newton as “the Great Restorer of True Philosophy”.\n\n\nApplication to machine creativity\n\n\n\nMachines as flowers for the DNA of creativity\nFrom Lovelace’s “Notes by the Translator”:\n\nThe Analytical Engine has no pretensions whatever to originate any thing. It can do whatever we know how to order it to perform. (source)\n\nIn his seminal paper “Computing machinery and intelligence” (1950), Alan Turing referenced Lovelace’s observation as the sixth objection to the possibility that machines might think. He then objected:\n\nThe view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. It is a very useful assumption under many circumstances, but one too easily forgets that it is false. (source).\n\nTuring was led to Lovelace’s objection by debates with Douglas Hartree, who in his book “Calculating Instruments and Machines” (page 70, 1949), quoted Lovelace approvingly. He objected using the phrase “electronic brain” for devices like electronic calculating machines or automatic pilots. He clarified that these machines cannot “think for themselves” and can only execute the instructions provided to them.\nThus, machines, in this view, are akin to flowers—organisms that reproduce and grow according to a predetermined genetic code but do not originate new genetic information on their own. Creativity, like DNA, must be instilled by a designer or operator, who programs the machine with the “genetic code” of what to create.\nAs a short etymological fun fact, the word “development” is a little capsule of the “flower for the DNA” idea:\n\nFirst use 1756, from French développement (“unrolling”). Compare with envelopment (“rolling”).\n\nThe idea is that of “opening up a scroll and showing what has always been written there. In the machines’ creative process can be seen as a similar”unrolling” of predetermined instructions or codes, much like the genetic “unrolling” in a blooming flower.\nThis is most explicitly manifest in the idea of preformationism, prevalent around 17th to 18th century. It seems the same intuitive appeals of preformationism apply to Lovelace’s objection.\n(A brief personal anecdote: When I was a kid, I thought bus cards contained tiny compressed coins inside, and when you “beep” them, those tiny coins fall into the machine through tiny openings on the card. Preformationism in economics!)"
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html",
    "href": "blog/posts/decline-of-mathematics/index.html",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "href": "blog/posts/decline-of-mathematics/index.html#invariant-theory",
    "title": "The Decline of Mathematical Fields",
    "section": "",
    "text": "In the 1880’s and 90’s the Theory of Invariants was seen to have unified many areas of mathematics, but by 1940 mathematicians, if asked, would have said the theory was dead. … most contemporary mathematicians have difficulty in naming one practitioner of the theory.\n(Fisher 1966)\n\n\nInvariant theory has already been pronounced dead several times, and like the phoenix it has been again and again rising from its ashes. The first period in the history of the theory culminated with the discovery of the so-called “symbolic method” which in theory allowed the computation of all invariants by a quasi-mechanical process, But it was soon realized that, except in a very few simple cases, the actual computation would lead to enormous labor, disproportionate with the interest of the outcome, especially in a period when all calculations were done by hand (it might be worthwhile to push the XIXth Century computations of invariants a little further along, with the help of modern computers). Partly for that reason, the next problem in the theory was the search for “fundamental systems” of invariants, i.e., finite sets such that any invariant would be a polynomial in the fundamental invariants. It is well known that the existence of such systems was proved by Hilbert in 1890, in a brilliant paper which made him famous overnight and which may be considered as the first paper in “modern algebra,” by its conceptual approach and methods. But Hilbert’s success also spelled the doom of XIXth Century invariant theory, which was left with no big problems to solve and soon faded into oblivion.\n(Dieudonné and Carrell 1970)\n\n\nHilbert’s paper did not immediately kill the subject, but rather acted as a progressive illness, beginning with an initial shock, and slowly consuming the computational body of the theory from within, so that by the early 1920’s the subject was clearly moribund. Abstraction ruled: the disciples of Emmy Noether, a student of Gordan, led the fight against the discredited computational empire, perhaps as a reaction to Noether’s original, onerous thesis topic that involved computing the invariants for a quartic form in three variables.\nClassical invariant theory, by Peter Olver 1999\n\n\n\nConsider all degree-2 homogeneous polynomials (over complex numbers). That is, consider functions like\n\\[\nf(z) = a_1 z_1^2 + a_2 z_1z_2 + a_3 z_2^2, \\quad a_1, a_2, a_3 \\in \\C.\n\\]\nEach such polynomial \\(f\\) is equivalent to a point in \\(\\C^3\\). As usual, we always try to hit the function with linear transforms if it simplifies the function. Let \\(A\\) be a linear transform, such that\n\\[\nA(z_1, z_2) = (A_{11}z_1 + A_{12}z_2, A_{21}z_1 + A_{22}z_2)\n\\]\nIt would not do if \\(A\\) collapses everything to zero, so we require \\(A\\) to be invertible. Further, we are only interested in solving \\(f=0\\), not the value of \\(f\\) itself. Therefore, scaling \\(A\\) by a constant does not matter, so we can remove this ambiguity by requiring \\(\\det A = 1\\). That is, we only consider the group \\(SL(2)\\).\nIn fact, we are not considering the whole space \\(\\C^3\\), but only the space of lines – the projective plane \\(\\P\\C^2\\). The idea can be visualized in real space \\(\\R^3\\) by first taking a homogeneous polynomial’s solutions can be found by first solving it on the unit sphere, then zoom it in and out to get all the whole solution.\nFor example, if we have a polynomial \\(f(x, y, z) = x^3 + y^2z + 2xyz\\), then its solution \\(f=0\\) is a surface in \\(\\R^3\\). We can solve the problem by first solving the surface’s intersection with the unit sphere, then for each point on the intersection, drawing a ray from the origin to the point. You can picture it thus: Take a steel ball, draw a curve on the surface with a marker pen, then drill in at each point on the curve, resulting in a cut-out cone.\n\n\n\nRings of a tree. You can solve a polynomial by finding the intersection of the surface with the bark of the tree, then draw a line from the center to each point.\n\n\nTheorem: Any invariant of \\(f\\) is divisible by the discriminant \\(\\Delta = a_2^2 - 4a_1a_3\\).\nHilbert’s basis theorem: For any form of polynomial, the space of invariants has a finite basis."
  },
  {
    "objectID": "blog/posts/mathematical-phenomenology/index.html",
    "href": "blog/posts/mathematical-phenomenology/index.html",
    "title": "What does it feel like to be a mathematical object?",
    "section": "",
    "text": "TODO: change the folder name, and title, etc.\nStructuralism"
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html",
    "href": "blog/posts/principia-mathematicarum/index.html",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "",
    "text": "# The world as theories and interpretations\nWhat is light? Newton said it was a particle1. Huygens said it was a wave. Schrödinger said it was both. Some clever fool said it was a wavicle. And Feynman said it was whatever helps you sleep at night shuts you up and lets you calculate.\nSo is light a particle, or a wave? None of these explanations satisfied me, so I figured it out for myself."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "href": "blog/posts/principia-mathematicarum/index.html#the-wave-particle-duality",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "The wave-particle duality",
    "text": "The wave-particle duality\nThere are more than one wave-particle duality. In fact, there is nothing particularly two-ful or wave-ful or particle-ful about physics! Why are we so confused about wave-particle duality? I blame force of habit and evolution.\n\nA particle is a curve. That is, it is a function \\(\\gamma: (a, b) \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathcal M\\) is a manifold.\nA field is a function \\(\\phi: \\mathcal M \\to Y\\), where \\(Y\\) is any manifold you like. We say the field is \\(Y\\)-valued.\nA scalar field is a real-valued field.\nA wave is a more confusing name for a field. Why \"confusing\"? Because the word \"wave\" makes people think the field must be \"going up and down\" here, there, or everywhere, but the fact is, a field can be exactly flat everywhere, and still be a wave! So why did physicists call it a \"wave\" when they really mean a field? Well, force of habit... back in the old days, the only field they knew of is the water-wave, which can be described mathematically as \\(h: \\R^2 \\to \\R\\), where \\(h(x)\\) is the height of water at location \\(x\\).\nA particle theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain paths in \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA field theory over a manifold \\(\\mathcal M\\) is a physical theory that states that certain fields over \\(\\mathcal M\\) are \"physical\" while others are \"unphysical\".\nA wave theory is a field theory.\nA wave-particle duality over a manifold \\(\\mathcal M\\) is a tuple \\((T, T', f)\\). Here, \\(T\\) is a particle theory over \\(\\mathcal M\\), and \\(T'\\) is a field theory over \\(\\mathcal M\\), and \\(f\\) is an equivalence between \\(T, T'\\).\nA wave-equation is a differential equation satisfied by a field.\nAn equation of motion (of a particle) is a differential equation satisfied by a particle.\n\nIf our physical theory has a very special \"physical space\" \\(\\mathcal M\\), then a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\R\\) represents time. In other words, a particle is nothing more and nothing less than a trajectory in spacetime. This is what we mean by a \"particle\" by default, even though sometimes we would deal with \"timeless particles\", for which time is meaningless, and a particle must instead be a function \\(\\gamma: (a, b) \\to \\mathcal M\\).\nTimeless particles? Why yes! That’s how we study geometric optics as the study of light-rays.\n\nIn geometric optics\n\n\nIn Hamiltonian mechanics\n\n\nIn quantum mechanics"
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "href": "blog/posts/principia-mathematicarum/index.html#crash-course-in-modern-theoretical-physics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Crash course in modern theoretical physics",
    "text": "Crash course in modern theoretical physics\nRecall that a particle is a function \\(\\gamma: (a, b) \\to \\R\\times \\mathcal M\\). But what if we don’t use an interval \\((a, b)\\), but use a square, or a cylinder, or even a cube? This leads us to the idea of strings, branes, and other such fancy frontiers of theoretical physics.\n\nString theory\nA closed string is a function \\(\\mu: (a, b) \\times \\mathbb S^1 \\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers, and \\(\\mathbb S^1\\) is the circle.\nAn open string is a function \\(\\mu: (a, b) \\times (0, 1)\\to \\mathcal M\\), where \\(a &lt; b\\) are real numbers.\nA string theory is made of two parts: one, the types of strings that it decides about; two, a way to decide if a string is physical or unphysical.\n\n\nHow to make your own variational physical theory\n\nFind a manifold \\(\\mathcal A\\).\nFind another manifold \\(\\mathcal B\\).\nDefine a family of functions of type \\(\\mu: \\mathcal A \\to \\mathcal B\\). This will be the domain of your physical theory.\nWrite down an action function \\(S(\\mu)\\).\nSpecify a way to \"vary \\(\\mu\\) infinitesimally\". Write that as \\(\\delta\\).\nDerive consequences of \\[\\delta S(\\mu) = 0.\\]\n\nFollowing the recipe, we immediately get Lagrangian mechanics and Hamiltonian mechanics.\nNow, we made a small sleight of hand in the recipe. Can you spot it? It is in steps 4 and 5. Namely, we have claimed that we can \"write down an action function\" and \"vary \\(\\mu\\) infinitesimally\". However, not every \\(\\mathcal A, \\mathcal B\\) has enough structure to allow us to do that. The art of doing theoretical physics is mostly in putting in enough structure in \\(\\mathcal A, \\mathcal B\\) so that you can define \\(S(\\mu)\\) and \\(\\delta S(\\mu)\\).\n\n\nHow to clothe your manifolds\n::: epigraph The world found nothing sacred in the abstract nakedness of being human.\nHannah Arendt, The origins of totalitarianism :::\nSince a mere manifold is not structured enough for defining actions and infinitesimal variations, we will \"clothe\" the manifolds with enough structures so that they do. To make this concrete, we will consider how we could construct Lagrangian mechanics and Hamiltonian mechanics according to the recipe.\nLagrangian\nHamiltonian\nAnd if you go deep into theoretical physics, you will eventually encounter Calabi–Yau manifolds, which are \"compact Kähler manifolds with a vanishing first Chern class and a Ricci-flat metric\". All these extra structures give them enough theoretical niceness for elegant string theories.\n\n\nExercise for the reader\nApply the recipe to your favorite manifolds, and get it published in a journal of physics with an impact factor of at least 2."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-classical-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of classical mechanics",
    "text": "Interpretations of classical mechanics\nFigure 3 shows six main interpretations of classical mechanics. They are all equivalent in some exact mathematical sense.\n\n\n\nSix main interpretations of classical mechanics.\n\n\n\nPosthuman classical mechanics\nWhat is it like to be a bat? What is it like to be a robot? The umwelt, seeing in infrared."
  },
  {
    "objectID": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "href": "blog/posts/principia-mathematicarum/index.html#interpretations-of-quantum-mechanics",
    "title": "Principia Philosophica Naturalium Mathematicarum",
    "section": "Interpretations of quantum mechanics",
    "text": "Interpretations of quantum mechanics"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html",
    "title": "Hole Argument and Inverted Qualia",
    "section": "",
    "text": "BIB.\n\nhttps://plato.stanford.edu/ENTRIES/spacetime-holearg/\n\nThe hole argument, in Norton’s formulation\n\nGiven two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since\n\nThe two distributions are observationally identical.\nThe laws of the theory cannot pick between the two developments of the fields into the hole.\n\nBut by manifold substantivalism, they represent distinct physical systems.\nTherefore, manifold substantivalism has a problematic metaphysics.\n\n\n\nMacdonald, Alan. “Einstein’s hole argument.” American Journal of Physics 69.2 (2001): 223-225.\n\n\n\nRelationalism\n\nThis is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In a passage that predates the inverted qualia thought experiment, Leibniz imagined the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place – ergo, space is relational, not absolute.\n\nLeibniz’s third paper, in Samuel Clarke, A Collection of Papers, Which passed between the late Learned Mr. Leibnitz, and Dr. Clarke, In the Years 1715 and 1716 (London: 1717).\n\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\n\nThe hole argument as a prototype for gauge freedom.\n\nIf two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\n\n\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\n\n\nMetric essentialism\n\nMaudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\n\nNon-duality\n\nIt is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\) , then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces – where there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#section",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#section",
    "title": "Hole Argument and Inverted Qualia",
    "section": "",
    "text": "BIB.\n\nhttps://plato.stanford.edu/ENTRIES/spacetime-holearg/\n\nThe hole argument, in Norton’s formulation\n\nGiven two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since\n\nThe two distributions are observationally identical.\nThe laws of the theory cannot pick between the two developments of the fields into the hole.\n\nBut by manifold substantivalism, they represent distinct physical systems.\nTherefore, manifold substantivalism has a problematic metaphysics.\n\n\n\nMacdonald, Alan. “Einstein’s hole argument.” American Journal of Physics 69.2 (2001): 223-225.\n\n\n\nRelationalism\n\nThis is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In a passage that predates the inverted qualia thought experiment, Leibniz imagined the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place – ergo, space is relational, not absolute.\n\nLeibniz’s third paper, in Samuel Clarke, A Collection of Papers, Which passed between the late Learned Mr. Leibnitz, and Dr. Clarke, In the Years 1715 and 1716 (London: 1717).\n\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\n\nThe hole argument as a prototype for gauge freedom.\n\nIf two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\n\n\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\n\n\nMetric essentialism\n\nMaudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\n\nNon-duality\n\nIt is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\) , then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces – where there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#inverted-qualia",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#inverted-qualia",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Inverted qualia",
    "text": "Inverted qualia\n(Byrne 2004)\nThe inverted qualia thought experiment has been used, like the philosophical zombie, in a whole host of arguments. Let’s deal with functionalism, which seems rather urgent these days, what with the advent of AI and all.\nArgument against functionalism\nThe following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.\nThus, the mental does not supervene on functional organization.\nThus, functionalism is false.\nAccording to functionalism, mental states are functional states: states defined by their causal role with respect to inputs, outputs, and other states. So, according to functionalism, necessarily, two creatures who are functionally alike are also mentally alike.\n\nPrecursors to the inverted qualia problem\n(Eastwood 1986)\nAlhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.\n\n\n\nLeonardo da Vinci’s drawings comparing the eye to a camera obscura. From Codex Atlanticus (1490-1495). Figure from Wikimedia Commons.\n\n\n\n… certain extravagant situations are to be avoided, as they would create ‘monstrosities’, or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#color-space",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#color-space",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Color space",
    "text": "Color space\n\nHuman eye structure\nSpectral sensitivity and response\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short).\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is essentially a deterministic function that maps a spectral flux density to three response intensities. Mathematically, it is a function\n\\[C(P) := (I_S(P), I_M(P), I_L(P))\\]\nwith type \\((\\R^+ \\to \\R^+) \\to (\\R^+)^3\\), where \\(\\R^+ = [0, \\infty)\\) is the space of non-negative real numbers.\nThe color space is the range of the function \\(C\\). Because \\(C\\) is a linear functional, color space is a convex cone-shaped subset of \\(\\R^3\\). On the edge of the cone are the pure colors, produced by spectra that are concentrated at just one wavelength. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness.\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the gamut are points of pure spectral colors, from pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.\nFor any three spectra \\(P_1, P_2, P_3\\), we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-hole-argument",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-hole-argument",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The hole argument",
    "text": "The hole argument\n(Norton, Pooley, and Read 1999)\nThe hole argument, in Norton’s formulation\n\nGiven two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since\n\nThe two distributions are observationally identical. The laws of the theory cannot pick between the two developments of the fields into the hole.\nBut by manifold substantivalism, they represent distinct physical systems.\n\nTherefore, manifold substantivalism has a problematic metaphysics.\n\n\nResponses to the hole argument\nRelationalism. This is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In Leibniz’s third paper during the Leibniz–Clarke correspondence (Clarke 1717), Leibniz proposed the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place. Ergo, space is relational, not absolute.\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\nGauge freedom. If two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\nMetric essentialism. Maudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\nNon-duality. It is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\), then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces -\nwhere there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#example-calculation",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#example-calculation",
    "title": "Hole Argument and Inverted Qualia",
    "section": "example calculation",
    "text": "example calculation\nMacdonald, Alan. “Einstein’s hole argument.” American Journal of Physics 69.2 (2001): 223-225."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#responses",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#responses",
    "title": "Hole Argument and Inverted Qualia",
    "section": "responses",
    "text": "responses\nRelationalism\nThis is Einstein’s response, and also the typical response nowadays.\nThis line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In a passage that predates the inverted qualia thought experiment, Leibniz imagined the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place -\nergo, space is relational, not absolute.\nLeibniz’s third paper, in Samuel Clarke, A Collection of Papers, Which passed between the late Learned Mr. Leibnitz, and Dr. Clarke, In the Years 1715 and 1716 (London: 1717).\nWhile God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.\nThe hole argument as a prototype for gauge freedom.\nIf two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.\n\nverifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;\ndeterminism—the laws of the theory are unable to fix the candidate surplus structure.\n\nMetric essentialism\nMaudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.\nNon-duality\nIt is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with \\(\\R^N\\) , then quotienting out smooth deformations.\nThe point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.\nThis is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces -\nwhere there is literally an unchanging substance (a rubber sheet) with changeable property (the strain field)."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#human-eye-structure",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#human-eye-structure",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Human eye structure",
    "text": "Human eye structure\nSpectral sensitivity and response\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short).\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is essentially a deterministic function that maps a spectral flux density to three response intensities. Mathematically, it is a function of type:\n\\[C: (\\R^+ \\to \\R^+) \\to \\R^3\\]\nwhere \\(\\R^+\\) means the space of non-negative real numbers. It is defined by\n\\[C(P) = (I_S(P), I_M(P), I_L(P))\\]\nDefine the color space as the range of the function \\(C\\). Because \\(C\\) is a linear functional, color space is a convex cone-shaped subset of \\(\\R^3\\). On the edge of the cone are the pure colors, produced by spectra that are concentrated at just one wavelength. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#cie-color-spaces",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#cie-color-spaces",
    "title": "Hole Argument and Inverted Qualia",
    "section": "CIE color spaces",
    "text": "CIE color spaces\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the gamut are points of pure spectral colors -\nfrom pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.\nFor any three spectra \\(P_1, P_2, P_3\\), we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.\nSubsequent color spaces are just minor adjustments to ICE 1931.\nIt defines three numbers \\(X, Y, Z\\). It was created before human cone cells were discovered. However, it turns out to be almost exactly a linear transform of \\(I_S, I_M, I_L\\), by \\[\n\\begin{bmatrix}\nX\\\\Y\\\\Z\n\\end{bmatrix}\n=\n\\left[\\begin{aligned}\n  1&.910\\,20 \\!\\!\\!&\\!\\! -1&.112\\,12 \\!\\!\\!&\\!\\! 0&.201\\,91 \\\\\n  0&.370\\,95 \\!\\!\\!&\\!\\!  0&.629\\,05 \\!\\!\\!&\\!\\! 0&         \\\\\n  0&         \\!\\!\\!&\\!\\!  0&         \\!\\!\\!&\\!\\! 1&.000\\,00\n\\end{aligned}\\right]\n\\begin{bmatrix}\nI_L\\\\I_M\\\\I_S\n\\end{bmatrix}\n\\]\nThe color gamut of CIE 1931 is defined by the projective transform\n\\[(x, y, z) := \\left(\\frac{X}{X+Y+Z},\\frac{Y}{X+Y+Z},\\frac{Z}{X+Y+Z}\\right)\\]\nusually plotted over the \\(x+y+z = 1\\) plane.\nThe RGB values required to match 1 unit of energy at each wavelength.\n700, 546.1, and 435.8 nm"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#riemannian-metric",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#riemannian-metric",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Riemannian metric",
    "text": "Riemannian metric\nThe MacAdam ellipses …\n\n\n\nMacAdam ellipses the CIE 1931 \\(xy\\)-diagram, 10× actual size. Figure from Wikimedia Commons.\n\n\n\n\n\n(da Fonseca and Samengo 2016, fig. 8b)\n\n\nFrom the \\(S_S, S_M, S_L\\) curves, we can use information theory to predict the JND in color space.\n(da Fonseca and Samengo 2016) explain ~87% of the variance of human color discrimination ability\nImagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker’s ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization – a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.\nIf the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.\nIf the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.\nNote that, while color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. (Bujack et al. 2022) reported that there is “diminishing returns” in color distances. Color difference might not even be symmetric, meaning that if we ask a subject “How far is color 1 from color 2?” and then ask the opposite direction, we might get a different answer. This reminds me of KL divergence."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#arguments",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#arguments",
    "title": "Hole Argument and Inverted Qualia",
    "section": "arguments",
    "text": "arguments\nThe inverted qualia thought experiment has been used, like p-zombie argument, in a whole host of arguments. Let’s deal with functionalism, which seems rather urgent these days, what with the advent of AI and all.\nArgument against functionalism\nThe following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.\nThus, the mental does not supervene on functional organization.\nThus, functionalism is false.\nAccording to functionalism, mental states are functional states: states defined by their causal role with respect to inputs, outputs, and other states. So, according to functionalism, necessarily, two creatures who are functionally alike are also mentally alike.\nAlhazen, Leonardo, and Late-Medieval Speculation on the Inversion of Images in the Eye (1986)\nAlhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.\n\n\n\nimage.png\n\n\n[File:1490-95 da vinci\ncodex atlanticus.jpg\nWikimedia Commons](https://commons.wikimedia.org/wiki/File:1490-95_da_vinci_-_codex_atlanticus.jpg) - &gt; … certain extravagant situations are to be avoided, as they would create ‘monstrosities’, or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#problem-of-consciousness",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#problem-of-consciousness",
    "title": "Hole Argument and Inverted Qualia",
    "section": "Problem of consciousness",
    "text": "Problem of consciousness\n(Metzinger 2004, chapter TODO; Roden 2015, chap. 4)\nThe just noticeable difference (JND) in color perception possibly shows that we see metric, not colors themselves.\nSo what do those color words do? They might be special “landmarks” in the geometry of color space, much like on a map, the peaks and troughs are local maxima of curvature, and the mountain passes are local minima of curvature (Griffin and Mylonas 2019).\nThe meta-problem of consciousness (Chalmers 2018) is TODO\nThe inverted polarization spectrum for mantis shrimps. Why would they be confused?\n(Kleinlogel and White 2008)\nThe mantis shrimp species Gonodactylus smithii can detect polarization of light over the entire 3-dimensional Poincare sphere. It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.\nNow, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincare sphere is inverted compared to yours? When you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, etc."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#meta-problem-of-consciousness",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#meta-problem-of-consciousness",
    "title": "Hole Argument and Inverted Qualia",
    "section": "meta-problem of consciousness",
    "text": "meta-problem of consciousness\nOn the psychological origins of dualism: Dual-process cognition and the explanatory gap (2012)\nOn the psychological origins of dualism: Dual-process cognition and the explanatory gap (2012) collapsed:: true\nWe have Type 1 and Type 2 cognitive processes for judging if something is conscious.\nType 1 processes\nPicture\n\n\n\nimage.png\n\n\nfast, domain-specific, automatic (the authors don’t argue if they are also associative)\nThree apparent features reliably produce AGENT categorization:\nhas eye-like shapes on a head-like bump;\nreacts to the environment unpredictably;\nmoves on its own, not a slave to mere inertia.\nConfirmed by judgment-speed experiments - &gt; … presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute… Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.\nType 2 processes\nrational deliberation, theory application, or conscious reasoning\nAny brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.\nThe brain doesn’t have eyes\nThe brain seems to do nothing by itself, stewing alone in a dark cave;\nThe brain doesn’t display any motion, let alone non-inertial motion. - &gt; Since the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.\n- &gt; Jenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick & Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious\nAlternative physicalist theory of consciousness designed to satisfy Type 1 process won’t satisfy Type 2 process.\nThe eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.\nAnd lock-in syndrome people don’t interact and don’t display noninertial motions.\nEvolutionary origin of the dual process\nOnly very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.\nThus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.\nThe Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.\n(Non-)Analogies\nThe authors thought that there is no Type 1 intuition for general relativity, so there’s no explanatory gap there. But I beg to differ.\nGeneral Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent “explanatory gap”, as a nagging feeling “but how do we know which one is the real spacetime manifold? The theory is incomplete because it doesn’t tell us that.”.\nThis is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there’s a unique spacetime structure.\nAs another example, Bergson famously debated Einstein over the nature of time.\nIntentionality explanatory gap.\nSome philosophers did propose an explanatory gap.\nAlthough most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.\nThis would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics. -"
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-meta-problem",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-meta-problem",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The meta-problem",
    "text": "The meta-problem\nWe have Type 1 and Type 2 cognitive processes for judging if something is conscious.\nType 1 processes\n(Fiala, Arico, and Nichols 2012)\nfast, domain-specific, automatic (the authors don’t argue if they are also associative)\nThree apparent features reliably produce AGENT categorization:\nhas eye-like shapes on a head-like bump;\nreacts to the environment unpredictably;\nmoves on its own, not a slave to mere inertia.\nConfirmed by judgment-speed experiments\n\n… presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute… Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.\n\nType 2 processes\nrational deliberation, theory application, or conscious reasoning\nAny brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.\nThe brain doesn’t have eyes\nThe brain seems to do nothing by itself, stewing alone in a dark cave;\nThe brain doesn’t display any motion, let alone non-inertial motion.\n\nSince the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.\n\n\nJenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick & Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious\n\nAlternative physicalist theory of consciousness designed to satisfy Type 1 process won’t satisfy Type 2 process.\nThe eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.\nAnd lock-in syndrome people don’t interact and don’t display noninertial motions.\nEvolutionary origin of the dual process\nOnly very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.\nThus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.\nThe Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.\n(Non-)Analogies\nThe authors thought that there is no Type 1 intuition for general relativity, so there’s no explanatory gap there. But I beg to differ.\nGeneral Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent “explanatory gap”, as a nagging feeling “but how do we know which one is the real spacetime manifold? The theory is incomplete because it doesn’t tell us that.”.\nThis is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there’s a unique spacetime structure.\nAs another example, Bergson famously debated Einstein over the nature of time.\nIntentionality explanatory gap.\nSome philosophers did propose an explanatory gap.\nAlthough most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.\nThis would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics."
  },
  {
    "objectID": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-color",
    "href": "blog/posts/hole-argument-inverted-qualia/index.html#the-geometry-of-color",
    "title": "Hole Argument and Inverted Qualia",
    "section": "The geometry of color",
    "text": "The geometry of color\n\nThe manifold of colors\n(Logvinenko 2015)\nSpectral sensitivity and response\n\\[I_L = \\int S_L(\\lambda) R(\\lambda) d\\lambda\\]\n\\(I_L\\) is the response intensity of long-wavelength-type cone cells, in units of neural spike per second.\n\\(R(\\lambda)\\) is the spectral radiance at wavelength \\(\\lambda\\), or spectrum for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).\n\\(S_L\\) is the spectral sensitivity function of the long-type cone cells.\nWe can similarly define \\(I_M, I_S\\), for the other two cone cell types (medium and short). They are approximately bell curves.\n\n\n\nSchematic diagram of human cone cell sensitivity. Each curve is “normalized”, meaning that it is multiplied by a positive real number, so that its maximal value is exactly 1.\n\n\nIf we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is just a deterministic function that maps a spectrum to three real numbers:\n\\[C(P) := (I_S(P), I_M(P), I_L(P))\\]\nwith type \\((\\R^+ \\to \\R^+) \\to (\\R^+)^3\\), where \\(\\R^+ = [0, \\infty)\\) is the space of non-negative real numbers. Define this as the \\((I_S, I_M, I_L)\\) as the neural color space.1 Furthermore, the biochemical limit on neural firing is 1000 Hz (“Neuron Firing Rates in Humans” 2015), thus the neural color space is bounded within a cube.\n1 This seems as close to “sense data” (Hatfield 2021) as it gets in science.Because \\(C\\) is a linear functional, and any two colors can be mixed to give a third color, neural color space is a convex cone. On the tip of the cone is \\((0, 0, 0)\\), the color of pure darkness.\nConsider a wall painted with a “pure reflective” layer, in the sense that it reflects exactly light at wavelength \\(500 \\;\\mathrm{nm}\\), and nothing else. Then, under any illumination, the color of the wall would fall on the same line in neural color space (at least until it saturates the firing rates).\nPure spectral colors are special colors, in the following diagram, on the edge of the cone are lines of pure spectral color, each produced by a spectrum that is concentrated at just one wavelength.\n\n\n\nThe pure spectral colors in neural color space. The rainbow curve represents the spectrum of visible light, from violet to red. Each point on this curve corresponds to a specific wavelength of light and its unique combination of stimulations to the three types of cone cells. For each point on the spectral curve, we can draw a straight line to the origin. Each point on the line has the same color, but appears increasingly bright.\n\n\nBecause the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on \\(\\R^2\\), named the gamut. Mathematically, it is the projective transform: \\[(s, m, l) := \\left(\\frac{I_S}{I_S + I_M + I_L}, \\frac{I_M}{I_S + I_M + I_L}, \\frac{I_L}{I_S + I_M + I_L} \\right)\\]\nThe curving edge of the gamut are points of pure spectral colors, from pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.\n\n\n\n(Schrödinger 1920, fig. 3)\n\n\nFor any three spectra \\(P_1, P_2, P_3\\), we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of \\(C(P_1), C(P_2), C(P_3)\\), which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.\n\n\n\nDifferent depictions of the same color space. Figure from Wikimedia Commons\n\n\n\n\nLinear geometry\nGrassmann, famous for originating linear algebra, studied color theory and applied linear algebra to it. Essentially, he discovered that the human color vision function \\(C\\), defined previously, is a linear function. He discovered this by color-mixing experiments, in the style of 19th century psychophysics. Considering it was 50 years before the neuron doctrine became accepted, and 100 years before cone cells were observed, he did very well.\nFor any three spectra \\(I_1, I_2, I_3\\), we can define their colors as \\(C_i := C(I_i)\\). Since \\(C\\) is a linear function, as long as \\(\\{C_1, C_2, C_3\\}\\) are linearly independent, we can represent any color as \\(C(x_1 I_1 + x_2 I_2 + x_3 I_3)\\) for some \\((x_1, x_2, x_3) \\in \\R^3\\).\nFor example, we can go to a scientific standard shop and buy a set of standard lamps, which when plugged into a standard plug, viewed in a standard room, at a standard distance and a standard angle, by a standard observer,2 will create a standard red, a standard green, and a standard blue. Then, using opaque to cover up parts of the lamp, and combining the lights, we can create any color \\(C(x_1 I_1 + x_2 I_2 + x_3 I_3)\\), for any \\((x_1, x_2, x_3) \\in [0, 1]^3\\). By buying more lamps, we can create all colors with \\((x_1, x_2, x_3) \\in (\\R^+)^3\\).\n2 Because humans are resistant to standardization, the standard observer is obtained by taking data from real observers in good health that are physiologically similar, and their average. The methodology resembles l’homme moyen (“the average man”) of Adolphe Quetelet, a fanatic for anthropometry. Also, the standard observer is not required to drink standard cups of tea.Here, we notice a difficulty: we can’t take a negative amount of lamp. Fortunately, we can bypass the difficulty by adding a fourth lamp, a “standard white” lamp emitting a spectrum \\(I_0\\). Then, for any other spectrum \\(I\\), there exists \\((x_1, x_2, x_3, x_4) \\in (\\R^+)^4\\), such that\n\\[\nC(I) + C(x_0 I_0) = C(x_1 I_1 + x_2 I_2 + x_3 I_3)\n\\]\nwhich allows us to place the color of \\(I\\) at the unique point. Of course, the choice of \\((x_1, x_2, x_3, x_4)\\) is not unique. However, since color space is linear, the sum \\(C(x_1 I_1 + x_2 I_2 + x_3 I_3 - x_0 I_0)\\) is unique. Once \\(C(I_0)\\) is itself constructed as a linear sum of \\(C(\\sum_{i=1}^3 x_{i0}I_i)\\), we would have located \\(C(I)\\) in color space.\nThis is essentially the state of the art of colorimetry in 1931, when CIE 1931 was constructed by color-mixing experiments. An observer is seated in a standard room, and sees two light sources. On the left, a to-be-measured light \\(I\\) is mixed with a standard white light \\(I_0\\), and on the right, are three standard blue, green, red lights \\(I_1, I_2, I_3\\). The observer turns the 4 knobs until two sides look indistinguishable. This was repeated for many observers, over many days, for many light sources. The result is a table with three columns, and many rows. Each row is an industrially important light source, and the three columns are the standard red, standard green, standard blue. It schematically looks like this (I made up the data):\n\n\n\ncolor\nstandard red\nstandard green\nstandard blue\n\n\n\n\nstandard red\n1.000\n0.000\n0.000\n\n\nstandard green\n0.000\n1.000\n0.000\n\n\nstandard blue\n0.000\n0.000\n1.000\n\n\nstandard white\n0.334\n0.334\n0.332\n\n\n…\n…\n…\n…\n\n\n\n\n\n\n\n\n\nTechnically\n\n\n\nTechnically, the CIE 1931 color of a spectrum \\(I\\) is a point in \\(\\R^3\\) defined by\n\\[\nC_{\\text{CIE 1931}}(I) := \\left(\\int I(\\lambda) \\bar r(\\lambda) d\\lambda , \\int I(\\lambda) \\bar g(\\lambda) d\\lambda , \\int I(\\lambda) \\bar b(\\lambda) d\\lambda \\right)\n\\]\nwhere \\(\\bar r, \\bar g, \\bar b\\) are “standard observer color matching functions”. They are not any real observer’s sensitivities, because they have negative values. Note that this means the CIE 1931 coordinates of standard red is not \\((1, 0, 0)\\).\nOf course, the two definitions had better agree. This they tried to do so, using the spectroscopy of the time.\n\n\n\n\nRiemannian geometry\n\nMagnitude-notions are only possible where there is an antecedent general notion which admits of different specialisations… the only simple notions whose specialisations form a multiply extended manifoldness are the positions of perceived objects and colours. More frequent occasions for the creation and development of these notions occur first in the higher mathematic.\nRiemann’s Habilitation dissertation, 1854 (Riemann 2016)\n\nThe MacAdam ellipses …\n… of course, since color space is 3D, we really should be concerned with MacAdam ellipsoids. However, those are hard to map and hard to plot.\n\n\n\nMacAdam ellipses the CIE 1931 \\(xy\\)-diagram, 10× actual size. Figure from Wikimedia Commons.\n\n\n\n\n\n(da Fonseca and Samengo 2016, fig. 8b)\n\n\nFrom the \\(S_S, S_M, S_L\\) curves, we can use information theory to predict the JND in color space.\nCIELAB color space is a smooth mapping from CIE 1931 color space to \\(\\R^3\\), such that the MacAdam ellipses are stretched roughly spherical, meaning the metric is mostly Euclidean. This is impossible to do perfectly, as color space is curved, in the same sense that a space containing a black hole is curved. However, since color space is not too curved, the CIELAB color space can be treated as Euclidean in practice.\n(da Fonseca and Samengo 2016) explain ~87% of the variance of human color discrimination ability\nImagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker’s ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization – a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.\nIf the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.\nIf the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.\nNote that, while color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. (Bujack et al. 2022) reported that there is “diminishing returns” in color distances.3\n3 According to CIE, the color difference \\(\\Delta E\\), is not symmetric, meaning that if we ask a subject “How far is color 1 from color 2?” and then ask the opposite direction, we usually get a different answer. This reminds me of KL divergence. I don’t know if anyone has studied this in detail, but it ought to interest the information geometers.\n\n\nAll visible colors, plotted in CIELAB color space. Figure from Wikimedia Commons"
  }
]
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2023-09-01">
<meta name="description" content="Toy model of grokking: tiny neural networks learn modular arithmetics after it has already reached full correctness on the training set.">

<title>Yuxi on the Wired - Grokking modular arithmetics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta property="og:title" content="Yuxi on the Wired - Grokking modular arithmetics">
<meta property="og:description" content="Toy model of grokking: tiny neural networks learn modular arithmetics after it has already reached full correctness on the training set.">
<meta property="og:image" content="https://yuxi-liu-wired.github.io/blog/posts/grokking-modular-arithmetics/figure/network.png">
<meta property="og:site-name" content="Yuxi on the Wired">
<meta property="og:image:height" content="493">
<meta property="og:image:width" content="491">
<meta name="twitter:title" content="Yuxi on the Wired - Grokking modular arithmetics">
<meta name="twitter:description" content="Toy model of grokking: tiny neural networks learn modular arithmetics after it has already reached full correctness on the training set.">
<meta name="twitter:image" content="https://yuxi-liu-wired.github.io/blog/posts/grokking-modular-arithmetics/figure/network.png">
<meta name="twitter:image-height" content="493">
<meta name="twitter:image-width" content="491">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html" rel="" target="">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://bair.berkeley.edu/" rel="" target=""><i class="bi bi-folder-symlink" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi.liu.1995@gmail.com" rel="" target=""><i class="bi bi-envelope" role="img" aria-label="email">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Grokking modular arithmetics</h1>
                  <div>
        <div class="description">
          Toy model of grokking: tiny neural networks learn modular arithmetics after it has already reached full correctness on the training set.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">interpretation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 1, 2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">March 5, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#grokking" id="toc-grokking" class="nav-link" data-scroll-target="#grokking">Grokking</a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation</a></li>
  <li><a href="#the-null-hypothesis" id="toc-the-null-hypothesis" class="nav-link" data-scroll-target="#the-null-hypothesis">The null hypothesis</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions">Extensions</a></li>
  </ul></li>
  <li><a href="#some-other-quotes" id="toc-some-other-quotes" class="nav-link" data-scroll-target="#some-other-quotes">Some other quotes</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<p><small>This essay reproduces the paper <a href="https://openreview.net/forum?id=0ZUKLCxwBo">A simple and interpretable model of grokking modular arithmetic tasks</a> <span class="citation" data-cites="TODO">(<a href="#ref-TODO" role="doc-biblioref"><strong>TODO?</strong></a>)</span>. The code is available on GitHub at <a href="https://github.com/yuxi-liu-wired/grokking-modular-arithmetics"><code>yuxi-liu-wired/grokking-modular-arithmetics</code></a>.</small></p>
<section id="setup" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>Given a natural number <span class="math inline">\(N\)</span>, we have modular arithmetic on <span class="math inline">\(\mathbb Z_N = \{0, 1, ..., N-1\}\)</span>. For example, <span class="math inline">\(\mathbb Z_{12}\)</span> is the “clock face modular arithmetic”. The problem for our neural network is to learn binary functions on <span class="math inline">\(\mathbb Z_N\)</span>. That is, we are to learn a binary function <span class="math inline">\(f: \mathbb Z_N\times \mathbb Z_N \to \mathbb Z_N\)</span>.</p>
<p>Each such binary function can be exactly specified by a <span class="math inline">\(N\times N\)</span> table, so there are <span class="math inline">\(N^{N^2}\)</span> possible such functions. Most of them are completely random and uninteresting, both for us and for neural networks, but a few are very interesting, and modular addition is one such interesting function.</p>
<p>For example, modular addition on <span class="math inline">\(\mathbb Z_6\)</span> has the following multiplicative table:</p>
<table class="table">
<thead>
<tr class="header">
<th>+</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>3</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>0</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="odd">
<td>4</td>
<td>4</td>
<td>5</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr class="even">
<td>5</td>
<td>5</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>Since the entire dataset is known and specified in advance, we can define the train set ratio <span class="math inline">\(\alpha = \frac{|D_{train}|}{|D|}\)</span>, where <span class="math inline">\(D\)</span> is the full dataset (the multiplication table), and <span class="math inline">\(D_{train}\)</span> is the training dataset. We expect that, as <span class="math inline">\(\alpha\)</span> approaches <span class="math inline">\(1\)</span>, the network becomes better at generalizing to the test set.</p>
<p>The network architecture we use has 3 layers:</p>
<ul>
<li>Input is <span class="math inline">\(x = [x^{(1)}, x^{(2)}]\)</span>. Both <span class="math inline">\(x^{(1)}, x^{(2)} \in \mathbb R^N\)</span> are one-hot encodings of <span class="math inline">\(\mathbb Z_N\)</span>.</li>
<li>Hidden layer activation is <span class="math inline">\(z = \phi(\frac{1}{\sqrt M} W^{(1)}z)\)</span>, where <span class="math inline">\(\phi\)</span> is the activation function. Here <span class="math inline">\(z \in \mathbb R^M\)</span> can be of any width.</li>
<li>Output is <span class="math inline">\(y = \frac 1N W^{(2)}z\)</span>, where <span class="math inline">\(y \in \mathbb R^N\)</span> should be a one-hot encoding of <span class="math inline">\(\mathbb Z_N\)</span>.</li>
<li>All entries of <span class="math inline">\(W^{(1)}, W^{(2)} \sim \mathcal N(0, 1)\)</span> are initialized as standard gaussians.</li>
<li><span class="math inline">\(W^{(1)}, W^{(2)}\)</span> are all the parameters of the network. There is no bias. Thus the network has <span class="math inline">\(3MN\)</span> parameters in total.</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/network.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">An example network with the given architecture, with <span class="math inline">\(N=3, M = 10\)</span>.</figcaption>
</figure>
</div>
<p>In the paper, Gromov found that grokking occurs under different choices of activation functions <span class="math inline">\(\phi\)</span>, different training methods (SGD, Adam, etc), and different training set ratio <span class="math inline">\(\alpha\)</span>.</p>
<p>The simplest example where grokking occurs is with</p>
<ul>
<li>Quadratic activation function: <span class="math inline">\(\phi(t) = t^2\)</span>.</li>
<li>Full-batch gradient descent.</li>
<li>MSE loss.</li>
</ul>
<p>I used AdamW optimizer instead of standard gradient descent, since it converges faster. The dataset is formatted as an array of triples of form <span class="math inline">\((x_1, x_2, y)\)</span>, interpreted as <span class="math inline">\(x_1 + x_2 = y \mod N\)</span>. I split the dataset randomly into two datasets.</p>
</section>
<section id="results" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="grokking" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="grokking">Grokking</h3>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/learning curves.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Learning curves showing grokking.</figcaption>
</figure>
</div>
<p>Some observations:</p>
<ul>
<li>The test set accuracy curve <em>decreases</em> as train set accuracy increases to perfection.</li>
<li>The test set accuracy curves rises only after train set accuracy is perfect. First slowly, then rapidly (“grokking”). This can be quite puzzling, since if the network has really achieved perfection on the training set, then there is nothing left to learn, and so it shouldn’t be able to improve any further – and yet it does improve.</li>
<li>Perfect accuracy on train set is reached at epoch 10x that of train set.</li>
<li>The learning curves shows something smoother, but also something interesting: the train loss decreases monotonically, but the test loss rises, then decreases.</li>
<li>For a while, test loss rose <em>while</em> test accuracy increased!</li>
</ul>
<p>Some lessons:</p>
<ul>
<li>Grokking might look less dramatic when plotted not by argmax-accuracy, but by MSE.
<ul>
<li>See for example <a href="https://arxiv.org/abs/2201.02177">[2201.02177] Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets</a> <span class="citation" data-cites="TODO">(<a href="#ref-TODO" role="doc-biblioref"><strong>TODO?</strong></a>)</span>. One wonders what they would have found if they had plotted MSE losses instead of accuracies?</li>
<li><a href="https://arxiv.org/abs/2301.05217">[2301.05217] Progress measures for grokking via mechanistic interpretability</a> <span class="citation" data-cites="TODO">(<a href="#ref-TODO" role="doc-biblioref"><strong>TODO?</strong></a>)</span> does plot train and test loss, and in this paper, the grokking appears in the loss curves as well. This seems harder to understand using our small model (they used a Transformer).</li>
</ul></li>
<li>Train loss can decrease while test loss increase, but this trend can also be reversed. The shape of learning curves is quite complex.</li>
</ul>
</section>
<section id="interpretation" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="interpretation">Interpretation</h3>
<p>Since the neural network is so small, we can interpret it. What kind of neural network did we end up, that could do modular addition?</p>
<p>Directly inspecting the weight matrices, we notice suggestive wavy bands that resemble sine waves.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/weights ordered by frequency_unsorted.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">The weight matrices.</figcaption>
</figure>
</div>
<p>Let’s sort them according to frequency, as found by running a Fourier transform and picking the highest peak:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/weights ordered by frequency.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">The weight matrices, with columns ordered by frequency.</figcaption>
</figure>
</div>
<p>We see that the learned neural network is probably doing some Fourier transform. This can be confirmed by plotting the activation map on every hidden neuron. Specifically, for each hidden neuron, we can calculate its activation upon each of the <span class="math inline">\(N\times N\)</span> possible inputs. THis is plotted as a heatmap with <span class="math inline">\(N\times N\)</span> pixels. We then get one heatmap per hidden neuron, and display all of them in a grid:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/activation maps.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">The activation pattern of neurons in the hidden layer as one scans through all possible inputs.</figcaption>
</figure>
</div>
<p>We see that the network has learned some sine waves. It seems to be a robust fact that networks trained to do modular arithmetics, with one-hot encoding, learns to use trigonometry for this task. (the use of one-hot encoding seems very relevant, as <a href="https://www.lesswrong.com/posts/tdENX8dzdro8PXAzP/short-remark-on-the-subjective-mathematical-naturalness-of">noted here</a>).</p>
</section>
<section id="the-null-hypothesis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-null-hypothesis">The null hypothesis</h3>
<p>As a good comparison with the above interpretation of the neural network, we leverage the same tools on the “null hypothesis”. There are two ways to do the null hypothesis: either initialize the neural network randomly and then interpret it, or initialize it, train it to perform a randomly generated binary operation, then interpret it.</p>
<p>As one would expect, the neural network can successfully memorize arbitrary binary operations, without generalization (as there is no pattern to generalize).</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/learning curves_random.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Learning curves for a neural network trained on a randomly initialized binary operation.</figcaption>
</figure>
</div>
<p>For both null hypotheses, I tried interpreting them using the same methodology, they look as well as one might have expected: complete noise.</p>
<div id="fig-noisy-network" class="quarto-layout-panel page-columns page-full">
<p></p><figcaption>Figure&nbsp;1: The network randomly initialized.</figcaption><p></p>
<figure class="figure page-columns page-full">
<div class="quarto-layout-row quarto-layout-valign-top page-columns page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/activation maps_null.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Activation maps.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/weights ordered by frequency_null.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Weight matrices.</figcaption>
</figure>
</div>
</div>
</div>
</figure>
</div>
<div id="fig-random-operation-network" class="quarto-layout-panel page-columns page-full">
<p></p><figcaption>Figure&nbsp;2: The network trained to perform a randomly initialized binary operation.</figcaption><p></p>
<figure class="figure page-columns page-full">
<div class="quarto-layout-row quarto-layout-valign-top page-columns page-full">
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/activation maps_random.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Activation maps.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/weights ordered by frequency_random.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Weight matrices.</figcaption>
</figure>
</div>
</div>
</div>
</figure>
</div>
</section>
<section id="extensions" class="level3">
<h3 class="anchored" data-anchor-id="extensions">Extensions</h3>
<p>This toy is small and simple. It runs in a minute. Here are some ideas for playing with the toy:</p>
<ul>
<li>Modular multiplication.</li>
<li>Random operation (as a null hypothesis).</li>
<li>Different activation functions (sine, ReLU).</li>
<li>Different accelerators (SGD, Adam, etc)</li>
<li>Two hidden layers.</li>
</ul>
</section>
</section>
<section id="some-other-quotes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="some-other-quotes">Some other quotes</h2>
<p><a href="https://arxiv.org/abs/2301.02679">[2301.02679] Grokking modular arithmetic</a></p>
<blockquote class="blockquote">
<p>In particular, random feature models such as infinitely-wide neural networks (in the NTK regime) do not exhibit grokking, at least on the tasks that involve modular functions.</p>
<p>In our minimal setup, the simplest explanation for grokking is that once training loss reached a certain value, the only way to further minimize it is to start learning the right features.</p>
</blockquote>
<p><a href="https://arxiv.org/pdf/2004.07780.pdf">Geirhos, Robert, et al.&nbsp;“Shortcut learning in deep neural networks.” Nature Machine Intelligence 2.11 (2020): 665-673.</a> <span class="citation" data-cites="TODO">(<a href="#ref-TODO" role="doc-biblioref"><strong>TODO?</strong></a>)</span></p>
<blockquote class="blockquote">
<p>many of deep learning’s failures can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in comparative psychology, education and linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/taxonomy_decision_rules.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure 3 from <span class="citation" data-cites="TODO">(<a href="#ref-TODO" role="doc-biblioref"><strong>TODO?</strong></a>)</span></figcaption>
</figure>
</div>
<p><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson <span class="citation" data-cites="suttonBitterLesson2019">(<span>Sutton 2019</span>)</span></a></p>
<blockquote class="blockquote">
<p>One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.</p>
</blockquote>
<p><a href="https://gwern.net/scaling-hypothesis#why-does-pretraining-work">The Scaling Hypothesis # Why Does Pretraining Work?</a></p>
<blockquote class="blockquote">
<p>Early on in training, a model learns the crudest levels: that some letters like ‘e’ are more frequent than others like ‘z’, that every 5 characters or so there is a space, and so on. It goes from predicted uniformly-distributed bytes to what looks like Base-60 encoding—alphanumeric gibberish. As crude as this may be, it’s enough to make quite a bit of absolute progress: a random predictor needs 8 bits to ‘predict’ a byte/character, but just by at least matching letter and space frequencies, it can almost halve its error to around 5 bits…</p>
<p>… a sample will state that someone is “alive” and then 10 sentences later, use the word “dead”, or it will digress into an irrelevant argument instead of the expected next argument, or someone will do something physically improbable, or it may just continue for a while without seeming to get anywhere.All of these errors are far less than &lt;0.02 bits per character; we are now talking not hundredths of bits per characters but less than ten-thousandths.The pretraining thesis argues that this can go even further: we can compare this performance directly with humans doing the same objective task, who can achieve closer to 0.7 bits per character. What is in that missing &gt;0.4?</p>
<p>The last bits are deepest. The implication here is that the final few bits are the most valuable bits, which require the most of what we think of as intelligence.</p>
</blockquote>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-suttonBitterLesson2019" class="csl-entry" role="listitem">
Sutton, Richard. 2019. <span>“The <span>Bitter Lesson</span>.”</span>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left"><span class="faux-block">Everything ©<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache License 2.0</a></span></div>   
    <div class="nav-footer-center"><span class="faux-block">Yuxi on the Wired</span></div>
    <div class="nav-footer-right"><span class="faux-block"><a href="../../../sitemap.xml">sitemap</a></span></div>
  </div>
</footer>



</body></html>
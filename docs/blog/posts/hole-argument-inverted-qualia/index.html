<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2023-11-01">
<meta name="description" content="TODO description.">

<title>Yuxi on the Wired - Hole Argument and Inverted Qualia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Yuxi on the Wired - Hole Argument and Inverted Qualia">
<meta property="og:description" content="TODO description.">
<meta property="og:image" content="https://yuxi-liu-wired.github.io/blog/posts/hole-argument-inverted-qualia/img/blog icon.jpg">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta name="twitter:title" content="Yuxi on the Wired - Hole Argument and Inverted Qualia">
<meta name="twitter:description" content="TODO description.">
<meta name="twitter:image" content="https://yuxi-liu-wired.github.io/blog/posts/hole-argument-inverted-qualia/img/blog icon.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.qmd"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.qmd"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://bair.berkeley.edu/"> <i class="bi bi-folder-symlink" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi.liu.1995@gmail.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Hole Argument and Inverted Qualia</h1>
                  <div>
        <div class="description">
          TODO description.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">fun</div>
                <div class="quarto-category">philosophy</div>
                <div class="quarto-category">math</div>
                <div class="quarto-category">physics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 1, 2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 20, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-hole-argument" id="toc-the-hole-argument" class="nav-link" data-scroll-target="#the-hole-argument">The hole argument</a>
  <ul class="collapse">
  <li><a href="#responses-to-the-hole-argument" id="toc-responses-to-the-hole-argument" class="nav-link" data-scroll-target="#responses-to-the-hole-argument">Responses to the hole argument</a></li>
  </ul></li>
  <li><a href="#the-geometry-of-color" id="toc-the-geometry-of-color" class="nav-link" data-scroll-target="#the-geometry-of-color">The geometry of color</a>
  <ul class="collapse">
  <li><a href="#the-manifold-of-colors" id="toc-the-manifold-of-colors" class="nav-link" data-scroll-target="#the-manifold-of-colors">The manifold of colors</a></li>
  <li><a href="#linear-geometry" id="toc-linear-geometry" class="nav-link" data-scroll-target="#linear-geometry">Linear geometry</a></li>
  <li><a href="#riemannian-geometry" id="toc-riemannian-geometry" class="nav-link" data-scroll-target="#riemannian-geometry">Riemannian geometry</a></li>
  </ul></li>
  <li><a href="#inverted-qualia" id="toc-inverted-qualia" class="nav-link" data-scroll-target="#inverted-qualia">Inverted qualia</a>
  <ul class="collapse">
  <li><a href="#precursors-to-the-inverted-qualia-problem" id="toc-precursors-to-the-inverted-qualia-problem" class="nav-link" data-scroll-target="#precursors-to-the-inverted-qualia-problem">Precursors to the inverted qualia problem</a></li>
  </ul></li>
  <li><a href="#problem-of-consciousness" id="toc-problem-of-consciousness" class="nav-link" data-scroll-target="#problem-of-consciousness">Problem of consciousness</a></li>
  <li><a href="#the-meta-problem" id="toc-the-meta-problem" class="nav-link" data-scroll-target="#the-meta-problem">The meta-problem</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
</section>
<section id="the-hole-argument" class="level2">
<h2 class="anchored" data-anchor-id="the-hole-argument">The hole argument</h2>
<p><span class="citation" data-cites="nortonHoleArgument1999">(<a href="#ref-nortonHoleArgument1999" role="doc-biblioref">Norton, Pooley, and Read 1999</a>)</span></p>
<p>The hole argument, in Norton’s formulation</p>
<ul>
<li>Given two distributions of metric and material fields, related by a hole transformation, they are indeterminant by both observation and theory, since
<ul>
<li>The two distributions are observationally identical. The laws of the theory cannot pick between the two developments of the fields into the hole.</li>
<li>But by manifold substantivalism, they represent distinct physical systems.</li>
</ul></li>
<li>Therefore, manifold substantivalism has a problematic metaphysics.</li>
</ul>
<section id="responses-to-the-hole-argument" class="level3">
<h3 class="anchored" data-anchor-id="responses-to-the-hole-argument">Responses to the hole argument</h3>
<p><strong>Relationalism</strong>. This is Einstein’s response, and also the typical response nowadays.</p>
<p>This line of thought can be traced back to Leibniz’s theory of relative space against Newton’s theory of absolute space. In Leibniz’s third paper during the <a href="https://en.wikipedia.org/wiki/Leibniz%E2%80%93Clarke_correspondence">Leibniz–Clarke correspondence</a> <span class="citation" data-cites="clarkeCollectionPapersWhich1717">(<a href="#ref-clarkeCollectionPapersWhich1717" role="doc-biblioref">Clarke 1717</a>)</span>, Leibniz proposed the “inverted space” thought experiment: Suppose at the moment of creation, God were to switch between East and West, nothing would act different. Since God must have created the world according to the principle of sufficient reason, God must have had no such degree of freedom in the first place. Ergo, space is relational, not absolute.</p>
<p>While God or the principle of sufficient reason is no longer so assured, Leibniz’s thought experiment remains potent.</p>
<p><strong>Gauge freedom</strong>. If two criteria are true, then it is a gauge freedom, and indeterminancy in it is no longer an issue.</p>
<ol type="i">
<li><p>verifiability—changes in the candidate surplus structure make no difference to what can be verified in observation;</p></li>
<li><p>determinism—the laws of the theory are unable to fix the candidate surplus structure.</p></li>
</ol>
<p><strong>Metric essentialism</strong>. Maudlin (1990) urges that each spacetime event carries its metrical properties essentially; that is, it would not be that very event if (after redistribution of the fields) we tried to assign different metrical properties to it.</p>
<p><strong>Non-duality</strong>. It is quite possible to regard smooth manifold as derivative, and Riemannian manifold as original. Indeed, we may construct a smooth manifold by starting with <span class="math inline">\(\R^N\)</span>, then quotienting out smooth deformations.</p>
<p>The point is this: mathematically speaking, there is no necessary division between substance and property, though it is a very useful intuition. Physically speaking, the division has led to errors, such as Einstein’s failed 1914 attempt at non-relativistic theory of gravity.</p>
<p>This is especially true in the case of general relativity, because it developed from 19th century differential geometry, which tended to be understood as about geometry of deformable surfaces -</p>
<p>where there is literally an unchanging <em>substance</em> (a rubber sheet) with changeable <em>property</em> (the strain field).</p>
</section>
</section>
<section id="the-geometry-of-color" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-geometry-of-color">The geometry of color</h2>
<section id="the-manifold-of-colors" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-manifold-of-colors">The manifold of colors</h3>
<p><span class="citation" data-cites="logvinenkoGeometricStructureColor2015">(<a href="#ref-logvinenkoGeometricStructureColor2015" role="doc-biblioref">Logvinenko 2015</a>)</span></p>
<p>Spectral sensitivity and response</p>
<p><span class="math display">\[I_L = \int S_L(\lambda) R(\lambda) d\lambda\]</span></p>
<p><span class="math inline">\(I_L\)</span> is the <strong>response intensity</strong> of long-wavelength-type cone cells, in units of neural spike per second.</p>
<p><span class="math inline">\(R(\lambda)\)</span> is the spectral radiance at wavelength <span class="math inline">\(\lambda\)</span>, or <strong>spectrum</strong> for short. It has units of watt per square-nanometer (of retinal area) per nanometer (of wavelength).</p>
<p><span class="math inline">\(S_L\)</span> is the <strong>spectral sensitivity</strong> function of the long-type cone cells.</p>
<p>We can similarly define <span class="math inline">\(I_M, I_S\)</span>, for the other two cone cell types (medium and short). They are approximately bell curves.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/cone_cell_sensitivity.svg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Schematic diagram of human cone cell sensitivity. Each curve is “normalized”, meaning that it is multiplied by a positive real number, so that its maximal value is exactly 1.</figcaption>
</figure>
</div>
<p>If we ignore the rod cells, and assume no adaptation to darkness (“scotopic vision”), then human color vision is just a deterministic function that maps a spectrum to three real numbers:</p>
<p><span class="math display">\[C(P) := (I_S(P), I_M(P), I_L(P))\]</span></p>
<p>with type <span class="math inline">\((\R^+ \to \R^+) \to (\R^+)^3\)</span>, where <span class="math inline">\(\R^+ = [0, \infty)\)</span> is the space of non-negative real numbers. Define this as the <span class="math inline">\((I_S, I_M, I_L)\)</span> as the <strong>neural color space</strong>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Furthermore, the biochemical limit on neural firing is 1000 Hz <span class="citation" data-cites="NeuronFiringRates2015">(<a href="#ref-NeuronFiringRates2015" role="doc-biblioref"><span>“Neuron Firing Rates in Humans”</span> 2015</a>)</span>, thus the neural color space is bounded within a cube.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;This seems as close to “sense data” <span class="citation" data-cites="hatfieldSenseData2021">(<a href="#ref-hatfieldSenseData2021" role="doc-biblioref">Hatfield 2021</a>)</span> as it gets in science.</p></div></div><p>Because <span class="math inline">\(C\)</span> is a linear functional, and any two colors can be mixed to give a third color, neural color space is a convex cone. On the tip of the cone is <span class="math inline">\((0, 0, 0)\)</span>, the color of pure darkness.</p>
<p>Consider a wall painted with a “pure reflective” layer, in the sense that it reflects exactly light at wavelength <span class="math inline">\(500 \;\mathrm{nm}\)</span>, and nothing else. Then, under any illumination, the color of the wall would fall on the same line in neural color space (at least until it saturates the firing rates).</p>
<p>Pure spectral colors are special colors, in the following diagram, on the edge of the cone are lines of pure spectral color, each produced by a spectrum that is concentrated at just one wavelength.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/neural_color_space_3d.svg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The pure spectral colors in neural color space. The rainbow curve represents the spectrum of visible light, from violet to red. Each point on this curve corresponds to a specific wavelength of light and its unique combination of stimulations to the three types of cone cells. For each point on the spectral curve, we can draw a straight line to the origin. Each point on the line has the same color, but appears increasingly bright.</figcaption>
</figure>
</div>
<p>Because the cone shape is uninteresting, the color space is typically represented by chopping off the cone midway, producing a roughly horseshoe-shaped region on <span class="math inline">\(\R^2\)</span>, named the <strong>gamut</strong>. Mathematically, it is the projective transform: <span class="math display">\[(s, m, l) := \left(\frac{I_S}{I_S + I_M + I_L}, \frac{I_M}{I_S + I_M + I_L}, \frac{I_L}{I_S + I_M + I_L} \right)\]</span></p>
<p>The curving edge of the gamut are points of pure spectral colors, from pure 700 nm line on the red end, to the pure 400 nm line on the purple end. Every point inside the gamut can be mixed by two pure spectral colors.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/schrodinger_1920_spektralkegel.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="schrodingerGrundlinienTheorieFarbenmetrik1920">(<a href="#ref-schrodingerGrundlinienTheorieFarbenmetrik1920" role="doc-biblioref">Schrödinger 1920, fig. 3</a>)</span></figcaption>
</figure>
</div>
<p>For any three spectra <span class="math inline">\(P_1, P_2, P_3\)</span>, we can take any convex sum, and create a mixed color. The space of all colors created by their convex sum is the convex sum of <span class="math inline">\(C(P_1), C(P_2), C(P_3)\)</span>, which looks like a triangular cone. It intersects the gamut at a triangle. Every color inside the triangle can be created by mixing the three spectra, but any color outside cannot.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Color_solid_comparison_hsl_hsv_cube_cylinder_cone.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Different depictions of the same color space. Figure from <a href="https://commons.wikimedia.org/wiki/File:Color_solid_comparison_hsl_hsv_cube_cylinder_cone.png">Wikimedia Commons</a></figcaption>
</figure>
</div>
</section>
<section id="linear-geometry" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="linear-geometry">Linear geometry</h3>
<p>Grassmann, famous for originating linear algebra, studied color theory and applied linear algebra to it. Essentially, he discovered that the human color vision function <span class="math inline">\(C\)</span>, defined previously, is a linear function. He discovered this by color-mixing experiments, in the style of 19th century psychophysics. Considering it was 50 years before the <a href="https://en.wikipedia.org/wiki/Neuron_doctrine">neuron doctrine</a> became accepted, and 100 years before cone cells were observed, he did very well.</p>
<p>For any three spectra <span class="math inline">\(I_1, I_2, I_3\)</span>, we can define their colors as <span class="math inline">\(C_i := C(I_i)\)</span>. Since <span class="math inline">\(C\)</span> is a linear function, as long as <span class="math inline">\(\{C_1, C_2, C_3\}\)</span> are linearly independent, we can represent any color as <span class="math inline">\(C(x_1 I_1 + x_2 I_2 + x_3 I_3)\)</span> for some <span class="math inline">\((x_1, x_2, x_3) \in \R^3\)</span>.</p>
<p>For example, we can go to a scientific standard shop and buy a set of standard lamps, which when plugged into a standard plug, viewed in a standard room, at a standard distance and a standard angle, by a standard observer,<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> will create a standard red, a standard green, and a standard blue. Then, using opaque to cover up parts of the lamp, and combining the lights, we can create any color <span class="math inline">\(C(x_1 I_1 + x_2 I_2 + x_3 I_3)\)</span>, for any <span class="math inline">\((x_1, x_2, x_3) \in [0, 1]^3\)</span>. By buying more lamps, we can create all colors with <span class="math inline">\((x_1, x_2, x_3) \in (\R^+)^3\)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Because humans are resistant to standardization, the standard observer is obtained by taking data from real observers in good health that are physiologically similar, and their average. The methodology resembles <em>l’homme moyen</em> (“the average man”) of <a href="https://en.wikipedia.org/wiki/Adolphe_Quetelet">Adolphe Quetelet</a>, a fanatic for anthropometry. Also, the standard observer is not required to drink <a href="https://en.wikipedia.org/wiki/ISO_3103">standard cups of tea</a>.</p></div></div><p>Here, we notice a difficulty: we can’t take a negative amount of lamp. Fortunately, we can bypass the difficulty by adding a fourth lamp, a “standard white” lamp emitting a spectrum <span class="math inline">\(I_0\)</span>. Then, for any other spectrum <span class="math inline">\(I\)</span>, there exists <span class="math inline">\((x_1, x_2, x_3, x_4) \in (\R^+)^4\)</span>, such that</p>
<p><span class="math display">\[
C(I) + C(x_0 I_0) = C(x_1 I_1 + x_2 I_2 + x_3 I_3)
\]</span></p>
<p>which allows us to place the color of <span class="math inline">\(I\)</span> at the unique point. Of course, the choice of <span class="math inline">\((x_1, x_2, x_3, x_4)\)</span> is not unique. However, since color space is linear, the sum <span class="math inline">\(C(x_1 I_1 + x_2 I_2 + x_3 I_3 - x_0 I_0)\)</span> is unique. Once <span class="math inline">\(C(I_0)\)</span> is itself constructed as a linear sum of <span class="math inline">\(C(\sum_{i=1}^3 x_{i0}I_i)\)</span>, we would have located <span class="math inline">\(C(I)\)</span> in color space.</p>
<p>This is essentially the state of the art of colorimetry in 1931, when CIE 1931 was constructed by color-mixing experiments. An observer is seated in a standard room, and sees two light sources. On the left, a to-be-measured light <span class="math inline">\(I\)</span> is mixed with a standard white light <span class="math inline">\(I_0\)</span>, and on the right, are three standard blue, green, red lights <span class="math inline">\(I_1, I_2, I_3\)</span>. The observer turns the 4 knobs until two sides look indistinguishable. This was repeated for many observers, over many days, for many light sources. The result is a table with three columns, and many rows. Each row is an industrially important light source, and the three columns are the standard red, standard green, standard blue. It schematically looks like this (I made up the data):</p>
<table class="table">
<thead>
<tr class="header">
<th>color</th>
<th>standard red</th>
<th>standard green</th>
<th>standard blue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>standard red</td>
<td>1.000</td>
<td>0.000</td>
<td>0.000</td>
</tr>
<tr class="even">
<td>standard green</td>
<td>0.000</td>
<td>1.000</td>
<td>0.000</td>
</tr>
<tr class="odd">
<td>standard blue</td>
<td>0.000</td>
<td>0.000</td>
<td>1.000</td>
</tr>
<tr class="even">
<td>standard white</td>
<td>0.334</td>
<td>0.334</td>
<td>0.332</td>
</tr>
<tr class="odd">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled" title="Technically">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Technically
</div>
</div>
<div class="callout-body-container callout-body">
<p>Technically, the CIE 1931 color of a spectrum <span class="math inline">\(I\)</span> is a point in <span class="math inline">\(\R^3\)</span> defined by</p>
<p><span class="math display">\[
C_{\text{CIE 1931}}(I) := \left(\int I(\lambda) \bar r(\lambda) d\lambda , \int I(\lambda) \bar g(\lambda) d\lambda , \int I(\lambda) \bar b(\lambda) d\lambda \right)
\]</span></p>
<p>where <span class="math inline">\(\bar r, \bar g, \bar b\)</span> are “standard observer color matching functions”. They are not any real observer’s sensitivities, because they have negative values. Note that this means the CIE 1931 coordinates of standard red is not <span class="math inline">\((1, 0, 0)\)</span>.</p>
<p>Of course, the two definitions had better agree. This they tried to do so, using the spectroscopy of the time.</p>
</div>
</div>
</section>
<section id="riemannian-geometry" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="riemannian-geometry">Riemannian geometry</h3>
<blockquote class="blockquote">
<p>Magnitude-notions are only possible where there is an antecedent general notion which admits of different specialisations… the only simple notions whose specialisations form a multiply extended manifoldness are the positions of perceived objects and colours. More frequent occasions for the creation and development of these notions occur first in the higher mathematic.</p>
<p>Riemann’s Habilitation dissertation, 1854 <span class="citation" data-cites="riemannHypothesesWhichLie2016">(<a href="#ref-riemannHypothesesWhichLie2016" role="doc-biblioref">Riemann 2016</a>)</span></p>
</blockquote>
<p>The <a href="https://en.wikipedia.org/wiki/MacAdam_ellipse">MacAdam ellipses</a> …</p>
<p>… of course, since color space is 3D, we really should be concerned with MacAdam <em>ellipsoids</em>. However, those are hard to map and hard to plot.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/CIExy1931_MacAdam.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">MacAdam ellipses the CIE 1931 <span class="math inline">\(xy\)</span>-diagram, 10× actual size. Figure from <a href="https://commons.wikimedia.org/wiki/File:CIExy1931_MacAdam.png">Wikimedia Commons</a>.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Fonseca_2016_fig_8b.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption"><span class="citation" data-cites="dafonsecaDerivationHumanChromatic2016">(<a href="#ref-dafonsecaDerivationHumanChromatic2016" role="doc-biblioref">da Fonseca and Samengo 2016, fig. 8b</a>)</span></figcaption>
</figure>
</div>
<p>From the <span class="math inline">\(S_S, S_M, S_L\)</span> curves, we can use information theory to predict the JND in color space.</p>
<p>CIELAB color space is a smooth mapping from CIE 1931 color space to <span class="math inline">\(\R^3\)</span>, such that the MacAdam ellipses are stretched roughly spherical, meaning the metric is mostly Euclidean. This is impossible to do perfectly, as color space is curved, in the same sense that a space containing a black hole is curved. However, since color space is not too curved, the CIELAB color space can be treated as Euclidean in practice.</p>
<p><span class="citation" data-cites="dafonsecaDerivationHumanChromatic2016">(<a href="#ref-dafonsecaDerivationHumanChromatic2016" role="doc-biblioref">da Fonseca and Samengo 2016</a>)</span> explain ~87% of the variance of human color discrimination ability</p>
<p>Imagine a hiker navigating a mountain path equipped only with an altimeter and a detailed altitude map. The hiker’s ability to pinpoint their location on the map relies on sensing altitude changes. In regions where the terrain is steep (representing high sensitivity), even a small step forward (change in stimulus intensity) will register a noticeable altitude change on the altimeter (change in perceived sensation). This allows for precise localization – a small JND. However, along flatter sections of the trail (low sensitivity), the hiker might need to traverse a longer distance to observe a meaningful altitude difference, leading to a larger JND and greater uncertainty about their position on the map.</p>
<p>If the phenomenology of color is but the metric geometry of color space, then we have not only dispelled the inverted qualia problem, but also have dispelled the problem of other minds. We should be able to construct the phenomenal geometry of color from retinal measurements. By comparing my retina and your retina, we can objectively determine whether my green is the same as yours.</p>
<p>If the inverted qualia problem is dissolved by the hole argument, then the hard problem of color perception is gone as well. What remains is merely determining the metric of color space. In this way, the biophysics of the eye-brain system would mostly solve the easy problem of color perception.</p>
<p>Note that, while color space is locally Riemannian, this is not so over longer distances. That is, once we are measuring the subjective distances between pairs of far-different colors, the data no longer behave like distances on a curved 3D space. <span class="citation" data-cites="bujackNonRiemannianNaturePerceptual2022">(<a href="#ref-bujackNonRiemannianNaturePerceptual2022" role="doc-biblioref">Bujack et al. 2022</a>)</span> reported that there is “diminishing returns” in color distances.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;According to CIE, the color difference <span class="math inline">\(\Delta E\)</span>, is <a href="https://en.wikipedia.org/wiki/Color_difference#CIELAB_%CE%94E*">not symmetric</a>, meaning that if we ask a subject “How far is color 1 from color 2?” and then ask the opposite direction, we usually get a different answer. This reminds me of <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a>. I don’t know if anyone has studied this in detail, but it ought to interest the <a href="https://en.wikipedia.org/wiki/Information_geometry">information geometers</a>.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">All visible colors, plotted in CIELAB color space. Figure from <a href="https://commons.wikimedia.org/wiki/File:Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png">Wikimedia Commons</a></figcaption>
</figure>
</div>
</section>
</section>
<section id="inverted-qualia" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="inverted-qualia">Inverted qualia</h2>
<p><span class="citation" data-cites="byrneInvertedQualia2004">(<a href="#ref-byrneInvertedQualia2004" role="doc-biblioref">Byrne 2004</a>)</span></p>
<p>The inverted qualia thought experiment has been used, like the philosophical zombie, in a whole host of arguments. Let’s deal with functionalism, which seems rather urgent these days, what with the advent of AI and all.</p>
<p>Argument against functionalism</p>
<p>The following spectrum inversion scenario is possible: Invert and Nonvert are functionally alike, and are both looking at a tomato.</p>
<p>Thus, the mental does not supervene on functional organization.</p>
<p>Thus, functionalism is false.</p>
<p>According to functionalism, mental states are functional states: states defined by their causal role with respect to inputs, outputs, and other states. So, according to functionalism, necessarily, two creatures who are functionally alike are also mentally alike.</p>
<section id="precursors-to-the-inverted-qualia-problem" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="precursors-to-the-inverted-qualia-problem">Precursors to the inverted qualia problem</h3>
<p><span class="citation" data-cites="eastwoodAlhazenLeonardoLatemedieval1986">(<a href="#ref-eastwoodAlhazenLeonardoLatemedieval1986" role="doc-biblioref">Eastwood 1986</a>)</span></p>
<p>Alhazen had considered the theory that the eye works like a camera obscura, and he had pronounced it impossible, as it would create an inverted image. Similarly, da Vinci developed no less than 8 different hypothetical mechanisms inside the eye to invert the image again, so that the image would land on the retina right-side-up.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/1490-95_da_vinci_-_codex_atlanticus.jpg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Leonardo da Vinci’s drawings comparing the eye to a camera obscura. From <em>Codex Atlanticus</em> (1490-1495). Figure from <a href="https://commons.wikimedia.org/wiki/File:1490-95_da_vinci_-_codex_atlanticus.jpg">Wikimedia Commons</a>.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>… certain extravagant situations are to be avoided, as they would create ‘monstrosities’, or disfigurations. The concern about hypothetical monstrous results occurs at four points in the description. (1) If the refracting surface of the vitreous were not completely regular and spherical, a monstrous visual form would appear, (2) If the refracting surface of the vitreous were the surface of a small sphere, causing the intersection of rays before even reaching the centre of curvature of the cornea and the anterior glacial surface, once again there could occur a monstrous visual form. Presumably the disfiguration anticipated here by Alhazen is simply the inverted image after intersection, but he does not say.</p>
</blockquote>
</section>
</section>
<section id="problem-of-consciousness" class="level2">
<h2 class="anchored" data-anchor-id="problem-of-consciousness">Problem of consciousness</h2>
<p><span class="citation" data-cites="metzingerBeingNoOne2004 rodenPosthumanLifePhilosophy2015">(<a href="#ref-metzingerBeingNoOne2004" role="doc-biblioref">Metzinger 2004</a>, chapter TODO; <a href="#ref-rodenPosthumanLifePhilosophy2015" role="doc-biblioref">Roden 2015, chap. 4</a>)</span></p>
<p>The just noticeable difference (JND) in color perception possibly shows that we see metric, not colors themselves.</p>
<p>So what do those color words do? They might be special “landmarks” in the geometry of color space, much like on a map, the peaks and troughs are local maxima of curvature, and the mountain passes are local minima of curvature <span class="citation" data-cites="griffinCategoricalColourGeometry2019">(<a href="#ref-griffinCategoricalColourGeometry2019" role="doc-biblioref">Griffin and Mylonas 2019</a>)</span>.</p>
<p>The meta-problem of consciousness <span class="citation" data-cites="chalmersMetaproblemConsciousness2018">(<a href="#ref-chalmersMetaproblemConsciousness2018" role="doc-biblioref">Chalmers 2018</a>)</span> is TODO</p>
<p>The inverted polarization spectrum for mantis shrimps. Why would they be confused?</p>
<p><span class="citation" data-cites="kleinlogelSecretWorldShrimps2008">(<a href="#ref-kleinlogelSecretWorldShrimps2008" role="doc-biblioref">Kleinlogel and White 2008</a>)</span></p>
<p>The mantis shrimp species <em>Gonodactylus smithii</em> can detect polarization of light over the entire 3-dimensional Poincare sphere. It performs this by building 3 kinds of ommatidia, each specialized for two kinds of polarization. One is specialized for the horizontal-vertical, one for the diagonal-antidiagonal, and one for the clockwise-anticlockwise.</p>
<p>Now, a Gonodactylus philosopher might propose the following inverted qualia problem: What if my qualia on the Poincare sphere is inverted compared to yours? When you see a horizontally polarized light, you feel the same way as I see a vertically polarized light, etc.</p>
</section>
<section id="the-meta-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-meta-problem">The meta-problem</h2>
<p>We have Type 1 and Type 2 cognitive processes for judging if something is conscious.</p>
<p>Type 1 processes</p>
<p><span class="citation" data-cites="fialaPsychologicalOriginsDualism2012">(<a href="#ref-fialaPsychologicalOriginsDualism2012" role="doc-biblioref">Fiala, Arico, and Nichols 2012</a>)</span></p>
<p>fast, domain-specific, automatic (the authors don’t argue if they are also associative)</p>
<p>Three apparent features reliably produce AGENT categorization:</p>
<p>has eye-like shapes on a head-like bump;</p>
<p>reacts to the environment unpredictably;</p>
<p>moves on its own, not a slave to mere inertia.</p>
<p>Confirmed by judgment-speed experiments</p>
<blockquote class="blockquote">
<p>… presented subjects with a sequence of Object/Attribution pairs (e.g., ant/feels pain), and the subjects were asked to respond as quickly as possible (Yes or No) whether the object had the attribute… Participants responded significantly more slowly when they denied conscious states to objects that do have the superficial AGENCY cues, namely, insects. This result is neatly explained by our hypothesis that insects automatically activate the low road to consciousness attribution; in order to deny that insects have conscious states, subjects had to “override” the low-road output, which explains why reaction times are slower in such cases.</p>
</blockquote>
<p>Type 2 processes</p>
<p>rational deliberation, theory application, or conscious reasoning</p>
<p>Any brain-based physical theory of consciousness can at most convince Type 2 process, not the Type 1 process.</p>
<p>The brain doesn’t have eyes</p>
<p>The brain seems to do nothing by itself, stewing alone in a dark cave;</p>
<p>The brain doesn’t display any motion, let alone non-inertial motion.</p>
<blockquote class="blockquote">
<p>Since the two systems generate the same answer in typical cases, there is typically no resistance to the idea that other people are conscious. However, when we consider the mass of grey matter that composes the human brain (and on which the majority of physicalist reductions of consciousness will focus), the result is altogether different.</p>
</blockquote>
<blockquote class="blockquote">
<p>Jenny might believe that consciousness is identical to populations of neurons firing in synchrony at a rate between 40Hz and 60Hz; on this basis she could infer (using the high road) that specific brain regions that are firing synchronously are conscious experiences. (Crick &amp; Koch, 1990). If Jenny knew that Jimmy’s brain had regions that were firing synchronously between 40-60Hz, she could infer (using the high road) that Jimmy’s brain states are conscious experiences. But since this description of Jimmy’s brain does not advert to any of the featural cues that trigger AGENCY categorization, Jenny’s low road is not activated, and thus remains silent on whether the synchronously firing neurons are conscious</p>
</blockquote>
<p>Alternative physicalist theory of consciousness designed to satisfy Type 1 process won’t satisfy Type 2 process.</p>
<p>The eyes are clearly unnecessary, as even eyeless people (Anophthalmia) can be conscious.</p>
<p>And lock-in syndrome people don’t interact and don’t display noninertial motions.</p>
<p>Evolutionary origin of the dual process</p>
<p>Only very recently is it possible to see neurons firing. So for millions of years, humans could have only inferred consciousness through external features, such as eye motion, non-inertial motion, etc.</p>
<p>Thus arose Type 1 process for detecting consciousness, which is incompatible with modern neuroscience.</p>
<p>The Type 2 process is a general process for understanding abstract theories, not for consciousness specifically.</p>
<p>(Non-)Analogies</p>
<p>The authors thought that there is no Type 1 intuition for general relativity, so there’s no explanatory gap there. But I beg to differ.</p>
<p>General Relativity is acceptable to Type 2 processes, but not to Type 1 processes, which has an intuitive understanding of the world as having Newtonian spacetime. Consequently, there is a persistent “explanatory gap”, as a nagging feeling “but how do we know which one is the <em>real</em> spacetime manifold? The theory is incomplete because it doesn’t tell us that.”.</p>
<p>This is probably what made the hole argument so perplexing even to Einstein. The hole argument appeals to the Type 1 intuition that there’s a unique spacetime structure.</p>
<p>As another example, Bergson famously debated Einstein over the nature of time.</p>
<p>Intentionality explanatory gap.</p>
<p>Some philosophers did propose an explanatory gap.</p>
<p>Although most people seem to have no difficulty granting intentionality to computers and other things they regard as unconscious.</p>
<p>This would be explainable if the Type 1 process for intentionality-attribution happens to fit well with modern physics.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bujackNonRiemannianNaturePerceptual2022" class="csl-entry" role="listitem">
Bujack, Roxana, Emily Teti, Jonah Miller, Elektra Caffrey, and Terece L. Turton. 2022. <span>“The Non-<span>Riemannian</span> Nature of Perceptual Color Space.”</span> <em>Proceedings of the National Academy of Sciences</em> 119 (18): e2119753119. <a href="https://doi.org/10.1073/pnas.2119753119">https://doi.org/10.1073/pnas.2119753119</a>.
</div>
<div id="ref-byrneInvertedQualia2004" class="csl-entry" role="listitem">
Byrne, Alex. 2004. <span>“Inverted Qualia.”</span>
</div>
<div id="ref-chalmersMetaproblemConsciousness2018" class="csl-entry" role="listitem">
Chalmers, David. 2018. <span>“The Meta-Problem of Consciousness.”</span>
</div>
<div id="ref-clarkeCollectionPapersWhich1717" class="csl-entry" role="listitem">
Clarke, Samuel. 1717. <em>A <span>Collection</span> of <span>Papers</span>, <span>Which</span> Passed Between the Late <span>Learned Mr</span>. <span>Leibnitz</span>, and <span>Dr</span>. <span>Clarke</span>, <span>In</span> the <span>Years</span> 1715 and 1716</em>. Vol. 1. James Knapton, at the Crown in St. Paul’s Church-Yard.
</div>
<div id="ref-dafonsecaDerivationHumanChromatic2016" class="csl-entry" role="listitem">
da Fonseca, María, and Inés Samengo. 2016. <span>“Derivation of Human Chromatic Discrimination Ability from an Information-Theoretical Notion of Distance in Color Space.”</span> <em>Neural Computation</em> 28 (12): 2628–55.
</div>
<div id="ref-eastwoodAlhazenLeonardoLatemedieval1986" class="csl-entry" role="listitem">
Eastwood, Bruce. 1986. <span>“Alhazen, <span>Leonardo</span>, and Late-Medieval Speculation on the Inversion of Images in the Eye.”</span> <em>Annals of Science</em> 43 (5): 413–46. <a href="https://doi.org/10.1080/00033798600200311">https://doi.org/10.1080/00033798600200311</a>.
</div>
<div id="ref-fialaPsychologicalOriginsDualism2012" class="csl-entry" role="listitem">
Fiala, Brian, Adam Arico, and Shaun Nichols. 2012. <span>“On the Psychological Origins of Dualism: <span class="nocase">Dual-process</span> Cognition and the Explanatory Gap.”</span> <em>Creating Consilience: Integrating the Sciences and the Humanities</em>, 88–110.
</div>
<div id="ref-griffinCategoricalColourGeometry2019" class="csl-entry" role="listitem">
Griffin, Lewis D., and Dimitris Mylonas. 2019. <span>“Categorical Colour Geometry.”</span> <em>PloS One</em> 14 (5): e0216296.
</div>
<div id="ref-hatfieldSenseData2021" class="csl-entry" role="listitem">
Hatfield, Gary. 2021. <span>“Sense <span>Data</span>.”</span> In <em>The <span>Stanford Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N. Zalta, Fall 2021. Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-kleinlogelSecretWorldShrimps2008" class="csl-entry" role="listitem">
Kleinlogel, Sonja, and Andrew G. White. 2008. <span>“The Secret World of Shrimps: Polarisation Vision at Its Best.”</span> <em>PLoS One</em> 3 (5): e2190.
</div>
<div id="ref-logvinenkoGeometricStructureColor2015" class="csl-entry" role="listitem">
Logvinenko, Alexander D. 2015. <span>“The Geometric Structure of Color.”</span> <em>Journal of Vision</em> 15 (1): 16–16.
</div>
<div id="ref-metzingerBeingNoOne2004" class="csl-entry" role="listitem">
Metzinger, Thomas. 2004. <em>Being No One: The Self-Model Theory of Subjectivity</em>. 1. paperback ed. A <span>Bradford</span> Book. Cambridge, Mass.: MIT Press.
</div>
<div id="ref-NeuronFiringRates2015" class="csl-entry" role="listitem">
<span>“Neuron Firing Rates in Humans.”</span> 2015. <em>AI Impacts</em>. https://aiimpacts.org/rate-of-neuron-firing/.
</div>
<div id="ref-nortonHoleArgument1999" class="csl-entry" role="listitem">
Norton, John D., Oliver Pooley, and James Read. 1999. <span>“The <span>Hole Argument</span>,”</span> February.
</div>
<div id="ref-riemannHypothesesWhichLie2016" class="csl-entry" role="listitem">
Riemann, Bernhard. 2016. <em>On the <span>Hypotheses Which Lie</span> at the <span>Bases</span> of <span>Geometry</span></em>. Edited by Jürgen Jost. 1st ed. 2016. Classic <span>Texts</span> in the <span>Sciences</span>. Cham: Springer International Publishing : Imprint: Birkh<span>ä</span>user. <a href="https://doi.org/10.1007/978-3-319-26042-6">https://doi.org/10.1007/978-3-319-26042-6</a>.
</div>
<div id="ref-rodenPosthumanLifePhilosophy2015" class="csl-entry" role="listitem">
Roden, David. 2015. <em>Posthuman Life: Philosophy at the Edge of the Human</em>. London: Routledge.
</div>
<div id="ref-schrodingerGrundlinienTheorieFarbenmetrik1920" class="csl-entry" role="listitem">
Schrödinger, Erwin. 1920. <span>“Grundlinien Einer Theorie Der Farbenmetrik Im Tagessehen.”</span> <em>Annalen Der Physik</em> 368 (21): 427–56.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/yuxi-liu-wired\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Everything ©<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache License 2.0</a></span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>
    <div class="nav-footer-right">
<p><span class="faux-block"><a href="../../../sitemap.xml">sitemap</a></span></p>
</div>
  </div>
</footer>




</body></html>